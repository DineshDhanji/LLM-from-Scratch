{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a892bafd",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7726dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.5.1+cu121\n",
      "tensorflow version: could not be determined\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "from model import *\n",
    "from utils import *\n",
    "import importlib.metadata\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    \"tensorflow\",\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    try:\n",
    "        print(f\"{p} version: {importlib.metadata.version(p)}\")\n",
    "    except importlib.metadata.PackageNotFoundError:\n",
    "        try:\n",
    "            mod = importlib.import_module(p)\n",
    "            print(f\"{p} version (from __version__): {mod.__version__}\")\n",
    "        except Exception:\n",
    "            print(f\"{p} version: could not be determined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176892b",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c88f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"drop_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f69509c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval() # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72a08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: Every effort moves you rentingetic wasnم refres RexMeCHicular stren.\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Before trainin, we are just testing the model with a few tokens\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(f\"Output text: {token_ids_to_text(token_ids, tokenizer)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce61857",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a64b3",
   "metadata": {},
   "source": [
    "#### Dummy Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import urllib.request\n",
    "\n",
    "# file_path = \"the-verdict.txt\"\n",
    "# url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         text_data = response.read().decode(\"utf-8\")\n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#         file.write(text_data)\n",
    "# else:\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         text_data = file.read()\n",
    "# # First 100 characters\n",
    "# print(text_data[:99])\n",
    "\n",
    "# total_characters = len(text_data)\n",
    "# total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "# print(\"Characters:\", total_characters)\n",
    "# print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff27256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train/validation ratio\n",
    "# train_ratio = 0.90\n",
    "# split_idx = int(train_ratio * len(text_data))\n",
    "# train_data = text_data[:split_idx]\n",
    "# val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# train_loader = create_dataloader_v1(\n",
    "#     train_data,\n",
    "#     batch_size=2,\n",
    "#     max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "#     stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "#     drop_last=True,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0,\n",
    "# )\n",
    "\n",
    "# val_loader = create_dataloader_v1(\n",
    "#     val_data,\n",
    "#     batch_size=2,\n",
    "#     max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "#     stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "#     drop_last=False,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbdcd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check\n",
    "\n",
    "# if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "#     print(\"Not enough tokens for the training loader. \"\n",
    "#           \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "#           \"increase the `training_ratio`\")\n",
    "\n",
    "# if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "#     print(\"Not enough tokens for the validation loader. \"\n",
    "#           \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "#           \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965172eb",
   "metadata": {},
   "source": [
    "#### Actual Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96305ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = \"roneneldan/TinyStories\"\n",
    "DATASET_DIR = \"./dataset/\"\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, cache_dir=DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92e72470",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [_[\"text\"] for _ in dataset[\"train\"]]\n",
    "val_data = [_[\"text\"] for _ in dataset[\"validation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a935c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v2(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v2(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9415a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5402bed",
   "metadata": {},
   "source": [
    "### Training the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09038603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8998eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():  # Only for Apple Silicon (Mac)\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ae11760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "993a12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path, device):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(f\"[Checkpoint Loaded] Epoch: {checkpoint['epoch']}, Step: {checkpoint['step']}\")\n",
    "        return checkpoint['epoch'] + 1, checkpoint['step'], checkpoint['tokens_seen'], checkpoint['best_val_loss']\n",
    "    else:\n",
    "        return 0, -1, 0, float('inf')  # Start fresh\n",
    "\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "    checkpoint_path=\"checkpoint.pt\",\n",
    "    best_model_path=\"best_model.pt\"\n",
    "):\n",
    "    # Load checkpoint if exists\n",
    "    start_epoch, global_step, tokens_seen, best_val_loss = load_checkpoint(model, optimizer, checkpoint_path, device)\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            model.train()\n",
    "            loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "            for input_batch, target_batch in loop:\n",
    "                optimizer.zero_grad()\n",
    "                loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                tokens_seen += input_batch.numel()\n",
    "                global_step += 1\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "\n",
    "                # Optional mid-training eval (rare for large models)\n",
    "                if global_step % eval_freq == 0:\n",
    "                    train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                    train_losses.append(train_loss)\n",
    "                    val_losses.append(val_loss)\n",
    "                    track_tokens_seen.append(tokens_seen)\n",
    "                    print(f\"[Step {global_step}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Epoch-end evaluation\n",
    "            train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            track_tokens_seen.append(tokens_seen)\n",
    "\n",
    "            print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"[Saved New Best Model @ Epoch {epoch+1}]\")\n",
    "\n",
    "            # Save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'step': global_step,\n",
    "                'tokens_seen': tokens_seen,\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "\n",
    "            # Show generated sample\n",
    "            generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[Training Interrupted] Saving checkpoint...\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'step': global_step,\n",
    "            'tokens_seen': tokens_seen,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "        print(\"[Checkpoint Saved Successfully]\")\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3563e425",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Set seed\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize model, move to device\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m GPTModel(GPT_CONFIG_124M)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# ========== Execution Start ==========\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Initialize model, move to device\n",
    "model = GPTModel(GPT_CONFIG_124M).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "# Run training (resumable + interrupt-safe)\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=1,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# ========== Execution End ==========\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de70a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.532, Val loss 9.460\n",
      "Ep 1 (Step 000005): Train loss 7.736, Val loss 7.743\n",
      "Ep 1 (Step 000010): Train loss 6.890, Val loss 6.603\n",
      "Ep 1 (Step 000015): Train loss 6.298, Val loss 6.163\n",
      "Ep 1 (Step 000020): Train loss 6.397, Val loss 5.862\n",
      "Ep 1 (Step 000025): Train loss 5.600, Val loss 5.745\n",
      "Ep 1 (Step 000030): Train loss 5.546, Val loss 5.646\n",
      "Ep 1 (Step 000035): Train loss 5.721, Val loss 5.502\n",
      "Ep 1 (Step 000040): Train loss 5.722, Val loss 5.412\n",
      "Ep 1 (Step 000045): Train loss 5.351, Val loss 5.303\n",
      "Ep 1 (Step 000050): Train loss 5.374, Val loss 5.177\n",
      "Ep 1 (Step 000055): Train loss 5.120, Val loss 5.132\n",
      "Ep 1 (Step 000060): Train loss 5.513, Val loss 5.053\n",
      "Ep 1 (Step 000065): Train loss 5.042, Val loss 4.998\n",
      "Ep 1 (Step 000070): Train loss 5.122, Val loss 4.968\n",
      "Ep 1 (Step 000075): Train loss 4.812, Val loss 4.927\n",
      "Ep 1 (Step 000080): Train loss 4.758, Val loss 4.881\n",
      "Ep 1 (Step 000085): Train loss 4.687, Val loss 4.813\n",
      "Ep 1 (Step 000090): Train loss 4.915, Val loss 4.810\n",
      "Ep 1 (Step 000095): Train loss 4.964, Val loss 4.756\n",
      "Ep 1 (Step 000100): Train loss 4.825, Val loss 4.762\n",
      "Ep 1 (Step 000105): Train loss 4.643, Val loss 4.708\n",
      "Ep 1 (Step 000110): Train loss 4.812, Val loss 4.743\n",
      "Ep 1 (Step 000115): Train loss 4.959, Val loss 4.712\n",
      "Ep 1 (Step 000120): Train loss 5.094, Val loss 4.740\n",
      "Ep 1 (Step 000125): Train loss 4.433, Val loss 4.713\n",
      "Ep 1 (Step 000130): Train loss 4.576, Val loss 4.638\n",
      "Ep 1 (Step 000135): Train loss 4.857, Val loss 4.619\n",
      "Ep 1 (Step 000140): Train loss 4.471, Val loss 4.623\n",
      "Ep 1 (Step 000145): Train loss 4.425, Val loss 4.613\n",
      "Ep 1 (Step 000150): Train loss 4.540, Val loss 4.568\n",
      "Ep 1 (Step 000155): Train loss 4.502, Val loss 4.592\n",
      "Ep 1 (Step 000160): Train loss 4.418, Val loss 4.597\n",
      "Ep 1 (Step 000165): Train loss 4.186, Val loss 4.561\n",
      "Ep 1 (Step 000170): Train loss 4.465, Val loss 4.517\n",
      "Ep 1 (Step 000175): Train loss 4.595, Val loss 4.530\n",
      "Ep 1 (Step 000180): Train loss 4.168, Val loss 4.468\n",
      "Ep 1 (Step 000185): Train loss 4.337, Val loss 4.473\n",
      "Ep 1 (Step 000190): Train loss 4.532, Val loss 4.467\n",
      "Ep 1 (Step 000195): Train loss 4.221, Val loss 4.471\n",
      "Ep 1 (Step 000200): Train loss 4.448, Val loss 4.482\n",
      "Ep 1 (Step 000205): Train loss 4.483, Val loss 4.448\n",
      "Ep 1 (Step 000210): Train loss 4.224, Val loss 4.432\n",
      "Ep 1 (Step 000215): Train loss 4.347, Val loss 4.381\n",
      "Ep 1 (Step 000220): Train loss 4.440, Val loss 4.377\n",
      "Ep 1 (Step 000225): Train loss 4.297, Val loss 4.364\n",
      "Ep 1 (Step 000230): Train loss 4.460, Val loss 4.430\n",
      "Ep 1 (Step 000235): Train loss 4.412, Val loss 4.392\n",
      "Ep 1 (Step 000240): Train loss 4.285, Val loss 4.401\n",
      "Ep 1 (Step 000245): Train loss 4.421, Val loss 4.415\n",
      "Ep 1 (Step 000250): Train loss 4.143, Val loss 4.376\n",
      "Ep 1 (Step 000255): Train loss 4.209, Val loss 4.348\n",
      "Ep 1 (Step 000260): Train loss 3.901, Val loss 4.352\n",
      "Ep 1 (Step 000265): Train loss 4.427, Val loss 4.334\n",
      "Ep 1 (Step 000270): Train loss 4.171, Val loss 4.328\n",
      "Ep 1 (Step 000275): Train loss 4.190, Val loss 4.326\n",
      "Ep 1 (Step 000280): Train loss 4.336, Val loss 4.371\n",
      "Ep 1 (Step 000285): Train loss 4.154, Val loss 4.371\n",
      "Ep 1 (Step 000290): Train loss 4.494, Val loss 4.391\n",
      "Ep 1 (Step 000295): Train loss 4.220, Val loss 4.325\n",
      "Ep 1 (Step 000300): Train loss 4.447, Val loss 4.284\n",
      "Ep 1 (Step 000305): Train loss 3.978, Val loss 4.286\n",
      "Ep 1 (Step 000310): Train loss 4.078, Val loss 4.233\n",
      "Ep 1 (Step 000315): Train loss 4.430, Val loss 4.263\n",
      "Ep 1 (Step 000320): Train loss 4.058, Val loss 4.265\n",
      "Ep 1 (Step 000325): Train loss 4.084, Val loss 4.253\n",
      "Ep 1 (Step 000330): Train loss 4.232, Val loss 4.242\n",
      "Ep 1 (Step 000335): Train loss 4.008, Val loss 4.221\n",
      "Ep 1 (Step 000340): Train loss 4.153, Val loss 4.219\n",
      "Ep 1 (Step 000345): Train loss 4.241, Val loss 4.236\n",
      "Ep 1 (Step 000350): Train loss 4.156, Val loss 4.246\n",
      "Ep 1 (Step 000355): Train loss 4.066, Val loss 4.237\n",
      "Ep 1 (Step 000360): Train loss 4.068, Val loss 4.223\n",
      "Ep 1 (Step 000365): Train loss 3.928, Val loss 4.244\n",
      "Ep 1 (Step 000370): Train loss 4.000, Val loss 4.226\n",
      "Ep 1 (Step 000375): Train loss 4.099, Val loss 4.200\n",
      "Ep 1 (Step 000380): Train loss 4.036, Val loss 4.197\n",
      "Ep 1 (Step 000385): Train loss 4.110, Val loss 4.208\n",
      "Ep 1 (Step 000390): Train loss 4.138, Val loss 4.177\n",
      "Ep 1 (Step 000395): Train loss 4.350, Val loss 4.153\n",
      "Ep 1 (Step 000400): Train loss 4.067, Val loss 4.185\n",
      "Ep 1 (Step 000405): Train loss 3.965, Val loss 4.188\n",
      "Ep 1 (Step 000410): Train loss 4.034, Val loss 4.207\n",
      "Ep 1 (Step 000415): Train loss 3.955, Val loss 4.210\n",
      "Ep 1 (Step 000420): Train loss 4.180, Val loss 4.219\n",
      "Ep 1 (Step 000425): Train loss 4.040, Val loss 4.186\n",
      "Ep 1 (Step 000430): Train loss 4.009, Val loss 4.198\n",
      "Ep 1 (Step 000435): Train loss 4.138, Val loss 4.162\n",
      "Ep 1 (Step 000440): Train loss 3.858, Val loss 4.148\n",
      "Ep 1 (Step 000445): Train loss 4.146, Val loss 4.116\n",
      "Ep 1 (Step 000450): Train loss 3.929, Val loss 4.134\n",
      "Ep 1 (Step 000455): Train loss 4.108, Val loss 4.136\n",
      "Ep 1 (Step 000460): Train loss 4.313, Val loss 4.092\n",
      "Ep 1 (Step 000465): Train loss 4.252, Val loss 4.099\n",
      "Ep 1 (Step 000470): Train loss 3.856, Val loss 4.124\n",
      "Ep 1 (Step 000475): Train loss 4.059, Val loss 4.122\n",
      "Ep 1 (Step 000480): Train loss 3.871, Val loss 4.109\n",
      "Ep 1 (Step 000485): Train loss 4.110, Val loss 4.053\n",
      "Ep 1 (Step 000490): Train loss 4.266, Val loss 4.094\n",
      "Ep 1 (Step 000495): Train loss 4.020, Val loss 4.067\n",
      "Ep 1 (Step 000500): Train loss 4.040, Val loss 4.063\n",
      "Ep 1 (Step 000505): Train loss 3.996, Val loss 4.071\n",
      "Ep 1 (Step 000510): Train loss 3.935, Val loss 4.056\n",
      "Ep 1 (Step 000515): Train loss 4.059, Val loss 4.097\n",
      "Ep 1 (Step 000520): Train loss 3.817, Val loss 4.077\n",
      "Ep 1 (Step 000525): Train loss 3.832, Val loss 4.074\n",
      "Ep 1 (Step 000530): Train loss 4.026, Val loss 4.056\n",
      "Ep 1 (Step 000535): Train loss 4.124, Val loss 4.087\n",
      "Ep 1 (Step 000540): Train loss 3.918, Val loss 4.082\n",
      "Ep 1 (Step 000545): Train loss 4.077, Val loss 4.070\n",
      "Ep 1 (Step 000550): Train loss 3.886, Val loss 4.045\n",
      "Ep 1 (Step 000555): Train loss 3.977, Val loss 4.068\n",
      "Ep 1 (Step 000560): Train loss 3.987, Val loss 4.073\n",
      "Ep 1 (Step 000565): Train loss 4.009, Val loss 4.058\n",
      "Ep 1 (Step 000570): Train loss 3.860, Val loss 4.013\n",
      "Ep 1 (Step 000575): Train loss 3.913, Val loss 3.967\n",
      "Ep 1 (Step 000580): Train loss 3.668, Val loss 3.948\n",
      "Ep 1 (Step 000585): Train loss 3.818, Val loss 3.973\n",
      "Ep 1 (Step 000590): Train loss 4.158, Val loss 3.954\n",
      "Ep 1 (Step 000595): Train loss 3.706, Val loss 3.947\n",
      "Ep 1 (Step 000600): Train loss 3.591, Val loss 3.953\n",
      "Ep 1 (Step 000605): Train loss 4.087, Val loss 3.968\n",
      "Ep 1 (Step 000610): Train loss 3.714, Val loss 3.956\n",
      "Ep 1 (Step 000615): Train loss 4.043, Val loss 3.954\n",
      "Ep 1 (Step 000620): Train loss 3.929, Val loss 3.980\n",
      "Ep 1 (Step 000625): Train loss 3.887, Val loss 3.962\n",
      "Ep 1 (Step 000630): Train loss 3.916, Val loss 3.967\n",
      "Ep 1 (Step 000635): Train loss 4.054, Val loss 3.935\n",
      "Ep 1 (Step 000640): Train loss 3.819, Val loss 3.935\n",
      "Ep 1 (Step 000645): Train loss 3.836, Val loss 3.945\n",
      "Ep 1 (Step 000650): Train loss 3.947, Val loss 3.943\n",
      "Ep 1 (Step 000655): Train loss 3.889, Val loss 3.957\n",
      "Ep 1 (Step 000660): Train loss 3.892, Val loss 3.981\n",
      "Ep 1 (Step 000665): Train loss 3.720, Val loss 3.939\n",
      "Ep 1 (Step 000670): Train loss 3.840, Val loss 3.904\n",
      "Ep 1 (Step 000675): Train loss 3.500, Val loss 3.932\n",
      "Ep 1 (Step 000680): Train loss 3.524, Val loss 3.926\n",
      "Ep 1 (Step 000685): Train loss 3.931, Val loss 3.912\n",
      "Ep 1 (Step 000690): Train loss 3.938, Val loss 3.900\n",
      "Ep 1 (Step 000695): Train loss 4.008, Val loss 3.902\n",
      "Ep 1 (Step 000700): Train loss 3.733, Val loss 3.907\n",
      "Ep 1 (Step 000705): Train loss 3.546, Val loss 3.915\n",
      "Ep 1 (Step 000710): Train loss 4.026, Val loss 3.905\n",
      "Ep 1 (Step 000715): Train loss 4.086, Val loss 3.879\n",
      "Ep 1 (Step 000720): Train loss 3.768, Val loss 3.882\n",
      "Ep 1 (Step 000725): Train loss 3.813, Val loss 3.917\n",
      "Ep 1 (Step 000730): Train loss 3.701, Val loss 3.918\n",
      "Ep 1 (Step 000735): Train loss 3.960, Val loss 3.928\n",
      "Ep 1 (Step 000740): Train loss 4.376, Val loss 3.936\n",
      "Ep 1 (Step 000745): Train loss 3.881, Val loss 3.978\n",
      "Ep 1 (Step 000750): Train loss 3.822, Val loss 3.969\n",
      "Ep 1 (Step 000755): Train loss 3.688, Val loss 3.936\n",
      "Ep 1 (Step 000760): Train loss 4.452, Val loss 3.917\n",
      "Ep 1 (Step 000765): Train loss 3.827, Val loss 3.913\n",
      "Ep 1 (Step 000770): Train loss 3.887, Val loss 3.923\n",
      "Ep 1 (Step 000775): Train loss 3.701, Val loss 3.914\n",
      "Ep 1 (Step 000780): Train loss 4.139, Val loss 3.908\n",
      "Ep 1 (Step 000785): Train loss 3.939, Val loss 3.933\n",
      "Ep 1 (Step 000790): Train loss 3.791, Val loss 3.919\n",
      "Ep 1 (Step 000795): Train loss 3.857, Val loss 3.931\n",
      "Ep 1 (Step 000800): Train loss 3.636, Val loss 3.885\n",
      "Ep 1 (Step 000805): Train loss 3.562, Val loss 3.887\n",
      "Ep 1 (Step 000810): Train loss 3.876, Val loss 3.875\n",
      "Ep 1 (Step 000815): Train loss 3.732, Val loss 3.876\n",
      "Ep 1 (Step 000820): Train loss 3.645, Val loss 3.899\n",
      "Ep 1 (Step 000825): Train loss 3.863, Val loss 3.924\n",
      "Ep 1 (Step 000830): Train loss 3.661, Val loss 3.883\n",
      "Ep 1 (Step 000835): Train loss 4.120, Val loss 3.872\n",
      "Ep 1 (Step 000840): Train loss 3.690, Val loss 3.884\n",
      "Ep 1 (Step 000845): Train loss 3.850, Val loss 3.914\n",
      "Ep 1 (Step 000850): Train loss 3.812, Val loss 3.881\n",
      "Ep 1 (Step 000855): Train loss 3.761, Val loss 3.855\n",
      "Ep 1 (Step 000860): Train loss 3.611, Val loss 3.844\n",
      "Ep 1 (Step 000865): Train loss 3.984, Val loss 3.866\n",
      "Ep 1 (Step 000870): Train loss 3.813, Val loss 3.887\n",
      "Ep 1 (Step 000875): Train loss 3.830, Val loss 3.875\n",
      "Ep 1 (Step 000880): Train loss 3.698, Val loss 3.864\n",
      "Ep 1 (Step 000885): Train loss 3.652, Val loss 3.881\n",
      "Ep 1 (Step 000890): Train loss 3.740, Val loss 3.895\n",
      "Ep 1 (Step 000895): Train loss 3.582, Val loss 3.918\n",
      "Ep 1 (Step 000900): Train loss 3.875, Val loss 3.964\n",
      "Ep 1 (Step 000905): Train loss 3.686, Val loss 3.918\n",
      "Ep 1 (Step 000910): Train loss 3.724, Val loss 3.894\n",
      "Ep 1 (Step 000915): Train loss 3.893, Val loss 3.872\n",
      "Ep 1 (Step 000920): Train loss 3.525, Val loss 3.848\n",
      "Ep 1 (Step 000925): Train loss 3.602, Val loss 3.843\n",
      "Ep 1 (Step 000930): Train loss 3.771, Val loss 3.851\n",
      "Ep 1 (Step 000935): Train loss 3.813, Val loss 3.839\n",
      "Ep 1 (Step 000940): Train loss 3.597, Val loss 3.847\n",
      "Ep 1 (Step 000945): Train loss 3.638, Val loss 3.829\n",
      "Ep 1 (Step 000950): Train loss 3.576, Val loss 3.819\n",
      "Ep 1 (Step 000955): Train loss 3.649, Val loss 3.832\n",
      "Ep 1 (Step 000960): Train loss 3.532, Val loss 3.824\n",
      "Ep 1 (Step 000965): Train loss 3.925, Val loss 3.825\n",
      "Ep 1 (Step 000970): Train loss 3.623, Val loss 3.848\n",
      "Ep 1 (Step 000975): Train loss 3.733, Val loss 3.838\n",
      "Ep 1 (Step 000980): Train loss 3.596, Val loss 3.824\n",
      "Ep 1 (Step 000985): Train loss 3.413, Val loss 3.831\n",
      "Ep 1 (Step 000990): Train loss 3.938, Val loss 3.821\n",
      "Ep 1 (Step 000995): Train loss 3.767, Val loss 3.804\n",
      "Ep 1 (Step 001000): Train loss 3.630, Val loss 3.806\n",
      "Ep 1 (Step 001005): Train loss 3.792, Val loss 3.798\n",
      "Ep 1 (Step 001010): Train loss 3.584, Val loss 3.829\n",
      "Ep 1 (Step 001015): Train loss 3.719, Val loss 3.844\n",
      "Ep 1 (Step 001020): Train loss 3.989, Val loss 3.812\n",
      "Ep 1 (Step 001025): Train loss 3.714, Val loss 3.813\n",
      "Ep 1 (Step 001030): Train loss 3.946, Val loss 3.784\n",
      "Ep 1 (Step 001035): Train loss 3.843, Val loss 3.744\n",
      "Ep 1 (Step 001040): Train loss 3.500, Val loss 3.766\n",
      "Ep 1 (Step 001045): Train loss 3.919, Val loss 3.789\n",
      "Ep 1 (Step 001050): Train loss 3.639, Val loss 3.764\n",
      "Ep 1 (Step 001055): Train loss 3.591, Val loss 3.759\n",
      "Ep 1 (Step 001060): Train loss 3.770, Val loss 3.751\n",
      "Ep 1 (Step 001065): Train loss 3.366, Val loss 3.772\n",
      "Ep 1 (Step 001070): Train loss 3.648, Val loss 3.770\n",
      "Ep 1 (Step 001075): Train loss 3.781, Val loss 3.776\n",
      "Ep 1 (Step 001080): Train loss 3.891, Val loss 3.799\n",
      "Ep 1 (Step 001085): Train loss 3.548, Val loss 3.772\n",
      "Ep 1 (Step 001090): Train loss 3.612, Val loss 3.790\n",
      "Ep 1 (Step 001095): Train loss 4.047, Val loss 3.788\n",
      "Ep 1 (Step 001100): Train loss 3.755, Val loss 3.782\n",
      "Ep 1 (Step 001105): Train loss 3.600, Val loss 3.787\n",
      "Ep 1 (Step 001110): Train loss 3.930, Val loss 3.777\n",
      "Ep 1 (Step 001115): Train loss 3.576, Val loss 3.773\n",
      "Ep 1 (Step 001120): Train loss 3.410, Val loss 3.772\n",
      "Ep 1 (Step 001125): Train loss 3.634, Val loss 3.756\n",
      "Ep 1 (Step 001130): Train loss 3.921, Val loss 3.745\n",
      "Ep 1 (Step 001135): Train loss 3.516, Val loss 3.718\n",
      "Ep 1 (Step 001140): Train loss 3.516, Val loss 3.738\n",
      "Ep 1 (Step 001145): Train loss 3.681, Val loss 3.729\n",
      "Ep 1 (Step 001150): Train loss 3.487, Val loss 3.743\n",
      "Ep 1 (Step 001155): Train loss 3.636, Val loss 3.752\n",
      "Ep 1 (Step 001160): Train loss 3.739, Val loss 3.761\n",
      "Ep 1 (Step 001165): Train loss 3.711, Val loss 3.782\n",
      "Ep 1 (Step 001170): Train loss 3.486, Val loss 3.747\n",
      "Ep 1 (Step 001175): Train loss 3.778, Val loss 3.720\n",
      "Ep 1 (Step 001180): Train loss 3.706, Val loss 3.695\n",
      "Ep 1 (Step 001185): Train loss 3.573, Val loss 3.725\n",
      "Ep 1 (Step 001190): Train loss 3.290, Val loss 3.697\n",
      "Ep 1 (Step 001195): Train loss 3.419, Val loss 3.704\n",
      "Ep 1 (Step 001200): Train loss 3.578, Val loss 3.709\n",
      "Ep 1 (Step 001205): Train loss 3.491, Val loss 3.703\n",
      "Ep 1 (Step 001210): Train loss 3.653, Val loss 3.729\n",
      "Ep 1 (Step 001215): Train loss 3.496, Val loss 3.712\n",
      "Ep 1 (Step 001220): Train loss 3.649, Val loss 3.700\n",
      "Ep 1 (Step 001225): Train loss 3.567, Val loss 3.750\n",
      "Ep 1 (Step 001230): Train loss 3.764, Val loss 3.721\n",
      "Ep 1 (Step 001235): Train loss 3.565, Val loss 3.686\n",
      "Ep 1 (Step 001240): Train loss 3.818, Val loss 3.706\n",
      "Ep 1 (Step 001245): Train loss 3.652, Val loss 3.739\n",
      "Ep 1 (Step 001250): Train loss 3.726, Val loss 3.724\n",
      "Ep 1 (Step 001255): Train loss 4.063, Val loss 3.780\n",
      "Ep 1 (Step 001260): Train loss 3.768, Val loss 3.772\n",
      "Ep 1 (Step 001265): Train loss 3.646, Val loss 3.716\n",
      "Ep 1 (Step 001270): Train loss 3.522, Val loss 3.753\n",
      "Ep 1 (Step 001275): Train loss 3.592, Val loss 3.725\n",
      "Ep 1 (Step 001280): Train loss 3.888, Val loss 3.712\n",
      "Ep 1 (Step 001285): Train loss 3.693, Val loss 3.716\n",
      "Ep 1 (Step 001290): Train loss 4.044, Val loss 3.715\n",
      "Ep 1 (Step 001295): Train loss 3.652, Val loss 3.704\n",
      "Ep 1 (Step 001300): Train loss 3.549, Val loss 3.734\n",
      "Ep 1 (Step 001305): Train loss 3.621, Val loss 3.719\n",
      "Ep 1 (Step 001310): Train loss 3.535, Val loss 3.713\n",
      "Ep 1 (Step 001315): Train loss 3.647, Val loss 3.722\n",
      "Ep 1 (Step 001320): Train loss 3.630, Val loss 3.695\n",
      "Ep 1 (Step 001325): Train loss 3.476, Val loss 3.728\n",
      "Ep 1 (Step 001330): Train loss 3.411, Val loss 3.726\n",
      "Ep 1 (Step 001335): Train loss 3.681, Val loss 3.731\n",
      "Ep 1 (Step 001340): Train loss 3.759, Val loss 3.699\n",
      "Ep 1 (Step 001345): Train loss 3.775, Val loss 3.688\n",
      "Ep 1 (Step 001350): Train loss 3.465, Val loss 3.714\n",
      "Ep 1 (Step 001355): Train loss 3.628, Val loss 3.715\n",
      "Ep 1 (Step 001360): Train loss 3.861, Val loss 3.714\n",
      "Ep 1 (Step 001365): Train loss 3.746, Val loss 3.697\n",
      "Ep 1 (Step 001370): Train loss 3.645, Val loss 3.672\n",
      "Ep 1 (Step 001375): Train loss 3.801, Val loss 3.688\n",
      "Ep 1 (Step 001380): Train loss 3.743, Val loss 3.695\n",
      "Ep 1 (Step 001385): Train loss 3.305, Val loss 3.719\n",
      "Ep 1 (Step 001390): Train loss 3.743, Val loss 3.738\n",
      "Ep 1 (Step 001395): Train loss 3.880, Val loss 3.738\n",
      "Ep 1 (Step 001400): Train loss 3.890, Val loss 3.725\n",
      "Ep 1 (Step 001405): Train loss 3.799, Val loss 3.713\n",
      "Ep 1 (Step 001410): Train loss 3.525, Val loss 3.690\n",
      "Ep 1 (Step 001415): Train loss 3.758, Val loss 3.672\n",
      "Ep 1 (Step 001420): Train loss 3.835, Val loss 3.670\n",
      "Ep 1 (Step 001425): Train loss 3.678, Val loss 3.667\n",
      "Ep 1 (Step 001430): Train loss 3.566, Val loss 3.662\n",
      "Ep 1 (Step 001435): Train loss 3.419, Val loss 3.667\n",
      "Ep 1 (Step 001440): Train loss 3.535, Val loss 3.712\n",
      "Ep 1 (Step 001445): Train loss 3.439, Val loss 3.713\n",
      "Ep 1 (Step 001450): Train loss 3.481, Val loss 3.703\n",
      "Ep 1 (Step 001455): Train loss 3.717, Val loss 3.703\n",
      "Ep 1 (Step 001460): Train loss 3.708, Val loss 3.711\n",
      "Ep 1 (Step 001465): Train loss 3.590, Val loss 3.703\n",
      "Ep 1 (Step 001470): Train loss 3.550, Val loss 3.693\n",
      "Ep 1 (Step 001475): Train loss 3.493, Val loss 3.683\n",
      "Ep 1 (Step 001480): Train loss 3.463, Val loss 3.672\n",
      "Ep 1 (Step 001485): Train loss 3.685, Val loss 3.677\n",
      "Ep 1 (Step 001490): Train loss 3.430, Val loss 3.671\n",
      "Ep 1 (Step 001495): Train loss 3.399, Val loss 3.642\n",
      "Ep 1 (Step 001500): Train loss 3.512, Val loss 3.625\n",
      "Ep 1 (Step 001505): Train loss 3.734, Val loss 3.646\n",
      "Ep 1 (Step 001510): Train loss 3.765, Val loss 3.638\n",
      "Ep 1 (Step 001515): Train loss 3.563, Val loss 3.620\n",
      "Ep 1 (Step 001520): Train loss 3.445, Val loss 3.656\n",
      "Ep 1 (Step 001525): Train loss 3.402, Val loss 3.663\n",
      "Ep 1 (Step 001530): Train loss 3.580, Val loss 3.688\n",
      "Ep 1 (Step 001535): Train loss 3.639, Val loss 3.694\n",
      "Ep 1 (Step 001540): Train loss 3.634, Val loss 3.688\n",
      "Ep 1 (Step 001545): Train loss 3.626, Val loss 3.706\n",
      "Ep 1 (Step 001550): Train loss 3.452, Val loss 3.694\n",
      "Ep 1 (Step 001555): Train loss 3.594, Val loss 3.710\n",
      "Ep 1 (Step 001560): Train loss 3.569, Val loss 3.698\n",
      "Ep 1 (Step 001565): Train loss 3.528, Val loss 3.685\n",
      "Ep 1 (Step 001570): Train loss 3.719, Val loss 3.646\n",
      "Ep 1 (Step 001575): Train loss 3.420, Val loss 3.662\n",
      "Ep 1 (Step 001580): Train loss 3.365, Val loss 3.683\n",
      "Ep 1 (Step 001585): Train loss 3.658, Val loss 3.670\n",
      "Ep 1 (Step 001590): Train loss 3.474, Val loss 3.675\n",
      "Ep 1 (Step 001595): Train loss 3.651, Val loss 3.654\n",
      "Ep 1 (Step 001600): Train loss 3.385, Val loss 3.663\n",
      "Ep 1 (Step 001605): Train loss 3.588, Val loss 3.633\n",
      "Ep 1 (Step 001610): Train loss 3.844, Val loss 3.651\n",
      "Ep 1 (Step 001615): Train loss 3.695, Val loss 3.662\n",
      "Ep 1 (Step 001620): Train loss 3.566, Val loss 3.660\n",
      "Ep 1 (Step 001625): Train loss 3.610, Val loss 3.656\n",
      "Ep 1 (Step 001630): Train loss 3.421, Val loss 3.662\n",
      "Ep 1 (Step 001635): Train loss 3.697, Val loss 3.664\n",
      "Ep 1 (Step 001640): Train loss 3.528, Val loss 3.671\n",
      "Ep 1 (Step 001645): Train loss 3.602, Val loss 3.638\n",
      "Ep 1 (Step 001650): Train loss 3.575, Val loss 3.610\n",
      "Ep 1 (Step 001655): Train loss 3.397, Val loss 3.598\n",
      "Ep 1 (Step 001660): Train loss 3.419, Val loss 3.631\n",
      "Ep 1 (Step 001665): Train loss 3.498, Val loss 3.663\n",
      "Ep 1 (Step 001670): Train loss 3.492, Val loss 3.664\n",
      "Ep 1 (Step 001675): Train loss 3.579, Val loss 3.696\n",
      "Ep 1 (Step 001680): Train loss 3.767, Val loss 3.710\n",
      "Ep 1 (Step 001685): Train loss 3.804, Val loss 3.669\n",
      "Ep 1 (Step 001690): Train loss 3.376, Val loss 3.657\n",
      "Ep 1 (Step 001695): Train loss 3.657, Val loss 3.646\n",
      "Ep 1 (Step 001700): Train loss 3.624, Val loss 3.673\n",
      "Ep 1 (Step 001705): Train loss 3.721, Val loss 3.660\n",
      "Ep 1 (Step 001710): Train loss 3.733, Val loss 3.628\n",
      "Ep 1 (Step 001715): Train loss 3.636, Val loss 3.629\n",
      "Ep 1 (Step 001720): Train loss 3.423, Val loss 3.624\n",
      "Ep 1 (Step 001725): Train loss 3.796, Val loss 3.631\n",
      "Ep 1 (Step 001730): Train loss 3.515, Val loss 3.633\n",
      "Ep 1 (Step 001735): Train loss 3.429, Val loss 3.674\n",
      "Ep 1 (Step 001740): Train loss 3.529, Val loss 3.655\n",
      "Ep 1 (Step 001745): Train loss 3.512, Val loss 3.644\n",
      "Ep 1 (Step 001750): Train loss 3.807, Val loss 3.632\n",
      "Ep 1 (Step 001755): Train loss 3.660, Val loss 3.682\n",
      "Ep 1 (Step 001760): Train loss 3.332, Val loss 3.639\n",
      "Ep 1 (Step 001765): Train loss 3.470, Val loss 3.684\n",
      "Ep 1 (Step 001770): Train loss 3.474, Val loss 3.645\n",
      "Ep 1 (Step 001775): Train loss 3.642, Val loss 3.621\n",
      "Ep 1 (Step 001780): Train loss 4.015, Val loss 3.613\n",
      "Ep 1 (Step 001785): Train loss 3.706, Val loss 3.629\n",
      "Ep 1 (Step 001790): Train loss 3.510, Val loss 3.613\n",
      "Ep 1 (Step 001795): Train loss 3.428, Val loss 3.644\n",
      "Ep 1 (Step 001800): Train loss 3.261, Val loss 3.623\n",
      "Ep 1 (Step 001805): Train loss 3.757, Val loss 3.634\n",
      "Ep 1 (Step 001810): Train loss 3.795, Val loss 3.636\n",
      "Ep 1 (Step 001815): Train loss 3.283, Val loss 3.664\n",
      "Ep 1 (Step 001820): Train loss 3.640, Val loss 3.697\n",
      "Ep 1 (Step 001825): Train loss 3.604, Val loss 3.696\n",
      "Ep 1 (Step 001830): Train loss 3.648, Val loss 3.720\n",
      "Ep 1 (Step 001835): Train loss 3.590, Val loss 3.693\n",
      "Ep 1 (Step 001840): Train loss 3.594, Val loss 3.718\n",
      "Ep 1 (Step 001845): Train loss 3.494, Val loss 3.707\n",
      "Ep 1 (Step 001850): Train loss 3.444, Val loss 3.714\n",
      "Ep 1 (Step 001855): Train loss 3.492, Val loss 3.717\n",
      "Ep 1 (Step 001860): Train loss 3.394, Val loss 3.688\n",
      "Ep 1 (Step 001865): Train loss 3.524, Val loss 3.678\n",
      "Ep 1 (Step 001870): Train loss 3.572, Val loss 3.703\n",
      "Ep 1 (Step 001875): Train loss 3.684, Val loss 3.747\n",
      "Ep 1 (Step 001880): Train loss 3.960, Val loss 3.793\n",
      "Ep 1 (Step 001885): Train loss 4.148, Val loss 3.754\n",
      "Ep 1 (Step 001890): Train loss 3.784, Val loss 3.762\n",
      "Ep 1 (Step 001895): Train loss 3.790, Val loss 3.768\n",
      "Ep 1 (Step 001900): Train loss 3.607, Val loss 3.710\n",
      "Ep 1 (Step 001905): Train loss 3.664, Val loss 3.695\n",
      "Ep 1 (Step 001910): Train loss 3.541, Val loss 3.730\n",
      "Ep 1 (Step 001915): Train loss 3.951, Val loss 3.731\n",
      "Ep 1 (Step 001920): Train loss 3.706, Val loss 3.741\n",
      "Ep 1 (Step 001925): Train loss 3.766, Val loss 3.718\n",
      "Ep 1 (Step 001930): Train loss 3.911, Val loss 3.746\n",
      "Ep 1 (Step 001935): Train loss 3.425, Val loss 3.690\n",
      "Ep 1 (Step 001940): Train loss 3.609, Val loss 3.697\n",
      "Ep 1 (Step 001945): Train loss 3.696, Val loss 3.745\n",
      "Ep 1 (Step 001950): Train loss 3.704, Val loss 3.748\n",
      "Ep 1 (Step 001955): Train loss 3.528, Val loss 3.727\n",
      "Ep 1 (Step 001960): Train loss 3.458, Val loss 3.722\n",
      "Ep 1 (Step 001965): Train loss 3.693, Val loss 3.716\n",
      "Ep 1 (Step 001970): Train loss 3.790, Val loss 3.695\n",
      "Ep 1 (Step 001975): Train loss 3.776, Val loss 3.713\n",
      "Ep 1 (Step 001980): Train loss 3.494, Val loss 3.701\n",
      "Ep 1 (Step 001985): Train loss 3.385, Val loss 3.661\n",
      "Ep 1 (Step 001990): Train loss 3.353, Val loss 3.682\n",
      "Ep 1 (Step 001995): Train loss 3.575, Val loss 3.701\n",
      "Ep 1 (Step 002000): Train loss 3.616, Val loss 3.730\n",
      "Ep 1 (Step 002005): Train loss 3.738, Val loss 3.714\n",
      "Ep 1 (Step 002010): Train loss 3.616, Val loss 3.717\n",
      "Ep 1 (Step 002015): Train loss 3.669, Val loss 3.684\n",
      "Ep 1 (Step 002020): Train loss 3.409, Val loss 3.698\n",
      "Ep 1 (Step 002025): Train loss 3.428, Val loss 3.668\n",
      "Ep 1 (Step 002030): Train loss 3.614, Val loss 3.696\n",
      "Ep 1 (Step 002035): Train loss 3.561, Val loss 3.697\n",
      "Ep 1 (Step 002040): Train loss 3.557, Val loss 3.730\n",
      "Ep 1 (Step 002045): Train loss 3.465, Val loss 3.722\n",
      "Ep 1 (Step 002050): Train loss 3.647, Val loss 3.712\n",
      "Ep 1 (Step 002055): Train loss 3.784, Val loss 3.718\n",
      "Ep 1 (Step 002060): Train loss 3.850, Val loss 3.692\n",
      "Ep 1 (Step 002065): Train loss 3.509, Val loss 3.721\n",
      "Ep 1 (Step 002070): Train loss 3.668, Val loss 3.707\n",
      "Ep 1 (Step 002075): Train loss 3.605, Val loss 3.701\n",
      "Ep 1 (Step 002080): Train loss 3.845, Val loss 3.728\n",
      "Ep 1 (Step 002085): Train loss 3.654, Val loss 3.717\n",
      "Ep 1 (Step 002090): Train loss 3.468, Val loss 3.723\n",
      "Ep 1 (Step 002095): Train loss 3.544, Val loss 3.733\n",
      "Ep 1 (Step 002100): Train loss 3.443, Val loss 3.731\n",
      "Ep 1 (Step 002105): Train loss 3.462, Val loss 3.699\n",
      "Ep 1 (Step 002110): Train loss 3.416, Val loss 3.691\n",
      "Ep 1 (Step 002115): Train loss 3.574, Val loss 3.687\n",
      "Ep 1 (Step 002120): Train loss 3.565, Val loss 3.718\n",
      "Ep 1 (Step 002125): Train loss 3.824, Val loss 3.714\n",
      "Ep 1 (Step 002130): Train loss 3.659, Val loss 3.726\n",
      "Ep 1 (Step 002135): Train loss 3.389, Val loss 3.727\n",
      "Ep 1 (Step 002140): Train loss 3.617, Val loss 3.726\n",
      "Ep 1 (Step 002145): Train loss 3.684, Val loss 3.703\n",
      "Ep 1 (Step 002150): Train loss 3.734, Val loss 3.710\n",
      "Ep 1 (Step 002155): Train loss 3.386, Val loss 3.707\n",
      "Ep 1 (Step 002160): Train loss 3.524, Val loss 3.691\n",
      "Ep 1 (Step 002165): Train loss 3.614, Val loss 3.787\n",
      "Ep 1 (Step 002170): Train loss 3.752, Val loss 3.817\n",
      "Ep 1 (Step 002175): Train loss 3.636, Val loss 3.788\n",
      "Ep 1 (Step 002180): Train loss 3.529, Val loss 3.841\n",
      "Ep 1 (Step 002185): Train loss 3.672, Val loss 3.811\n",
      "Ep 1 (Step 002190): Train loss 3.670, Val loss 3.805\n",
      "Ep 1 (Step 002195): Train loss 3.627, Val loss 3.797\n",
      "Ep 1 (Step 002200): Train loss 3.601, Val loss 3.782\n",
      "Ep 1 (Step 002205): Train loss 3.692, Val loss 3.826\n",
      "Ep 1 (Step 002210): Train loss 3.705, Val loss 3.815\n",
      "Ep 1 (Step 002215): Train loss 3.717, Val loss 3.774\n",
      "Ep 1 (Step 002220): Train loss 3.469, Val loss 3.776\n",
      "Ep 1 (Step 002225): Train loss 3.456, Val loss 3.793\n",
      "Ep 1 (Step 002230): Train loss 3.407, Val loss 3.768\n",
      "Ep 1 (Step 002235): Train loss 3.476, Val loss 3.798\n",
      "Ep 1 (Step 002240): Train loss 3.993, Val loss 3.850\n",
      "Ep 1 (Step 002245): Train loss 3.946, Val loss 3.796\n",
      "Ep 1 (Step 002250): Train loss 3.741, Val loss 3.807\n",
      "Ep 1 (Step 002255): Train loss 3.590, Val loss 3.809\n",
      "Ep 1 (Step 002260): Train loss 3.984, Val loss 3.839\n",
      "Ep 1 (Step 002265): Train loss 3.674, Val loss 3.868\n",
      "Ep 1 (Step 002270): Train loss 3.797, Val loss 3.893\n",
      "Ep 1 (Step 002275): Train loss 3.848, Val loss 3.957\n",
      "Ep 1 (Step 002280): Train loss 3.723, Val loss 4.037\n",
      "Ep 1 (Step 002285): Train loss 3.878, Val loss 3.997\n",
      "Ep 1 (Step 002290): Train loss 3.659, Val loss 3.951\n",
      "Ep 1 (Step 002295): Train loss 3.633, Val loss 3.978\n",
      "Ep 1 (Step 002300): Train loss 3.990, Val loss 3.971\n",
      "Ep 1 (Step 002305): Train loss 3.894, Val loss 3.931\n",
      "Ep 1 (Step 002310): Train loss 4.018, Val loss 3.973\n",
      "Ep 1 (Step 002315): Train loss 3.936, Val loss 3.918\n",
      "Ep 1 (Step 002320): Train loss 3.718, Val loss 3.934\n",
      "Ep 1 (Step 002325): Train loss 4.040, Val loss 3.948\n",
      "Ep 1 (Step 002330): Train loss 3.871, Val loss 3.923\n",
      "Ep 1 (Step 002335): Train loss 3.773, Val loss 3.919\n",
      "Ep 1 (Step 002340): Train loss 3.855, Val loss 3.911\n",
      "Ep 1 (Step 002345): Train loss 3.470, Val loss 3.877\n",
      "Ep 1 (Step 002350): Train loss 3.779, Val loss 3.849\n",
      "Ep 1 (Step 002355): Train loss 3.687, Val loss 3.853\n",
      "Ep 1 (Step 002360): Train loss 3.779, Val loss 3.888\n",
      "Ep 1 (Step 002365): Train loss 3.439, Val loss 3.869\n",
      "Ep 1 (Step 002370): Train loss 3.911, Val loss 3.840\n",
      "Ep 1 (Step 002375): Train loss 3.705, Val loss 3.806\n",
      "Ep 1 (Step 002380): Train loss 3.770, Val loss 3.803\n",
      "Ep 1 (Step 002385): Train loss 3.974, Val loss 3.819\n",
      "Ep 1 (Step 002390): Train loss 3.606, Val loss 3.821\n",
      "Ep 1 (Step 002395): Train loss 3.630, Val loss 3.792\n",
      "Ep 1 (Step 002400): Train loss 3.546, Val loss 3.804\n",
      "Ep 1 (Step 002405): Train loss 3.708, Val loss 3.848\n",
      "Ep 1 (Step 002410): Train loss 3.754, Val loss 3.821\n",
      "Ep 1 (Step 002415): Train loss 4.057, Val loss 3.884\n",
      "Ep 1 (Step 002420): Train loss 3.946, Val loss 3.975\n",
      "Ep 1 (Step 002425): Train loss 3.923, Val loss 3.983\n",
      "Ep 1 (Step 002430): Train loss 3.727, Val loss 3.957\n",
      "Ep 1 (Step 002435): Train loss 3.698, Val loss 3.899\n",
      "Ep 1 (Step 002440): Train loss 3.849, Val loss 3.870\n",
      "Ep 1 (Step 002445): Train loss 4.036, Val loss 3.860\n",
      "Ep 1 (Step 002450): Train loss 3.990, Val loss 3.869\n",
      "Ep 1 (Step 002455): Train loss 3.671, Val loss 3.862\n",
      "Ep 1 (Step 002460): Train loss 3.715, Val loss 3.892\n",
      "Ep 1 (Step 002465): Train loss 3.687, Val loss 3.917\n",
      "Ep 1 (Step 002470): Train loss 3.598, Val loss 3.875\n",
      "Ep 1 (Step 002475): Train loss 3.606, Val loss 3.841\n",
      "Ep 1 (Step 002480): Train loss 3.888, Val loss 3.869\n",
      "Ep 1 (Step 002485): Train loss 3.863, Val loss 3.858\n",
      "Ep 1 (Step 002490): Train loss 3.680, Val loss 3.837\n",
      "Ep 1 (Step 002495): Train loss 3.836, Val loss 3.824\n",
      "Ep 1 (Step 002500): Train loss 3.599, Val loss 3.821\n",
      "Ep 1 (Step 002505): Train loss 3.699, Val loss 3.807\n",
      "Ep 1 (Step 002510): Train loss 3.937, Val loss 3.803\n",
      "Ep 1 (Step 002515): Train loss 3.359, Val loss 3.805\n",
      "Ep 1 (Step 002520): Train loss 3.803, Val loss 3.802\n",
      "Ep 1 (Step 002525): Train loss 3.614, Val loss 3.809\n",
      "Ep 1 (Step 002530): Train loss 3.642, Val loss 3.805\n",
      "Ep 1 (Step 002535): Train loss 3.616, Val loss 3.873\n",
      "Ep 1 (Step 002540): Train loss 3.607, Val loss 3.852\n",
      "Ep 1 (Step 002545): Train loss 3.634, Val loss 3.852\n",
      "Ep 1 (Step 002550): Train loss 3.520, Val loss 3.850\n",
      "Ep 1 (Step 002555): Train loss 3.589, Val loss 3.831\n",
      "Ep 1 (Step 002560): Train loss 3.582, Val loss 3.854\n",
      "Ep 1 (Step 002565): Train loss 3.677, Val loss 3.847\n",
      "Ep 1 (Step 002570): Train loss 3.646, Val loss 3.843\n",
      "Ep 1 (Step 002575): Train loss 3.718, Val loss 3.846\n",
      "Ep 1 (Step 002580): Train loss 3.989, Val loss 3.871\n",
      "Ep 1 (Step 002585): Train loss 3.779, Val loss 3.840\n",
      "Ep 1 (Step 002590): Train loss 3.819, Val loss 3.840\n",
      "Ep 1 (Step 002595): Train loss 3.615, Val loss 3.811\n",
      "Ep 1 (Step 002600): Train loss 3.793, Val loss 3.812\n",
      "Ep 1 (Step 002605): Train loss 3.763, Val loss 3.800\n",
      "Ep 1 (Step 002610): Train loss 3.508, Val loss 3.805\n",
      "Ep 1 (Step 002615): Train loss 3.774, Val loss 3.816\n",
      "Ep 1 (Step 002620): Train loss 4.127, Val loss 3.836\n",
      "Ep 1 (Step 002625): Train loss 3.603, Val loss 3.851\n",
      "Ep 1 (Step 002630): Train loss 3.728, Val loss 3.815\n",
      "Ep 1 (Step 002635): Train loss 3.707, Val loss 3.825\n",
      "Ep 1 (Step 002640): Train loss 3.993, Val loss 3.820\n",
      "Ep 1 (Step 002645): Train loss 3.582, Val loss 3.855\n",
      "Ep 1 (Step 002650): Train loss 3.773, Val loss 3.874\n",
      "Ep 1 (Step 002655): Train loss 3.734, Val loss 3.848\n",
      "Ep 1 (Step 002660): Train loss 4.014, Val loss 3.867\n",
      "Ep 1 (Step 002665): Train loss 3.552, Val loss 3.832\n",
      "Ep 1 (Step 002670): Train loss 3.778, Val loss 3.815\n",
      "Ep 1 (Step 002675): Train loss 3.752, Val loss 3.796\n",
      "Ep 1 (Step 002680): Train loss 3.625, Val loss 3.768\n",
      "Ep 1 (Step 002685): Train loss 3.549, Val loss 3.758\n",
      "Ep 1 (Step 002690): Train loss 3.868, Val loss 3.729\n",
      "Ep 1 (Step 002695): Train loss 3.542, Val loss 3.708\n",
      "Ep 1 (Step 002700): Train loss 3.589, Val loss 3.727\n",
      "Ep 1 (Step 002705): Train loss 3.830, Val loss 3.705\n",
      "Ep 1 (Step 002710): Train loss 3.813, Val loss 3.727\n",
      "Ep 1 (Step 002715): Train loss 3.735, Val loss 3.728\n",
      "Ep 1 (Step 002720): Train loss 3.637, Val loss 3.704\n",
      "Ep 1 (Step 002725): Train loss 3.529, Val loss 3.716\n",
      "Ep 1 (Step 002730): Train loss 3.642, Val loss 3.738\n",
      "Ep 1 (Step 002735): Train loss 3.879, Val loss 3.727\n",
      "Ep 1 (Step 002740): Train loss 3.795, Val loss 3.708\n",
      "Ep 1 (Step 002745): Train loss 3.496, Val loss 3.706\n",
      "Ep 1 (Step 002750): Train loss 3.745, Val loss 3.683\n",
      "Ep 1 (Step 002755): Train loss 3.895, Val loss 3.691\n",
      "Ep 1 (Step 002760): Train loss 3.618, Val loss 3.692\n",
      "Ep 1 (Step 002765): Train loss 3.711, Val loss 3.687\n",
      "Ep 1 (Step 002770): Train loss 3.688, Val loss 3.698\n",
      "Ep 1 (Step 002775): Train loss 3.788, Val loss 3.713\n",
      "Ep 1 (Step 002780): Train loss 3.874, Val loss 3.690\n",
      "Ep 1 (Step 002785): Train loss 3.964, Val loss 3.692\n",
      "Ep 1 (Step 002790): Train loss 3.820, Val loss 3.683\n",
      "Ep 1 (Step 002795): Train loss 3.927, Val loss 3.692\n",
      "Ep 1 (Step 002800): Train loss 3.329, Val loss 3.709\n",
      "Ep 1 (Step 002805): Train loss 3.774, Val loss 3.719\n",
      "Ep 1 (Step 002810): Train loss 3.856, Val loss 3.735\n",
      "Ep 1 (Step 002815): Train loss 3.689, Val loss 3.718\n",
      "Ep 1 (Step 002820): Train loss 3.585, Val loss 3.713\n",
      "Ep 1 (Step 002825): Train loss 3.741, Val loss 3.712\n",
      "Ep 1 (Step 002830): Train loss 3.772, Val loss 3.736\n",
      "Ep 1 (Step 002835): Train loss 3.878, Val loss 3.729\n",
      "Ep 1 (Step 002840): Train loss 3.714, Val loss 3.717\n",
      "Ep 1 (Step 002845): Train loss 3.559, Val loss 3.684\n",
      "Ep 1 (Step 002850): Train loss 3.698, Val loss 3.675\n",
      "Ep 1 (Step 002855): Train loss 3.663, Val loss 3.694\n",
      "Ep 1 (Step 002860): Train loss 3.759, Val loss 3.731\n",
      "Ep 1 (Step 002865): Train loss 3.773, Val loss 3.789\n",
      "Ep 1 (Step 002870): Train loss 3.577, Val loss 3.810\n",
      "Ep 1 (Step 002875): Train loss 3.779, Val loss 3.836\n",
      "Ep 1 (Step 002880): Train loss 4.005, Val loss 3.869\n",
      "Ep 1 (Step 002885): Train loss 3.766, Val loss 3.885\n",
      "Ep 1 (Step 002890): Train loss 3.875, Val loss 3.904\n",
      "Ep 1 (Step 002895): Train loss 3.562, Val loss 3.848\n",
      "Ep 1 (Step 002900): Train loss 3.741, Val loss 3.816\n",
      "Ep 1 (Step 002905): Train loss 3.715, Val loss 3.798\n",
      "Ep 1 (Step 002910): Train loss 3.730, Val loss 3.802\n",
      "Ep 1 (Step 002915): Train loss 3.578, Val loss 3.854\n",
      "Ep 1 (Step 002920): Train loss 3.947, Val loss 3.841\n",
      "Ep 1 (Step 002925): Train loss 3.861, Val loss 3.858\n",
      "Ep 1 (Step 002930): Train loss 3.582, Val loss 3.832\n",
      "Ep 1 (Step 002935): Train loss 3.878, Val loss 3.839\n",
      "Ep 1 (Step 002940): Train loss 3.721, Val loss 3.839\n",
      "Ep 1 (Step 002945): Train loss 3.789, Val loss 3.830\n",
      "Ep 1 (Step 002950): Train loss 3.598, Val loss 3.867\n",
      "Ep 1 (Step 002955): Train loss 3.706, Val loss 3.796\n",
      "Ep 1 (Step 002960): Train loss 3.709, Val loss 3.777\n",
      "Ep 1 (Step 002965): Train loss 3.572, Val loss 3.742\n",
      "Ep 1 (Step 002970): Train loss 3.755, Val loss 3.736\n",
      "Ep 1 (Step 002975): Train loss 3.626, Val loss 3.763\n",
      "Ep 1 (Step 002980): Train loss 3.796, Val loss 3.797\n",
      "Ep 1 (Step 002985): Train loss 3.792, Val loss 3.806\n",
      "Ep 1 (Step 002990): Train loss 3.838, Val loss 3.781\n",
      "Ep 1 (Step 002995): Train loss 3.561, Val loss 3.758\n",
      "Ep 1 (Step 003000): Train loss 3.537, Val loss 3.730\n",
      "Ep 1 (Step 003005): Train loss 4.078, Val loss 3.720\n",
      "Ep 1 (Step 003010): Train loss 3.681, Val loss 3.741\n",
      "Ep 1 (Step 003015): Train loss 3.727, Val loss 3.727\n",
      "Ep 1 (Step 003020): Train loss 3.704, Val loss 3.747\n",
      "Ep 1 (Step 003025): Train loss 3.678, Val loss 3.728\n",
      "Ep 1 (Step 003030): Train loss 4.164, Val loss 3.749\n",
      "Ep 1 (Step 003035): Train loss 3.715, Val loss 3.754\n",
      "Ep 1 (Step 003040): Train loss 3.786, Val loss 3.749\n",
      "Ep 1 (Step 003045): Train loss 3.785, Val loss 3.746\n",
      "Ep 1 (Step 003050): Train loss 3.794, Val loss 3.703\n",
      "Ep 1 (Step 003055): Train loss 3.708, Val loss 3.687\n",
      "Ep 1 (Step 003060): Train loss 3.883, Val loss 3.717\n",
      "Ep 1 (Step 003065): Train loss 3.580, Val loss 3.723\n",
      "Ep 1 (Step 003070): Train loss 3.896, Val loss 3.712\n",
      "Ep 1 (Step 003075): Train loss 3.548, Val loss 3.744\n",
      "Ep 1 (Step 003080): Train loss 3.674, Val loss 3.727\n",
      "Ep 1 (Step 003085): Train loss 3.588, Val loss 3.732\n",
      "Ep 1 (Step 003090): Train loss 3.595, Val loss 3.750\n",
      "Ep 1 (Step 003095): Train loss 3.874, Val loss 3.761\n",
      "Ep 1 (Step 003100): Train loss 3.719, Val loss 3.838\n",
      "Ep 1 (Step 003105): Train loss 3.490, Val loss 3.824\n",
      "Ep 1 (Step 003110): Train loss 3.682, Val loss 3.853\n",
      "Ep 1 (Step 003115): Train loss 3.793, Val loss 3.916\n",
      "Ep 1 (Step 003120): Train loss 3.692, Val loss 3.938\n",
      "Ep 1 (Step 003125): Train loss 3.861, Val loss 3.939\n",
      "Ep 1 (Step 003130): Train loss 3.888, Val loss 3.943\n",
      "Ep 1 (Step 003135): Train loss 3.899, Val loss 3.944\n",
      "Ep 1 (Step 003140): Train loss 3.735, Val loss 3.918\n",
      "Ep 1 (Step 003145): Train loss 3.932, Val loss 3.925\n",
      "Ep 1 (Step 003150): Train loss 3.789, Val loss 4.017\n",
      "Ep 1 (Step 003155): Train loss 4.024, Val loss 4.008\n",
      "Ep 1 (Step 003160): Train loss 3.783, Val loss 4.020\n",
      "Ep 1 (Step 003165): Train loss 3.855, Val loss 4.033\n",
      "Ep 1 (Step 003170): Train loss 3.996, Val loss 4.000\n",
      "Ep 1 (Step 003175): Train loss 3.687, Val loss 3.949\n",
      "Ep 1 (Step 003180): Train loss 4.035, Val loss 3.925\n",
      "Ep 1 (Step 003185): Train loss 4.013, Val loss 3.952\n",
      "Ep 1 (Step 003190): Train loss 3.849, Val loss 3.908\n",
      "Ep 1 (Step 003195): Train loss 3.705, Val loss 3.902\n",
      "Ep 1 (Step 003200): Train loss 3.720, Val loss 3.862\n",
      "Ep 1 (Step 003205): Train loss 3.619, Val loss 3.848\n",
      "Ep 1 (Step 003210): Train loss 3.839, Val loss 3.851\n",
      "Ep 1 (Step 003215): Train loss 3.824, Val loss 3.841\n",
      "Ep 1 (Step 003220): Train loss 4.032, Val loss 3.825\n",
      "Ep 1 (Step 003225): Train loss 3.760, Val loss 3.836\n",
      "Ep 1 (Step 003230): Train loss 3.550, Val loss 3.853\n",
      "Ep 1 (Step 003235): Train loss 3.947, Val loss 3.846\n",
      "Ep 1 (Step 003240): Train loss 3.829, Val loss 3.832\n",
      "Ep 1 (Step 003245): Train loss 3.797, Val loss 3.821\n",
      "Ep 1 (Step 003250): Train loss 4.103, Val loss 3.869\n",
      "Ep 1 (Step 003255): Train loss 3.806, Val loss 3.872\n",
      "Ep 1 (Step 003260): Train loss 3.663, Val loss 3.849\n",
      "Ep 1 (Step 003265): Train loss 3.802, Val loss 3.848\n",
      "Ep 1 (Step 003270): Train loss 4.027, Val loss 3.831\n",
      "Ep 1 (Step 003275): Train loss 3.640, Val loss 3.812\n",
      "Ep 1 (Step 003280): Train loss 3.804, Val loss 3.822\n",
      "Ep 1 (Step 003285): Train loss 3.770, Val loss 3.882\n",
      "Ep 1 (Step 003290): Train loss 3.839, Val loss 3.931\n",
      "Ep 1 (Step 003295): Train loss 3.854, Val loss 3.936\n",
      "Ep 1 (Step 003300): Train loss 4.119, Val loss 3.899\n",
      "Ep 1 (Step 003305): Train loss 3.914, Val loss 3.919\n",
      "Ep 1 (Step 003310): Train loss 3.844, Val loss 3.934\n",
      "Ep 1 (Step 003315): Train loss 3.857, Val loss 3.959\n",
      "Ep 1 (Step 003320): Train loss 3.940, Val loss 3.920\n",
      "Ep 1 (Step 003325): Train loss 3.654, Val loss 3.917\n",
      "Ep 1 (Step 003330): Train loss 3.704, Val loss 3.903\n",
      "Ep 1 (Step 003335): Train loss 3.960, Val loss 3.898\n",
      "Ep 1 (Step 003340): Train loss 3.907, Val loss 3.894\n",
      "Ep 1 (Step 003345): Train loss 3.613, Val loss 3.852\n",
      "Ep 1 (Step 003350): Train loss 3.807, Val loss 3.868\n",
      "Ep 1 (Step 003355): Train loss 3.696, Val loss 3.907\n",
      "Ep 1 (Step 003360): Train loss 3.788, Val loss 3.852\n",
      "Ep 1 (Step 003365): Train loss 3.688, Val loss 3.863\n",
      "Ep 1 (Step 003370): Train loss 3.706, Val loss 3.886\n",
      "Ep 1 (Step 003375): Train loss 3.761, Val loss 3.879\n",
      "Ep 1 (Step 003380): Train loss 3.870, Val loss 3.845\n",
      "Ep 1 (Step 003385): Train loss 3.493, Val loss 3.870\n",
      "Ep 1 (Step 003390): Train loss 3.698, Val loss 3.860\n",
      "Ep 1 (Step 003395): Train loss 3.722, Val loss 3.887\n",
      "Ep 1 (Step 003400): Train loss 3.643, Val loss 3.923\n",
      "Ep 1 (Step 003405): Train loss 4.101, Val loss 3.912\n",
      "Ep 1 (Step 003410): Train loss 3.717, Val loss 3.902\n",
      "Ep 1 (Step 003415): Train loss 3.915, Val loss 3.885\n",
      "Ep 1 (Step 003420): Train loss 3.882, Val loss 3.889\n",
      "Ep 1 (Step 003425): Train loss 3.843, Val loss 3.845\n",
      "Ep 1 (Step 003430): Train loss 3.700, Val loss 3.838\n",
      "Ep 1 (Step 003435): Train loss 3.827, Val loss 3.879\n",
      "Ep 1 (Step 003440): Train loss 3.832, Val loss 3.853\n",
      "Ep 1 (Step 003445): Train loss 3.841, Val loss 3.849\n",
      "Ep 1 (Step 003450): Train loss 3.743, Val loss 3.849\n",
      "Ep 1 (Step 003455): Train loss 3.827, Val loss 3.875\n",
      "Ep 1 (Step 003460): Train loss 3.753, Val loss 3.846\n",
      "Ep 1 (Step 003465): Train loss 3.579, Val loss 3.819\n",
      "Ep 1 (Step 003470): Train loss 3.402, Val loss 3.794\n",
      "Ep 1 (Step 003475): Train loss 3.728, Val loss 3.859\n",
      "Ep 1 (Step 003480): Train loss 3.798, Val loss 3.916\n",
      "Ep 1 (Step 003485): Train loss 3.675, Val loss 3.883\n",
      "Ep 1 (Step 003490): Train loss 3.861, Val loss 3.875\n",
      "Ep 1 (Step 003495): Train loss 3.906, Val loss 3.858\n",
      "Ep 1 (Step 003500): Train loss 3.793, Val loss 3.860\n",
      "Ep 1 (Step 003505): Train loss 3.871, Val loss 3.844\n",
      "Ep 1 (Step 003510): Train loss 3.705, Val loss 3.823\n",
      "Ep 1 (Step 003515): Train loss 3.750, Val loss 3.808\n",
      "Ep 1 (Step 003520): Train loss 3.824, Val loss 3.821\n",
      "Ep 1 (Step 003525): Train loss 3.749, Val loss 3.842\n",
      "Ep 1 (Step 003530): Train loss 3.577, Val loss 3.802\n",
      "Ep 1 (Step 003535): Train loss 3.844, Val loss 3.828\n",
      "Ep 1 (Step 003540): Train loss 3.966, Val loss 3.962\n",
      "Ep 1 (Step 003545): Train loss 4.140, Val loss 4.031\n",
      "Ep 1 (Step 003550): Train loss 3.734, Val loss 4.031\n",
      "Ep 1 (Step 003555): Train loss 3.864, Val loss 3.990\n",
      "Ep 1 (Step 003560): Train loss 4.131, Val loss 4.164\n",
      "Ep 1 (Step 003565): Train loss 4.195, Val loss 4.230\n",
      "Ep 1 (Step 003570): Train loss 4.219, Val loss 4.205\n",
      "Ep 1 (Step 003575): Train loss 4.034, Val loss 4.170\n",
      "Ep 1 (Step 003580): Train loss 4.135, Val loss 4.130\n",
      "Ep 1 (Step 003585): Train loss 4.317, Val loss 4.095\n",
      "Ep 1 (Step 003590): Train loss 4.242, Val loss 4.105\n",
      "Ep 1 (Step 003595): Train loss 3.848, Val loss 4.056\n",
      "Ep 1 (Step 003600): Train loss 3.971, Val loss 4.025\n",
      "Ep 1 (Step 003605): Train loss 4.060, Val loss 4.010\n",
      "Ep 1 (Step 003610): Train loss 4.029, Val loss 4.006\n",
      "Ep 1 (Step 003615): Train loss 3.934, Val loss 4.002\n",
      "Ep 1 (Step 003620): Train loss 4.131, Val loss 4.015\n",
      "Ep 1 (Step 003625): Train loss 4.061, Val loss 3.998\n",
      "Ep 1 (Step 003630): Train loss 3.791, Val loss 3.945\n",
      "Ep 1 (Step 003635): Train loss 4.055, Val loss 3.908\n",
      "Ep 1 (Step 003640): Train loss 3.825, Val loss 3.890\n",
      "Ep 1 (Step 003645): Train loss 3.810, Val loss 3.875\n",
      "Ep 1 (Step 003650): Train loss 3.593, Val loss 3.865\n",
      "Ep 1 (Step 003655): Train loss 3.828, Val loss 3.878\n",
      "Ep 1 (Step 003660): Train loss 3.746, Val loss 3.875\n",
      "Ep 1 (Step 003665): Train loss 3.775, Val loss 3.902\n",
      "Ep 1 (Step 003670): Train loss 3.837, Val loss 3.864\n",
      "Ep 1 (Step 003675): Train loss 3.762, Val loss 3.837\n",
      "Ep 1 (Step 003680): Train loss 3.903, Val loss 3.823\n",
      "Ep 1 (Step 003685): Train loss 4.057, Val loss 3.839\n",
      "Ep 1 (Step 003690): Train loss 3.512, Val loss 3.875\n",
      "Ep 1 (Step 003695): Train loss 3.871, Val loss 3.874\n",
      "Ep 1 (Step 003700): Train loss 3.674, Val loss 3.906\n",
      "Ep 1 (Step 003705): Train loss 3.527, Val loss 3.887\n",
      "Ep 1 (Step 003710): Train loss 4.142, Val loss 3.894\n",
      "Ep 1 (Step 003715): Train loss 3.830, Val loss 3.900\n",
      "Ep 1 (Step 003720): Train loss 3.741, Val loss 3.904\n",
      "Ep 1 (Step 003725): Train loss 4.094, Val loss 3.873\n",
      "Ep 1 (Step 003730): Train loss 3.908, Val loss 3.841\n",
      "Ep 1 (Step 003735): Train loss 3.836, Val loss 3.805\n",
      "Ep 1 (Step 003740): Train loss 3.707, Val loss 3.813\n",
      "Ep 1 (Step 003745): Train loss 4.062, Val loss 3.797\n",
      "Ep 1 (Step 003750): Train loss 3.910, Val loss 3.782\n",
      "Ep 1 (Step 003755): Train loss 3.842, Val loss 3.744\n",
      "Ep 1 (Step 003760): Train loss 3.626, Val loss 3.754\n",
      "Ep 1 (Step 003765): Train loss 3.543, Val loss 3.770\n",
      "Ep 1 (Step 003770): Train loss 3.772, Val loss 3.796\n",
      "Ep 1 (Step 003775): Train loss 3.920, Val loss 3.798\n",
      "Ep 1 (Step 003780): Train loss 3.685, Val loss 3.774\n",
      "Ep 1 (Step 003785): Train loss 4.141, Val loss 3.786\n",
      "Ep 1 (Step 003790): Train loss 3.402, Val loss 3.796\n",
      "Ep 1 (Step 003795): Train loss 4.062, Val loss 3.805\n",
      "Ep 1 (Step 003800): Train loss 3.732, Val loss 3.792\n",
      "Ep 1 (Step 003805): Train loss 3.776, Val loss 3.801\n",
      "Ep 1 (Step 003810): Train loss 3.707, Val loss 3.786\n",
      "Ep 1 (Step 003815): Train loss 3.699, Val loss 3.788\n",
      "Ep 1 (Step 003820): Train loss 3.772, Val loss 3.782\n",
      "Ep 1 (Step 003825): Train loss 3.809, Val loss 3.791\n",
      "Ep 1 (Step 003830): Train loss 4.056, Val loss 3.799\n",
      "Ep 1 (Step 003835): Train loss 3.851, Val loss 3.779\n",
      "Ep 1 (Step 003840): Train loss 3.717, Val loss 3.757\n",
      "Ep 1 (Step 003845): Train loss 3.777, Val loss 3.775\n",
      "Ep 1 (Step 003850): Train loss 3.638, Val loss 3.776\n",
      "Ep 1 (Step 003855): Train loss 3.949, Val loss 3.777\n",
      "Ep 1 (Step 003860): Train loss 3.843, Val loss 3.795\n",
      "Ep 1 (Step 003865): Train loss 3.858, Val loss 3.769\n",
      "Ep 1 (Step 003870): Train loss 3.685, Val loss 3.753\n",
      "Ep 1 (Step 003875): Train loss 4.307, Val loss 3.774\n",
      "Ep 1 (Step 003880): Train loss 3.796, Val loss 3.762\n",
      "Ep 1 (Step 003885): Train loss 3.734, Val loss 3.799\n",
      "Ep 1 (Step 003890): Train loss 3.843, Val loss 3.805\n",
      "Ep 1 (Step 003895): Train loss 3.583, Val loss 3.792\n",
      "Ep 1 (Step 003900): Train loss 3.893, Val loss 3.758\n",
      "Ep 1 (Step 003905): Train loss 3.791, Val loss 3.734\n",
      "Ep 1 (Step 003910): Train loss 3.542, Val loss 3.740\n",
      "Ep 1 (Step 003915): Train loss 3.582, Val loss 3.752\n",
      "Ep 1 (Step 003920): Train loss 3.410, Val loss 3.735\n",
      "Ep 1 (Step 003925): Train loss 3.481, Val loss 3.754\n",
      "Ep 1 (Step 003930): Train loss 3.655, Val loss 3.794\n",
      "Ep 1 (Step 003935): Train loss 3.497, Val loss 3.782\n",
      "Ep 1 (Step 003940): Train loss 3.705, Val loss 3.780\n",
      "Ep 1 (Step 003945): Train loss 3.685, Val loss 3.770\n",
      "Ep 1 (Step 003950): Train loss 3.725, Val loss 3.775\n",
      "Ep 1 (Step 003955): Train loss 3.714, Val loss 3.770\n",
      "Ep 1 (Step 003960): Train loss 3.855, Val loss 3.796\n",
      "Ep 1 (Step 003965): Train loss 3.637, Val loss 3.810\n",
      "Ep 1 (Step 003970): Train loss 3.492, Val loss 3.822\n",
      "Ep 1 (Step 003975): Train loss 3.875, Val loss 3.816\n",
      "Ep 1 (Step 003980): Train loss 3.561, Val loss 3.767\n",
      "Ep 1 (Step 003985): Train loss 3.861, Val loss 3.776\n",
      "Ep 1 (Step 003990): Train loss 3.618, Val loss 3.794\n",
      "Ep 1 (Step 003995): Train loss 3.417, Val loss 3.842\n",
      "Ep 1 (Step 004000): Train loss 3.631, Val loss 3.853\n",
      "Ep 1 (Step 004005): Train loss 3.658, Val loss 3.923\n",
      "Ep 1 (Step 004010): Train loss 3.880, Val loss 3.896\n",
      "Ep 1 (Step 004015): Train loss 3.702, Val loss 3.875\n",
      "Ep 1 (Step 004020): Train loss 3.689, Val loss 3.871\n",
      "Ep 1 (Step 004025): Train loss 4.047, Val loss 3.871\n",
      "Ep 1 (Step 004030): Train loss 3.641, Val loss 3.893\n",
      "Ep 1 (Step 004035): Train loss 3.627, Val loss 3.955\n",
      "Ep 1 (Step 004040): Train loss 3.887, Val loss 3.964\n",
      "Ep 1 (Step 004045): Train loss 3.766, Val loss 3.988\n",
      "Ep 1 (Step 004050): Train loss 3.734, Val loss 3.935\n",
      "Ep 1 (Step 004055): Train loss 3.687, Val loss 3.883\n",
      "Ep 1 (Step 004060): Train loss 3.897, Val loss 3.874\n",
      "Ep 1 (Step 004065): Train loss 3.751, Val loss 3.905\n",
      "Ep 1 (Step 004070): Train loss 3.812, Val loss 3.905\n",
      "Ep 1 (Step 004075): Train loss 3.851, Val loss 3.900\n",
      "Ep 1 (Step 004080): Train loss 3.678, Val loss 3.853\n",
      "Ep 1 (Step 004085): Train loss 3.387, Val loss 3.835\n",
      "Ep 1 (Step 004090): Train loss 3.776, Val loss 3.807\n",
      "Ep 1 (Step 004095): Train loss 3.916, Val loss 3.786\n",
      "Ep 1 (Step 004100): Train loss 3.798, Val loss 3.773\n",
      "Ep 1 (Step 004105): Train loss 3.768, Val loss 3.792\n",
      "Ep 1 (Step 004110): Train loss 3.592, Val loss 3.791\n",
      "Ep 1 (Step 004115): Train loss 3.494, Val loss 3.822\n",
      "Ep 1 (Step 004120): Train loss 3.753, Val loss 3.796\n",
      "Ep 1 (Step 004125): Train loss 3.577, Val loss 3.767\n",
      "Ep 1 (Step 004130): Train loss 3.645, Val loss 3.756\n",
      "Ep 1 (Step 004135): Train loss 3.621, Val loss 3.767\n",
      "Ep 1 (Step 004140): Train loss 3.857, Val loss 3.811\n",
      "Ep 1 (Step 004145): Train loss 3.859, Val loss 3.804\n",
      "Ep 1 (Step 004150): Train loss 4.176, Val loss 3.816\n",
      "Ep 1 (Step 004155): Train loss 3.718, Val loss 3.813\n",
      "Ep 1 (Step 004160): Train loss 3.628, Val loss 3.797\n",
      "Ep 1 (Step 004165): Train loss 3.571, Val loss 3.791\n",
      "Ep 1 (Step 004170): Train loss 3.895, Val loss 3.798\n",
      "Ep 1 (Step 004175): Train loss 3.757, Val loss 3.778\n",
      "Ep 1 (Step 004180): Train loss 3.727, Val loss 3.751\n",
      "Ep 1 (Step 004185): Train loss 3.513, Val loss 3.740\n",
      "Ep 1 (Step 004190): Train loss 3.903, Val loss 3.759\n",
      "Ep 1 (Step 004195): Train loss 3.462, Val loss 3.753\n",
      "Ep 1 (Step 004200): Train loss 3.854, Val loss 3.744\n",
      "Ep 1 (Step 004205): Train loss 3.797, Val loss 3.746\n",
      "Ep 1 (Step 004210): Train loss 3.315, Val loss 3.731\n",
      "Ep 1 (Step 004215): Train loss 3.998, Val loss 3.782\n",
      "Ep 1 (Step 004220): Train loss 3.730, Val loss 3.803\n",
      "Ep 1 (Step 004225): Train loss 3.897, Val loss 3.800\n",
      "Ep 1 (Step 004230): Train loss 3.964, Val loss 3.787\n",
      "Ep 1 (Step 004235): Train loss 3.761, Val loss 3.781\n",
      "Ep 1 (Step 004240): Train loss 3.979, Val loss 3.765\n",
      "Ep 1 (Step 004245): Train loss 3.662, Val loss 3.797\n",
      "Ep 1 (Step 004250): Train loss 3.721, Val loss 3.795\n",
      "Ep 1 (Step 004255): Train loss 3.653, Val loss 3.776\n",
      "Ep 1 (Step 004260): Train loss 3.672, Val loss 3.780\n",
      "Ep 1 (Step 004265): Train loss 3.526, Val loss 3.809\n",
      "Ep 1 (Step 004270): Train loss 3.875, Val loss 3.754\n",
      "Ep 1 (Step 004275): Train loss 3.633, Val loss 3.746\n",
      "Ep 1 (Step 004280): Train loss 3.693, Val loss 3.740\n",
      "Ep 1 (Step 004285): Train loss 3.651, Val loss 3.733\n",
      "Ep 1 (Step 004290): Train loss 3.547, Val loss 3.771\n",
      "Ep 1 (Step 004295): Train loss 3.745, Val loss 3.773\n",
      "Ep 1 (Step 004300): Train loss 3.786, Val loss 3.740\n",
      "Ep 1 (Step 004305): Train loss 3.561, Val loss 3.731\n",
      "Ep 1 (Step 004310): Train loss 3.465, Val loss 3.742\n",
      "Ep 1 (Step 004315): Train loss 3.854, Val loss 3.718\n",
      "Ep 1 (Step 004320): Train loss 3.607, Val loss 3.698\n",
      "Ep 1 (Step 004325): Train loss 3.688, Val loss 3.686\n",
      "Ep 1 (Step 004330): Train loss 3.929, Val loss 3.693\n",
      "Ep 1 (Step 004335): Train loss 3.672, Val loss 3.689\n",
      "Ep 1 (Step 004340): Train loss 3.906, Val loss 3.672\n",
      "Ep 1 (Step 004345): Train loss 3.953, Val loss 3.674\n",
      "Ep 1 (Step 004350): Train loss 3.525, Val loss 3.700\n",
      "Ep 1 (Step 004355): Train loss 3.569, Val loss 3.710\n",
      "Ep 1 (Step 004360): Train loss 3.575, Val loss 3.699\n",
      "Ep 1 (Step 004365): Train loss 3.746, Val loss 3.750\n",
      "Ep 1 (Step 004370): Train loss 3.502, Val loss 3.698\n",
      "Ep 1 (Step 004375): Train loss 3.892, Val loss 3.709\n",
      "Ep 1 (Step 004380): Train loss 3.856, Val loss 3.760\n",
      "Ep 1 (Step 004385): Train loss 3.396, Val loss 3.774\n",
      "Ep 1 (Step 004390): Train loss 3.623, Val loss 3.738\n",
      "Ep 1 (Step 004395): Train loss 3.678, Val loss 3.710\n",
      "Ep 1 (Step 004400): Train loss 3.657, Val loss 3.699\n",
      "Ep 1 (Step 004405): Train loss 3.621, Val loss 3.700\n",
      "Ep 1 (Step 004410): Train loss 3.680, Val loss 3.700\n",
      "Ep 1 (Step 004415): Train loss 3.592, Val loss 3.723\n",
      "Ep 1 (Step 004420): Train loss 3.737, Val loss 3.749\n",
      "Ep 1 (Step 004425): Train loss 3.844, Val loss 3.747\n",
      "Ep 1 (Step 004430): Train loss 3.554, Val loss 3.726\n",
      "Ep 1 (Step 004435): Train loss 3.766, Val loss 3.712\n",
      "Ep 1 (Step 004440): Train loss 3.636, Val loss 3.701\n",
      "Ep 1 (Step 004445): Train loss 3.514, Val loss 3.713\n",
      "Ep 1 (Step 004450): Train loss 3.666, Val loss 3.713\n",
      "Ep 1 (Step 004455): Train loss 3.832, Val loss 3.711\n",
      "Ep 1 (Step 004460): Train loss 3.461, Val loss 3.712\n",
      "Ep 1 (Step 004465): Train loss 3.521, Val loss 3.712\n",
      "Ep 1 (Step 004470): Train loss 3.550, Val loss 3.737\n",
      "Ep 1 (Step 004475): Train loss 3.712, Val loss 3.743\n",
      "Ep 1 (Step 004480): Train loss 3.669, Val loss 3.735\n",
      "Ep 1 (Step 004485): Train loss 3.452, Val loss 3.709\n",
      "Ep 1 (Step 004490): Train loss 3.253, Val loss 3.719\n",
      "Ep 1 (Step 004495): Train loss 3.701, Val loss 3.726\n",
      "Ep 1 (Step 004500): Train loss 3.768, Val loss 3.721\n",
      "Ep 1 (Step 004505): Train loss 3.789, Val loss 3.712\n",
      "Ep 1 (Step 004510): Train loss 3.561, Val loss 3.712\n",
      "Ep 1 (Step 004515): Train loss 3.627, Val loss 3.731\n",
      "Ep 1 (Step 004520): Train loss 3.415, Val loss 3.744\n",
      "Ep 1 (Step 004525): Train loss 3.804, Val loss 3.715\n",
      "Ep 1 (Step 004530): Train loss 3.852, Val loss 3.720\n",
      "Ep 1 (Step 004535): Train loss 3.710, Val loss 3.692\n",
      "Ep 1 (Step 004540): Train loss 3.479, Val loss 3.670\n",
      "Ep 1 (Step 004545): Train loss 3.465, Val loss 3.686\n",
      "Ep 1 (Step 004550): Train loss 3.982, Val loss 3.716\n",
      "Ep 1 (Step 004555): Train loss 3.619, Val loss 3.722\n",
      "Ep 1 (Step 004560): Train loss 3.920, Val loss 3.676\n",
      "Ep 1 (Step 004565): Train loss 3.518, Val loss 3.646\n",
      "Ep 1 (Step 004570): Train loss 3.630, Val loss 3.649\n",
      "Ep 1 (Step 004575): Train loss 3.413, Val loss 3.660\n",
      "Ep 1 (Step 004580): Train loss 3.482, Val loss 3.670\n",
      "Ep 1 (Step 004585): Train loss 3.560, Val loss 3.649\n",
      "Ep 1 (Step 004590): Train loss 3.639, Val loss 3.660\n",
      "Ep 1 (Step 004595): Train loss 3.573, Val loss 3.664\n",
      "Ep 1 (Step 004600): Train loss 3.783, Val loss 3.686\n",
      "Ep 1 (Step 004605): Train loss 3.571, Val loss 3.716\n",
      "Ep 1 (Step 004610): Train loss 3.568, Val loss 3.751\n",
      "Ep 1 (Step 004615): Train loss 3.729, Val loss 3.744\n",
      "Ep 1 (Step 004620): Train loss 3.730, Val loss 3.728\n",
      "Ep 1 (Step 004625): Train loss 3.833, Val loss 3.739\n",
      "Ep 1 (Step 004630): Train loss 3.728, Val loss 3.735\n",
      "Ep 1 (Step 004635): Train loss 3.573, Val loss 3.722\n",
      "Ep 1 (Step 004640): Train loss 3.619, Val loss 3.729\n",
      "Ep 1 (Step 004645): Train loss 4.017, Val loss 3.740\n",
      "Ep 1 (Step 004650): Train loss 3.555, Val loss 3.740\n",
      "Ep 1 (Step 004655): Train loss 3.701, Val loss 3.747\n",
      "Ep 1 (Step 004660): Train loss 3.738, Val loss 3.733\n",
      "Ep 1 (Step 004665): Train loss 3.790, Val loss 3.750\n",
      "Ep 1 (Step 004670): Train loss 3.560, Val loss 3.737\n",
      "Ep 1 (Step 004675): Train loss 3.678, Val loss 3.716\n",
      "Ep 1 (Step 004680): Train loss 3.580, Val loss 3.701\n",
      "Ep 1 (Step 004685): Train loss 3.630, Val loss 3.690\n",
      "Ep 1 (Step 004690): Train loss 3.889, Val loss 3.658\n",
      "Ep 1 (Step 004695): Train loss 3.692, Val loss 3.675\n",
      "Ep 1 (Step 004700): Train loss 3.608, Val loss 3.711\n",
      "Ep 1 (Step 004705): Train loss 3.358, Val loss 3.741\n",
      "Ep 1 (Step 004710): Train loss 4.180, Val loss 3.731\n",
      "Ep 1 (Step 004715): Train loss 3.825, Val loss 3.700\n",
      "Ep 1 (Step 004720): Train loss 4.068, Val loss 3.739\n",
      "Ep 1 (Step 004725): Train loss 3.781, Val loss 3.722\n",
      "Ep 1 (Step 004730): Train loss 3.543, Val loss 3.734\n",
      "Ep 1 (Step 004735): Train loss 3.685, Val loss 3.741\n",
      "Ep 1 (Step 004740): Train loss 3.452, Val loss 3.748\n",
      "Ep 1 (Step 004745): Train loss 3.795, Val loss 3.768\n",
      "Ep 1 (Step 004750): Train loss 3.559, Val loss 3.782\n",
      "Ep 1 (Step 004755): Train loss 3.846, Val loss 3.762\n",
      "Ep 1 (Step 004760): Train loss 3.542, Val loss 3.757\n",
      "Ep 1 (Step 004765): Train loss 3.526, Val loss 3.739\n",
      "Ep 1 (Step 004770): Train loss 3.721, Val loss 3.743\n",
      "Ep 1 (Step 004775): Train loss 4.082, Val loss 3.749\n",
      "Ep 1 (Step 004780): Train loss 4.199, Val loss 3.744\n",
      "Ep 1 (Step 004785): Train loss 3.573, Val loss 3.724\n",
      "Ep 1 (Step 004790): Train loss 3.747, Val loss 3.714\n",
      "Ep 1 (Step 004795): Train loss 3.773, Val loss 3.704\n",
      "Ep 1 (Step 004800): Train loss 3.784, Val loss 3.706\n",
      "Ep 1 (Step 004805): Train loss 3.653, Val loss 3.696\n",
      "Ep 1 (Step 004810): Train loss 3.982, Val loss 3.676\n",
      "Ep 1 (Step 004815): Train loss 3.928, Val loss 3.683\n",
      "Ep 1 (Step 004820): Train loss 3.792, Val loss 3.730\n",
      "Ep 1 (Step 004825): Train loss 3.773, Val loss 3.732\n",
      "Ep 1 (Step 004830): Train loss 4.019, Val loss 3.724\n",
      "Ep 1 (Step 004835): Train loss 3.733, Val loss 3.702\n",
      "Ep 1 (Step 004840): Train loss 3.666, Val loss 3.705\n",
      "Ep 1 (Step 004845): Train loss 3.447, Val loss 3.716\n",
      "Ep 1 (Step 004850): Train loss 3.722, Val loss 3.709\n",
      "Ep 1 (Step 004855): Train loss 3.710, Val loss 3.672\n",
      "Ep 1 (Step 004860): Train loss 3.885, Val loss 3.645\n",
      "Ep 1 (Step 004865): Train loss 3.589, Val loss 3.661\n",
      "Ep 1 (Step 004870): Train loss 3.685, Val loss 3.666\n",
      "Ep 1 (Step 004875): Train loss 3.428, Val loss 3.670\n",
      "Ep 1 (Step 004880): Train loss 3.480, Val loss 3.669\n",
      "Ep 1 (Step 004885): Train loss 3.732, Val loss 3.691\n",
      "Ep 1 (Step 004890): Train loss 3.737, Val loss 3.713\n",
      "Ep 1 (Step 004895): Train loss 3.779, Val loss 3.708\n",
      "Ep 1 (Step 004900): Train loss 3.847, Val loss 3.696\n",
      "Ep 1 (Step 004905): Train loss 3.557, Val loss 3.692\n",
      "Ep 1 (Step 004910): Train loss 3.918, Val loss 3.677\n",
      "Ep 1 (Step 004915): Train loss 3.938, Val loss 3.672\n",
      "Ep 1 (Step 004920): Train loss 3.477, Val loss 3.676\n",
      "Ep 1 (Step 004925): Train loss 3.560, Val loss 3.655\n",
      "Ep 1 (Step 004930): Train loss 3.566, Val loss 3.662\n",
      "Ep 1 (Step 004935): Train loss 3.613, Val loss 3.679\n",
      "Ep 1 (Step 004940): Train loss 3.436, Val loss 3.667\n",
      "Ep 1 (Step 004945): Train loss 3.770, Val loss 3.666\n",
      "Ep 1 (Step 004950): Train loss 3.692, Val loss 3.659\n",
      "Ep 1 (Step 004955): Train loss 3.515, Val loss 3.663\n",
      "Ep 1 (Step 004960): Train loss 3.317, Val loss 3.663\n",
      "Ep 1 (Step 004965): Train loss 3.565, Val loss 3.671\n",
      "Ep 1 (Step 004970): Train loss 3.636, Val loss 3.673\n",
      "Ep 1 (Step 004975): Train loss 3.678, Val loss 3.672\n",
      "Ep 1 (Step 004980): Train loss 3.606, Val loss 3.658\n",
      "Ep 1 (Step 004985): Train loss 3.672, Val loss 3.668\n",
      "Ep 1 (Step 004990): Train loss 3.679, Val loss 3.667\n",
      "Ep 1 (Step 004995): Train loss 3.689, Val loss 3.670\n",
      "Ep 1 (Step 005000): Train loss 3.487, Val loss 3.677\n",
      "Ep 1 (Step 005005): Train loss 3.774, Val loss 3.672\n",
      "Ep 1 (Step 005010): Train loss 3.649, Val loss 3.685\n",
      "Ep 1 (Step 005015): Train loss 3.755, Val loss 3.701\n",
      "Ep 1 (Step 005020): Train loss 3.795, Val loss 3.689\n",
      "Ep 1 (Step 005025): Train loss 3.883, Val loss 3.702\n",
      "Ep 1 (Step 005030): Train loss 3.693, Val loss 3.656\n",
      "Ep 1 (Step 005035): Train loss 3.512, Val loss 3.655\n",
      "Ep 1 (Step 005040): Train loss 3.405, Val loss 3.686\n",
      "Ep 1 (Step 005045): Train loss 3.802, Val loss 3.702\n",
      "Ep 1 (Step 005050): Train loss 3.536, Val loss 3.716\n",
      "Ep 1 (Step 005055): Train loss 3.857, Val loss 3.688\n",
      "Ep 1 (Step 005060): Train loss 3.269, Val loss 3.716\n",
      "Ep 1 (Step 005065): Train loss 3.626, Val loss 3.668\n",
      "Ep 1 (Step 005070): Train loss 3.693, Val loss 3.702\n",
      "Ep 1 (Step 005075): Train loss 3.484, Val loss 3.697\n",
      "Ep 1 (Step 005080): Train loss 3.711, Val loss 3.703\n",
      "Ep 1 (Step 005085): Train loss 3.437, Val loss 3.690\n",
      "Ep 1 (Step 005090): Train loss 3.560, Val loss 3.675\n",
      "Ep 1 (Step 005095): Train loss 3.499, Val loss 3.656\n",
      "Ep 1 (Step 005100): Train loss 3.575, Val loss 3.678\n",
      "Ep 1 (Step 005105): Train loss 3.590, Val loss 3.684\n",
      "Ep 1 (Step 005110): Train loss 3.744, Val loss 3.688\n",
      "Ep 1 (Step 005115): Train loss 3.530, Val loss 3.688\n",
      "Ep 1 (Step 005120): Train loss 3.583, Val loss 3.700\n",
      "Ep 1 (Step 005125): Train loss 3.534, Val loss 3.698\n",
      "Ep 1 (Step 005130): Train loss 3.852, Val loss 3.696\n",
      "Ep 1 (Step 005135): Train loss 3.803, Val loss 3.692\n",
      "Ep 1 (Step 005140): Train loss 3.673, Val loss 3.692\n",
      "Ep 1 (Step 005145): Train loss 3.626, Val loss 3.678\n",
      "Ep 1 (Step 005150): Train loss 3.796, Val loss 3.664\n",
      "Ep 1 (Step 005155): Train loss 3.540, Val loss 3.655\n",
      "Ep 1 (Step 005160): Train loss 3.590, Val loss 3.666\n",
      "Ep 1 (Step 005165): Train loss 3.310, Val loss 3.683\n",
      "Ep 1 (Step 005170): Train loss 3.536, Val loss 3.680\n",
      "Ep 1 (Step 005175): Train loss 3.678, Val loss 3.698\n",
      "Ep 1 (Step 005180): Train loss 3.457, Val loss 3.682\n",
      "Ep 1 (Step 005185): Train loss 3.449, Val loss 3.684\n",
      "Ep 1 (Step 005190): Train loss 3.568, Val loss 3.677\n",
      "Ep 1 (Step 005195): Train loss 3.402, Val loss 3.678\n",
      "Ep 1 (Step 005200): Train loss 3.489, Val loss 3.649\n",
      "Ep 1 (Step 005205): Train loss 3.634, Val loss 3.657\n",
      "Ep 1 (Step 005210): Train loss 3.760, Val loss 3.659\n",
      "Ep 1 (Step 005215): Train loss 3.651, Val loss 3.663\n",
      "Ep 1 (Step 005220): Train loss 3.623, Val loss 3.651\n",
      "Ep 1 (Step 005225): Train loss 3.543, Val loss 3.635\n",
      "Ep 1 (Step 005230): Train loss 3.576, Val loss 3.629\n",
      "Ep 1 (Step 005235): Train loss 3.514, Val loss 3.611\n",
      "Ep 1 (Step 005240): Train loss 3.548, Val loss 3.607\n",
      "Ep 1 (Step 005245): Train loss 3.893, Val loss 3.633\n",
      "Ep 1 (Step 005250): Train loss 3.283, Val loss 3.640\n",
      "Ep 1 (Step 005255): Train loss 3.893, Val loss 3.621\n",
      "Ep 1 (Step 005260): Train loss 3.454, Val loss 3.625\n",
      "Ep 1 (Step 005265): Train loss 3.540, Val loss 3.628\n",
      "Ep 1 (Step 005270): Train loss 3.635, Val loss 3.633\n",
      "Ep 1 (Step 005275): Train loss 3.435, Val loss 3.618\n",
      "Ep 1 (Step 005280): Train loss 3.708, Val loss 3.610\n",
      "Ep 1 (Step 005285): Train loss 3.571, Val loss 3.599\n",
      "Ep 1 (Step 005290): Train loss 3.530, Val loss 3.609\n",
      "Ep 1 (Step 005295): Train loss 3.258, Val loss 3.607\n",
      "Ep 1 (Step 005300): Train loss 3.358, Val loss 3.624\n",
      "Ep 1 (Step 005305): Train loss 3.421, Val loss 3.615\n",
      "Ep 1 (Step 005310): Train loss 3.545, Val loss 3.608\n",
      "Ep 1 (Step 005315): Train loss 3.330, Val loss 3.613\n",
      "Ep 1 (Step 005320): Train loss 3.567, Val loss 3.620\n",
      "Ep 1 (Step 005325): Train loss 3.432, Val loss 3.607\n",
      "Ep 1 (Step 005330): Train loss 3.722, Val loss 3.614\n",
      "Ep 1 (Step 005335): Train loss 3.396, Val loss 3.648\n",
      "Ep 1 (Step 005340): Train loss 3.655, Val loss 3.660\n",
      "Ep 1 (Step 005345): Train loss 3.735, Val loss 3.687\n",
      "Ep 1 (Step 005350): Train loss 3.549, Val loss 3.679\n",
      "Ep 1 (Step 005355): Train loss 3.507, Val loss 3.668\n",
      "Ep 1 (Step 005360): Train loss 3.383, Val loss 3.662\n",
      "Ep 1 (Step 005365): Train loss 3.661, Val loss 3.635\n",
      "Ep 1 (Step 005370): Train loss 3.545, Val loss 3.655\n",
      "Ep 1 (Step 005375): Train loss 3.812, Val loss 3.693\n",
      "Ep 1 (Step 005380): Train loss 3.604, Val loss 3.669\n",
      "Ep 1 (Step 005385): Train loss 3.737, Val loss 3.646\n",
      "Ep 1 (Step 005390): Train loss 3.529, Val loss 3.638\n",
      "Ep 1 (Step 005395): Train loss 3.548, Val loss 3.662\n",
      "Ep 1 (Step 005400): Train loss 3.461, Val loss 3.658\n",
      "Ep 1 (Step 005405): Train loss 3.809, Val loss 3.654\n",
      "Ep 1 (Step 005410): Train loss 3.662, Val loss 3.654\n",
      "Ep 1 (Step 005415): Train loss 3.386, Val loss 3.642\n",
      "Ep 1 (Step 005420): Train loss 3.394, Val loss 3.645\n",
      "Ep 1 (Step 005425): Train loss 3.611, Val loss 3.694\n",
      "Ep 1 (Step 005430): Train loss 3.601, Val loss 3.730\n",
      "Ep 1 (Step 005435): Train loss 3.591, Val loss 3.692\n",
      "Ep 1 (Step 005440): Train loss 3.483, Val loss 3.709\n",
      "Ep 1 (Step 005445): Train loss 3.613, Val loss 3.712\n",
      "Ep 1 (Step 005450): Train loss 3.570, Val loss 3.699\n",
      "Ep 1 (Step 005455): Train loss 3.413, Val loss 3.678\n",
      "Ep 1 (Step 005460): Train loss 3.605, Val loss 3.679\n",
      "Ep 1 (Step 005465): Train loss 3.618, Val loss 3.682\n",
      "Ep 1 (Step 005470): Train loss 3.537, Val loss 3.728\n",
      "Ep 1 (Step 005475): Train loss 3.535, Val loss 3.724\n",
      "Ep 1 (Step 005480): Train loss 3.258, Val loss 3.711\n",
      "Ep 1 (Step 005485): Train loss 3.341, Val loss 3.722\n",
      "Ep 1 (Step 005490): Train loss 3.578, Val loss 3.740\n",
      "Ep 1 (Step 005495): Train loss 3.723, Val loss 3.753\n",
      "Ep 1 (Step 005500): Train loss 3.949, Val loss 3.742\n",
      "Ep 1 (Step 005505): Train loss 3.662, Val loss 3.733\n",
      "Ep 1 (Step 005510): Train loss 3.571, Val loss 3.711\n",
      "Ep 1 (Step 005515): Train loss 3.659, Val loss 3.681\n",
      "Ep 1 (Step 005520): Train loss 3.455, Val loss 3.683\n",
      "Ep 1 (Step 005525): Train loss 3.408, Val loss 3.690\n",
      "Ep 1 (Step 005530): Train loss 3.702, Val loss 3.715\n",
      "Ep 1 (Step 005535): Train loss 3.548, Val loss 3.680\n",
      "Ep 1 (Step 005540): Train loss 3.635, Val loss 3.668\n",
      "Ep 1 (Step 005545): Train loss 3.571, Val loss 3.679\n",
      "Ep 1 (Step 005550): Train loss 3.759, Val loss 3.688\n",
      "Ep 1 (Step 005555): Train loss 3.507, Val loss 3.678\n",
      "Ep 1 (Step 005560): Train loss 3.557, Val loss 3.671\n",
      "Ep 1 (Step 005565): Train loss 3.441, Val loss 3.686\n",
      "Ep 1 (Step 005570): Train loss 3.499, Val loss 3.663\n",
      "Ep 1 (Step 005575): Train loss 3.639, Val loss 3.703\n",
      "Ep 1 (Step 005580): Train loss 3.590, Val loss 3.730\n",
      "Ep 1 (Step 005585): Train loss 3.824, Val loss 3.756\n",
      "Ep 1 (Step 005590): Train loss 3.681, Val loss 3.685\n",
      "Ep 1 (Step 005595): Train loss 3.519, Val loss 3.679\n",
      "Ep 1 (Step 005600): Train loss 3.478, Val loss 3.715\n",
      "Ep 1 (Step 005605): Train loss 3.652, Val loss 3.720\n",
      "Ep 1 (Step 005610): Train loss 3.533, Val loss 3.688\n",
      "Ep 1 (Step 005615): Train loss 3.655, Val loss 3.668\n",
      "Ep 1 (Step 005620): Train loss 3.329, Val loss 3.668\n",
      "Ep 1 (Step 005625): Train loss 3.663, Val loss 3.699\n",
      "Ep 1 (Step 005630): Train loss 3.703, Val loss 3.691\n",
      "Ep 1 (Step 005635): Train loss 3.501, Val loss 3.741\n",
      "Ep 1 (Step 005640): Train loss 3.901, Val loss 3.709\n",
      "Ep 1 (Step 005645): Train loss 3.825, Val loss 3.697\n",
      "Ep 1 (Step 005650): Train loss 3.522, Val loss 3.686\n",
      "Ep 1 (Step 005655): Train loss 3.678, Val loss 3.665\n",
      "Ep 1 (Step 005660): Train loss 3.328, Val loss 3.662\n",
      "Ep 1 (Step 005665): Train loss 3.423, Val loss 3.650\n",
      "Ep 1 (Step 005670): Train loss 3.491, Val loss 3.651\n",
      "Ep 1 (Step 005675): Train loss 3.531, Val loss 3.667\n",
      "Ep 1 (Step 005680): Train loss 3.780, Val loss 3.650\n",
      "Ep 1 (Step 005685): Train loss 3.571, Val loss 3.639\n",
      "Ep 1 (Step 005690): Train loss 3.397, Val loss 3.628\n",
      "Ep 1 (Step 005695): Train loss 3.521, Val loss 3.648\n",
      "Ep 1 (Step 005700): Train loss 3.476, Val loss 3.630\n",
      "Ep 1 (Step 005705): Train loss 3.384, Val loss 3.641\n",
      "Ep 1 (Step 005710): Train loss 3.680, Val loss 3.649\n",
      "Ep 1 (Step 005715): Train loss 3.604, Val loss 3.654\n",
      "Ep 1 (Step 005720): Train loss 3.538, Val loss 3.636\n",
      "Ep 1 (Step 005725): Train loss 3.371, Val loss 3.637\n",
      "Ep 1 (Step 005730): Train loss 3.470, Val loss 3.640\n",
      "Ep 1 (Step 005735): Train loss 3.598, Val loss 3.621\n",
      "Ep 1 (Step 005740): Train loss 3.470, Val loss 3.603\n",
      "Ep 1 (Step 005745): Train loss 3.489, Val loss 3.613\n",
      "Ep 1 (Step 005750): Train loss 3.713, Val loss 3.623\n",
      "Ep 1 (Step 005755): Train loss 3.193, Val loss 3.614\n",
      "Ep 1 (Step 005760): Train loss 3.231, Val loss 3.613\n",
      "Ep 1 (Step 005765): Train loss 3.542, Val loss 3.620\n",
      "Ep 1 (Step 005770): Train loss 3.685, Val loss 3.612\n",
      "Ep 1 (Step 005775): Train loss 3.583, Val loss 3.586\n",
      "Ep 1 (Step 005780): Train loss 3.449, Val loss 3.594\n",
      "Ep 1 (Step 005785): Train loss 3.396, Val loss 3.587\n",
      "Ep 1 (Step 005790): Train loss 3.499, Val loss 3.574\n",
      "Ep 1 (Step 005795): Train loss 3.649, Val loss 3.593\n",
      "Ep 1 (Step 005800): Train loss 3.535, Val loss 3.610\n",
      "Ep 1 (Step 005805): Train loss 3.403, Val loss 3.607\n",
      "Ep 1 (Step 005810): Train loss 3.405, Val loss 3.604\n",
      "Ep 1 (Step 005815): Train loss 3.508, Val loss 3.600\n",
      "Ep 1 (Step 005820): Train loss 3.617, Val loss 3.598\n",
      "Ep 1 (Step 005825): Train loss 3.947, Val loss 3.608\n",
      "Ep 1 (Step 005830): Train loss 3.174, Val loss 3.599\n",
      "Ep 1 (Step 005835): Train loss 3.708, Val loss 3.617\n",
      "Ep 1 (Step 005840): Train loss 3.633, Val loss 3.647\n",
      "Ep 1 (Step 005845): Train loss 3.633, Val loss 3.643\n",
      "Ep 1 (Step 005850): Train loss 3.395, Val loss 3.640\n",
      "Ep 1 (Step 005855): Train loss 3.915, Val loss 3.636\n",
      "Ep 1 (Step 005860): Train loss 3.524, Val loss 3.653\n",
      "Ep 1 (Step 005865): Train loss 3.318, Val loss 3.637\n",
      "Ep 1 (Step 005870): Train loss 3.495, Val loss 3.631\n",
      "Ep 1 (Step 005875): Train loss 3.634, Val loss 3.612\n",
      "Ep 1 (Step 005880): Train loss 3.564, Val loss 3.593\n",
      "Ep 1 (Step 005885): Train loss 3.611, Val loss 3.652\n",
      "Ep 1 (Step 005890): Train loss 3.401, Val loss 3.697\n",
      "Ep 1 (Step 005895): Train loss 3.396, Val loss 3.675\n",
      "Ep 1 (Step 005900): Train loss 3.800, Val loss 3.693\n",
      "Ep 1 (Step 005905): Train loss 3.786, Val loss 3.702\n",
      "Ep 1 (Step 005910): Train loss 3.519, Val loss 3.709\n",
      "Ep 1 (Step 005915): Train loss 3.413, Val loss 3.681\n",
      "Ep 1 (Step 005920): Train loss 3.754, Val loss 3.675\n",
      "Ep 1 (Step 005925): Train loss 3.336, Val loss 3.680\n",
      "Ep 1 (Step 005930): Train loss 3.401, Val loss 3.677\n",
      "Ep 1 (Step 005935): Train loss 3.509, Val loss 3.681\n",
      "Ep 1 (Step 005940): Train loss 3.500, Val loss 3.677\n",
      "Ep 1 (Step 005945): Train loss 3.392, Val loss 3.685\n",
      "Ep 1 (Step 005950): Train loss 3.484, Val loss 3.686\n",
      "Ep 1 (Step 005955): Train loss 3.579, Val loss 3.675\n",
      "Ep 1 (Step 005960): Train loss 3.576, Val loss 3.668\n",
      "Ep 1 (Step 005965): Train loss 3.635, Val loss 3.659\n",
      "Ep 1 (Step 005970): Train loss 3.574, Val loss 3.655\n",
      "Ep 1 (Step 005975): Train loss 3.334, Val loss 3.644\n",
      "Ep 1 (Step 005980): Train loss 3.795, Val loss 3.640\n",
      "Ep 1 (Step 005985): Train loss 3.690, Val loss 3.643\n",
      "Ep 1 (Step 005990): Train loss 3.256, Val loss 3.633\n",
      "Ep 1 (Step 005995): Train loss 3.426, Val loss 3.628\n",
      "Ep 1 (Step 006000): Train loss 3.418, Val loss 3.637\n",
      "Ep 1 (Step 006005): Train loss 3.316, Val loss 3.630\n",
      "Ep 1 (Step 006010): Train loss 3.550, Val loss 3.626\n",
      "Ep 1 (Step 006015): Train loss 3.560, Val loss 3.594\n",
      "Ep 1 (Step 006020): Train loss 3.405, Val loss 3.593\n",
      "Ep 1 (Step 006025): Train loss 3.683, Val loss 3.590\n",
      "Ep 1 (Step 006030): Train loss 3.629, Val loss 3.574\n",
      "Ep 1 (Step 006035): Train loss 3.728, Val loss 3.577\n",
      "Ep 1 (Step 006040): Train loss 3.576, Val loss 3.584\n",
      "Ep 1 (Step 006045): Train loss 3.473, Val loss 3.610\n",
      "Ep 1 (Step 006050): Train loss 3.416, Val loss 3.630\n",
      "Ep 1 (Step 006055): Train loss 3.792, Val loss 3.613\n",
      "Ep 1 (Step 006060): Train loss 3.265, Val loss 3.600\n",
      "Ep 1 (Step 006065): Train loss 3.615, Val loss 3.583\n",
      "Ep 1 (Step 006070): Train loss 3.317, Val loss 3.597\n",
      "Ep 1 (Step 006075): Train loss 3.458, Val loss 3.598\n",
      "Ep 1 (Step 006080): Train loss 3.538, Val loss 3.605\n",
      "Ep 1 (Step 006085): Train loss 3.429, Val loss 3.620\n",
      "Ep 1 (Step 006090): Train loss 3.524, Val loss 3.616\n",
      "Ep 1 (Step 006095): Train loss 3.372, Val loss 3.594\n",
      "Ep 1 (Step 006100): Train loss 3.519, Val loss 3.582\n",
      "Ep 1 (Step 006105): Train loss 3.424, Val loss 3.584\n",
      "Ep 1 (Step 006110): Train loss 3.390, Val loss 3.560\n",
      "Ep 1 (Step 006115): Train loss 3.299, Val loss 3.582\n",
      "Ep 1 (Step 006120): Train loss 3.637, Val loss 3.608\n",
      "Ep 1 (Step 006125): Train loss 3.341, Val loss 3.555\n",
      "Ep 1 (Step 006130): Train loss 3.485, Val loss 3.523\n",
      "Ep 1 (Step 006135): Train loss 3.637, Val loss 3.523\n",
      "Ep 1 (Step 006140): Train loss 3.276, Val loss 3.553\n",
      "Ep 1 (Step 006145): Train loss 3.560, Val loss 3.570\n",
      "Ep 1 (Step 006150): Train loss 3.477, Val loss 3.572\n",
      "Ep 1 (Step 006155): Train loss 3.541, Val loss 3.578\n",
      "Ep 1 (Step 006160): Train loss 3.614, Val loss 3.580\n",
      "Ep 1 (Step 006165): Train loss 3.345, Val loss 3.567\n",
      "Ep 1 (Step 006170): Train loss 3.268, Val loss 3.560\n",
      "Ep 1 (Step 006175): Train loss 3.444, Val loss 3.564\n",
      "Ep 1 (Step 006180): Train loss 3.399, Val loss 3.575\n",
      "Ep 1 (Step 006185): Train loss 3.543, Val loss 3.593\n",
      "Ep 1 (Step 006190): Train loss 3.779, Val loss 3.595\n",
      "Ep 1 (Step 006195): Train loss 3.251, Val loss 3.554\n",
      "Ep 1 (Step 006200): Train loss 3.595, Val loss 3.558\n",
      "Ep 1 (Step 006205): Train loss 3.433, Val loss 3.565\n",
      "Ep 1 (Step 006210): Train loss 3.536, Val loss 3.553\n",
      "Ep 1 (Step 006215): Train loss 3.606, Val loss 3.548\n",
      "Ep 1 (Step 006220): Train loss 3.563, Val loss 3.551\n",
      "Ep 1 (Step 006225): Train loss 3.447, Val loss 3.560\n",
      "Ep 1 (Step 006230): Train loss 3.426, Val loss 3.557\n",
      "Ep 1 (Step 006235): Train loss 3.410, Val loss 3.565\n",
      "Ep 1 (Step 006240): Train loss 3.751, Val loss 3.573\n",
      "Ep 1 (Step 006245): Train loss 3.392, Val loss 3.577\n",
      "Ep 1 (Step 006250): Train loss 3.579, Val loss 3.567\n",
      "Ep 1 (Step 006255): Train loss 3.532, Val loss 3.592\n",
      "Ep 1 (Step 006260): Train loss 3.607, Val loss 3.597\n",
      "Ep 1 (Step 006265): Train loss 3.355, Val loss 3.624\n",
      "Ep 1 (Step 006270): Train loss 3.586, Val loss 3.641\n",
      "Ep 1 (Step 006275): Train loss 3.775, Val loss 3.642\n",
      "Ep 1 (Step 006280): Train loss 3.461, Val loss 3.627\n",
      "Ep 1 (Step 006285): Train loss 3.430, Val loss 3.604\n",
      "Ep 1 (Step 006290): Train loss 3.673, Val loss 3.642\n",
      "Ep 1 (Step 006295): Train loss 3.495, Val loss 3.668\n",
      "Ep 1 (Step 006300): Train loss 3.586, Val loss 3.637\n",
      "Ep 1 (Step 006305): Train loss 3.498, Val loss 3.629\n",
      "Ep 1 (Step 006310): Train loss 3.414, Val loss 3.641\n",
      "Ep 1 (Step 006315): Train loss 3.641, Val loss 3.635\n",
      "Ep 1 (Step 006320): Train loss 3.427, Val loss 3.624\n",
      "Ep 1 (Step 006325): Train loss 3.179, Val loss 3.617\n",
      "Ep 1 (Step 006330): Train loss 3.382, Val loss 3.623\n",
      "Ep 1 (Step 006335): Train loss 3.525, Val loss 3.648\n",
      "Ep 1 (Step 006340): Train loss 3.652, Val loss 3.637\n",
      "Ep 1 (Step 006345): Train loss 3.618, Val loss 3.618\n",
      "Ep 1 (Step 006350): Train loss 3.765, Val loss 3.618\n",
      "Ep 1 (Step 006355): Train loss 3.422, Val loss 3.597\n",
      "Ep 1 (Step 006360): Train loss 3.415, Val loss 3.592\n",
      "Ep 1 (Step 006365): Train loss 3.174, Val loss 3.610\n",
      "Ep 1 (Step 006370): Train loss 3.522, Val loss 3.616\n",
      "Ep 1 (Step 006375): Train loss 3.499, Val loss 3.620\n",
      "Ep 1 (Step 006380): Train loss 3.763, Val loss 3.599\n",
      "Ep 1 (Step 006385): Train loss 3.444, Val loss 3.586\n",
      "Ep 1 (Step 006390): Train loss 3.244, Val loss 3.578\n",
      "Ep 1 (Step 006395): Train loss 3.616, Val loss 3.566\n",
      "Ep 1 (Step 006400): Train loss 3.376, Val loss 3.558\n",
      "Ep 1 (Step 006405): Train loss 3.593, Val loss 3.567\n",
      "Ep 1 (Step 006410): Train loss 3.517, Val loss 3.570\n",
      "Ep 1 (Step 006415): Train loss 3.438, Val loss 3.564\n",
      "Ep 1 (Step 006420): Train loss 3.698, Val loss 3.560\n",
      "Ep 1 (Step 006425): Train loss 3.339, Val loss 3.571\n",
      "Ep 1 (Step 006430): Train loss 3.719, Val loss 3.571\n",
      "Ep 1 (Step 006435): Train loss 3.532, Val loss 3.557\n",
      "Ep 1 (Step 006440): Train loss 3.664, Val loss 3.553\n",
      "Ep 1 (Step 006445): Train loss 3.529, Val loss 3.558\n",
      "Ep 1 (Step 006450): Train loss 3.172, Val loss 3.534\n",
      "Ep 1 (Step 006455): Train loss 3.377, Val loss 3.530\n",
      "Ep 1 (Step 006460): Train loss 3.490, Val loss 3.534\n",
      "Ep 1 (Step 006465): Train loss 3.573, Val loss 3.559\n",
      "Ep 1 (Step 006470): Train loss 3.448, Val loss 3.587\n",
      "Ep 1 (Step 006475): Train loss 3.474, Val loss 3.609\n",
      "Ep 1 (Step 006480): Train loss 3.601, Val loss 3.595\n",
      "Ep 1 (Step 006485): Train loss 3.452, Val loss 3.585\n",
      "Ep 1 (Step 006490): Train loss 3.720, Val loss 3.567\n",
      "Ep 1 (Step 006495): Train loss 3.282, Val loss 3.552\n",
      "Ep 1 (Step 006500): Train loss 3.310, Val loss 3.554\n",
      "Ep 1 (Step 006505): Train loss 3.355, Val loss 3.541\n",
      "Ep 1 (Step 006510): Train loss 3.503, Val loss 3.540\n",
      "Ep 1 (Step 006515): Train loss 3.666, Val loss 3.533\n",
      "Ep 1 (Step 006520): Train loss 3.518, Val loss 3.540\n",
      "Ep 1 (Step 006525): Train loss 3.370, Val loss 3.551\n",
      "Ep 1 (Step 006530): Train loss 3.420, Val loss 3.524\n",
      "Ep 1 (Step 006535): Train loss 3.345, Val loss 3.514\n",
      "Ep 1 (Step 006540): Train loss 3.319, Val loss 3.513\n",
      "Ep 1 (Step 006545): Train loss 3.552, Val loss 3.528\n",
      "Ep 1 (Step 006550): Train loss 3.628, Val loss 3.562\n",
      "Ep 1 (Step 006555): Train loss 3.827, Val loss 3.552\n",
      "Ep 1 (Step 006560): Train loss 3.372, Val loss 3.522\n",
      "Ep 1 (Step 006565): Train loss 3.454, Val loss 3.518\n",
      "Ep 1 (Step 006570): Train loss 3.552, Val loss 3.522\n",
      "Ep 1 (Step 006575): Train loss 3.276, Val loss 3.527\n",
      "Ep 1 (Step 006580): Train loss 3.592, Val loss 3.510\n",
      "Ep 1 (Step 006585): Train loss 3.393, Val loss 3.506\n",
      "Ep 1 (Step 006590): Train loss 3.319, Val loss 3.511\n",
      "Ep 1 (Step 006595): Train loss 3.687, Val loss 3.497\n",
      "Ep 1 (Step 006600): Train loss 3.411, Val loss 3.493\n",
      "Ep 1 (Step 006605): Train loss 3.397, Val loss 3.494\n",
      "Ep 1 (Step 006610): Train loss 3.237, Val loss 3.513\n",
      "Ep 1 (Step 006615): Train loss 3.371, Val loss 3.502\n",
      "Ep 1 (Step 006620): Train loss 3.224, Val loss 3.480\n",
      "Ep 1 (Step 006625): Train loss 3.204, Val loss 3.494\n",
      "Ep 1 (Step 006630): Train loss 3.334, Val loss 3.502\n",
      "Ep 1 (Step 006635): Train loss 3.506, Val loss 3.502\n",
      "Ep 1 (Step 006640): Train loss 3.506, Val loss 3.508\n",
      "Ep 1 (Step 006645): Train loss 3.772, Val loss 3.484\n",
      "Ep 1 (Step 006650): Train loss 3.625, Val loss 3.458\n",
      "Ep 1 (Step 006655): Train loss 3.636, Val loss 3.468\n",
      "Ep 1 (Step 006660): Train loss 3.265, Val loss 3.460\n",
      "Ep 1 (Step 006665): Train loss 3.262, Val loss 3.469\n",
      "Ep 1 (Step 006670): Train loss 3.417, Val loss 3.473\n",
      "Ep 1 (Step 006675): Train loss 3.309, Val loss 3.458\n",
      "Ep 1 (Step 006680): Train loss 3.425, Val loss 3.450\n",
      "Ep 1 (Step 006685): Train loss 3.633, Val loss 3.450\n",
      "Ep 1 (Step 006690): Train loss 3.361, Val loss 3.471\n",
      "Ep 1 (Step 006695): Train loss 3.357, Val loss 3.481\n",
      "Ep 1 (Step 006700): Train loss 3.387, Val loss 3.475\n",
      "Ep 1 (Step 006705): Train loss 3.414, Val loss 3.466\n",
      "Ep 1 (Step 006710): Train loss 3.385, Val loss 3.469\n",
      "Ep 1 (Step 006715): Train loss 3.588, Val loss 3.477\n",
      "Ep 1 (Step 006720): Train loss 3.648, Val loss 3.471\n",
      "Ep 1 (Step 006725): Train loss 3.157, Val loss 3.466\n",
      "Ep 1 (Step 006730): Train loss 3.238, Val loss 3.474\n",
      "Ep 1 (Step 006735): Train loss 3.414, Val loss 3.478\n",
      "Ep 1 (Step 006740): Train loss 3.187, Val loss 3.477\n",
      "Ep 1 (Step 006745): Train loss 3.533, Val loss 3.495\n",
      "Ep 1 (Step 006750): Train loss 3.565, Val loss 3.503\n",
      "Ep 1 (Step 006755): Train loss 3.115, Val loss 3.491\n",
      "Ep 1 (Step 006760): Train loss 3.688, Val loss 3.476\n",
      "Ep 1 (Step 006765): Train loss 3.101, Val loss 3.468\n",
      "Ep 1 (Step 006770): Train loss 3.583, Val loss 3.465\n",
      "Ep 1 (Step 006775): Train loss 3.200, Val loss 3.462\n",
      "Ep 1 (Step 006780): Train loss 3.303, Val loss 3.479\n",
      "Ep 1 (Step 006785): Train loss 3.613, Val loss 3.497\n",
      "Ep 1 (Step 006790): Train loss 3.364, Val loss 3.504\n",
      "Ep 1 (Step 006795): Train loss 3.380, Val loss 3.518\n",
      "Ep 1 (Step 006800): Train loss 3.584, Val loss 3.518\n",
      "Ep 1 (Step 006805): Train loss 3.424, Val loss 3.517\n",
      "Ep 1 (Step 006810): Train loss 3.525, Val loss 3.531\n",
      "Ep 1 (Step 006815): Train loss 3.300, Val loss 3.523\n",
      "Ep 1 (Step 006820): Train loss 3.379, Val loss 3.509\n",
      "Ep 1 (Step 006825): Train loss 3.269, Val loss 3.500\n",
      "Ep 1 (Step 006830): Train loss 3.709, Val loss 3.520\n",
      "Ep 1 (Step 006835): Train loss 3.349, Val loss 3.515\n",
      "Ep 1 (Step 006840): Train loss 3.309, Val loss 3.495\n",
      "Ep 1 (Step 006845): Train loss 3.522, Val loss 3.488\n",
      "Ep 1 (Step 006850): Train loss 3.364, Val loss 3.487\n",
      "Ep 1 (Step 006855): Train loss 3.595, Val loss 3.485\n",
      "Ep 1 (Step 006860): Train loss 3.565, Val loss 3.495\n",
      "Ep 1 (Step 006865): Train loss 3.380, Val loss 3.505\n",
      "Ep 1 (Step 006870): Train loss 3.422, Val loss 3.466\n",
      "Ep 1 (Step 006875): Train loss 3.612, Val loss 3.476\n",
      "Ep 1 (Step 006880): Train loss 3.178, Val loss 3.480\n",
      "Ep 1 (Step 006885): Train loss 3.346, Val loss 3.467\n",
      "Ep 1 (Step 006890): Train loss 3.343, Val loss 3.480\n",
      "Ep 1 (Step 006895): Train loss 3.943, Val loss 3.482\n",
      "Ep 1 (Step 006900): Train loss 3.308, Val loss 3.491\n",
      "Ep 1 (Step 006905): Train loss 3.366, Val loss 3.483\n",
      "Ep 1 (Step 006910): Train loss 3.407, Val loss 3.492\n",
      "Ep 1 (Step 006915): Train loss 3.787, Val loss 3.497\n",
      "Ep 1 (Step 006920): Train loss 3.130, Val loss 3.479\n",
      "Ep 1 (Step 006925): Train loss 3.398, Val loss 3.458\n",
      "Ep 1 (Step 006930): Train loss 3.401, Val loss 3.464\n",
      "Ep 1 (Step 006935): Train loss 3.317, Val loss 3.484\n",
      "Ep 1 (Step 006940): Train loss 3.360, Val loss 3.493\n",
      "Ep 1 (Step 006945): Train loss 3.289, Val loss 3.470\n",
      "Ep 1 (Step 006950): Train loss 3.374, Val loss 3.450\n",
      "Ep 1 (Step 006955): Train loss 3.553, Val loss 3.462\n",
      "Ep 1 (Step 006960): Train loss 3.487, Val loss 3.471\n",
      "Ep 1 (Step 006965): Train loss 3.380, Val loss 3.479\n",
      "Ep 1 (Step 006970): Train loss 3.302, Val loss 3.480\n",
      "Ep 1 (Step 006975): Train loss 3.324, Val loss 3.483\n",
      "Ep 1 (Step 006980): Train loss 3.546, Val loss 3.494\n",
      "Ep 1 (Step 006985): Train loss 3.801, Val loss 3.508\n",
      "Ep 1 (Step 006990): Train loss 3.465, Val loss 3.467\n",
      "Ep 1 (Step 006995): Train loss 3.351, Val loss 3.466\n",
      "Ep 1 (Step 007000): Train loss 3.470, Val loss 3.502\n",
      "Ep 1 (Step 007005): Train loss 3.560, Val loss 3.488\n",
      "Ep 1 (Step 007010): Train loss 3.302, Val loss 3.471\n",
      "Ep 1 (Step 007015): Train loss 3.346, Val loss 3.454\n",
      "Ep 1 (Step 007020): Train loss 3.479, Val loss 3.456\n",
      "Ep 1 (Step 007025): Train loss 3.344, Val loss 3.454\n",
      "Ep 1 (Step 007030): Train loss 3.528, Val loss 3.470\n",
      "Ep 1 (Step 007035): Train loss 3.402, Val loss 3.486\n",
      "Ep 1 (Step 007040): Train loss 3.508, Val loss 3.485\n",
      "Ep 1 (Step 007045): Train loss 3.419, Val loss 3.472\n",
      "Ep 1 (Step 007050): Train loss 3.274, Val loss 3.464\n",
      "Ep 1 (Step 007055): Train loss 3.546, Val loss 3.470\n",
      "Ep 1 (Step 007060): Train loss 3.576, Val loss 3.500\n",
      "Ep 1 (Step 007065): Train loss 3.276, Val loss 3.492\n",
      "Ep 1 (Step 007070): Train loss 3.280, Val loss 3.496\n",
      "Ep 1 (Step 007075): Train loss 3.193, Val loss 3.515\n",
      "Ep 1 (Step 007080): Train loss 3.304, Val loss 3.537\n",
      "Ep 1 (Step 007085): Train loss 3.313, Val loss 3.494\n",
      "Ep 1 (Step 007090): Train loss 3.547, Val loss 3.485\n",
      "Ep 1 (Step 007095): Train loss 3.093, Val loss 3.513\n",
      "Ep 1 (Step 007100): Train loss 3.596, Val loss 3.517\n",
      "Ep 1 (Step 007105): Train loss 3.375, Val loss 3.474\n",
      "Ep 1 (Step 007110): Train loss 3.522, Val loss 3.477\n",
      "Ep 1 (Step 007115): Train loss 3.081, Val loss 3.476\n",
      "Ep 1 (Step 007120): Train loss 3.350, Val loss 3.494\n",
      "Ep 1 (Step 007125): Train loss 3.214, Val loss 3.489\n",
      "Ep 1 (Step 007130): Train loss 3.170, Val loss 3.477\n",
      "Ep 1 (Step 007135): Train loss 3.229, Val loss 3.493\n",
      "Ep 1 (Step 007140): Train loss 3.434, Val loss 3.463\n",
      "Ep 1 (Step 007145): Train loss 3.581, Val loss 3.458\n",
      "Ep 1 (Step 007150): Train loss 3.501, Val loss 3.465\n",
      "Ep 1 (Step 007155): Train loss 3.427, Val loss 3.434\n",
      "Ep 1 (Step 007160): Train loss 3.267, Val loss 3.444\n",
      "Ep 1 (Step 007165): Train loss 3.436, Val loss 3.457\n",
      "Ep 1 (Step 007170): Train loss 3.264, Val loss 3.456\n",
      "Ep 1 (Step 007175): Train loss 3.542, Val loss 3.457\n",
      "Ep 1 (Step 007180): Train loss 3.371, Val loss 3.461\n",
      "Ep 1 (Step 007185): Train loss 3.485, Val loss 3.463\n",
      "Ep 1 (Step 007190): Train loss 3.419, Val loss 3.451\n",
      "Ep 1 (Step 007195): Train loss 3.315, Val loss 3.447\n",
      "Ep 1 (Step 007200): Train loss 3.538, Val loss 3.447\n",
      "Ep 1 (Step 007205): Train loss 3.653, Val loss 3.464\n",
      "Ep 1 (Step 007210): Train loss 3.281, Val loss 3.436\n",
      "Ep 1 (Step 007215): Train loss 3.296, Val loss 3.428\n",
      "Ep 1 (Step 007220): Train loss 3.242, Val loss 3.428\n",
      "Ep 1 (Step 007225): Train loss 3.265, Val loss 3.432\n",
      "Ep 1 (Step 007230): Train loss 3.365, Val loss 3.430\n",
      "Ep 1 (Step 007235): Train loss 3.239, Val loss 3.440\n",
      "Ep 1 (Step 007240): Train loss 3.258, Val loss 3.432\n",
      "Ep 1 (Step 007245): Train loss 3.294, Val loss 3.430\n",
      "Ep 1 (Step 007250): Train loss 3.591, Val loss 3.434\n",
      "Ep 1 (Step 007255): Train loss 3.524, Val loss 3.441\n",
      "Ep 1 (Step 007260): Train loss 2.932, Val loss 3.442\n",
      "Ep 1 (Step 007265): Train loss 3.357, Val loss 3.440\n",
      "Ep 1 (Step 007270): Train loss 3.443, Val loss 3.436\n",
      "Ep 1 (Step 007275): Train loss 3.260, Val loss 3.433\n",
      "Ep 1 (Step 007280): Train loss 3.469, Val loss 3.444\n",
      "Ep 1 (Step 007285): Train loss 3.434, Val loss 3.441\n",
      "Ep 1 (Step 007290): Train loss 3.287, Val loss 3.441\n",
      "Ep 1 (Step 007295): Train loss 3.378, Val loss 3.440\n",
      "Ep 1 (Step 007300): Train loss 3.346, Val loss 3.455\n",
      "Ep 1 (Step 007305): Train loss 3.169, Val loss 3.435\n",
      "Ep 1 (Step 007310): Train loss 3.182, Val loss 3.420\n",
      "Ep 1 (Step 007315): Train loss 3.335, Val loss 3.412\n",
      "Ep 1 (Step 007320): Train loss 3.413, Val loss 3.418\n",
      "Ep 1 (Step 007325): Train loss 3.422, Val loss 3.434\n",
      "Ep 1 (Step 007330): Train loss 3.523, Val loss 3.434\n",
      "Ep 1 (Step 007335): Train loss 3.354, Val loss 3.427\n",
      "Ep 1 (Step 007340): Train loss 3.255, Val loss 3.424\n",
      "Ep 1 (Step 007345): Train loss 3.186, Val loss 3.431\n",
      "Ep 1 (Step 007350): Train loss 3.270, Val loss 3.447\n",
      "Ep 1 (Step 007355): Train loss 3.571, Val loss 3.449\n",
      "Ep 1 (Step 007360): Train loss 3.576, Val loss 3.453\n",
      "Ep 1 (Step 007365): Train loss 3.460, Val loss 3.436\n",
      "Ep 1 (Step 007370): Train loss 3.197, Val loss 3.440\n",
      "Ep 1 (Step 007375): Train loss 3.439, Val loss 3.462\n",
      "Ep 1 (Step 007380): Train loss 3.172, Val loss 3.457\n",
      "Ep 1 (Step 007385): Train loss 3.188, Val loss 3.447\n",
      "Ep 1 (Step 007390): Train loss 3.483, Val loss 3.435\n",
      "Ep 1 (Step 007395): Train loss 3.164, Val loss 3.441\n",
      "Ep 1 (Step 007400): Train loss 2.994, Val loss 3.440\n",
      "Ep 1 (Step 007405): Train loss 3.369, Val loss 3.451\n",
      "Ep 1 (Step 007410): Train loss 3.270, Val loss 3.481\n",
      "Ep 1 (Step 007415): Train loss 3.601, Val loss 3.452\n",
      "Ep 1 (Step 007420): Train loss 3.988, Val loss 3.444\n",
      "Ep 1 (Step 007425): Train loss 3.310, Val loss 3.426\n",
      "Ep 1 (Step 007430): Train loss 3.361, Val loss 3.430\n",
      "Ep 1 (Step 007435): Train loss 3.395, Val loss 3.445\n",
      "Ep 1 (Step 007440): Train loss 3.464, Val loss 3.453\n",
      "Ep 1 (Step 007445): Train loss 3.176, Val loss 3.429\n",
      "Ep 1 (Step 007450): Train loss 3.442, Val loss 3.420\n",
      "Ep 1 (Step 007455): Train loss 3.366, Val loss 3.447\n",
      "Ep 1 (Step 007460): Train loss 3.012, Val loss 3.463\n",
      "Ep 1 (Step 007465): Train loss 3.112, Val loss 3.479\n",
      "Ep 1 (Step 007470): Train loss 3.443, Val loss 3.479\n",
      "Ep 1 (Step 007475): Train loss 3.408, Val loss 3.459\n",
      "Ep 1 (Step 007480): Train loss 3.374, Val loss 3.445\n",
      "Ep 1 (Step 007485): Train loss 3.339, Val loss 3.434\n",
      "Ep 1 (Step 007490): Train loss 3.515, Val loss 3.425\n",
      "Ep 1 (Step 007495): Train loss 3.309, Val loss 3.450\n",
      "Ep 1 (Step 007500): Train loss 3.431, Val loss 3.466\n",
      "Ep 1 (Step 007505): Train loss 3.235, Val loss 3.451\n",
      "Ep 1 (Step 007510): Train loss 3.401, Val loss 3.480\n",
      "Ep 1 (Step 007515): Train loss 3.653, Val loss 3.524\n",
      "Ep 1 (Step 007520): Train loss 3.557, Val loss 3.489\n",
      "Ep 1 (Step 007525): Train loss 3.496, Val loss 3.487\n",
      "Ep 1 (Step 007530): Train loss 3.576, Val loss 3.472\n",
      "Ep 1 (Step 007535): Train loss 3.036, Val loss 3.466\n",
      "Ep 1 (Step 007540): Train loss 3.546, Val loss 3.455\n",
      "Ep 1 (Step 007545): Train loss 3.695, Val loss 3.461\n",
      "Ep 1 (Step 007550): Train loss 3.306, Val loss 3.460\n",
      "Ep 1 (Step 007555): Train loss 3.349, Val loss 3.484\n",
      "Ep 1 (Step 007560): Train loss 3.482, Val loss 3.474\n",
      "Ep 1 (Step 007565): Train loss 3.240, Val loss 3.467\n",
      "Ep 1 (Step 007570): Train loss 3.425, Val loss 3.445\n",
      "Ep 1 (Step 007575): Train loss 3.307, Val loss 3.465\n",
      "Ep 1 (Step 007580): Train loss 3.777, Val loss 3.476\n",
      "Ep 1 (Step 007585): Train loss 3.314, Val loss 3.467\n",
      "Ep 1 (Step 007590): Train loss 3.669, Val loss 3.475\n",
      "Ep 1 (Step 007595): Train loss 3.671, Val loss 3.480\n",
      "Ep 1 (Step 007600): Train loss 3.300, Val loss 3.462\n",
      "Ep 1 (Step 007605): Train loss 3.458, Val loss 3.460\n",
      "Ep 1 (Step 007610): Train loss 3.527, Val loss 3.456\n",
      "Ep 1 (Step 007615): Train loss 3.163, Val loss 3.459\n",
      "Ep 1 (Step 007620): Train loss 3.293, Val loss 3.444\n",
      "Ep 1 (Step 007625): Train loss 3.444, Val loss 3.431\n",
      "Ep 1 (Step 007630): Train loss 3.315, Val loss 3.440\n",
      "Ep 1 (Step 007635): Train loss 3.332, Val loss 3.454\n",
      "Ep 1 (Step 007640): Train loss 3.460, Val loss 3.436\n",
      "Ep 1 (Step 007645): Train loss 3.332, Val loss 3.427\n",
      "Ep 1 (Step 007650): Train loss 3.450, Val loss 3.436\n",
      "Ep 1 (Step 007655): Train loss 3.593, Val loss 3.439\n",
      "Ep 1 (Step 007660): Train loss 3.444, Val loss 3.425\n",
      "Ep 1 (Step 007665): Train loss 3.449, Val loss 3.434\n",
      "Ep 1 (Step 007670): Train loss 3.336, Val loss 3.410\n",
      "Ep 1 (Step 007675): Train loss 3.403, Val loss 3.400\n",
      "Ep 1 (Step 007680): Train loss 3.475, Val loss 3.398\n",
      "Ep 1 (Step 007685): Train loss 3.447, Val loss 3.394\n",
      "Ep 1 (Step 007690): Train loss 3.059, Val loss 3.396\n",
      "Ep 1 (Step 007695): Train loss 3.281, Val loss 3.400\n",
      "Ep 1 (Step 007700): Train loss 3.345, Val loss 3.414\n",
      "Ep 1 (Step 007705): Train loss 3.364, Val loss 3.421\n",
      "Ep 1 (Step 007710): Train loss 3.407, Val loss 3.439\n",
      "Ep 1 (Step 007715): Train loss 3.574, Val loss 3.443\n",
      "Ep 1 (Step 007720): Train loss 3.108, Val loss 3.430\n",
      "Ep 1 (Step 007725): Train loss 3.143, Val loss 3.417\n",
      "Ep 1 (Step 007730): Train loss 3.463, Val loss 3.417\n",
      "Ep 1 (Step 007735): Train loss 3.508, Val loss 3.426\n",
      "Ep 1 (Step 007740): Train loss 3.430, Val loss 3.420\n",
      "Ep 1 (Step 007745): Train loss 3.373, Val loss 3.413\n",
      "Ep 1 (Step 007750): Train loss 3.305, Val loss 3.432\n",
      "Ep 1 (Step 007755): Train loss 3.127, Val loss 3.414\n",
      "Ep 1 (Step 007760): Train loss 3.364, Val loss 3.411\n",
      "Ep 1 (Step 007765): Train loss 3.634, Val loss 3.391\n",
      "Ep 1 (Step 007770): Train loss 3.301, Val loss 3.397\n",
      "Ep 1 (Step 007775): Train loss 3.312, Val loss 3.386\n",
      "Ep 1 (Step 007780): Train loss 3.601, Val loss 3.384\n",
      "Ep 1 (Step 007785): Train loss 3.187, Val loss 3.382\n",
      "Ep 1 (Step 007790): Train loss 3.589, Val loss 3.401\n",
      "Ep 1 (Step 007795): Train loss 3.257, Val loss 3.414\n",
      "Ep 1 (Step 007800): Train loss 3.569, Val loss 3.409\n",
      "Ep 1 (Step 007805): Train loss 3.208, Val loss 3.392\n",
      "Ep 1 (Step 007810): Train loss 3.559, Val loss 3.403\n",
      "Ep 1 (Step 007815): Train loss 3.419, Val loss 3.419\n",
      "Ep 1 (Step 007820): Train loss 3.469, Val loss 3.440\n",
      "Ep 1 (Step 007825): Train loss 3.525, Val loss 3.427\n",
      "Ep 1 (Step 007830): Train loss 3.414, Val loss 3.428\n",
      "Ep 1 (Step 007835): Train loss 3.374, Val loss 3.453\n",
      "Ep 1 (Step 007840): Train loss 3.486, Val loss 3.469\n",
      "Ep 1 (Step 007845): Train loss 3.210, Val loss 3.487\n",
      "Ep 1 (Step 007850): Train loss 3.615, Val loss 3.459\n",
      "Ep 1 (Step 007855): Train loss 3.384, Val loss 3.451\n",
      "Ep 1 (Step 007860): Train loss 3.243, Val loss 3.421\n",
      "Ep 1 (Step 007865): Train loss 3.133, Val loss 3.415\n",
      "Ep 1 (Step 007870): Train loss 3.432, Val loss 3.441\n",
      "Ep 1 (Step 007875): Train loss 3.295, Val loss 3.450\n",
      "Ep 1 (Step 007880): Train loss 3.313, Val loss 3.447\n",
      "Ep 1 (Step 007885): Train loss 3.302, Val loss 3.431\n",
      "Ep 1 (Step 007890): Train loss 3.209, Val loss 3.433\n",
      "Ep 1 (Step 007895): Train loss 3.272, Val loss 3.422\n",
      "Ep 1 (Step 007900): Train loss 3.361, Val loss 3.428\n",
      "Ep 1 (Step 007905): Train loss 3.192, Val loss 3.441\n",
      "Ep 1 (Step 007910): Train loss 3.489, Val loss 3.426\n",
      "Ep 1 (Step 007915): Train loss 3.159, Val loss 3.415\n",
      "Ep 1 (Step 007920): Train loss 3.748, Val loss 3.400\n",
      "Ep 1 (Step 007925): Train loss 3.626, Val loss 3.388\n",
      "Ep 1 (Step 007930): Train loss 3.308, Val loss 3.375\n",
      "Ep 1 (Step 007935): Train loss 3.308, Val loss 3.373\n",
      "Ep 1 (Step 007940): Train loss 3.353, Val loss 3.373\n",
      "Ep 1 (Step 007945): Train loss 3.294, Val loss 3.371\n",
      "Ep 1 (Step 007950): Train loss 3.599, Val loss 3.380\n",
      "Ep 1 (Step 007955): Train loss 3.356, Val loss 3.386\n",
      "Ep 1 (Step 007960): Train loss 2.785, Val loss 3.387\n",
      "Ep 1 (Step 007965): Train loss 3.336, Val loss 3.424\n",
      "Ep 1 (Step 007970): Train loss 3.656, Val loss 3.446\n",
      "Ep 1 (Step 007975): Train loss 3.267, Val loss 3.444\n",
      "Ep 1 (Step 007980): Train loss 3.480, Val loss 3.429\n",
      "Ep 1 (Step 007985): Train loss 3.415, Val loss 3.422\n",
      "Ep 1 (Step 007990): Train loss 3.605, Val loss 3.412\n",
      "Ep 1 (Step 007995): Train loss 3.267, Val loss 3.385\n",
      "Ep 1 (Step 008000): Train loss 4.007, Val loss 3.381\n",
      "Ep 1 (Step 008005): Train loss 3.408, Val loss 3.406\n",
      "Ep 1 (Step 008010): Train loss 3.752, Val loss 3.412\n",
      "Ep 1 (Step 008015): Train loss 3.606, Val loss 3.397\n",
      "Ep 1 (Step 008020): Train loss 3.239, Val loss 3.392\n",
      "Ep 1 (Step 008025): Train loss 3.593, Val loss 3.400\n",
      "Ep 1 (Step 008030): Train loss 3.617, Val loss 3.408\n",
      "Ep 1 (Step 008035): Train loss 3.310, Val loss 3.401\n",
      "Ep 1 (Step 008040): Train loss 3.675, Val loss 3.399\n",
      "Ep 1 (Step 008045): Train loss 3.194, Val loss 3.415\n",
      "Ep 1 (Step 008050): Train loss 3.393, Val loss 3.428\n",
      "Ep 1 (Step 008055): Train loss 3.243, Val loss 3.416\n",
      "Ep 1 (Step 008060): Train loss 3.232, Val loss 3.407\n",
      "Ep 1 (Step 008065): Train loss 3.449, Val loss 3.394\n",
      "Ep 1 (Step 008070): Train loss 3.663, Val loss 3.397\n",
      "Ep 1 (Step 008075): Train loss 3.291, Val loss 3.407\n",
      "Ep 1 (Step 008080): Train loss 3.119, Val loss 3.390\n",
      "Ep 1 (Step 008085): Train loss 3.218, Val loss 3.379\n",
      "Ep 1 (Step 008090): Train loss 3.529, Val loss 3.369\n",
      "Ep 1 (Step 008095): Train loss 3.344, Val loss 3.376\n",
      "Ep 1 (Step 008100): Train loss 3.473, Val loss 3.381\n",
      "Ep 1 (Step 008105): Train loss 3.454, Val loss 3.395\n",
      "Ep 1 (Step 008110): Train loss 3.320, Val loss 3.411\n",
      "Ep 1 (Step 008115): Train loss 3.136, Val loss 3.417\n",
      "Ep 1 (Step 008120): Train loss 3.597, Val loss 3.385\n",
      "Ep 1 (Step 008125): Train loss 3.348, Val loss 3.384\n",
      "Ep 1 (Step 008130): Train loss 3.510, Val loss 3.388\n",
      "Ep 1 (Step 008135): Train loss 3.237, Val loss 3.389\n",
      "Ep 1 (Step 008140): Train loss 3.344, Val loss 3.391\n",
      "Ep 1 (Step 008145): Train loss 3.720, Val loss 3.396\n",
      "Ep 1 (Step 008150): Train loss 3.266, Val loss 3.373\n",
      "Ep 1 (Step 008155): Train loss 3.420, Val loss 3.366\n",
      "Ep 1 (Step 008160): Train loss 3.301, Val loss 3.371\n",
      "Ep 1 (Step 008165): Train loss 3.139, Val loss 3.396\n",
      "Ep 1 (Step 008170): Train loss 3.469, Val loss 3.387\n",
      "Ep 1 (Step 008175): Train loss 3.094, Val loss 3.385\n",
      "Ep 1 (Step 008180): Train loss 3.299, Val loss 3.385\n",
      "Ep 1 (Step 008185): Train loss 3.303, Val loss 3.404\n",
      "Ep 1 (Step 008190): Train loss 3.317, Val loss 3.426\n",
      "Ep 1 (Step 008195): Train loss 3.160, Val loss 3.418\n",
      "Ep 1 (Step 008200): Train loss 3.056, Val loss 3.398\n",
      "Ep 1 (Step 008205): Train loss 3.180, Val loss 3.387\n",
      "Ep 1 (Step 008210): Train loss 2.921, Val loss 3.384\n",
      "Ep 1 (Step 008215): Train loss 3.085, Val loss 3.380\n",
      "Ep 1 (Step 008220): Train loss 3.154, Val loss 3.379\n",
      "Ep 1 (Step 008225): Train loss 3.057, Val loss 3.375\n",
      "Ep 1 (Step 008230): Train loss 3.429, Val loss 3.352\n",
      "Ep 1 (Step 008235): Train loss 3.589, Val loss 3.348\n",
      "Ep 1 (Step 008240): Train loss 3.208, Val loss 3.348\n",
      "Ep 1 (Step 008245): Train loss 3.327, Val loss 3.358\n",
      "Ep 1 (Step 008250): Train loss 3.171, Val loss 3.363\n",
      "Ep 1 (Step 008255): Train loss 3.166, Val loss 3.354\n",
      "Ep 1 (Step 008260): Train loss 3.130, Val loss 3.347\n",
      "Ep 1 (Step 008265): Train loss 3.570, Val loss 3.356\n",
      "Ep 1 (Step 008270): Train loss 3.384, Val loss 3.358\n",
      "Ep 1 (Step 008275): Train loss 3.269, Val loss 3.361\n",
      "Ep 1 (Step 008280): Train loss 3.314, Val loss 3.374\n",
      "Ep 1 (Step 008285): Train loss 3.313, Val loss 3.374\n",
      "Ep 1 (Step 008290): Train loss 3.635, Val loss 3.372\n",
      "Ep 1 (Step 008295): Train loss 3.231, Val loss 3.376\n",
      "Ep 1 (Step 008300): Train loss 3.254, Val loss 3.386\n",
      "Ep 1 (Step 008305): Train loss 3.128, Val loss 3.386\n",
      "Ep 1 (Step 008310): Train loss 3.294, Val loss 3.382\n",
      "Ep 1 (Step 008315): Train loss 3.373, Val loss 3.368\n",
      "Ep 1 (Step 008320): Train loss 3.439, Val loss 3.367\n",
      "Ep 1 (Step 008325): Train loss 3.379, Val loss 3.387\n",
      "Ep 1 (Step 008330): Train loss 3.127, Val loss 3.401\n",
      "Ep 1 (Step 008335): Train loss 3.374, Val loss 3.393\n",
      "Ep 1 (Step 008340): Train loss 3.217, Val loss 3.386\n",
      "Ep 1 (Step 008345): Train loss 3.059, Val loss 3.385\n",
      "Ep 1 (Step 008350): Train loss 3.405, Val loss 3.376\n",
      "Ep 1 (Step 008355): Train loss 3.190, Val loss 3.368\n",
      "Ep 1 (Step 008360): Train loss 3.318, Val loss 3.381\n",
      "Ep 1 (Step 008365): Train loss 3.500, Val loss 3.413\n",
      "Ep 1 (Step 008370): Train loss 3.026, Val loss 3.397\n",
      "Ep 1 (Step 008375): Train loss 3.433, Val loss 3.373\n",
      "Ep 1 (Step 008380): Train loss 3.311, Val loss 3.374\n",
      "Ep 1 (Step 008385): Train loss 3.166, Val loss 3.370\n",
      "Ep 1 (Step 008390): Train loss 3.083, Val loss 3.370\n",
      "Ep 1 (Step 008395): Train loss 3.267, Val loss 3.386\n",
      "Ep 1 (Step 008400): Train loss 3.236, Val loss 3.401\n",
      "Ep 1 (Step 008405): Train loss 3.217, Val loss 3.390\n",
      "Ep 1 (Step 008410): Train loss 3.527, Val loss 3.375\n",
      "Ep 1 (Step 008415): Train loss 3.147, Val loss 3.372\n",
      "Ep 1 (Step 008420): Train loss 3.137, Val loss 3.382\n",
      "Ep 1 (Step 008425): Train loss 3.186, Val loss 3.396\n",
      "Ep 1 (Step 008430): Train loss 3.160, Val loss 3.413\n",
      "Ep 1 (Step 008435): Train loss 3.505, Val loss 3.417\n",
      "Ep 1 (Step 008440): Train loss 3.490, Val loss 3.410\n",
      "Ep 1 (Step 008445): Train loss 3.286, Val loss 3.382\n",
      "Ep 1 (Step 008450): Train loss 3.283, Val loss 3.373\n",
      "Ep 1 (Step 008455): Train loss 3.184, Val loss 3.375\n",
      "Ep 1 (Step 008460): Train loss 2.997, Val loss 3.389\n",
      "Ep 1 (Step 008465): Train loss 3.308, Val loss 3.392\n",
      "Ep 1 (Step 008470): Train loss 2.993, Val loss 3.390\n",
      "Ep 1 (Step 008475): Train loss 3.221, Val loss 3.387\n",
      "Ep 1 (Step 008480): Train loss 3.067, Val loss 3.401\n",
      "Ep 1 (Step 008485): Train loss 3.141, Val loss 3.418\n",
      "Ep 1 (Step 008490): Train loss 3.173, Val loss 3.413\n",
      "Ep 1 (Step 008495): Train loss 3.389, Val loss 3.381\n",
      "Ep 1 (Step 008500): Train loss 3.280, Val loss 3.373\n",
      "Ep 1 (Step 008505): Train loss 3.358, Val loss 3.379\n",
      "Ep 1 (Step 008510): Train loss 3.031, Val loss 3.383\n",
      "Ep 1 (Step 008515): Train loss 3.277, Val loss 3.397\n",
      "Ep 1 (Step 008520): Train loss 3.241, Val loss 3.407\n",
      "Ep 1 (Step 008525): Train loss 3.362, Val loss 3.416\n",
      "Ep 1 (Step 008530): Train loss 3.167, Val loss 3.400\n",
      "Ep 1 (Step 008535): Train loss 3.337, Val loss 3.380\n",
      "Ep 1 (Step 008540): Train loss 3.208, Val loss 3.381\n",
      "Ep 1 (Step 008545): Train loss 3.197, Val loss 3.381\n",
      "Ep 1 (Step 008550): Train loss 3.321, Val loss 3.376\n",
      "Ep 1 (Step 008555): Train loss 3.431, Val loss 3.389\n",
      "Ep 1 (Step 008560): Train loss 3.264, Val loss 3.387\n",
      "Ep 1 (Step 008565): Train loss 3.307, Val loss 3.366\n",
      "Ep 1 (Step 008570): Train loss 3.182, Val loss 3.370\n",
      "Ep 1 (Step 008575): Train loss 3.228, Val loss 3.366\n",
      "Ep 1 (Step 008580): Train loss 3.481, Val loss 3.355\n",
      "Ep 1 (Step 008585): Train loss 3.303, Val loss 3.357\n",
      "Ep 1 (Step 008590): Train loss 3.246, Val loss 3.349\n",
      "Ep 1 (Step 008595): Train loss 3.575, Val loss 3.342\n",
      "Ep 1 (Step 008600): Train loss 3.217, Val loss 3.350\n",
      "Ep 1 (Step 008605): Train loss 3.377, Val loss 3.354\n",
      "Ep 1 (Step 008610): Train loss 3.436, Val loss 3.363\n",
      "Ep 1 (Step 008615): Train loss 3.125, Val loss 3.359\n",
      "Ep 1 (Step 008620): Train loss 3.252, Val loss 3.370\n",
      "Ep 1 (Step 008625): Train loss 3.403, Val loss 3.378\n",
      "Ep 1 (Step 008630): Train loss 3.270, Val loss 3.380\n",
      "Ep 1 (Step 008635): Train loss 3.430, Val loss 3.362\n",
      "Ep 1 (Step 008640): Train loss 3.265, Val loss 3.361\n",
      "Ep 1 (Step 008645): Train loss 3.362, Val loss 3.362\n",
      "Ep 1 (Step 008650): Train loss 3.282, Val loss 3.351\n",
      "Ep 1 (Step 008655): Train loss 3.101, Val loss 3.361\n",
      "Ep 1 (Step 008660): Train loss 3.344, Val loss 3.357\n",
      "Ep 1 (Step 008665): Train loss 3.208, Val loss 3.369\n",
      "Ep 1 (Step 008670): Train loss 3.289, Val loss 3.395\n",
      "Ep 1 (Step 008675): Train loss 3.393, Val loss 3.368\n",
      "Ep 1 (Step 008680): Train loss 3.113, Val loss 3.364\n",
      "Ep 1 (Step 008685): Train loss 3.113, Val loss 3.357\n",
      "Ep 1 (Step 008690): Train loss 3.413, Val loss 3.371\n",
      "Ep 1 (Step 008695): Train loss 3.226, Val loss 3.382\n",
      "Ep 1 (Step 008700): Train loss 3.412, Val loss 3.396\n",
      "Ep 1 (Step 008705): Train loss 3.410, Val loss 3.400\n",
      "Ep 1 (Step 008710): Train loss 3.273, Val loss 3.393\n",
      "Ep 1 (Step 008715): Train loss 3.225, Val loss 3.374\n",
      "Ep 1 (Step 008720): Train loss 3.133, Val loss 3.368\n",
      "Ep 1 (Step 008725): Train loss 3.191, Val loss 3.377\n",
      "Ep 1 (Step 008730): Train loss 3.244, Val loss 3.377\n",
      "Ep 1 (Step 008735): Train loss 3.062, Val loss 3.360\n",
      "Ep 1 (Step 008740): Train loss 3.263, Val loss 3.386\n",
      "Ep 1 (Step 008745): Train loss 3.154, Val loss 3.405\n",
      "Ep 1 (Step 008750): Train loss 3.583, Val loss 3.416\n",
      "Ep 1 (Step 008755): Train loss 3.207, Val loss 3.405\n",
      "Ep 1 (Step 008760): Train loss 3.463, Val loss 3.395\n",
      "Ep 1 (Step 008765): Train loss 3.372, Val loss 3.376\n",
      "Ep 1 (Step 008770): Train loss 3.164, Val loss 3.395\n",
      "Ep 1 (Step 008775): Train loss 3.056, Val loss 3.422\n",
      "Ep 1 (Step 008780): Train loss 3.388, Val loss 3.438\n",
      "Ep 1 (Step 008785): Train loss 3.480, Val loss 3.414\n",
      "Ep 1 (Step 008790): Train loss 3.332, Val loss 3.407\n",
      "Ep 1 (Step 008795): Train loss 3.551, Val loss 3.417\n",
      "Ep 1 (Step 008800): Train loss 3.726, Val loss 3.418\n",
      "Ep 1 (Step 008805): Train loss 3.501, Val loss 3.392\n",
      "Ep 1 (Step 008810): Train loss 3.402, Val loss 3.402\n",
      "Ep 1 (Step 008815): Train loss 3.148, Val loss 3.395\n",
      "Ep 1 (Step 008820): Train loss 3.158, Val loss 3.399\n",
      "Ep 1 (Step 008825): Train loss 3.125, Val loss 3.420\n",
      "Ep 1 (Step 008830): Train loss 3.242, Val loss 3.411\n",
      "Ep 1 (Step 008835): Train loss 3.025, Val loss 3.378\n",
      "Ep 1 (Step 008840): Train loss 3.364, Val loss 3.366\n",
      "Ep 1 (Step 008845): Train loss 3.597, Val loss 3.387\n",
      "Ep 1 (Step 008850): Train loss 3.421, Val loss 3.412\n",
      "Ep 1 (Step 008855): Train loss 3.676, Val loss 3.415\n",
      "Ep 1 (Step 008860): Train loss 3.196, Val loss 3.397\n",
      "Ep 1 (Step 008865): Train loss 3.169, Val loss 3.385\n",
      "Ep 1 (Step 008870): Train loss 3.121, Val loss 3.350\n",
      "Ep 1 (Step 008875): Train loss 3.478, Val loss 3.347\n",
      "Ep 1 (Step 008880): Train loss 3.693, Val loss 3.376\n",
      "Ep 1 (Step 008885): Train loss 3.094, Val loss 3.370\n",
      "Ep 1 (Step 008890): Train loss 3.225, Val loss 3.350\n",
      "Ep 1 (Step 008895): Train loss 3.202, Val loss 3.348\n",
      "Ep 1 (Step 008900): Train loss 3.183, Val loss 3.353\n",
      "Ep 1 (Step 008905): Train loss 3.530, Val loss 3.355\n",
      "Ep 1 (Step 008910): Train loss 3.094, Val loss 3.352\n",
      "Ep 1 (Step 008915): Train loss 3.047, Val loss 3.346\n",
      "Ep 1 (Step 008920): Train loss 3.150, Val loss 3.354\n",
      "Ep 1 (Step 008925): Train loss 3.350, Val loss 3.356\n",
      "Ep 1 (Step 008930): Train loss 3.052, Val loss 3.358\n",
      "Ep 1 (Step 008935): Train loss 3.235, Val loss 3.362\n",
      "Ep 1 (Step 008940): Train loss 3.177, Val loss 3.402\n",
      "Ep 1 (Step 008945): Train loss 3.524, Val loss 3.411\n",
      "Ep 1 (Step 008950): Train loss 3.252, Val loss 3.391\n",
      "Ep 1 (Step 008955): Train loss 2.973, Val loss 3.386\n",
      "Ep 1 (Step 008960): Train loss 3.312, Val loss 3.389\n",
      "Ep 1 (Step 008965): Train loss 3.197, Val loss 3.358\n",
      "Ep 1 (Step 008970): Train loss 3.592, Val loss 3.345\n",
      "Ep 1 (Step 008975): Train loss 3.111, Val loss 3.359\n",
      "Ep 1 (Step 008980): Train loss 3.269, Val loss 3.389\n",
      "Ep 1 (Step 008985): Train loss 3.375, Val loss 3.389\n",
      "Ep 1 (Step 008990): Train loss 3.492, Val loss 3.375\n",
      "Ep 1 (Step 008995): Train loss 3.393, Val loss 3.368\n",
      "Ep 1 (Step 009000): Train loss 3.160, Val loss 3.371\n",
      "Ep 1 (Step 009005): Train loss 3.123, Val loss 3.370\n",
      "Ep 1 (Step 009010): Train loss 3.340, Val loss 3.358\n",
      "Ep 1 (Step 009015): Train loss 3.248, Val loss 3.351\n",
      "Ep 1 (Step 009020): Train loss 2.978, Val loss 3.343\n",
      "Ep 1 (Step 009025): Train loss 3.662, Val loss 3.361\n",
      "Ep 1 (Step 009030): Train loss 3.115, Val loss 3.371\n",
      "Ep 1 (Step 009035): Train loss 3.692, Val loss 3.371\n",
      "Ep 1 (Step 009040): Train loss 3.452, Val loss 3.386\n",
      "Ep 1 (Step 009045): Train loss 3.209, Val loss 3.396\n",
      "Ep 1 (Step 009050): Train loss 3.137, Val loss 3.382\n",
      "Ep 1 (Step 009055): Train loss 3.307, Val loss 3.369\n",
      "Ep 1 (Step 009060): Train loss 3.152, Val loss 3.380\n",
      "Ep 1 (Step 009065): Train loss 3.473, Val loss 3.367\n",
      "Ep 1 (Step 009070): Train loss 3.542, Val loss 3.362\n",
      "Ep 1 (Step 009075): Train loss 3.191, Val loss 3.359\n",
      "Ep 1 (Step 009080): Train loss 2.972, Val loss 3.353\n",
      "Ep 1 (Step 009085): Train loss 3.278, Val loss 3.354\n",
      "Ep 1 (Step 009090): Train loss 3.039, Val loss 3.353\n",
      "Ep 1 (Step 009095): Train loss 3.402, Val loss 3.340\n",
      "Ep 1 (Step 009100): Train loss 3.250, Val loss 3.334\n",
      "Ep 1 (Step 009105): Train loss 3.481, Val loss 3.339\n",
      "Ep 1 (Step 009110): Train loss 3.482, Val loss 3.339\n",
      "Ep 1 (Step 009115): Train loss 3.383, Val loss 3.336\n",
      "Ep 1 (Step 009120): Train loss 3.149, Val loss 3.310\n",
      "Ep 1 (Step 009125): Train loss 3.247, Val loss 3.308\n",
      "Ep 1 (Step 009130): Train loss 3.202, Val loss 3.297\n",
      "Ep 1 (Step 009135): Train loss 3.193, Val loss 3.297\n",
      "Ep 1 (Step 009140): Train loss 3.493, Val loss 3.301\n",
      "Ep 1 (Step 009145): Train loss 3.126, Val loss 3.300\n",
      "Ep 1 (Step 009150): Train loss 3.145, Val loss 3.310\n",
      "Ep 1 (Step 009155): Train loss 3.161, Val loss 3.320\n",
      "Ep 1 (Step 009160): Train loss 3.153, Val loss 3.310\n",
      "Ep 1 (Step 009165): Train loss 3.260, Val loss 3.328\n",
      "Ep 1 (Step 009170): Train loss 3.366, Val loss 3.315\n",
      "Ep 1 (Step 009175): Train loss 3.401, Val loss 3.313\n",
      "Ep 1 (Step 009180): Train loss 3.316, Val loss 3.319\n",
      "Ep 1 (Step 009185): Train loss 3.198, Val loss 3.323\n",
      "Ep 1 (Step 009190): Train loss 3.186, Val loss 3.319\n",
      "Ep 1 (Step 009195): Train loss 3.463, Val loss 3.308\n",
      "Ep 1 (Step 009200): Train loss 3.459, Val loss 3.307\n",
      "Ep 1 (Step 009205): Train loss 3.189, Val loss 3.306\n",
      "Ep 1 (Step 009210): Train loss 3.072, Val loss 3.304\n",
      "Ep 1 (Step 009215): Train loss 3.341, Val loss 3.299\n",
      "Ep 1 (Step 009220): Train loss 3.266, Val loss 3.303\n",
      "Ep 1 (Step 009225): Train loss 3.094, Val loss 3.308\n",
      "Ep 1 (Step 009230): Train loss 3.266, Val loss 3.309\n",
      "Ep 1 (Step 009235): Train loss 3.178, Val loss 3.313\n",
      "Ep 1 (Step 009240): Train loss 3.186, Val loss 3.327\n",
      "Ep 1 (Step 009245): Train loss 3.045, Val loss 3.345\n",
      "Ep 1 (Step 009250): Train loss 3.517, Val loss 3.342\n",
      "Ep 1 (Step 009255): Train loss 3.293, Val loss 3.333\n",
      "Ep 1 (Step 009260): Train loss 3.042, Val loss 3.345\n",
      "Ep 1 (Step 009265): Train loss 3.418, Val loss 3.366\n",
      "Ep 1 (Step 009270): Train loss 3.073, Val loss 3.323\n",
      "Ep 1 (Step 009275): Train loss 3.561, Val loss 3.316\n",
      "Ep 1 (Step 009280): Train loss 3.206, Val loss 3.336\n",
      "Ep 1 (Step 009285): Train loss 3.137, Val loss 3.350\n",
      "Ep 1 (Step 009290): Train loss 3.471, Val loss 3.349\n",
      "Ep 1 (Step 009295): Train loss 3.468, Val loss 3.351\n",
      "Ep 1 (Step 009300): Train loss 3.180, Val loss 3.360\n",
      "Ep 1 (Step 009305): Train loss 3.167, Val loss 3.353\n",
      "Ep 1 (Step 009310): Train loss 3.114, Val loss 3.337\n",
      "Ep 1 (Step 009315): Train loss 3.071, Val loss 3.354\n",
      "Ep 1 (Step 009320): Train loss 3.041, Val loss 3.360\n",
      "Ep 1 (Step 009325): Train loss 3.070, Val loss 3.372\n",
      "Ep 1 (Step 009330): Train loss 3.178, Val loss 3.366\n",
      "Ep 1 (Step 009335): Train loss 3.166, Val loss 3.351\n",
      "Ep 1 (Step 009340): Train loss 3.121, Val loss 3.352\n",
      "Ep 1 (Step 009345): Train loss 2.876, Val loss 3.351\n",
      "Ep 1 (Step 009350): Train loss 3.241, Val loss 3.341\n",
      "Ep 1 (Step 009355): Train loss 3.348, Val loss 3.332\n",
      "Ep 1 (Step 009360): Train loss 3.240, Val loss 3.343\n",
      "Ep 1 (Step 009365): Train loss 3.471, Val loss 3.336\n",
      "Ep 1 (Step 009370): Train loss 3.208, Val loss 3.325\n",
      "Ep 1 (Step 009375): Train loss 2.965, Val loss 3.333\n",
      "Ep 1 (Step 009380): Train loss 3.135, Val loss 3.332\n",
      "Ep 1 (Step 009385): Train loss 3.276, Val loss 3.328\n",
      "Ep 1 (Step 009390): Train loss 3.226, Val loss 3.336\n",
      "Ep 1 (Step 009395): Train loss 3.350, Val loss 3.337\n",
      "Ep 1 (Step 009400): Train loss 3.565, Val loss 3.340\n",
      "Ep 1 (Step 009405): Train loss 3.102, Val loss 3.326\n",
      "Ep 1 (Step 009410): Train loss 3.272, Val loss 3.317\n",
      "Ep 1 (Step 009415): Train loss 3.161, Val loss 3.312\n",
      "Ep 1 (Step 009420): Train loss 3.104, Val loss 3.306\n",
      "Ep 1 (Step 009425): Train loss 3.239, Val loss 3.309\n",
      "Ep 1 (Step 009430): Train loss 3.198, Val loss 3.305\n",
      "Ep 1 (Step 009435): Train loss 3.316, Val loss 3.319\n",
      "Ep 1 (Step 009440): Train loss 3.328, Val loss 3.313\n",
      "Ep 1 (Step 009445): Train loss 3.237, Val loss 3.329\n",
      "Ep 1 (Step 009450): Train loss 3.760, Val loss 3.324\n",
      "Ep 1 (Step 009455): Train loss 3.450, Val loss 3.301\n",
      "Ep 1 (Step 009460): Train loss 3.230, Val loss 3.295\n",
      "Ep 1 (Step 009465): Train loss 3.202, Val loss 3.305\n",
      "Ep 1 (Step 009470): Train loss 3.314, Val loss 3.309\n",
      "Ep 1 (Step 009475): Train loss 3.029, Val loss 3.330\n",
      "Ep 1 (Step 009480): Train loss 3.272, Val loss 3.329\n",
      "Ep 1 (Step 009485): Train loss 3.266, Val loss 3.357\n",
      "Ep 1 (Step 009490): Train loss 3.196, Val loss 3.340\n",
      "Ep 1 (Step 009495): Train loss 3.493, Val loss 3.318\n",
      "Ep 1 (Step 009500): Train loss 3.493, Val loss 3.295\n",
      "Ep 1 (Step 009505): Train loss 3.364, Val loss 3.280\n",
      "Ep 1 (Step 009510): Train loss 3.056, Val loss 3.285\n",
      "Ep 1 (Step 009515): Train loss 2.944, Val loss 3.299\n",
      "Ep 1 (Step 009520): Train loss 3.412, Val loss 3.308\n",
      "Ep 1 (Step 009525): Train loss 3.123, Val loss 3.305\n",
      "Ep 1 (Step 009530): Train loss 3.396, Val loss 3.318\n",
      "Ep 1 (Step 009535): Train loss 3.615, Val loss 3.317\n",
      "Ep 1 (Step 009540): Train loss 3.163, Val loss 3.347\n",
      "Ep 1 (Step 009545): Train loss 3.149, Val loss 3.336\n",
      "Ep 1 (Step 009550): Train loss 3.048, Val loss 3.331\n",
      "Ep 1 (Step 009555): Train loss 3.051, Val loss 3.321\n",
      "Ep 1 (Step 009560): Train loss 3.258, Val loss 3.309\n",
      "Ep 1 (Step 009565): Train loss 3.081, Val loss 3.314\n",
      "Ep 1 (Step 009570): Train loss 3.302, Val loss 3.334\n",
      "Ep 1 (Step 009575): Train loss 3.191, Val loss 3.332\n",
      "Ep 1 (Step 009580): Train loss 3.259, Val loss 3.296\n",
      "Ep 1 (Step 009585): Train loss 3.407, Val loss 3.296\n",
      "Ep 1 (Step 009590): Train loss 3.196, Val loss 3.309\n",
      "Ep 1 (Step 009595): Train loss 3.416, Val loss 3.308\n",
      "Ep 1 (Step 009600): Train loss 2.924, Val loss 3.317\n",
      "Ep 1 (Step 009605): Train loss 3.290, Val loss 3.329\n",
      "Ep 1 (Step 009610): Train loss 3.228, Val loss 3.329\n",
      "Ep 1 (Step 009615): Train loss 3.353, Val loss 3.310\n",
      "Ep 1 (Step 009620): Train loss 3.204, Val loss 3.319\n",
      "Ep 1 (Step 009625): Train loss 3.450, Val loss 3.321\n",
      "Ep 1 (Step 009630): Train loss 3.393, Val loss 3.325\n",
      "Ep 1 (Step 009635): Train loss 3.326, Val loss 3.317\n",
      "Ep 1 (Step 009640): Train loss 3.298, Val loss 3.316\n",
      "Ep 1 (Step 009645): Train loss 3.248, Val loss 3.313\n",
      "Ep 1 (Step 009650): Train loss 3.318, Val loss 3.300\n",
      "Ep 1 (Step 009655): Train loss 3.416, Val loss 3.313\n",
      "Ep 1 (Step 009660): Train loss 3.206, Val loss 3.314\n",
      "Ep 1 (Step 009665): Train loss 3.226, Val loss 3.297\n",
      "Ep 1 (Step 009670): Train loss 3.584, Val loss 3.284\n",
      "Ep 1 (Step 009675): Train loss 3.238, Val loss 3.305\n",
      "Ep 1 (Step 009680): Train loss 3.194, Val loss 3.311\n",
      "Ep 1 (Step 009685): Train loss 3.153, Val loss 3.321\n",
      "Ep 1 (Step 009690): Train loss 3.139, Val loss 3.320\n",
      "Ep 1 (Step 009695): Train loss 3.095, Val loss 3.292\n",
      "Ep 1 (Step 009700): Train loss 3.424, Val loss 3.272\n",
      "Ep 1 (Step 009705): Train loss 3.337, Val loss 3.271\n",
      "Ep 1 (Step 009710): Train loss 3.394, Val loss 3.278\n",
      "Ep 1 (Step 009715): Train loss 3.078, Val loss 3.291\n",
      "Ep 1 (Step 009720): Train loss 3.372, Val loss 3.304\n",
      "Ep 1 (Step 009725): Train loss 3.339, Val loss 3.324\n",
      "Ep 1 (Step 009730): Train loss 3.341, Val loss 3.305\n",
      "Ep 1 (Step 009735): Train loss 3.173, Val loss 3.313\n",
      "Ep 1 (Step 009740): Train loss 3.044, Val loss 3.303\n",
      "Ep 1 (Step 009745): Train loss 3.243, Val loss 3.302\n",
      "Ep 1 (Step 009750): Train loss 3.196, Val loss 3.298\n",
      "Ep 1 (Step 009755): Train loss 3.270, Val loss 3.291\n",
      "Ep 1 (Step 009760): Train loss 2.984, Val loss 3.282\n",
      "Ep 1 (Step 009765): Train loss 3.407, Val loss 3.279\n",
      "Ep 1 (Step 009770): Train loss 3.520, Val loss 3.298\n",
      "Ep 1 (Step 009775): Train loss 3.118, Val loss 3.306\n",
      "Ep 1 (Step 009780): Train loss 3.130, Val loss 3.302\n",
      "Ep 1 (Step 009785): Train loss 3.048, Val loss 3.301\n",
      "Ep 1 (Step 009790): Train loss 3.416, Val loss 3.295\n",
      "Ep 1 (Step 009795): Train loss 3.204, Val loss 3.271\n",
      "Ep 1 (Step 009800): Train loss 3.442, Val loss 3.266\n",
      "Ep 1 (Step 009805): Train loss 3.461, Val loss 3.264\n",
      "Ep 1 (Step 009810): Train loss 3.173, Val loss 3.271\n",
      "Ep 1 (Step 009815): Train loss 3.025, Val loss 3.264\n",
      "Ep 1 (Step 009820): Train loss 3.178, Val loss 3.250\n",
      "Ep 1 (Step 009825): Train loss 3.303, Val loss 3.240\n",
      "Ep 1 (Step 009830): Train loss 3.082, Val loss 3.245\n",
      "Ep 1 (Step 009835): Train loss 3.220, Val loss 3.255\n",
      "Ep 1 (Step 009840): Train loss 3.152, Val loss 3.246\n",
      "Ep 1 (Step 009845): Train loss 3.161, Val loss 3.265\n",
      "Ep 1 (Step 009850): Train loss 3.117, Val loss 3.285\n",
      "Ep 1 (Step 009855): Train loss 3.183, Val loss 3.280\n",
      "Ep 1 (Step 009860): Train loss 3.314, Val loss 3.272\n",
      "Ep 1 (Step 009865): Train loss 3.254, Val loss 3.286\n",
      "Ep 1 (Step 009870): Train loss 3.286, Val loss 3.294\n",
      "Ep 1 (Step 009875): Train loss 3.531, Val loss 3.301\n",
      "Ep 1 (Step 009880): Train loss 3.311, Val loss 3.308\n",
      "Ep 1 (Step 009885): Train loss 3.360, Val loss 3.295\n",
      "Ep 1 (Step 009890): Train loss 3.384, Val loss 3.276\n",
      "Ep 1 (Step 009895): Train loss 3.016, Val loss 3.266\n",
      "Ep 1 (Step 009900): Train loss 3.272, Val loss 3.253\n",
      "Ep 1 (Step 009905): Train loss 3.501, Val loss 3.261\n",
      "Ep 1 (Step 009910): Train loss 3.233, Val loss 3.272\n",
      "Ep 1 (Step 009915): Train loss 3.450, Val loss 3.254\n",
      "Ep 1 (Step 009920): Train loss 2.855, Val loss 3.250\n",
      "Ep 1 (Step 009925): Train loss 3.330, Val loss 3.260\n",
      "Ep 1 (Step 009930): Train loss 3.308, Val loss 3.268\n",
      "Ep 1 (Step 009935): Train loss 3.309, Val loss 3.280\n",
      "Ep 1 (Step 009940): Train loss 3.275, Val loss 3.253\n",
      "Ep 1 (Step 009945): Train loss 3.134, Val loss 3.253\n",
      "Ep 1 (Step 009950): Train loss 2.832, Val loss 3.260\n",
      "Ep 1 (Step 009955): Train loss 3.239, Val loss 3.286\n",
      "Ep 1 (Step 009960): Train loss 3.456, Val loss 3.294\n",
      "Ep 1 (Step 009965): Train loss 3.595, Val loss 3.287\n",
      "Ep 1 (Step 009970): Train loss 3.167, Val loss 3.278\n",
      "Ep 1 (Step 009975): Train loss 2.942, Val loss 3.255\n",
      "Ep 1 (Step 009980): Train loss 3.512, Val loss 3.265\n",
      "Ep 1 (Step 009985): Train loss 3.222, Val loss 3.291\n",
      "Ep 1 (Step 009990): Train loss 3.054, Val loss 3.299\n",
      "Ep 1 (Step 009995): Train loss 3.240, Val loss 3.296\n",
      "Ep 1 (Step 010000): Train loss 3.353, Val loss 3.307\n",
      "Ep 1 (Step 010005): Train loss 3.338, Val loss 3.309\n",
      "Ep 1 (Step 010010): Train loss 3.302, Val loss 3.335\n",
      "Ep 1 (Step 010015): Train loss 3.149, Val loss 3.302\n",
      "Ep 1 (Step 010020): Train loss 3.288, Val loss 3.305\n",
      "Ep 1 (Step 010025): Train loss 3.551, Val loss 3.273\n",
      "Ep 1 (Step 010030): Train loss 3.096, Val loss 3.251\n",
      "Ep 1 (Step 010035): Train loss 3.061, Val loss 3.271\n",
      "Ep 1 (Step 010040): Train loss 3.062, Val loss 3.297\n",
      "Ep 1 (Step 010045): Train loss 3.048, Val loss 3.328\n",
      "Ep 1 (Step 010050): Train loss 3.035, Val loss 3.323\n",
      "Ep 1 (Step 010055): Train loss 3.137, Val loss 3.289\n",
      "Ep 1 (Step 010060): Train loss 3.069, Val loss 3.290\n",
      "Ep 1 (Step 010065): Train loss 3.287, Val loss 3.280\n",
      "Ep 1 (Step 010070): Train loss 3.168, Val loss 3.257\n",
      "Ep 1 (Step 010075): Train loss 3.304, Val loss 3.259\n",
      "Ep 1 (Step 010080): Train loss 2.957, Val loss 3.261\n",
      "Ep 1 (Step 010085): Train loss 2.952, Val loss 3.254\n",
      "Ep 1 (Step 010090): Train loss 3.423, Val loss 3.259\n",
      "Ep 1 (Step 010095): Train loss 3.484, Val loss 3.280\n",
      "Ep 1 (Step 010100): Train loss 3.231, Val loss 3.282\n",
      "Ep 1 (Step 010105): Train loss 2.955, Val loss 3.268\n",
      "Ep 1 (Step 010110): Train loss 3.235, Val loss 3.256\n",
      "Ep 1 (Step 010115): Train loss 3.209, Val loss 3.252\n",
      "Ep 1 (Step 010120): Train loss 3.195, Val loss 3.268\n",
      "Ep 1 (Step 010125): Train loss 3.130, Val loss 3.279\n",
      "Ep 1 (Step 010130): Train loss 3.003, Val loss 3.262\n",
      "Ep 1 (Step 010135): Train loss 3.340, Val loss 3.263\n",
      "Ep 1 (Step 010140): Train loss 3.099, Val loss 3.262\n",
      "Ep 1 (Step 010145): Train loss 3.170, Val loss 3.264\n",
      "Ep 1 (Step 010150): Train loss 3.070, Val loss 3.272\n",
      "Ep 1 (Step 010155): Train loss 3.162, Val loss 3.252\n",
      "Ep 1 (Step 010160): Train loss 3.265, Val loss 3.247\n",
      "Ep 1 (Step 010165): Train loss 3.062, Val loss 3.261\n",
      "Ep 1 (Step 010170): Train loss 3.202, Val loss 3.291\n",
      "Ep 1 (Step 010175): Train loss 3.279, Val loss 3.282\n",
      "Ep 1 (Step 010180): Train loss 3.207, Val loss 3.273\n",
      "Ep 1 (Step 010185): Train loss 3.128, Val loss 3.260\n",
      "Ep 1 (Step 010190): Train loss 3.208, Val loss 3.250\n",
      "Ep 1 (Step 010195): Train loss 3.229, Val loss 3.251\n",
      "Ep 1 (Step 010200): Train loss 3.276, Val loss 3.235\n",
      "Ep 1 (Step 010205): Train loss 3.188, Val loss 3.244\n",
      "Ep 1 (Step 010210): Train loss 3.256, Val loss 3.236\n",
      "Ep 1 (Step 010215): Train loss 3.208, Val loss 3.232\n",
      "Ep 1 (Step 010220): Train loss 3.365, Val loss 3.241\n",
      "Ep 1 (Step 010225): Train loss 3.264, Val loss 3.250\n",
      "Ep 1 (Step 010230): Train loss 3.113, Val loss 3.274\n",
      "Ep 1 (Step 010235): Train loss 2.974, Val loss 3.269\n",
      "Ep 1 (Step 010240): Train loss 3.341, Val loss 3.256\n",
      "Ep 1 (Step 010245): Train loss 3.299, Val loss 3.272\n",
      "Ep 1 (Step 010250): Train loss 3.244, Val loss 3.282\n",
      "Ep 1 (Step 010255): Train loss 3.138, Val loss 3.293\n",
      "Ep 1 (Step 010260): Train loss 3.163, Val loss 3.264\n",
      "Ep 1 (Step 010265): Train loss 3.190, Val loss 3.255\n",
      "Ep 1 (Step 010270): Train loss 3.109, Val loss 3.247\n",
      "Ep 1 (Step 010275): Train loss 3.311, Val loss 3.251\n",
      "Ep 1 (Step 010280): Train loss 2.874, Val loss 3.265\n",
      "Ep 1 (Step 010285): Train loss 3.124, Val loss 3.277\n",
      "Ep 1 (Step 010290): Train loss 2.961, Val loss 3.267\n",
      "Ep 1 (Step 010295): Train loss 3.505, Val loss 3.264\n",
      "Ep 1 (Step 010300): Train loss 3.077, Val loss 3.264\n",
      "Ep 1 (Step 010305): Train loss 3.423, Val loss 3.263\n",
      "Ep 1 (Step 010310): Train loss 3.264, Val loss 3.251\n",
      "Ep 1 (Step 010315): Train loss 3.387, Val loss 3.247\n",
      "Ep 1 (Step 010320): Train loss 3.304, Val loss 3.252\n",
      "Ep 1 (Step 010325): Train loss 3.063, Val loss 3.250\n",
      "Ep 1 (Step 010330): Train loss 2.769, Val loss 3.250\n",
      "Ep 1 (Step 010335): Train loss 3.281, Val loss 3.256\n",
      "Ep 1 (Step 010340): Train loss 3.431, Val loss 3.272\n",
      "Ep 1 (Step 010345): Train loss 3.225, Val loss 3.284\n",
      "Ep 1 (Step 010350): Train loss 3.020, Val loss 3.272\n",
      "Ep 1 (Step 010355): Train loss 2.813, Val loss 3.269\n",
      "Ep 1 (Step 010360): Train loss 3.558, Val loss 3.256\n",
      "Ep 1 (Step 010365): Train loss 3.438, Val loss 3.249\n",
      "Ep 1 (Step 010370): Train loss 3.147, Val loss 3.239\n",
      "Ep 1 (Step 010375): Train loss 3.050, Val loss 3.248\n",
      "Ep 1 (Step 010380): Train loss 3.241, Val loss 3.251\n",
      "Ep 1 (Step 010385): Train loss 3.183, Val loss 3.251\n",
      "Ep 1 (Step 010390): Train loss 3.209, Val loss 3.230\n",
      "Ep 1 (Step 010395): Train loss 3.311, Val loss 3.226\n",
      "Ep 1 (Step 010400): Train loss 3.051, Val loss 3.242\n",
      "Ep 1 (Step 010405): Train loss 2.999, Val loss 3.262\n",
      "Ep 1 (Step 010410): Train loss 3.019, Val loss 3.264\n",
      "Ep 1 (Step 010415): Train loss 3.219, Val loss 3.264\n",
      "Ep 1 (Step 010420): Train loss 3.038, Val loss 3.258\n",
      "Ep 1 (Step 010425): Train loss 3.314, Val loss 3.230\n",
      "Ep 1 (Step 010430): Train loss 3.392, Val loss 3.216\n",
      "Ep 1 (Step 010435): Train loss 2.989, Val loss 3.225\n",
      "Ep 1 (Step 010440): Train loss 3.225, Val loss 3.264\n",
      "Ep 1 (Step 010445): Train loss 3.294, Val loss 3.283\n",
      "Ep 1 (Step 010450): Train loss 3.019, Val loss 3.268\n",
      "Ep 1 (Step 010455): Train loss 3.148, Val loss 3.243\n",
      "Ep 1 (Step 010460): Train loss 3.102, Val loss 3.244\n",
      "Ep 1 (Step 010465): Train loss 3.385, Val loss 3.257\n",
      "Ep 1 (Step 010470): Train loss 3.316, Val loss 3.254\n",
      "Ep 1 (Step 010475): Train loss 2.824, Val loss 3.236\n",
      "Ep 1 (Step 010480): Train loss 3.114, Val loss 3.247\n",
      "Ep 1 (Step 010485): Train loss 3.096, Val loss 3.257\n",
      "Ep 1 (Step 010490): Train loss 2.876, Val loss 3.248\n",
      "Ep 1 (Step 010495): Train loss 3.181, Val loss 3.241\n",
      "Ep 1 (Step 010500): Train loss 2.979, Val loss 3.239\n",
      "Ep 1 (Step 010505): Train loss 3.013, Val loss 3.236\n",
      "Ep 1 (Step 010510): Train loss 3.269, Val loss 3.219\n",
      "Ep 1 (Step 010515): Train loss 3.149, Val loss 3.231\n",
      "Ep 1 (Step 010520): Train loss 3.159, Val loss 3.224\n",
      "Ep 1 (Step 010525): Train loss 3.128, Val loss 3.243\n",
      "Ep 1 (Step 010530): Train loss 3.236, Val loss 3.243\n",
      "Ep 1 (Step 010535): Train loss 3.690, Val loss 3.226\n",
      "Ep 1 (Step 010540): Train loss 3.183, Val loss 3.218\n",
      "Ep 1 (Step 010545): Train loss 3.002, Val loss 3.220\n",
      "Ep 1 (Step 010550): Train loss 3.333, Val loss 3.222\n",
      "Ep 1 (Step 010555): Train loss 3.161, Val loss 3.203\n",
      "Ep 1 (Step 010560): Train loss 3.019, Val loss 3.192\n",
      "Ep 1 (Step 010565): Train loss 2.876, Val loss 3.192\n",
      "Ep 1 (Step 010570): Train loss 3.161, Val loss 3.215\n",
      "Ep 1 (Step 010575): Train loss 3.156, Val loss 3.229\n",
      "Ep 1 (Step 010580): Train loss 3.031, Val loss 3.217\n",
      "Ep 1 (Step 010585): Train loss 3.297, Val loss 3.214\n",
      "Ep 1 (Step 010590): Train loss 3.150, Val loss 3.210\n",
      "Ep 1 (Step 010595): Train loss 3.072, Val loss 3.231\n",
      "Ep 1 (Step 010600): Train loss 3.230, Val loss 3.224\n",
      "Ep 1 (Step 010605): Train loss 3.428, Val loss 3.230\n",
      "Ep 1 (Step 010610): Train loss 3.094, Val loss 3.237\n",
      "Ep 1 (Step 010615): Train loss 3.041, Val loss 3.232\n",
      "Ep 1 (Step 010620): Train loss 3.178, Val loss 3.210\n",
      "Ep 1 (Step 010625): Train loss 3.278, Val loss 3.225\n",
      "Ep 1 (Step 010630): Train loss 3.147, Val loss 3.224\n",
      "Ep 1 (Step 010635): Train loss 3.502, Val loss 3.231\n",
      "Ep 1 (Step 010640): Train loss 3.118, Val loss 3.218\n",
      "Ep 1 (Step 010645): Train loss 3.135, Val loss 3.201\n",
      "Ep 1 (Step 010650): Train loss 3.215, Val loss 3.220\n",
      "Ep 1 (Step 010655): Train loss 3.384, Val loss 3.236\n",
      "Ep 1 (Step 010660): Train loss 2.924, Val loss 3.238\n",
      "Ep 1 (Step 010665): Train loss 3.383, Val loss 3.239\n",
      "Ep 1 (Step 010670): Train loss 3.043, Val loss 3.228\n",
      "Ep 1 (Step 010675): Train loss 3.033, Val loss 3.226\n",
      "Ep 1 (Step 010680): Train loss 3.418, Val loss 3.241\n",
      "Ep 1 (Step 010685): Train loss 2.833, Val loss 3.215\n",
      "Ep 1 (Step 010690): Train loss 2.977, Val loss 3.207\n",
      "Ep 1 (Step 010695): Train loss 2.895, Val loss 3.207\n",
      "Ep 1 (Step 010700): Train loss 3.182, Val loss 3.192\n",
      "Ep 1 (Step 010705): Train loss 3.125, Val loss 3.191\n",
      "Ep 1 (Step 010710): Train loss 3.289, Val loss 3.187\n",
      "Ep 1 (Step 010715): Train loss 3.114, Val loss 3.180\n",
      "Ep 1 (Step 010720): Train loss 2.931, Val loss 3.184\n",
      "Ep 1 (Step 010725): Train loss 3.045, Val loss 3.184\n",
      "Ep 1 (Step 010730): Train loss 3.182, Val loss 3.191\n",
      "Ep 1 (Step 010735): Train loss 3.259, Val loss 3.213\n",
      "Ep 1 (Step 010740): Train loss 3.045, Val loss 3.208\n",
      "Ep 1 (Step 010745): Train loss 2.996, Val loss 3.207\n",
      "Ep 1 (Step 010750): Train loss 3.128, Val loss 3.203\n",
      "Ep 1 (Step 010755): Train loss 2.995, Val loss 3.210\n",
      "Ep 1 (Step 010760): Train loss 3.029, Val loss 3.217\n",
      "Ep 1 (Step 010765): Train loss 3.227, Val loss 3.213\n",
      "Ep 1 (Step 010770): Train loss 2.937, Val loss 3.197\n",
      "Ep 1 (Step 010775): Train loss 3.163, Val loss 3.198\n",
      "Ep 1 (Step 010780): Train loss 3.349, Val loss 3.208\n",
      "Ep 1 (Step 010785): Train loss 3.224, Val loss 3.209\n",
      "Ep 1 (Step 010790): Train loss 3.001, Val loss 3.209\n",
      "Ep 1 (Step 010795): Train loss 3.119, Val loss 3.224\n",
      "Ep 1 (Step 010800): Train loss 3.169, Val loss 3.227\n",
      "Ep 1 (Step 010805): Train loss 3.287, Val loss 3.193\n",
      "Ep 1 (Step 010810): Train loss 2.971, Val loss 3.175\n",
      "Ep 1 (Step 010815): Train loss 3.509, Val loss 3.187\n",
      "Ep 1 (Step 010820): Train loss 3.152, Val loss 3.193\n",
      "Ep 1 (Step 010825): Train loss 3.046, Val loss 3.200\n",
      "Ep 1 (Step 010830): Train loss 3.249, Val loss 3.209\n",
      "Ep 1 (Step 010835): Train loss 2.928, Val loss 3.207\n",
      "Ep 1 (Step 010840): Train loss 3.452, Val loss 3.202\n",
      "Ep 1 (Step 010845): Train loss 3.022, Val loss 3.188\n",
      "Ep 1 (Step 010850): Train loss 3.017, Val loss 3.189\n",
      "Ep 1 (Step 010855): Train loss 2.958, Val loss 3.193\n",
      "Ep 1 (Step 010860): Train loss 3.231, Val loss 3.190\n",
      "Ep 1 (Step 010865): Train loss 3.250, Val loss 3.195\n",
      "Ep 1 (Step 010870): Train loss 3.261, Val loss 3.197\n",
      "Ep 1 (Step 010875): Train loss 2.971, Val loss 3.188\n",
      "Ep 1 (Step 010880): Train loss 3.232, Val loss 3.195\n",
      "Ep 1 (Step 010885): Train loss 2.615, Val loss 3.193\n",
      "Ep 1 (Step 010890): Train loss 2.946, Val loss 3.191\n",
      "Ep 1 (Step 010895): Train loss 2.862, Val loss 3.201\n",
      "Ep 1 (Step 010900): Train loss 3.319, Val loss 3.191\n",
      "Ep 1 (Step 010905): Train loss 3.502, Val loss 3.188\n",
      "Ep 1 (Step 010910): Train loss 2.783, Val loss 3.192\n",
      "Ep 1 (Step 010915): Train loss 2.961, Val loss 3.194\n",
      "Ep 1 (Step 010920): Train loss 3.150, Val loss 3.182\n",
      "Ep 1 (Step 010925): Train loss 3.142, Val loss 3.178\n",
      "Ep 1 (Step 010930): Train loss 2.834, Val loss 3.193\n",
      "Ep 1 (Step 010935): Train loss 3.054, Val loss 3.171\n",
      "Ep 1 (Step 010940): Train loss 3.257, Val loss 3.185\n",
      "Ep 1 (Step 010945): Train loss 3.086, Val loss 3.176\n",
      "Ep 1 (Step 010950): Train loss 3.053, Val loss 3.194\n",
      "Ep 1 (Step 010955): Train loss 3.093, Val loss 3.190\n",
      "Ep 1 (Step 010960): Train loss 2.864, Val loss 3.187\n",
      "Ep 1 (Step 010965): Train loss 3.264, Val loss 3.179\n",
      "Ep 1 (Step 010970): Train loss 3.150, Val loss 3.187\n",
      "Ep 1 (Step 010975): Train loss 3.041, Val loss 3.195\n",
      "Ep 1 (Step 010980): Train loss 3.441, Val loss 3.172\n",
      "Ep 1 (Step 010985): Train loss 2.993, Val loss 3.172\n",
      "Ep 1 (Step 010990): Train loss 3.121, Val loss 3.192\n",
      "Ep 1 (Step 010995): Train loss 3.029, Val loss 3.206\n",
      "Ep 1 (Step 011000): Train loss 3.057, Val loss 3.195\n",
      "Ep 1 (Step 011005): Train loss 3.313, Val loss 3.189\n",
      "Ep 1 (Step 011010): Train loss 3.024, Val loss 3.175\n",
      "Ep 1 (Step 011015): Train loss 3.239, Val loss 3.175\n",
      "Ep 1 (Step 011020): Train loss 2.911, Val loss 3.182\n",
      "Ep 1 (Step 011025): Train loss 3.199, Val loss 3.164\n",
      "Ep 1 (Step 011030): Train loss 3.252, Val loss 3.168\n",
      "Ep 1 (Step 011035): Train loss 3.136, Val loss 3.175\n",
      "Ep 1 (Step 011040): Train loss 3.003, Val loss 3.177\n",
      "Ep 1 (Step 011045): Train loss 3.016, Val loss 3.201\n",
      "Ep 1 (Step 011050): Train loss 3.040, Val loss 3.188\n",
      "Ep 1 (Step 011055): Train loss 3.001, Val loss 3.172\n",
      "Ep 1 (Step 011060): Train loss 3.273, Val loss 3.178\n",
      "Ep 1 (Step 011065): Train loss 3.034, Val loss 3.195\n",
      "Ep 1 (Step 011070): Train loss 3.022, Val loss 3.211\n",
      "Ep 1 (Step 011075): Train loss 3.089, Val loss 3.178\n",
      "Ep 1 (Step 011080): Train loss 3.002, Val loss 3.175\n",
      "Ep 1 (Step 011085): Train loss 2.838, Val loss 3.189\n",
      "Ep 1 (Step 011090): Train loss 3.307, Val loss 3.186\n",
      "Ep 1 (Step 011095): Train loss 2.956, Val loss 3.182\n",
      "Ep 1 (Step 011100): Train loss 2.923, Val loss 3.191\n",
      "Ep 1 (Step 011105): Train loss 3.137, Val loss 3.183\n",
      "Ep 1 (Step 011110): Train loss 2.887, Val loss 3.171\n",
      "Ep 1 (Step 011115): Train loss 3.274, Val loss 3.167\n",
      "Ep 1 (Step 011120): Train loss 2.916, Val loss 3.171\n",
      "Ep 1 (Step 011125): Train loss 3.144, Val loss 3.164\n",
      "Ep 1 (Step 011130): Train loss 3.066, Val loss 3.159\n",
      "Ep 1 (Step 011135): Train loss 2.839, Val loss 3.155\n",
      "Ep 1 (Step 011140): Train loss 3.074, Val loss 3.169\n",
      "Ep 1 (Step 011145): Train loss 2.875, Val loss 3.173\n",
      "Ep 1 (Step 011150): Train loss 3.166, Val loss 3.147\n",
      "Ep 1 (Step 011155): Train loss 3.224, Val loss 3.144\n",
      "Ep 1 (Step 011160): Train loss 2.961, Val loss 3.157\n",
      "Ep 1 (Step 011165): Train loss 2.981, Val loss 3.150\n",
      "Ep 1 (Step 011170): Train loss 3.265, Val loss 3.152\n",
      "Ep 1 (Step 011175): Train loss 3.200, Val loss 3.151\n",
      "Ep 1 (Step 011180): Train loss 3.064, Val loss 3.139\n",
      "Ep 1 (Step 011185): Train loss 3.186, Val loss 3.133\n",
      "Ep 1 (Step 011190): Train loss 3.055, Val loss 3.158\n",
      "Ep 1 (Step 011195): Train loss 3.144, Val loss 3.175\n",
      "Ep 1 (Step 011200): Train loss 3.180, Val loss 3.180\n",
      "Ep 1 (Step 011205): Train loss 3.266, Val loss 3.155\n",
      "Ep 1 (Step 011210): Train loss 3.053, Val loss 3.152\n",
      "Ep 1 (Step 011215): Train loss 3.063, Val loss 3.141\n",
      "Ep 1 (Step 011220): Train loss 3.317, Val loss 3.144\n",
      "Ep 1 (Step 011225): Train loss 2.851, Val loss 3.160\n",
      "Ep 1 (Step 011230): Train loss 3.135, Val loss 3.174\n",
      "Ep 1 (Step 011235): Train loss 3.144, Val loss 3.167\n",
      "Ep 1 (Step 011240): Train loss 3.077, Val loss 3.142\n",
      "Ep 1 (Step 011245): Train loss 3.101, Val loss 3.129\n",
      "Ep 1 (Step 011250): Train loss 2.965, Val loss 3.121\n",
      "Ep 1 (Step 011255): Train loss 2.991, Val loss 3.127\n",
      "Ep 1 (Step 011260): Train loss 3.249, Val loss 3.123\n",
      "Ep 1 (Step 011265): Train loss 3.398, Val loss 3.125\n",
      "Ep 1 (Step 011270): Train loss 3.308, Val loss 3.119\n",
      "Ep 1 (Step 011275): Train loss 3.356, Val loss 3.131\n",
      "Ep 1 (Step 011280): Train loss 3.268, Val loss 3.133\n",
      "Ep 1 (Step 011285): Train loss 2.955, Val loss 3.117\n",
      "Ep 1 (Step 011290): Train loss 2.944, Val loss 3.118\n",
      "Ep 1 (Step 011295): Train loss 3.096, Val loss 3.111\n",
      "Ep 1 (Step 011300): Train loss 3.525, Val loss 3.120\n",
      "Ep 1 (Step 011305): Train loss 3.162, Val loss 3.126\n",
      "Ep 1 (Step 011310): Train loss 3.061, Val loss 3.142\n",
      "Ep 1 (Step 011315): Train loss 2.808, Val loss 3.143\n",
      "Ep 1 (Step 011320): Train loss 3.309, Val loss 3.152\n",
      "Ep 1 (Step 011325): Train loss 3.054, Val loss 3.162\n",
      "Ep 1 (Step 011330): Train loss 2.959, Val loss 3.166\n",
      "Ep 1 (Step 011335): Train loss 3.096, Val loss 3.164\n",
      "Ep 1 (Step 011340): Train loss 3.169, Val loss 3.161\n",
      "Ep 1 (Step 011345): Train loss 3.060, Val loss 3.159\n",
      "Ep 1 (Step 011350): Train loss 3.138, Val loss 3.166\n",
      "Ep 1 (Step 011355): Train loss 3.097, Val loss 3.149\n",
      "Ep 1 (Step 011360): Train loss 3.051, Val loss 3.139\n",
      "Ep 1 (Step 011365): Train loss 3.282, Val loss 3.156\n",
      "Ep 1 (Step 011370): Train loss 2.818, Val loss 3.153\n",
      "Ep 1 (Step 011375): Train loss 3.023, Val loss 3.135\n",
      "Ep 1 (Step 011380): Train loss 3.146, Val loss 3.139\n",
      "Ep 1 (Step 011385): Train loss 2.927, Val loss 3.145\n",
      "Ep 1 (Step 011390): Train loss 2.945, Val loss 3.137\n",
      "Ep 1 (Step 011395): Train loss 3.157, Val loss 3.131\n",
      "Ep 1 (Step 011400): Train loss 3.152, Val loss 3.118\n",
      "Ep 1 (Step 011405): Train loss 2.908, Val loss 3.112\n",
      "Ep 1 (Step 011410): Train loss 3.058, Val loss 3.133\n",
      "Ep 1 (Step 011415): Train loss 3.028, Val loss 3.154\n",
      "Ep 1 (Step 011420): Train loss 2.744, Val loss 3.132\n",
      "Ep 1 (Step 011425): Train loss 2.922, Val loss 3.136\n",
      "Ep 1 (Step 011430): Train loss 2.858, Val loss 3.134\n",
      "Ep 1 (Step 011435): Train loss 2.991, Val loss 3.162\n",
      "Ep 1 (Step 011440): Train loss 3.282, Val loss 3.171\n",
      "Ep 1 (Step 011445): Train loss 2.999, Val loss 3.153\n",
      "Ep 1 (Step 011450): Train loss 2.893, Val loss 3.152\n",
      "Ep 1 (Step 011455): Train loss 3.011, Val loss 3.148\n",
      "Ep 1 (Step 011460): Train loss 2.792, Val loss 3.151\n",
      "Ep 1 (Step 011465): Train loss 2.944, Val loss 3.142\n",
      "Ep 1 (Step 011470): Train loss 3.262, Val loss 3.135\n",
      "Ep 1 (Step 011475): Train loss 2.858, Val loss 3.127\n",
      "Ep 1 (Step 011480): Train loss 2.900, Val loss 3.124\n",
      "Ep 1 (Step 011485): Train loss 3.122, Val loss 3.124\n",
      "Ep 1 (Step 011490): Train loss 3.312, Val loss 3.136\n",
      "Ep 1 (Step 011495): Train loss 2.936, Val loss 3.129\n",
      "Ep 1 (Step 011500): Train loss 3.207, Val loss 3.113\n",
      "Ep 1 (Step 011505): Train loss 2.934, Val loss 3.096\n",
      "Ep 1 (Step 011510): Train loss 3.163, Val loss 3.089\n",
      "Ep 1 (Step 011515): Train loss 3.029, Val loss 3.110\n",
      "Ep 1 (Step 011520): Train loss 2.946, Val loss 3.108\n",
      "Ep 1 (Step 011525): Train loss 3.123, Val loss 3.114\n",
      "Ep 1 (Step 011530): Train loss 3.142, Val loss 3.129\n",
      "Ep 1 (Step 011535): Train loss 2.849, Val loss 3.126\n",
      "Ep 1 (Step 011540): Train loss 2.931, Val loss 3.124\n",
      "Ep 1 (Step 011545): Train loss 3.024, Val loss 3.113\n",
      "Ep 1 (Step 011550): Train loss 3.295, Val loss 3.100\n",
      "Ep 1 (Step 011555): Train loss 2.990, Val loss 3.099\n",
      "Ep 1 (Step 011560): Train loss 3.086, Val loss 3.108\n",
      "Ep 1 (Step 011565): Train loss 3.052, Val loss 3.107\n",
      "Ep 1 (Step 011570): Train loss 3.013, Val loss 3.093\n",
      "Ep 1 (Step 011575): Train loss 2.906, Val loss 3.100\n",
      "Ep 1 (Step 011580): Train loss 2.753, Val loss 3.094\n",
      "Ep 1 (Step 011585): Train loss 2.793, Val loss 3.109\n",
      "Ep 1 (Step 011590): Train loss 3.289, Val loss 3.097\n",
      "Ep 1 (Step 011595): Train loss 2.952, Val loss 3.078\n",
      "Ep 1 (Step 011600): Train loss 3.175, Val loss 3.073\n",
      "Ep 1 (Step 011605): Train loss 3.252, Val loss 3.078\n",
      "Ep 1 (Step 011610): Train loss 3.252, Val loss 3.088\n",
      "Ep 1 (Step 011615): Train loss 3.186, Val loss 3.104\n",
      "Ep 1 (Step 011620): Train loss 2.960, Val loss 3.125\n",
      "Ep 1 (Step 011625): Train loss 3.158, Val loss 3.113\n",
      "Ep 1 (Step 011630): Train loss 3.260, Val loss 3.110\n",
      "Ep 1 (Step 011635): Train loss 3.301, Val loss 3.118\n",
      "Ep 1 (Step 011640): Train loss 3.227, Val loss 3.126\n",
      "Ep 1 (Step 011645): Train loss 3.065, Val loss 3.121\n",
      "Ep 1 (Step 011650): Train loss 3.070, Val loss 3.105\n",
      "Ep 1 (Step 011655): Train loss 3.194, Val loss 3.099\n",
      "Ep 1 (Step 011660): Train loss 3.051, Val loss 3.116\n",
      "Ep 1 (Step 011665): Train loss 3.071, Val loss 3.115\n",
      "Ep 1 (Step 011670): Train loss 3.107, Val loss 3.113\n",
      "Ep 1 (Step 011675): Train loss 3.200, Val loss 3.106\n",
      "Ep 1 (Step 011680): Train loss 2.943, Val loss 3.094\n",
      "Ep 1 (Step 011685): Train loss 2.864, Val loss 3.089\n",
      "Ep 1 (Step 011690): Train loss 3.053, Val loss 3.089\n",
      "Ep 1 (Step 011695): Train loss 2.979, Val loss 3.076\n",
      "Ep 1 (Step 011700): Train loss 3.328, Val loss 3.059\n",
      "Ep 1 (Step 011705): Train loss 3.011, Val loss 3.076\n",
      "Ep 1 (Step 011710): Train loss 2.981, Val loss 3.085\n",
      "Ep 1 (Step 011715): Train loss 3.201, Val loss 3.109\n",
      "Ep 1 (Step 011720): Train loss 2.909, Val loss 3.119\n",
      "Ep 1 (Step 011725): Train loss 3.054, Val loss 3.104\n",
      "Ep 1 (Step 011730): Train loss 2.784, Val loss 3.094\n",
      "Ep 1 (Step 011735): Train loss 3.253, Val loss 3.115\n",
      "Ep 1 (Step 011740): Train loss 3.183, Val loss 3.124\n",
      "Ep 1 (Step 011745): Train loss 3.150, Val loss 3.123\n",
      "Ep 1 (Step 011750): Train loss 3.193, Val loss 3.117\n",
      "Ep 1 (Step 011755): Train loss 3.015, Val loss 3.116\n",
      "Ep 1 (Step 011760): Train loss 3.285, Val loss 3.096\n",
      "Ep 1 (Step 011765): Train loss 2.767, Val loss 3.086\n",
      "Ep 1 (Step 011770): Train loss 3.032, Val loss 3.095\n",
      "Ep 1 (Step 011775): Train loss 3.116, Val loss 3.108\n",
      "Ep 1 (Step 011780): Train loss 3.056, Val loss 3.097\n",
      "Ep 1 (Step 011785): Train loss 3.090, Val loss 3.087\n",
      "Ep 1 (Step 011790): Train loss 3.151, Val loss 3.095\n",
      "Ep 1 (Step 011795): Train loss 3.303, Val loss 3.094\n",
      "Ep 1 (Step 011800): Train loss 3.077, Val loss 3.074\n",
      "Ep 1 (Step 011805): Train loss 3.105, Val loss 3.079\n",
      "Ep 1 (Step 011810): Train loss 2.834, Val loss 3.092\n",
      "Ep 1 (Step 011815): Train loss 3.303, Val loss 3.114\n",
      "Ep 1 (Step 011820): Train loss 3.323, Val loss 3.105\n",
      "Ep 1 (Step 011825): Train loss 3.245, Val loss 3.081\n",
      "Ep 1 (Step 011830): Train loss 3.238, Val loss 3.073\n",
      "Ep 1 (Step 011835): Train loss 3.024, Val loss 3.092\n",
      "Ep 1 (Step 011840): Train loss 3.063, Val loss 3.090\n",
      "Ep 1 (Step 011845): Train loss 3.017, Val loss 3.088\n",
      "Ep 1 (Step 011850): Train loss 2.999, Val loss 3.078\n",
      "Ep 1 (Step 011855): Train loss 3.052, Val loss 3.085\n",
      "Ep 1 (Step 011860): Train loss 2.852, Val loss 3.063\n",
      "Ep 1 (Step 011865): Train loss 2.867, Val loss 3.078\n",
      "Ep 1 (Step 011870): Train loss 3.121, Val loss 3.074\n",
      "Ep 1 (Step 011875): Train loss 2.926, Val loss 3.063\n",
      "Ep 1 (Step 011880): Train loss 2.851, Val loss 3.061\n",
      "Ep 1 (Step 011885): Train loss 3.108, Val loss 3.071\n",
      "Ep 1 (Step 011890): Train loss 3.224, Val loss 3.083\n",
      "Ep 1 (Step 011895): Train loss 3.017, Val loss 3.084\n",
      "Ep 1 (Step 011900): Train loss 2.890, Val loss 3.090\n",
      "Ep 1 (Step 011905): Train loss 3.342, Val loss 3.084\n",
      "Ep 1 (Step 011910): Train loss 3.108, Val loss 3.071\n",
      "Ep 1 (Step 011915): Train loss 2.899, Val loss 3.048\n",
      "Ep 1 (Step 011920): Train loss 2.931, Val loss 3.051\n",
      "Ep 1 (Step 011925): Train loss 3.265, Val loss 3.067\n",
      "Ep 1 (Step 011930): Train loss 3.302, Val loss 3.079\n",
      "Ep 1 (Step 011935): Train loss 2.907, Val loss 3.081\n",
      "Ep 1 (Step 011940): Train loss 2.977, Val loss 3.062\n",
      "Ep 1 (Step 011945): Train loss 2.903, Val loss 3.047\n",
      "Ep 1 (Step 011950): Train loss 3.007, Val loss 3.070\n",
      "Ep 1 (Step 011955): Train loss 2.912, Val loss 3.102\n",
      "Ep 1 (Step 011960): Train loss 3.075, Val loss 3.081\n",
      "Ep 1 (Step 011965): Train loss 2.838, Val loss 3.057\n",
      "Ep 1 (Step 011970): Train loss 3.144, Val loss 3.063\n",
      "Ep 1 (Step 011975): Train loss 2.815, Val loss 3.071\n",
      "Ep 1 (Step 011980): Train loss 2.812, Val loss 3.051\n",
      "Ep 1 (Step 011985): Train loss 3.118, Val loss 3.043\n",
      "Ep 1 (Step 011990): Train loss 2.881, Val loss 3.040\n",
      "Ep 1 (Step 011995): Train loss 3.005, Val loss 3.036\n",
      "Ep 1 (Step 012000): Train loss 2.782, Val loss 3.050\n",
      "Ep 1 (Step 012005): Train loss 3.042, Val loss 3.057\n",
      "Ep 1 (Step 012010): Train loss 3.082, Val loss 3.051\n",
      "Ep 1 (Step 012015): Train loss 3.331, Val loss 3.052\n",
      "Ep 1 (Step 012020): Train loss 3.012, Val loss 3.053\n",
      "Ep 1 (Step 012025): Train loss 2.903, Val loss 3.051\n",
      "Ep 1 (Step 012030): Train loss 3.132, Val loss 3.044\n",
      "Ep 1 (Step 012035): Train loss 3.369, Val loss 3.046\n",
      "Ep 1 (Step 012040): Train loss 3.078, Val loss 3.057\n",
      "Ep 1 (Step 012045): Train loss 3.040, Val loss 3.068\n",
      "Ep 1 (Step 012050): Train loss 3.273, Val loss 3.061\n",
      "Ep 1 (Step 012055): Train loss 3.146, Val loss 3.032\n",
      "Ep 1 (Step 012060): Train loss 2.982, Val loss 3.037\n",
      "Ep 1 (Step 012065): Train loss 3.185, Val loss 3.030\n",
      "Ep 1 (Step 012070): Train loss 2.945, Val loss 3.043\n",
      "Ep 1 (Step 012075): Train loss 2.859, Val loss 3.056\n",
      "Ep 1 (Step 012080): Train loss 3.048, Val loss 3.061\n",
      "Ep 1 (Step 012085): Train loss 2.771, Val loss 3.058\n",
      "Ep 1 (Step 012090): Train loss 2.868, Val loss 3.054\n",
      "Ep 1 (Step 012095): Train loss 3.042, Val loss 3.031\n",
      "Ep 1 (Step 012100): Train loss 3.106, Val loss 3.033\n",
      "Ep 1 (Step 012105): Train loss 3.006, Val loss 3.032\n",
      "Ep 1 (Step 012110): Train loss 2.901, Val loss 3.021\n",
      "Ep 1 (Step 012115): Train loss 2.889, Val loss 3.007\n",
      "Ep 1 (Step 012120): Train loss 2.797, Val loss 3.029\n",
      "Ep 1 (Step 012125): Train loss 2.968, Val loss 3.055\n",
      "Ep 1 (Step 012130): Train loss 2.903, Val loss 3.046\n",
      "Ep 1 (Step 012135): Train loss 3.072, Val loss 3.022\n",
      "Ep 1 (Step 012140): Train loss 2.777, Val loss 3.013\n",
      "Ep 1 (Step 012145): Train loss 2.769, Val loss 3.019\n",
      "Ep 1 (Step 012150): Train loss 3.281, Val loss 3.023\n",
      "Ep 1 (Step 012155): Train loss 3.228, Val loss 3.031\n",
      "Ep 1 (Step 012160): Train loss 3.279, Val loss 3.016\n",
      "Ep 1 (Step 012165): Train loss 2.872, Val loss 3.007\n",
      "Ep 1 (Step 012170): Train loss 2.839, Val loss 3.017\n",
      "Ep 1 (Step 012175): Train loss 3.085, Val loss 3.005\n",
      "Ep 1 (Step 012180): Train loss 2.667, Val loss 3.007\n",
      "Ep 1 (Step 012185): Train loss 2.834, Val loss 3.009\n",
      "Ep 1 (Step 012190): Train loss 2.728, Val loss 3.010\n",
      "Ep 1 (Step 012195): Train loss 2.781, Val loss 3.005\n",
      "Ep 1 (Step 012200): Train loss 2.871, Val loss 3.003\n",
      "Ep 1 (Step 012205): Train loss 2.840, Val loss 3.019\n",
      "Ep 1 (Step 012210): Train loss 2.730, Val loss 3.017\n",
      "Ep 1 (Step 012215): Train loss 3.123, Val loss 3.017\n",
      "Ep 1 (Step 012220): Train loss 3.001, Val loss 3.022\n",
      "Ep 1 (Step 012225): Train loss 3.054, Val loss 3.027\n",
      "Ep 1 (Step 012230): Train loss 3.083, Val loss 3.033\n",
      "Ep 1 (Step 012235): Train loss 2.943, Val loss 3.017\n",
      "Ep 1 (Step 012240): Train loss 2.825, Val loss 3.020\n",
      "Ep 1 (Step 012245): Train loss 2.551, Val loss 3.028\n",
      "Ep 1 (Step 012250): Train loss 2.713, Val loss 3.030\n",
      "Ep 1 (Step 012255): Train loss 2.817, Val loss 3.032\n",
      "Ep 1 (Step 012260): Train loss 2.892, Val loss 3.028\n",
      "Ep 1 (Step 012265): Train loss 3.122, Val loss 3.035\n",
      "Ep 1 (Step 012270): Train loss 2.805, Val loss 3.029\n",
      "Ep 1 (Step 012275): Train loss 3.252, Val loss 3.015\n",
      "Ep 1 (Step 012280): Train loss 2.923, Val loss 3.013\n",
      "Ep 1 (Step 012285): Train loss 2.882, Val loss 3.016\n",
      "Ep 1 (Step 012290): Train loss 3.193, Val loss 3.017\n",
      "Ep 1 (Step 012295): Train loss 2.913, Val loss 3.022\n",
      "Ep 1 (Step 012300): Train loss 3.196, Val loss 3.033\n",
      "Ep 1 (Step 012305): Train loss 2.867, Val loss 3.029\n",
      "Ep 1 (Step 012310): Train loss 3.130, Val loss 3.020\n",
      "Ep 1 (Step 012315): Train loss 2.745, Val loss 3.003\n",
      "Ep 1 (Step 012320): Train loss 3.384, Val loss 3.013\n",
      "Ep 1 (Step 012325): Train loss 3.053, Val loss 3.026\n",
      "Ep 1 (Step 012330): Train loss 2.731, Val loss 3.036\n",
      "Ep 1 (Step 012335): Train loss 3.248, Val loss 3.036\n",
      "Ep 1 (Step 012340): Train loss 3.249, Val loss 3.046\n",
      "Ep 1 (Step 012345): Train loss 2.788, Val loss 3.058\n",
      "Ep 1 (Step 012350): Train loss 3.007, Val loss 3.065\n",
      "Ep 1 (Step 012355): Train loss 2.884, Val loss 3.057\n",
      "Ep 1 (Step 012360): Train loss 2.866, Val loss 3.052\n",
      "Ep 1 (Step 012365): Train loss 2.963, Val loss 3.043\n",
      "Ep 1 (Step 012370): Train loss 2.868, Val loss 3.035\n",
      "Ep 1 (Step 012375): Train loss 2.792, Val loss 3.034\n",
      "Ep 1 (Step 012380): Train loss 2.878, Val loss 3.029\n",
      "Ep 1 (Step 012385): Train loss 3.182, Val loss 3.030\n",
      "Ep 1 (Step 012390): Train loss 2.743, Val loss 3.030\n",
      "Ep 1 (Step 012395): Train loss 2.847, Val loss 3.047\n",
      "Ep 1 (Step 012400): Train loss 2.995, Val loss 3.045\n",
      "Ep 1 (Step 012405): Train loss 3.262, Val loss 3.045\n",
      "Ep 1 (Step 012410): Train loss 2.970, Val loss 3.043\n",
      "Ep 1 (Step 012415): Train loss 2.997, Val loss 3.018\n",
      "Ep 1 (Step 012420): Train loss 2.937, Val loss 3.009\n",
      "Ep 1 (Step 012425): Train loss 3.159, Val loss 3.016\n",
      "Ep 1 (Step 012430): Train loss 3.059, Val loss 3.029\n",
      "Ep 1 (Step 012435): Train loss 2.987, Val loss 3.035\n",
      "Ep 1 (Step 012440): Train loss 2.816, Val loss 3.040\n",
      "Ep 1 (Step 012445): Train loss 3.022, Val loss 3.037\n",
      "Ep 1 (Step 012450): Train loss 3.240, Val loss 3.046\n",
      "Ep 1 (Step 012455): Train loss 3.000, Val loss 3.027\n",
      "Ep 1 (Step 012460): Train loss 2.696, Val loss 3.006\n",
      "Ep 1 (Step 012465): Train loss 2.968, Val loss 3.008\n",
      "Ep 1 (Step 012470): Train loss 3.086, Val loss 3.013\n",
      "Ep 1 (Step 012475): Train loss 2.917, Val loss 3.022\n",
      "Ep 1 (Step 012480): Train loss 2.829, Val loss 3.025\n",
      "Ep 1 (Step 012485): Train loss 2.818, Val loss 3.014\n",
      "Ep 1 (Step 012490): Train loss 2.853, Val loss 3.013\n",
      "Ep 1 (Step 012495): Train loss 2.975, Val loss 3.027\n",
      "Ep 1 (Step 012500): Train loss 3.038, Val loss 3.023\n",
      "Ep 1 (Step 012505): Train loss 3.101, Val loss 3.031\n",
      "Ep 1 (Step 012510): Train loss 2.904, Val loss 3.039\n",
      "Ep 1 (Step 012515): Train loss 2.838, Val loss 3.028\n",
      "Ep 1 (Step 012520): Train loss 2.880, Val loss 3.018\n",
      "Ep 1 (Step 012525): Train loss 3.168, Val loss 3.032\n",
      "Ep 1 (Step 012530): Train loss 2.866, Val loss 3.041\n",
      "Ep 1 (Step 012535): Train loss 2.780, Val loss 3.042\n",
      "Ep 1 (Step 012540): Train loss 2.941, Val loss 3.026\n",
      "Ep 1 (Step 012545): Train loss 3.100, Val loss 3.018\n",
      "Ep 1 (Step 012550): Train loss 2.720, Val loss 3.032\n",
      "Ep 1 (Step 012555): Train loss 2.798, Val loss 3.022\n",
      "Ep 1 (Step 012560): Train loss 3.097, Val loss 3.021\n",
      "Ep 1 (Step 012565): Train loss 2.992, Val loss 3.012\n",
      "Ep 1 (Step 012570): Train loss 2.941, Val loss 3.011\n",
      "Ep 1 (Step 012575): Train loss 2.834, Val loss 3.014\n",
      "Ep 1 (Step 012580): Train loss 3.121, Val loss 3.023\n",
      "Ep 1 (Step 012585): Train loss 2.775, Val loss 3.031\n",
      "Ep 1 (Step 012590): Train loss 2.687, Val loss 3.026\n",
      "Ep 1 (Step 012595): Train loss 3.078, Val loss 3.019\n",
      "Ep 1 (Step 012600): Train loss 2.834, Val loss 3.000\n",
      "Ep 1 (Step 012605): Train loss 3.037, Val loss 2.991\n",
      "Ep 1 (Step 012610): Train loss 2.922, Val loss 2.983\n",
      "Ep 1 (Step 012615): Train loss 3.313, Val loss 2.990\n",
      "Ep 1 (Step 012620): Train loss 2.644, Val loss 3.007\n",
      "Ep 1 (Step 012625): Train loss 2.853, Val loss 3.029\n",
      "Ep 1 (Step 012630): Train loss 2.736, Val loss 3.038\n",
      "Ep 1 (Step 012635): Train loss 2.986, Val loss 3.024\n",
      "Ep 1 (Step 012640): Train loss 2.973, Val loss 3.021\n",
      "Ep 1 (Step 012645): Train loss 2.765, Val loss 3.026\n",
      "Ep 1 (Step 012650): Train loss 2.734, Val loss 3.025\n",
      "Ep 1 (Step 012655): Train loss 3.382, Val loss 3.028\n",
      "Ep 1 (Step 012660): Train loss 3.070, Val loss 3.031\n",
      "Ep 1 (Step 012665): Train loss 3.269, Val loss 3.019\n",
      "Ep 1 (Step 012670): Train loss 2.758, Val loss 3.028\n",
      "Ep 1 (Step 012675): Train loss 2.872, Val loss 3.028\n",
      "Ep 1 (Step 012680): Train loss 2.735, Val loss 3.021\n",
      "Ep 1 (Step 012685): Train loss 2.926, Val loss 3.012\n",
      "Ep 1 (Step 012690): Train loss 2.762, Val loss 3.005\n",
      "Ep 1 (Step 012695): Train loss 2.971, Val loss 3.001\n",
      "Ep 1 (Step 012700): Train loss 2.952, Val loss 3.007\n",
      "Ep 1 (Step 012705): Train loss 2.857, Val loss 3.001\n",
      "Ep 1 (Step 012710): Train loss 3.067, Val loss 3.006\n",
      "Ep 1 (Step 012715): Train loss 2.904, Val loss 3.012\n",
      "Ep 1 (Step 012720): Train loss 3.460, Val loss 3.001\n",
      "Ep 1 (Step 012725): Train loss 2.985, Val loss 3.002\n",
      "Ep 1 (Step 012730): Train loss 2.694, Val loss 3.016\n",
      "Ep 1 (Step 012735): Train loss 2.898, Val loss 3.016\n",
      "Ep 1 (Step 012740): Train loss 3.013, Val loss 2.987\n",
      "Ep 1 (Step 012745): Train loss 2.947, Val loss 2.979\n",
      "Ep 1 (Step 012750): Train loss 2.599, Val loss 2.988\n",
      "Ep 1 (Step 012755): Train loss 3.211, Val loss 2.993\n",
      "Ep 1 (Step 012760): Train loss 3.031, Val loss 3.006\n",
      "Ep 1 (Step 012765): Train loss 3.021, Val loss 3.007\n",
      "Ep 1 (Step 012770): Train loss 2.833, Val loss 2.999\n",
      "Ep 1 (Step 012775): Train loss 2.935, Val loss 2.994\n",
      "Ep 1 (Step 012780): Train loss 2.908, Val loss 3.006\n",
      "Ep 1 (Step 012785): Train loss 2.828, Val loss 3.003\n",
      "Ep 1 (Step 012790): Train loss 3.085, Val loss 3.007\n",
      "Ep 1 (Step 012795): Train loss 2.818, Val loss 3.006\n",
      "Ep 1 (Step 012800): Train loss 2.609, Val loss 3.009\n",
      "Ep 1 (Step 012805): Train loss 2.977, Val loss 2.992\n",
      "Ep 1 (Step 012810): Train loss 2.947, Val loss 2.985\n",
      "Ep 1 (Step 012815): Train loss 2.898, Val loss 2.985\n",
      "Ep 1 (Step 012820): Train loss 2.812, Val loss 2.980\n",
      "Ep 1 (Step 012825): Train loss 3.087, Val loss 2.974\n",
      "Ep 1 (Step 012830): Train loss 3.164, Val loss 2.986\n",
      "Ep 1 (Step 012835): Train loss 2.777, Val loss 3.005\n",
      "Ep 1 (Step 012840): Train loss 3.056, Val loss 3.014\n",
      "Ep 1 (Step 012845): Train loss 3.092, Val loss 3.030\n",
      "Ep 1 (Step 012850): Train loss 2.814, Val loss 3.013\n",
      "Ep 1 (Step 012855): Train loss 2.834, Val loss 3.010\n",
      "Ep 1 (Step 012860): Train loss 2.935, Val loss 3.002\n",
      "Ep 1 (Step 012865): Train loss 2.991, Val loss 3.003\n",
      "Ep 1 (Step 012870): Train loss 3.017, Val loss 3.003\n",
      "Ep 1 (Step 012875): Train loss 3.055, Val loss 3.007\n",
      "Ep 1 (Step 012880): Train loss 2.939, Val loss 3.016\n",
      "Ep 1 (Step 012885): Train loss 2.990, Val loss 3.019\n",
      "Ep 1 (Step 012890): Train loss 2.803, Val loss 3.016\n",
      "Ep 1 (Step 012895): Train loss 2.967, Val loss 3.018\n",
      "Ep 1 (Step 012900): Train loss 2.927, Val loss 3.025\n",
      "Ep 1 (Step 012905): Train loss 3.070, Val loss 3.015\n",
      "Ep 1 (Step 012910): Train loss 3.090, Val loss 3.015\n",
      "Ep 1 (Step 012915): Train loss 2.713, Val loss 3.031\n",
      "Ep 1 (Step 012920): Train loss 2.894, Val loss 3.021\n",
      "Ep 1 (Step 012925): Train loss 2.705, Val loss 3.003\n",
      "Ep 1 (Step 012930): Train loss 2.706, Val loss 3.003\n",
      "Ep 1 (Step 012935): Train loss 2.736, Val loss 2.995\n",
      "Ep 1 (Step 012940): Train loss 2.838, Val loss 3.007\n",
      "Ep 1 (Step 012945): Train loss 3.008, Val loss 3.016\n",
      "Ep 1 (Step 012950): Train loss 2.945, Val loss 3.009\n",
      "Ep 1 (Step 012955): Train loss 2.846, Val loss 3.014\n",
      "Ep 1 (Step 012960): Train loss 2.984, Val loss 2.999\n",
      "Ep 1 (Step 012965): Train loss 2.715, Val loss 2.997\n",
      "Ep 1 (Step 012970): Train loss 2.989, Val loss 3.003\n",
      "Ep 1 (Step 012975): Train loss 2.748, Val loss 3.021\n",
      "Ep 1 (Step 012980): Train loss 2.773, Val loss 3.021\n",
      "Ep 1 (Step 012985): Train loss 3.012, Val loss 3.023\n",
      "Ep 1 (Step 012990): Train loss 3.068, Val loss 3.019\n",
      "Ep 1 (Step 012995): Train loss 2.912, Val loss 3.030\n",
      "Ep 1 (Step 013000): Train loss 2.909, Val loss 3.004\n",
      "Ep 1 (Step 013005): Train loss 2.704, Val loss 2.983\n",
      "Ep 1 (Step 013010): Train loss 2.705, Val loss 2.981\n",
      "Ep 1 (Step 013015): Train loss 2.794, Val loss 2.994\n",
      "Ep 1 (Step 013020): Train loss 2.688, Val loss 2.979\n",
      "Ep 1 (Step 013025): Train loss 2.858, Val loss 2.986\n",
      "Ep 1 (Step 013030): Train loss 3.053, Val loss 2.992\n",
      "Ep 1 (Step 013035): Train loss 2.886, Val loss 2.972\n",
      "Ep 1 (Step 013040): Train loss 2.731, Val loss 2.978\n",
      "Ep 1 (Step 013045): Train loss 2.969, Val loss 2.978\n",
      "Ep 1 (Step 013050): Train loss 3.131, Val loss 3.004\n",
      "Ep 1 (Step 013055): Train loss 2.997, Val loss 3.014\n",
      "Ep 1 (Step 013060): Train loss 2.658, Val loss 3.012\n",
      "Ep 1 (Step 013065): Train loss 2.972, Val loss 2.995\n",
      "Ep 1 (Step 013070): Train loss 2.976, Val loss 2.975\n",
      "Ep 1 (Step 013075): Train loss 3.113, Val loss 2.994\n",
      "Ep 1 (Step 013080): Train loss 2.837, Val loss 2.992\n",
      "Ep 1 (Step 013085): Train loss 2.962, Val loss 3.016\n",
      "Ep 1 (Step 013090): Train loss 2.835, Val loss 3.021\n",
      "Ep 1 (Step 013095): Train loss 2.732, Val loss 3.007\n",
      "Ep 1 (Step 013100): Train loss 2.924, Val loss 3.006\n",
      "Ep 1 (Step 013105): Train loss 2.616, Val loss 3.005\n",
      "Ep 1 (Step 013110): Train loss 2.637, Val loss 3.001\n",
      "Ep 1 (Step 013115): Train loss 2.865, Val loss 2.983\n",
      "Ep 1 (Step 013120): Train loss 2.846, Val loss 2.975\n",
      "Ep 1 (Step 013125): Train loss 2.815, Val loss 2.970\n",
      "Ep 1 (Step 013130): Train loss 2.674, Val loss 2.961\n",
      "Ep 1 (Step 013135): Train loss 2.874, Val loss 2.967\n",
      "Ep 1 (Step 013140): Train loss 3.079, Val loss 2.960\n",
      "Ep 1 (Step 013145): Train loss 2.887, Val loss 2.953\n",
      "Ep 1 (Step 013150): Train loss 3.109, Val loss 2.958\n",
      "Ep 1 (Step 013155): Train loss 2.802, Val loss 2.961\n",
      "Ep 1 (Step 013160): Train loss 2.921, Val loss 2.984\n",
      "Ep 1 (Step 013165): Train loss 2.781, Val loss 2.992\n",
      "Ep 1 (Step 013170): Train loss 3.041, Val loss 2.992\n",
      "Ep 1 (Step 013175): Train loss 3.105, Val loss 2.975\n",
      "Ep 1 (Step 013180): Train loss 3.134, Val loss 2.985\n",
      "Ep 1 (Step 013185): Train loss 2.846, Val loss 2.971\n",
      "Ep 1 (Step 013190): Train loss 3.135, Val loss 2.966\n",
      "Ep 1 (Step 013195): Train loss 2.889, Val loss 2.977\n",
      "Ep 1 (Step 013200): Train loss 3.218, Val loss 2.978\n",
      "Ep 1 (Step 013205): Train loss 3.443, Val loss 2.947\n",
      "Ep 1 (Step 013210): Train loss 3.103, Val loss 2.952\n",
      "Ep 1 (Step 013215): Train loss 3.100, Val loss 2.957\n",
      "Ep 1 (Step 013220): Train loss 2.914, Val loss 2.956\n",
      "Ep 1 (Step 013225): Train loss 3.031, Val loss 2.945\n",
      "Ep 1 (Step 013230): Train loss 3.081, Val loss 2.970\n",
      "Ep 1 (Step 013235): Train loss 2.992, Val loss 2.980\n",
      "Ep 1 (Step 013240): Train loss 2.847, Val loss 2.957\n",
      "Ep 1 (Step 013245): Train loss 2.866, Val loss 2.945\n",
      "Ep 1 (Step 013250): Train loss 2.679, Val loss 2.932\n",
      "Ep 1 (Step 013255): Train loss 2.736, Val loss 2.944\n",
      "Ep 1 (Step 013260): Train loss 2.950, Val loss 2.963\n",
      "Ep 1 (Step 013265): Train loss 2.968, Val loss 2.959\n",
      "Ep 1 (Step 013270): Train loss 2.609, Val loss 2.949\n",
      "Ep 1 (Step 013275): Train loss 2.902, Val loss 2.957\n",
      "Ep 1 (Step 013280): Train loss 2.827, Val loss 2.960\n",
      "Ep 1 (Step 013285): Train loss 3.079, Val loss 2.934\n",
      "Ep 1 (Step 013290): Train loss 2.780, Val loss 2.935\n",
      "Ep 1 (Step 013295): Train loss 2.609, Val loss 2.944\n",
      "Ep 1 (Step 013300): Train loss 2.548, Val loss 2.954\n",
      "Ep 1 (Step 013305): Train loss 3.384, Val loss 2.952\n",
      "Ep 1 (Step 013310): Train loss 2.871, Val loss 2.953\n",
      "Ep 1 (Step 013315): Train loss 3.010, Val loss 2.967\n",
      "Ep 1 (Step 013320): Train loss 2.673, Val loss 2.972\n",
      "Ep 1 (Step 013325): Train loss 2.818, Val loss 2.988\n",
      "Ep 1 (Step 013330): Train loss 2.825, Val loss 2.987\n",
      "Ep 1 (Step 013335): Train loss 2.748, Val loss 2.981\n",
      "Ep 1 (Step 013340): Train loss 2.738, Val loss 2.971\n",
      "Ep 1 (Step 013345): Train loss 2.956, Val loss 2.968\n",
      "Ep 1 (Step 013350): Train loss 2.848, Val loss 2.973\n",
      "Ep 1 (Step 013355): Train loss 2.720, Val loss 2.982\n",
      "Ep 1 (Step 013360): Train loss 2.833, Val loss 2.993\n",
      "Ep 1 (Step 013365): Train loss 2.895, Val loss 2.979\n",
      "Ep 1 (Step 013370): Train loss 2.808, Val loss 2.952\n",
      "Ep 1 (Step 013375): Train loss 2.508, Val loss 2.948\n",
      "Ep 1 (Step 013380): Train loss 2.908, Val loss 2.949\n",
      "Ep 1 (Step 013385): Train loss 2.842, Val loss 2.960\n",
      "Ep 1 (Step 013390): Train loss 2.952, Val loss 2.969\n",
      "Ep 1 (Step 013395): Train loss 3.078, Val loss 2.974\n",
      "Ep 1 (Step 013400): Train loss 2.834, Val loss 2.979\n",
      "Ep 1 (Step 013405): Train loss 3.248, Val loss 2.983\n",
      "Ep 1 (Step 013410): Train loss 3.257, Val loss 2.982\n",
      "Ep 1 (Step 013415): Train loss 2.760, Val loss 2.976\n",
      "Ep 1 (Step 013420): Train loss 2.799, Val loss 2.986\n",
      "Ep 1 (Step 013425): Train loss 2.909, Val loss 2.987\n",
      "Ep 1 (Step 013430): Train loss 3.062, Val loss 2.980\n",
      "Ep 1 (Step 013435): Train loss 2.884, Val loss 2.991\n",
      "Ep 1 (Step 013440): Train loss 3.095, Val loss 2.987\n",
      "Ep 1 (Step 013445): Train loss 3.060, Val loss 2.972\n",
      "Ep 1 (Step 013450): Train loss 3.031, Val loss 2.959\n",
      "Ep 1 (Step 013455): Train loss 3.050, Val loss 2.963\n",
      "Ep 1 (Step 013460): Train loss 2.838, Val loss 2.964\n",
      "Ep 1 (Step 013465): Train loss 3.124, Val loss 2.965\n",
      "Ep 1 (Step 013470): Train loss 2.840, Val loss 2.962\n",
      "Ep 1 (Step 013475): Train loss 2.709, Val loss 2.951\n",
      "Ep 1 (Step 013480): Train loss 2.702, Val loss 2.947\n",
      "Ep 1 (Step 013485): Train loss 2.704, Val loss 2.954\n",
      "Ep 1 (Step 013490): Train loss 2.825, Val loss 2.950\n",
      "Ep 1 (Step 013495): Train loss 2.840, Val loss 2.949\n",
      "Ep 1 (Step 013500): Train loss 2.756, Val loss 2.943\n",
      "Ep 1 (Step 013505): Train loss 2.796, Val loss 2.941\n",
      "Ep 1 (Step 013510): Train loss 2.916, Val loss 2.948\n",
      "Ep 1 (Step 013515): Train loss 2.854, Val loss 2.946\n",
      "Ep 1 (Step 013520): Train loss 3.080, Val loss 2.936\n",
      "Ep 1 (Step 013525): Train loss 2.877, Val loss 2.951\n",
      "Ep 1 (Step 013530): Train loss 2.856, Val loss 2.960\n",
      "Ep 1 (Step 013535): Train loss 2.792, Val loss 2.939\n",
      "Ep 1 (Step 013540): Train loss 2.815, Val loss 2.940\n",
      "Ep 1 (Step 013545): Train loss 2.755, Val loss 2.947\n",
      "Ep 1 (Step 013550): Train loss 2.683, Val loss 2.944\n",
      "Ep 1 (Step 013555): Train loss 2.678, Val loss 2.949\n",
      "Ep 1 (Step 013560): Train loss 2.933, Val loss 2.951\n",
      "Ep 1 (Step 013565): Train loss 2.713, Val loss 2.968\n",
      "Ep 1 (Step 013570): Train loss 2.823, Val loss 2.962\n",
      "Ep 1 (Step 013575): Train loss 2.660, Val loss 2.955\n",
      "Ep 1 (Step 013580): Train loss 2.826, Val loss 2.952\n",
      "Ep 1 (Step 013585): Train loss 2.685, Val loss 2.953\n",
      "Ep 1 (Step 013590): Train loss 2.808, Val loss 2.965\n",
      "Ep 1 (Step 013595): Train loss 2.819, Val loss 2.951\n",
      "Ep 1 (Step 013600): Train loss 2.900, Val loss 2.932\n",
      "Ep 1 (Step 013605): Train loss 2.961, Val loss 2.923\n",
      "Ep 1 (Step 013610): Train loss 2.849, Val loss 2.940\n",
      "Ep 1 (Step 013615): Train loss 2.910, Val loss 2.945\n",
      "Ep 1 (Step 013620): Train loss 3.047, Val loss 2.930\n",
      "Ep 1 (Step 013625): Train loss 3.085, Val loss 2.937\n",
      "Ep 1 (Step 013630): Train loss 2.980, Val loss 2.949\n",
      "Ep 1 (Step 013635): Train loss 2.727, Val loss 2.966\n",
      "Ep 1 (Step 013640): Train loss 3.026, Val loss 2.939\n",
      "Ep 1 (Step 013645): Train loss 3.090, Val loss 2.921\n",
      "Ep 1 (Step 013650): Train loss 2.834, Val loss 2.924\n",
      "Ep 1 (Step 013655): Train loss 2.788, Val loss 2.936\n",
      "Ep 1 (Step 013660): Train loss 2.757, Val loss 2.930\n",
      "Ep 1 (Step 013665): Train loss 2.865, Val loss 2.926\n",
      "Ep 1 (Step 013670): Train loss 2.923, Val loss 2.930\n",
      "Ep 1 (Step 013675): Train loss 3.032, Val loss 2.950\n",
      "Ep 1 (Step 013680): Train loss 2.601, Val loss 2.952\n",
      "Ep 1 (Step 013685): Train loss 2.945, Val loss 2.943\n",
      "Ep 1 (Step 013690): Train loss 2.683, Val loss 2.936\n",
      "Ep 1 (Step 013695): Train loss 2.960, Val loss 2.934\n",
      "Ep 1 (Step 013700): Train loss 2.816, Val loss 2.912\n",
      "Ep 1 (Step 013705): Train loss 2.769, Val loss 2.914\n",
      "Ep 1 (Step 013710): Train loss 2.733, Val loss 2.917\n",
      "Ep 1 (Step 013715): Train loss 2.891, Val loss 2.914\n",
      "Ep 1 (Step 013720): Train loss 2.996, Val loss 2.918\n",
      "Ep 1 (Step 013725): Train loss 2.661, Val loss 2.919\n",
      "Ep 1 (Step 013730): Train loss 2.522, Val loss 2.909\n",
      "Ep 1 (Step 013735): Train loss 2.650, Val loss 2.902\n",
      "Ep 1 (Step 013740): Train loss 2.740, Val loss 2.900\n",
      "Ep 1 (Step 013745): Train loss 2.774, Val loss 2.906\n",
      "Ep 1 (Step 013750): Train loss 2.757, Val loss 2.907\n",
      "Ep 1 (Step 013755): Train loss 2.800, Val loss 2.923\n",
      "Ep 1 (Step 013760): Train loss 3.165, Val loss 2.919\n",
      "Ep 1 (Step 013765): Train loss 2.622, Val loss 2.905\n",
      "Ep 1 (Step 013770): Train loss 2.627, Val loss 2.920\n",
      "Ep 1 (Step 013775): Train loss 2.686, Val loss 2.924\n",
      "Ep 1 (Step 013780): Train loss 2.934, Val loss 2.940\n",
      "Ep 1 (Step 013785): Train loss 2.742, Val loss 2.955\n",
      "Ep 1 (Step 013790): Train loss 2.813, Val loss 2.954\n",
      "Ep 1 (Step 013795): Train loss 2.781, Val loss 2.950\n",
      "Ep 1 (Step 013800): Train loss 2.554, Val loss 2.956\n",
      "Ep 1 (Step 013805): Train loss 2.566, Val loss 2.941\n",
      "Ep 1 (Step 013810): Train loss 2.802, Val loss 2.934\n",
      "Ep 1 (Step 013815): Train loss 3.013, Val loss 2.951\n",
      "Ep 1 (Step 013820): Train loss 2.693, Val loss 2.958\n",
      "Ep 1 (Step 013825): Train loss 2.629, Val loss 2.968\n",
      "Ep 1 (Step 013830): Train loss 2.967, Val loss 2.951\n",
      "Ep 1 (Step 013835): Train loss 2.876, Val loss 2.944\n",
      "Ep 1 (Step 013840): Train loss 2.677, Val loss 2.941\n",
      "Ep 1 (Step 013845): Train loss 2.612, Val loss 2.939\n",
      "Ep 1 (Step 013850): Train loss 2.798, Val loss 2.962\n",
      "Ep 1 (Step 013855): Train loss 2.971, Val loss 2.965\n",
      "Ep 1 (Step 013860): Train loss 3.079, Val loss 2.953\n",
      "Ep 1 (Step 013865): Train loss 2.778, Val loss 2.955\n",
      "Ep 1 (Step 013870): Train loss 3.008, Val loss 2.959\n",
      "Ep 1 (Step 013875): Train loss 2.954, Val loss 2.945\n",
      "Ep 1 (Step 013880): Train loss 2.965, Val loss 2.933\n",
      "Ep 1 (Step 013885): Train loss 2.924, Val loss 2.929\n",
      "Ep 1 (Step 013890): Train loss 2.789, Val loss 2.929\n",
      "Ep 1 (Step 013895): Train loss 2.796, Val loss 2.936\n",
      "Ep 1 (Step 013900): Train loss 2.794, Val loss 2.950\n",
      "Ep 1 (Step 013905): Train loss 2.631, Val loss 2.949\n",
      "Ep 1 (Step 013910): Train loss 2.746, Val loss 2.968\n",
      "Ep 1 (Step 013915): Train loss 3.024, Val loss 2.935\n",
      "Ep 1 (Step 013920): Train loss 2.611, Val loss 2.923\n",
      "Ep 1 (Step 013925): Train loss 2.871, Val loss 2.915\n",
      "Ep 1 (Step 013930): Train loss 2.925, Val loss 2.946\n",
      "Ep 1 (Step 013935): Train loss 2.763, Val loss 2.949\n",
      "Ep 1 (Step 013940): Train loss 2.545, Val loss 2.947\n",
      "Ep 1 (Step 013945): Train loss 2.975, Val loss 2.940\n",
      "Ep 1 (Step 013950): Train loss 2.758, Val loss 2.935\n",
      "Ep 1 (Step 013955): Train loss 2.852, Val loss 2.946\n",
      "Ep 1 (Step 013960): Train loss 3.120, Val loss 2.960\n",
      "Ep 1 (Step 013965): Train loss 2.726, Val loss 2.938\n",
      "Ep 1 (Step 013970): Train loss 3.000, Val loss 2.919\n",
      "Ep 1 (Step 013975): Train loss 2.491, Val loss 2.909\n",
      "Ep 1 (Step 013980): Train loss 3.077, Val loss 2.915\n",
      "Ep 1 (Step 013985): Train loss 2.909, Val loss 2.905\n",
      "Ep 1 (Step 013990): Train loss 2.963, Val loss 2.900\n",
      "Ep 1 (Step 013995): Train loss 2.978, Val loss 2.920\n",
      "Ep 1 (Step 014000): Train loss 2.501, Val loss 2.919\n",
      "Ep 1 (Step 014005): Train loss 2.656, Val loss 2.916\n",
      "Ep 1 (Step 014010): Train loss 2.958, Val loss 2.926\n",
      "Ep 1 (Step 014015): Train loss 2.573, Val loss 2.927\n",
      "Ep 1 (Step 014020): Train loss 2.792, Val loss 2.908\n",
      "Ep 1 (Step 014025): Train loss 2.754, Val loss 2.906\n",
      "Ep 1 (Step 014030): Train loss 2.957, Val loss 2.913\n",
      "Ep 1 (Step 014035): Train loss 2.730, Val loss 2.925\n",
      "Ep 1 (Step 014040): Train loss 2.916, Val loss 2.913\n",
      "Ep 1 (Step 014045): Train loss 2.709, Val loss 2.898\n",
      "Ep 1 (Step 014050): Train loss 2.600, Val loss 2.913\n",
      "Ep 1 (Step 014055): Train loss 2.736, Val loss 2.929\n",
      "Ep 1 (Step 014060): Train loss 2.372, Val loss 2.925\n",
      "Ep 1 (Step 014065): Train loss 2.920, Val loss 2.913\n",
      "Ep 1 (Step 014070): Train loss 2.978, Val loss 2.906\n",
      "Ep 1 (Step 014075): Train loss 2.860, Val loss 2.902\n",
      "Ep 1 (Step 014080): Train loss 2.821, Val loss 2.932\n",
      "Ep 1 (Step 014085): Train loss 2.858, Val loss 2.933\n",
      "Ep 1 (Step 014090): Train loss 2.713, Val loss 2.921\n",
      "Ep 1 (Step 014095): Train loss 2.835, Val loss 2.909\n",
      "Ep 1 (Step 014100): Train loss 2.868, Val loss 2.896\n",
      "Ep 1 (Step 014105): Train loss 3.171, Val loss 2.911\n",
      "Ep 1 (Step 014110): Train loss 2.932, Val loss 2.919\n",
      "Ep 1 (Step 014115): Train loss 2.593, Val loss 2.906\n",
      "Ep 1 (Step 014120): Train loss 3.012, Val loss 2.894\n",
      "Ep 1 (Step 014125): Train loss 2.923, Val loss 2.886\n",
      "Ep 1 (Step 014130): Train loss 2.705, Val loss 2.892\n",
      "Ep 1 (Step 014135): Train loss 2.865, Val loss 2.892\n",
      "Ep 1 (Step 014140): Train loss 2.570, Val loss 2.890\n",
      "Ep 1 (Step 014145): Train loss 2.852, Val loss 2.904\n",
      "Ep 1 (Step 014150): Train loss 2.794, Val loss 2.902\n",
      "Ep 1 (Step 014155): Train loss 2.737, Val loss 2.907\n",
      "Ep 1 (Step 014160): Train loss 2.679, Val loss 2.895\n",
      "Ep 1 (Step 014165): Train loss 2.864, Val loss 2.901\n",
      "Ep 1 (Step 014170): Train loss 2.801, Val loss 2.900\n",
      "Ep 1 (Step 014175): Train loss 2.800, Val loss 2.904\n",
      "Ep 1 (Step 014180): Train loss 2.816, Val loss 2.897\n",
      "Ep 1 (Step 014185): Train loss 2.704, Val loss 2.884\n",
      "Ep 1 (Step 014190): Train loss 2.785, Val loss 2.876\n",
      "Ep 1 (Step 014195): Train loss 2.829, Val loss 2.880\n",
      "Ep 1 (Step 014200): Train loss 3.089, Val loss 2.876\n",
      "Ep 1 (Step 014205): Train loss 2.865, Val loss 2.870\n",
      "Ep 1 (Step 014210): Train loss 2.903, Val loss 2.875\n",
      "Ep 1 (Step 014215): Train loss 2.594, Val loss 2.871\n",
      "Ep 1 (Step 014220): Train loss 2.720, Val loss 2.881\n",
      "Ep 1 (Step 014225): Train loss 2.687, Val loss 2.879\n",
      "Ep 1 (Step 014230): Train loss 2.832, Val loss 2.898\n",
      "Ep 1 (Step 014235): Train loss 2.935, Val loss 2.912\n",
      "Ep 1 (Step 014240): Train loss 2.971, Val loss 2.910\n",
      "Ep 1 (Step 014245): Train loss 3.261, Val loss 2.897\n",
      "Ep 1 (Step 014250): Train loss 2.689, Val loss 2.904\n",
      "Ep 1 (Step 014255): Train loss 2.598, Val loss 2.892\n",
      "Ep 1 (Step 014260): Train loss 2.893, Val loss 2.886\n",
      "Ep 1 (Step 014265): Train loss 3.113, Val loss 2.891\n",
      "Ep 1 (Step 014270): Train loss 2.845, Val loss 2.908\n",
      "Ep 1 (Step 014275): Train loss 2.855, Val loss 2.905\n",
      "Ep 1 (Step 014280): Train loss 2.993, Val loss 2.892\n",
      "Ep 1 (Step 014285): Train loss 2.820, Val loss 2.886\n",
      "Ep 1 (Step 014290): Train loss 2.719, Val loss 2.878\n",
      "Ep 1 (Step 014295): Train loss 2.645, Val loss 2.876\n",
      "Ep 1 (Step 014300): Train loss 2.539, Val loss 2.865\n",
      "Ep 1 (Step 014305): Train loss 2.852, Val loss 2.866\n",
      "Ep 1 (Step 014310): Train loss 2.659, Val loss 2.863\n",
      "Ep 1 (Step 014315): Train loss 2.958, Val loss 2.864\n",
      "Ep 1 (Step 014320): Train loss 2.767, Val loss 2.885\n",
      "Ep 1 (Step 014325): Train loss 2.642, Val loss 2.890\n",
      "Ep 1 (Step 014330): Train loss 2.638, Val loss 2.865\n",
      "Ep 1 (Step 014335): Train loss 2.907, Val loss 2.843\n",
      "Ep 1 (Step 014340): Train loss 2.733, Val loss 2.846\n",
      "Ep 1 (Step 014345): Train loss 2.628, Val loss 2.877\n",
      "Ep 1 (Step 014350): Train loss 2.869, Val loss 2.874\n",
      "Ep 1 (Step 014355): Train loss 2.981, Val loss 2.868\n",
      "Ep 1 (Step 014360): Train loss 2.597, Val loss 2.859\n",
      "Ep 1 (Step 014365): Train loss 2.718, Val loss 2.853\n",
      "Ep 1 (Step 014370): Train loss 2.886, Val loss 2.868\n",
      "Ep 1 (Step 014375): Train loss 2.683, Val loss 2.861\n",
      "Ep 1 (Step 014380): Train loss 2.824, Val loss 2.856\n",
      "Ep 1 (Step 014385): Train loss 2.597, Val loss 2.848\n",
      "Ep 1 (Step 014390): Train loss 2.728, Val loss 2.858\n",
      "Ep 1 (Step 014395): Train loss 3.048, Val loss 2.851\n",
      "Ep 1 (Step 014400): Train loss 2.908, Val loss 2.851\n",
      "Ep 1 (Step 014405): Train loss 2.610, Val loss 2.845\n",
      "Ep 1 (Step 014410): Train loss 2.829, Val loss 2.830\n",
      "Ep 1 (Step 014415): Train loss 2.977, Val loss 2.835\n",
      "Ep 1 (Step 014420): Train loss 2.878, Val loss 2.856\n",
      "Ep 1 (Step 014425): Train loss 2.955, Val loss 2.838\n",
      "Ep 1 (Step 014430): Train loss 2.909, Val loss 2.833\n",
      "Ep 1 (Step 014435): Train loss 2.764, Val loss 2.838\n",
      "Ep 1 (Step 014440): Train loss 2.671, Val loss 2.840\n",
      "Ep 1 (Step 014445): Train loss 2.678, Val loss 2.850\n",
      "Ep 1 (Step 014450): Train loss 3.061, Val loss 2.856\n",
      "Ep 1 (Step 014455): Train loss 2.787, Val loss 2.852\n",
      "Ep 1 (Step 014460): Train loss 2.584, Val loss 2.859\n",
      "Ep 1 (Step 014465): Train loss 2.633, Val loss 2.845\n",
      "Ep 1 (Step 014470): Train loss 2.754, Val loss 2.835\n",
      "Ep 1 (Step 014475): Train loss 2.641, Val loss 2.850\n",
      "Ep 1 (Step 014480): Train loss 2.947, Val loss 2.871\n",
      "Ep 1 (Step 014485): Train loss 2.957, Val loss 2.894\n",
      "Ep 1 (Step 014490): Train loss 2.911, Val loss 2.890\n",
      "Ep 1 (Step 014495): Train loss 2.737, Val loss 2.872\n",
      "Ep 1 (Step 014500): Train loss 2.597, Val loss 2.864\n",
      "Ep 1 (Step 014505): Train loss 2.860, Val loss 2.854\n",
      "Ep 1 (Step 014510): Train loss 2.504, Val loss 2.870\n",
      "Ep 1 (Step 014515): Train loss 2.760, Val loss 2.888\n",
      "Ep 1 (Step 014520): Train loss 2.814, Val loss 2.875\n",
      "Ep 1 (Step 014525): Train loss 2.616, Val loss 2.869\n",
      "Ep 1 (Step 014530): Train loss 2.871, Val loss 2.867\n",
      "Ep 1 (Step 014535): Train loss 2.702, Val loss 2.867\n",
      "Ep 1 (Step 014540): Train loss 2.628, Val loss 2.858\n",
      "Ep 1 (Step 014545): Train loss 3.125, Val loss 2.849\n",
      "Ep 1 (Step 014550): Train loss 2.938, Val loss 2.845\n",
      "Ep 1 (Step 014555): Train loss 2.882, Val loss 2.850\n",
      "Ep 1 (Step 014560): Train loss 2.846, Val loss 2.847\n",
      "Ep 1 (Step 014565): Train loss 2.691, Val loss 2.845\n",
      "Ep 1 (Step 014570): Train loss 2.864, Val loss 2.856\n",
      "Ep 1 (Step 014575): Train loss 2.945, Val loss 2.866\n",
      "Ep 1 (Step 014580): Train loss 2.975, Val loss 2.866\n",
      "Ep 1 (Step 014585): Train loss 2.781, Val loss 2.849\n",
      "Ep 1 (Step 014590): Train loss 3.416, Val loss 2.836\n",
      "Ep 1 (Step 014595): Train loss 2.911, Val loss 2.829\n",
      "Ep 1 (Step 014600): Train loss 2.797, Val loss 2.821\n",
      "Ep 1 (Step 014605): Train loss 2.830, Val loss 2.819\n",
      "Ep 1 (Step 014610): Train loss 2.810, Val loss 2.831\n",
      "Ep 1 (Step 014615): Train loss 2.763, Val loss 2.836\n",
      "Ep 1 (Step 014620): Train loss 2.427, Val loss 2.831\n",
      "Ep 1 (Step 014625): Train loss 2.712, Val loss 2.820\n",
      "Ep 1 (Step 014630): Train loss 2.632, Val loss 2.824\n",
      "Ep 1 (Step 014635): Train loss 3.093, Val loss 2.822\n",
      "Ep 1 (Step 014640): Train loss 2.944, Val loss 2.811\n",
      "Ep 1 (Step 014645): Train loss 2.642, Val loss 2.814\n",
      "Ep 1 (Step 014650): Train loss 2.698, Val loss 2.817\n",
      "Ep 1 (Step 014655): Train loss 2.883, Val loss 2.822\n",
      "Ep 1 (Step 014660): Train loss 3.060, Val loss 2.835\n",
      "Ep 1 (Step 014665): Train loss 2.888, Val loss 2.826\n",
      "Ep 1 (Step 014670): Train loss 2.562, Val loss 2.831\n",
      "Ep 1 (Step 014675): Train loss 2.940, Val loss 2.840\n",
      "Ep 1 (Step 014680): Train loss 2.849, Val loss 2.829\n",
      "Ep 1 (Step 014685): Train loss 2.827, Val loss 2.830\n",
      "Ep 1 (Step 014690): Train loss 2.602, Val loss 2.824\n",
      "Ep 1 (Step 014695): Train loss 2.763, Val loss 2.833\n",
      "Ep 1 (Step 014700): Train loss 2.437, Val loss 2.828\n",
      "Ep 1 (Step 014705): Train loss 2.918, Val loss 2.836\n",
      "Ep 1 (Step 014710): Train loss 2.789, Val loss 2.834\n",
      "Ep 1 (Step 014715): Train loss 3.190, Val loss 2.839\n",
      "Ep 1 (Step 014720): Train loss 2.865, Val loss 2.840\n",
      "Ep 1 (Step 014725): Train loss 2.673, Val loss 2.845\n",
      "Ep 1 (Step 014730): Train loss 2.556, Val loss 2.841\n",
      "Ep 1 (Step 014735): Train loss 3.066, Val loss 2.844\n",
      "Ep 1 (Step 014740): Train loss 2.758, Val loss 2.852\n",
      "Ep 1 (Step 014745): Train loss 3.080, Val loss 2.852\n",
      "Ep 1 (Step 014750): Train loss 2.733, Val loss 2.839\n",
      "Ep 1 (Step 014755): Train loss 3.047, Val loss 2.828\n",
      "Ep 1 (Step 014760): Train loss 2.915, Val loss 2.834\n",
      "Ep 1 (Step 014765): Train loss 3.154, Val loss 2.837\n",
      "Ep 1 (Step 014770): Train loss 2.619, Val loss 2.828\n",
      "Ep 1 (Step 014775): Train loss 3.044, Val loss 2.827\n",
      "Ep 1 (Step 014780): Train loss 3.000, Val loss 2.826\n",
      "Ep 1 (Step 014785): Train loss 2.623, Val loss 2.820\n",
      "Ep 1 (Step 014790): Train loss 2.635, Val loss 2.824\n",
      "Ep 1 (Step 014795): Train loss 2.793, Val loss 2.814\n",
      "Ep 1 (Step 014800): Train loss 2.728, Val loss 2.799\n",
      "Ep 1 (Step 014805): Train loss 2.738, Val loss 2.794\n",
      "Ep 1 (Step 014810): Train loss 2.443, Val loss 2.800\n",
      "Ep 1 (Step 014815): Train loss 2.996, Val loss 2.818\n",
      "Ep 1 (Step 014820): Train loss 2.690, Val loss 2.827\n",
      "Ep 1 (Step 014825): Train loss 2.649, Val loss 2.803\n",
      "Ep 1 (Step 014830): Train loss 3.034, Val loss 2.800\n",
      "Ep 1 (Step 014835): Train loss 2.725, Val loss 2.804\n",
      "Ep 1 (Step 014840): Train loss 2.982, Val loss 2.813\n",
      "Ep 1 (Step 014845): Train loss 2.738, Val loss 2.796\n",
      "Ep 1 (Step 014850): Train loss 2.824, Val loss 2.808\n",
      "Ep 1 (Step 014855): Train loss 2.765, Val loss 2.817\n",
      "Ep 1 (Step 014860): Train loss 2.842, Val loss 2.818\n",
      "Ep 1 (Step 014865): Train loss 2.604, Val loss 2.811\n",
      "Ep 1 (Step 014870): Train loss 2.688, Val loss 2.792\n",
      "Ep 1 (Step 014875): Train loss 2.950, Val loss 2.792\n",
      "Ep 1 (Step 014880): Train loss 2.601, Val loss 2.800\n",
      "Ep 1 (Step 014885): Train loss 2.904, Val loss 2.811\n",
      "Ep 1 (Step 014890): Train loss 2.844, Val loss 2.811\n",
      "Ep 1 (Step 014895): Train loss 2.643, Val loss 2.820\n",
      "Ep 1 (Step 014900): Train loss 2.716, Val loss 2.814\n",
      "Ep 1 (Step 014905): Train loss 2.744, Val loss 2.814\n",
      "Ep 1 (Step 014910): Train loss 2.611, Val loss 2.827\n",
      "Ep 1 (Step 014915): Train loss 2.579, Val loss 2.825\n",
      "Ep 1 (Step 014920): Train loss 2.870, Val loss 2.834\n",
      "Ep 1 (Step 014925): Train loss 2.541, Val loss 2.820\n",
      "Ep 1 (Step 014930): Train loss 2.623, Val loss 2.807\n",
      "Ep 1 (Step 014935): Train loss 2.677, Val loss 2.804\n",
      "Ep 1 (Step 014940): Train loss 2.850, Val loss 2.800\n",
      "Ep 1 (Step 014945): Train loss 2.830, Val loss 2.816\n",
      "Ep 1 (Step 014950): Train loss 3.256, Val loss 2.824\n",
      "Ep 1 (Step 014955): Train loss 2.780, Val loss 2.834\n",
      "Ep 1 (Step 014960): Train loss 2.661, Val loss 2.823\n",
      "Ep 1 (Step 014965): Train loss 2.442, Val loss 2.834\n",
      "Ep 1 (Step 014970): Train loss 2.814, Val loss 2.840\n",
      "Ep 1 (Step 014975): Train loss 2.635, Val loss 2.829\n",
      "Ep 1 (Step 014980): Train loss 2.638, Val loss 2.824\n",
      "Ep 1 (Step 014985): Train loss 2.641, Val loss 2.820\n",
      "Ep 1 (Step 014990): Train loss 2.934, Val loss 2.811\n",
      "Ep 1 (Step 014995): Train loss 2.758, Val loss 2.816\n",
      "Ep 1 (Step 015000): Train loss 2.741, Val loss 2.819\n",
      "Ep 1 (Step 015005): Train loss 3.095, Val loss 2.823\n",
      "Ep 1 (Step 015010): Train loss 2.685, Val loss 2.804\n",
      "Ep 1 (Step 015015): Train loss 2.584, Val loss 2.800\n",
      "Ep 1 (Step 015020): Train loss 2.701, Val loss 2.814\n",
      "Ep 1 (Step 015025): Train loss 2.895, Val loss 2.818\n",
      "Ep 1 (Step 015030): Train loss 2.738, Val loss 2.808\n",
      "Ep 1 (Step 015035): Train loss 2.485, Val loss 2.790\n",
      "Ep 1 (Step 015040): Train loss 2.616, Val loss 2.776\n",
      "Ep 1 (Step 015045): Train loss 3.057, Val loss 2.776\n",
      "Ep 1 (Step 015050): Train loss 2.650, Val loss 2.790\n",
      "Ep 1 (Step 015055): Train loss 3.154, Val loss 2.800\n",
      "Ep 1 (Step 015060): Train loss 2.843, Val loss 2.802\n",
      "Ep 1 (Step 015065): Train loss 2.760, Val loss 2.807\n",
      "Ep 1 (Step 015070): Train loss 2.590, Val loss 2.801\n",
      "Ep 1 (Step 015075): Train loss 2.663, Val loss 2.801\n",
      "Ep 1 (Step 015080): Train loss 2.604, Val loss 2.801\n",
      "Ep 1 (Step 015085): Train loss 2.965, Val loss 2.822\n",
      "Ep 1 (Step 015090): Train loss 2.575, Val loss 2.825\n",
      "Ep 1 (Step 015095): Train loss 2.941, Val loss 2.820\n",
      "Ep 1 (Step 015100): Train loss 2.568, Val loss 2.824\n",
      "Ep 1 (Step 015105): Train loss 2.864, Val loss 2.806\n",
      "Ep 1 (Step 015110): Train loss 2.651, Val loss 2.809\n",
      "Ep 1 (Step 015115): Train loss 2.666, Val loss 2.812\n",
      "Ep 1 (Step 015120): Train loss 2.993, Val loss 2.805\n",
      "Ep 1 (Step 015125): Train loss 2.660, Val loss 2.798\n",
      "Ep 1 (Step 015130): Train loss 2.979, Val loss 2.786\n",
      "Ep 1 (Step 015135): Train loss 2.665, Val loss 2.786\n",
      "Ep 1 (Step 015140): Train loss 2.932, Val loss 2.779\n",
      "Ep 1 (Step 015145): Train loss 2.874, Val loss 2.784\n",
      "Ep 1 (Step 015150): Train loss 2.489, Val loss 2.782\n",
      "Ep 1 (Step 015155): Train loss 2.721, Val loss 2.793\n",
      "Ep 1 (Step 015160): Train loss 2.535, Val loss 2.788\n",
      "Ep 1 (Step 015165): Train loss 2.707, Val loss 2.796\n",
      "Ep 1 (Step 015170): Train loss 2.505, Val loss 2.777\n",
      "Ep 1 (Step 015175): Train loss 2.811, Val loss 2.777\n",
      "Ep 1 (Step 015180): Train loss 2.541, Val loss 2.793\n",
      "Ep 1 (Step 015185): Train loss 3.006, Val loss 2.794\n",
      "Ep 1 (Step 015190): Train loss 2.821, Val loss 2.803\n",
      "Ep 1 (Step 015195): Train loss 2.662, Val loss 2.802\n",
      "Ep 1 (Step 015200): Train loss 2.576, Val loss 2.788\n",
      "Ep 1 (Step 015205): Train loss 2.669, Val loss 2.778\n",
      "Ep 1 (Step 015210): Train loss 2.747, Val loss 2.789\n",
      "Ep 1 (Step 015215): Train loss 2.737, Val loss 2.783\n",
      "Ep 1 (Step 015220): Train loss 2.762, Val loss 2.816\n",
      "Ep 1 (Step 015225): Train loss 2.780, Val loss 2.793\n",
      "Ep 1 (Step 015230): Train loss 2.567, Val loss 2.796\n",
      "Ep 1 (Step 015235): Train loss 2.783, Val loss 2.793\n",
      "Ep 1 (Step 015240): Train loss 2.630, Val loss 2.796\n",
      "Ep 1 (Step 015245): Train loss 2.623, Val loss 2.800\n",
      "Ep 1 (Step 015250): Train loss 2.697, Val loss 2.776\n",
      "Ep 1 (Step 015255): Train loss 2.858, Val loss 2.775\n",
      "Ep 1 (Step 015260): Train loss 2.543, Val loss 2.789\n",
      "Ep 1 (Step 015265): Train loss 2.760, Val loss 2.791\n",
      "Ep 1 (Step 015270): Train loss 2.800, Val loss 2.798\n",
      "Ep 1 (Step 015275): Train loss 2.587, Val loss 2.800\n",
      "Ep 1 (Step 015280): Train loss 2.819, Val loss 2.792\n",
      "Ep 1 (Step 015285): Train loss 2.604, Val loss 2.800\n",
      "Ep 1 (Step 015290): Train loss 2.794, Val loss 2.796\n",
      "Ep 1 (Step 015295): Train loss 2.678, Val loss 2.787\n",
      "Ep 1 (Step 015300): Train loss 2.851, Val loss 2.791\n",
      "Ep 1 (Step 015305): Train loss 2.485, Val loss 2.773\n",
      "Ep 1 (Step 015310): Train loss 2.686, Val loss 2.778\n",
      "Ep 1 (Step 015315): Train loss 2.533, Val loss 2.772\n",
      "Ep 1 (Step 015320): Train loss 2.664, Val loss 2.792\n",
      "Ep 1 (Step 015325): Train loss 2.655, Val loss 2.773\n",
      "Ep 1 (Step 015330): Train loss 2.597, Val loss 2.783\n",
      "Ep 1 (Step 015335): Train loss 2.608, Val loss 2.787\n",
      "Ep 1 (Step 015340): Train loss 2.654, Val loss 2.797\n",
      "Ep 1 (Step 015345): Train loss 2.762, Val loss 2.801\n",
      "Ep 1 (Step 015350): Train loss 2.876, Val loss 2.784\n",
      "Ep 1 (Step 015355): Train loss 2.623, Val loss 2.785\n",
      "Ep 1 (Step 015360): Train loss 2.624, Val loss 2.776\n",
      "Ep 1 (Step 015365): Train loss 2.418, Val loss 2.786\n",
      "Ep 1 (Step 015370): Train loss 2.545, Val loss 2.775\n",
      "Ep 1 (Step 015375): Train loss 2.401, Val loss 2.781\n",
      "Ep 1 (Step 015380): Train loss 3.017, Val loss 2.772\n",
      "Ep 1 (Step 015385): Train loss 2.402, Val loss 2.760\n",
      "Ep 1 (Step 015390): Train loss 2.843, Val loss 2.770\n",
      "Ep 1 (Step 015395): Train loss 2.660, Val loss 2.759\n",
      "Ep 1 (Step 015400): Train loss 2.873, Val loss 2.761\n",
      "Ep 1 (Step 015405): Train loss 2.560, Val loss 2.762\n",
      "Ep 1 (Step 015410): Train loss 2.445, Val loss 2.748\n",
      "Ep 1 (Step 015415): Train loss 3.058, Val loss 2.731\n",
      "Ep 1 (Step 015420): Train loss 2.725, Val loss 2.744\n",
      "Ep 1 (Step 015425): Train loss 2.277, Val loss 2.758\n",
      "Ep 1 (Step 015430): Train loss 2.611, Val loss 2.770\n",
      "Ep 1 (Step 015435): Train loss 2.536, Val loss 2.769\n",
      "Ep 1 (Step 015440): Train loss 2.644, Val loss 2.769\n",
      "Ep 1 (Step 015445): Train loss 2.974, Val loss 2.786\n",
      "Ep 1 (Step 015450): Train loss 2.717, Val loss 2.766\n",
      "Ep 1 (Step 015455): Train loss 2.622, Val loss 2.760\n",
      "Ep 1 (Step 015460): Train loss 2.766, Val loss 2.762\n",
      "Ep 1 (Step 015465): Train loss 2.775, Val loss 2.770\n",
      "Ep 1 (Step 015470): Train loss 3.028, Val loss 2.773\n",
      "Ep 1 (Step 015475): Train loss 2.613, Val loss 2.786\n",
      "Ep 1 (Step 015480): Train loss 2.717, Val loss 2.783\n",
      "Ep 1 (Step 015485): Train loss 2.366, Val loss 2.785\n",
      "Ep 1 (Step 015490): Train loss 2.695, Val loss 2.791\n",
      "Ep 1 (Step 015495): Train loss 2.726, Val loss 2.796\n",
      "Ep 1 (Step 015500): Train loss 2.590, Val loss 2.771\n",
      "Ep 1 (Step 015505): Train loss 2.531, Val loss 2.782\n",
      "Ep 1 (Step 015510): Train loss 2.488, Val loss 2.784\n",
      "Ep 1 (Step 015515): Train loss 2.700, Val loss 2.788\n",
      "Ep 1 (Step 015520): Train loss 2.714, Val loss 2.777\n",
      "Ep 1 (Step 015525): Train loss 2.635, Val loss 2.780\n",
      "Ep 1 (Step 015530): Train loss 2.937, Val loss 2.789\n",
      "Ep 1 (Step 015535): Train loss 2.816, Val loss 2.790\n",
      "Ep 1 (Step 015540): Train loss 2.793, Val loss 2.791\n",
      "Ep 1 (Step 015545): Train loss 2.691, Val loss 2.783\n",
      "Ep 1 (Step 015550): Train loss 2.761, Val loss 2.772\n",
      "Ep 1 (Step 015555): Train loss 2.646, Val loss 2.780\n",
      "Ep 1 (Step 015560): Train loss 2.764, Val loss 2.787\n",
      "Ep 1 (Step 015565): Train loss 2.679, Val loss 2.778\n",
      "Ep 1 (Step 015570): Train loss 2.802, Val loss 2.785\n",
      "Ep 1 (Step 015575): Train loss 2.541, Val loss 2.744\n",
      "Ep 1 (Step 015580): Train loss 3.176, Val loss 2.745\n",
      "Ep 1 (Step 015585): Train loss 2.819, Val loss 2.751\n",
      "Ep 1 (Step 015590): Train loss 2.782, Val loss 2.753\n",
      "Ep 1 (Step 015595): Train loss 2.861, Val loss 2.753\n",
      "Ep 1 (Step 015600): Train loss 2.659, Val loss 2.758\n",
      "Ep 1 (Step 015605): Train loss 2.761, Val loss 2.763\n",
      "Ep 1 (Step 015610): Train loss 2.558, Val loss 2.750\n",
      "Ep 1 (Step 015615): Train loss 2.762, Val loss 2.759\n",
      "Ep 1 (Step 015620): Train loss 2.518, Val loss 2.755\n",
      "Ep 1 (Step 015625): Train loss 2.548, Val loss 2.746\n",
      "Ep 1 (Step 015630): Train loss 2.707, Val loss 2.752\n",
      "Ep 1 (Step 015635): Train loss 2.735, Val loss 2.754\n",
      "Ep 1 (Step 015640): Train loss 2.533, Val loss 2.758\n",
      "Ep 1 (Step 015645): Train loss 2.833, Val loss 2.772\n",
      "Ep 1 (Step 015650): Train loss 2.397, Val loss 2.766\n",
      "Ep 1 (Step 015655): Train loss 2.432, Val loss 2.775\n",
      "Ep 1 (Step 015660): Train loss 2.702, Val loss 2.777\n",
      "Ep 1 (Step 015665): Train loss 2.878, Val loss 2.781\n",
      "Ep 1 (Step 015670): Train loss 2.879, Val loss 2.769\n",
      "Ep 1 (Step 015675): Train loss 2.755, Val loss 2.735\n",
      "Ep 1 (Step 015680): Train loss 2.788, Val loss 2.721\n",
      "Ep 1 (Step 015685): Train loss 2.489, Val loss 2.725\n",
      "Ep 1 (Step 015690): Train loss 2.558, Val loss 2.738\n",
      "Ep 1 (Step 015695): Train loss 2.497, Val loss 2.757\n",
      "Ep 1 (Step 015700): Train loss 2.517, Val loss 2.744\n",
      "Ep 1 (Step 015705): Train loss 2.653, Val loss 2.745\n",
      "Ep 1 (Step 015710): Train loss 2.737, Val loss 2.751\n",
      "Ep 1 (Step 015715): Train loss 2.789, Val loss 2.750\n",
      "Ep 1 (Step 015720): Train loss 2.815, Val loss 2.751\n",
      "Ep 1 (Step 015725): Train loss 2.660, Val loss 2.734\n",
      "Ep 1 (Step 015730): Train loss 2.413, Val loss 2.733\n",
      "Ep 1 (Step 015735): Train loss 2.756, Val loss 2.727\n",
      "Ep 1 (Step 015740): Train loss 2.934, Val loss 2.742\n",
      "Ep 1 (Step 015745): Train loss 2.671, Val loss 2.757\n",
      "Ep 1 (Step 015750): Train loss 2.833, Val loss 2.769\n",
      "Ep 1 (Step 015755): Train loss 2.993, Val loss 2.767\n",
      "Ep 1 (Step 015760): Train loss 2.630, Val loss 2.762\n",
      "Ep 1 (Step 015765): Train loss 2.508, Val loss 2.758\n",
      "Ep 1 (Step 015770): Train loss 2.941, Val loss 2.776\n",
      "Ep 1 (Step 015775): Train loss 2.405, Val loss 2.772\n",
      "Ep 1 (Step 015780): Train loss 2.687, Val loss 2.773\n",
      "Ep 1 (Step 015785): Train loss 2.706, Val loss 2.758\n",
      "Ep 1 (Step 015790): Train loss 2.528, Val loss 2.746\n",
      "Ep 1 (Step 015795): Train loss 2.859, Val loss 2.754\n",
      "Ep 1 (Step 015800): Train loss 2.787, Val loss 2.765\n",
      "Ep 1 (Step 015805): Train loss 2.634, Val loss 2.773\n",
      "Ep 1 (Step 015810): Train loss 2.867, Val loss 2.789\n",
      "Ep 1 (Step 015815): Train loss 2.718, Val loss 2.791\n",
      "Ep 1 (Step 015820): Train loss 2.751, Val loss 2.768\n",
      "Ep 1 (Step 015825): Train loss 2.459, Val loss 2.752\n",
      "Ep 1 (Step 015830): Train loss 2.498, Val loss 2.737\n",
      "Ep 1 (Step 015835): Train loss 2.869, Val loss 2.731\n",
      "Ep 1 (Step 015840): Train loss 2.525, Val loss 2.739\n",
      "Ep 1 (Step 015845): Train loss 2.905, Val loss 2.754\n",
      "Ep 1 (Step 015850): Train loss 3.014, Val loss 2.764\n",
      "Ep 1 (Step 015855): Train loss 2.688, Val loss 2.758\n",
      "Ep 1 (Step 015860): Train loss 2.979, Val loss 2.755\n",
      "Ep 1 (Step 015865): Train loss 2.650, Val loss 2.736\n",
      "Ep 1 (Step 015870): Train loss 3.177, Val loss 2.725\n",
      "Ep 1 (Step 015875): Train loss 2.753, Val loss 2.720\n",
      "Ep 1 (Step 015880): Train loss 2.947, Val loss 2.730\n",
      "Ep 1 (Step 015885): Train loss 2.670, Val loss 2.733\n",
      "Ep 1 (Step 015890): Train loss 2.810, Val loss 2.737\n",
      "Ep 1 (Step 015895): Train loss 2.569, Val loss 2.731\n",
      "Ep 1 (Step 015900): Train loss 2.444, Val loss 2.736\n",
      "Ep 1 (Step 015905): Train loss 3.171, Val loss 2.748\n",
      "Ep 1 (Step 015910): Train loss 2.603, Val loss 2.735\n",
      "Ep 1 (Step 015915): Train loss 2.821, Val loss 2.734\n",
      "Ep 1 (Step 015920): Train loss 2.835, Val loss 2.718\n",
      "Ep 1 (Step 015925): Train loss 2.612, Val loss 2.713\n",
      "Ep 1 (Step 015930): Train loss 2.422, Val loss 2.725\n",
      "Ep 1 (Step 015935): Train loss 2.649, Val loss 2.736\n",
      "Ep 1 (Step 015940): Train loss 2.861, Val loss 2.743\n",
      "Ep 1 (Step 015945): Train loss 2.929, Val loss 2.737\n",
      "Ep 1 (Step 015950): Train loss 2.516, Val loss 2.750\n",
      "Ep 1 (Step 015955): Train loss 2.640, Val loss 2.737\n",
      "Ep 1 (Step 015960): Train loss 2.687, Val loss 2.725\n",
      "Ep 1 (Step 015965): Train loss 2.692, Val loss 2.744\n",
      "Ep 1 (Step 015970): Train loss 2.750, Val loss 2.746\n",
      "Ep 1 (Step 015975): Train loss 2.627, Val loss 2.738\n",
      "Ep 1 (Step 015980): Train loss 2.641, Val loss 2.754\n",
      "Ep 1 (Step 015985): Train loss 2.691, Val loss 2.747\n",
      "Ep 1 (Step 015990): Train loss 2.724, Val loss 2.755\n",
      "Ep 1 (Step 015995): Train loss 2.830, Val loss 2.753\n",
      "Ep 1 (Step 016000): Train loss 2.635, Val loss 2.747\n",
      "Ep 1 (Step 016005): Train loss 2.649, Val loss 2.743\n",
      "Ep 1 (Step 016010): Train loss 2.589, Val loss 2.741\n",
      "Ep 1 (Step 016015): Train loss 2.611, Val loss 2.729\n",
      "Ep 1 (Step 016020): Train loss 2.630, Val loss 2.724\n",
      "Ep 1 (Step 016025): Train loss 2.779, Val loss 2.717\n",
      "Ep 1 (Step 016030): Train loss 2.841, Val loss 2.726\n",
      "Ep 1 (Step 016035): Train loss 2.470, Val loss 2.738\n",
      "Ep 1 (Step 016040): Train loss 2.499, Val loss 2.729\n",
      "Ep 1 (Step 016045): Train loss 2.785, Val loss 2.721\n",
      "Ep 1 (Step 016050): Train loss 2.854, Val loss 2.738\n",
      "Ep 1 (Step 016055): Train loss 2.655, Val loss 2.746\n",
      "Ep 1 (Step 016060): Train loss 2.592, Val loss 2.738\n",
      "Ep 1 (Step 016065): Train loss 2.816, Val loss 2.727\n",
      "Ep 1 (Step 016070): Train loss 2.794, Val loss 2.719\n",
      "Ep 1 (Step 016075): Train loss 2.646, Val loss 2.723\n",
      "Ep 1 (Step 016080): Train loss 2.688, Val loss 2.719\n",
      "Ep 1 (Step 016085): Train loss 2.462, Val loss 2.713\n",
      "Ep 1 (Step 016090): Train loss 2.450, Val loss 2.699\n",
      "Ep 1 (Step 016095): Train loss 2.647, Val loss 2.708\n",
      "Ep 1 (Step 016100): Train loss 2.562, Val loss 2.716\n",
      "Ep 1 (Step 016105): Train loss 3.006, Val loss 2.709\n",
      "Ep 1 (Step 016110): Train loss 2.820, Val loss 2.720\n",
      "Ep 1 (Step 016115): Train loss 2.734, Val loss 2.721\n",
      "Ep 1 (Step 016120): Train loss 2.407, Val loss 2.701\n",
      "Ep 1 (Step 016125): Train loss 2.596, Val loss 2.683\n",
      "Ep 1 (Step 016130): Train loss 2.527, Val loss 2.677\n",
      "Ep 1 (Step 016135): Train loss 2.885, Val loss 2.681\n",
      "Ep 1 (Step 016140): Train loss 2.381, Val loss 2.672\n",
      "Ep 1 (Step 016145): Train loss 2.275, Val loss 2.684\n",
      "Ep 1 (Step 016150): Train loss 2.616, Val loss 2.671\n",
      "Ep 1 (Step 016155): Train loss 2.350, Val loss 2.659\n",
      "Ep 1 (Step 016160): Train loss 2.796, Val loss 2.665\n",
      "Ep 1 (Step 016165): Train loss 2.924, Val loss 2.679\n",
      "Ep 1 (Step 016170): Train loss 2.624, Val loss 2.676\n",
      "Ep 1 (Step 016175): Train loss 2.725, Val loss 2.665\n",
      "Ep 1 (Step 016180): Train loss 2.637, Val loss 2.658\n",
      "Ep 1 (Step 016185): Train loss 2.663, Val loss 2.664\n",
      "Ep 1 (Step 016190): Train loss 3.055, Val loss 2.668\n",
      "Ep 1 (Step 016195): Train loss 2.926, Val loss 2.686\n",
      "Ep 1 (Step 016200): Train loss 2.759, Val loss 2.688\n",
      "Ep 1 (Step 016205): Train loss 2.982, Val loss 2.688\n",
      "Ep 1 (Step 016210): Train loss 2.802, Val loss 2.682\n",
      "Ep 1 (Step 016215): Train loss 2.799, Val loss 2.681\n",
      "Ep 1 (Step 016220): Train loss 2.563, Val loss 2.682\n",
      "Ep 1 (Step 016225): Train loss 2.642, Val loss 2.669\n",
      "Ep 1 (Step 016230): Train loss 2.782, Val loss 2.668\n",
      "Ep 1 (Step 016235): Train loss 2.720, Val loss 2.666\n",
      "Ep 1 (Step 016240): Train loss 2.809, Val loss 2.672\n",
      "Ep 1 (Step 016245): Train loss 2.595, Val loss 2.687\n",
      "Ep 1 (Step 016250): Train loss 2.327, Val loss 2.694\n",
      "Ep 1 (Step 016255): Train loss 2.824, Val loss 2.705\n",
      "Ep 1 (Step 016260): Train loss 2.505, Val loss 2.704\n",
      "Ep 1 (Step 016265): Train loss 2.820, Val loss 2.702\n",
      "Ep 1 (Step 016270): Train loss 2.779, Val loss 2.680\n",
      "Ep 1 (Step 016275): Train loss 2.540, Val loss 2.668\n",
      "Ep 1 (Step 016280): Train loss 2.369, Val loss 2.670\n",
      "Ep 1 (Step 016285): Train loss 2.848, Val loss 2.686\n",
      "Ep 1 (Step 016290): Train loss 2.506, Val loss 2.690\n",
      "Ep 1 (Step 016295): Train loss 2.844, Val loss 2.710\n",
      "Ep 1 (Step 016300): Train loss 2.607, Val loss 2.699\n",
      "Ep 1 (Step 016305): Train loss 2.580, Val loss 2.683\n",
      "Ep 1 (Step 016310): Train loss 2.950, Val loss 2.679\n",
      "Ep 1 (Step 016315): Train loss 2.609, Val loss 2.668\n",
      "Ep 1 (Step 016320): Train loss 2.671, Val loss 2.666\n",
      "Ep 1 (Step 016325): Train loss 2.772, Val loss 2.675\n",
      "Ep 1 (Step 016330): Train loss 2.569, Val loss 2.661\n",
      "Ep 1 (Step 016335): Train loss 2.712, Val loss 2.661\n",
      "Ep 1 (Step 016340): Train loss 2.657, Val loss 2.668\n",
      "Ep 1 (Step 016345): Train loss 2.762, Val loss 2.679\n",
      "Ep 1 (Step 016350): Train loss 2.419, Val loss 2.670\n",
      "Ep 1 (Step 016355): Train loss 2.668, Val loss 2.691\n",
      "Ep 1 (Step 016360): Train loss 2.564, Val loss 2.708\n",
      "Ep 1 (Step 016365): Train loss 2.475, Val loss 2.728\n",
      "Ep 1 (Step 016370): Train loss 2.602, Val loss 2.734\n",
      "Ep 1 (Step 016375): Train loss 2.875, Val loss 2.733\n",
      "Ep 1 (Step 016380): Train loss 2.471, Val loss 2.710\n",
      "Ep 1 (Step 016385): Train loss 2.625, Val loss 2.707\n",
      "Ep 1 (Step 016390): Train loss 2.685, Val loss 2.704\n",
      "Ep 1 (Step 016395): Train loss 2.230, Val loss 2.709\n",
      "Ep 1 (Step 016400): Train loss 2.612, Val loss 2.714\n",
      "Ep 1 (Step 016405): Train loss 2.835, Val loss 2.719\n",
      "Ep 1 (Step 016410): Train loss 2.601, Val loss 2.723\n",
      "Ep 1 (Step 016415): Train loss 2.827, Val loss 2.718\n",
      "Ep 1 (Step 016420): Train loss 2.439, Val loss 2.726\n",
      "Ep 1 (Step 016425): Train loss 2.811, Val loss 2.719\n",
      "Ep 1 (Step 016430): Train loss 2.581, Val loss 2.705\n",
      "Ep 1 (Step 016435): Train loss 2.485, Val loss 2.691\n",
      "Ep 1 (Step 016440): Train loss 2.594, Val loss 2.688\n",
      "Ep 1 (Step 016445): Train loss 2.746, Val loss 2.696\n",
      "Ep 1 (Step 016450): Train loss 2.782, Val loss 2.691\n",
      "Ep 1 (Step 016455): Train loss 2.653, Val loss 2.690\n",
      "Ep 1 (Step 016460): Train loss 2.565, Val loss 2.691\n",
      "Ep 1 (Step 016465): Train loss 2.639, Val loss 2.701\n",
      "Ep 1 (Step 016470): Train loss 2.663, Val loss 2.708\n",
      "Ep 1 (Step 016475): Train loss 2.617, Val loss 2.692\n",
      "Ep 1 (Step 016480): Train loss 2.576, Val loss 2.689\n",
      "Ep 1 (Step 016485): Train loss 2.955, Val loss 2.695\n",
      "Ep 1 (Step 016490): Train loss 2.638, Val loss 2.703\n",
      "Ep 1 (Step 016495): Train loss 2.599, Val loss 2.712\n",
      "Ep 1 (Step 016500): Train loss 2.870, Val loss 2.695\n",
      "Ep 1 (Step 016505): Train loss 2.587, Val loss 2.676\n",
      "Ep 1 (Step 016510): Train loss 2.684, Val loss 2.676\n",
      "Ep 1 (Step 016515): Train loss 2.436, Val loss 2.676\n",
      "Ep 1 (Step 016520): Train loss 2.743, Val loss 2.688\n",
      "Ep 1 (Step 016525): Train loss 2.619, Val loss 2.705\n",
      "Ep 1 (Step 016530): Train loss 2.467, Val loss 2.696\n",
      "Ep 1 (Step 016535): Train loss 2.454, Val loss 2.685\n",
      "Ep 1 (Step 016540): Train loss 2.948, Val loss 2.673\n",
      "Ep 1 (Step 016545): Train loss 2.355, Val loss 2.684\n",
      "Ep 1 (Step 016550): Train loss 2.663, Val loss 2.698\n",
      "Ep 1 (Step 016555): Train loss 2.501, Val loss 2.684\n",
      "Ep 1 (Step 016560): Train loss 2.488, Val loss 2.688\n",
      "Ep 1 (Step 016565): Train loss 2.500, Val loss 2.691\n",
      "Ep 1 (Step 016570): Train loss 2.772, Val loss 2.690\n",
      "Ep 1 (Step 016575): Train loss 2.470, Val loss 2.691\n",
      "Ep 1 (Step 016580): Train loss 2.759, Val loss 2.686\n",
      "Ep 1 (Step 016585): Train loss 2.403, Val loss 2.676\n",
      "Ep 1 (Step 016590): Train loss 2.597, Val loss 2.675\n",
      "Ep 1 (Step 016595): Train loss 2.604, Val loss 2.689\n",
      "Ep 1 (Step 016600): Train loss 2.632, Val loss 2.717\n",
      "Ep 1 (Step 016605): Train loss 2.656, Val loss 2.716\n",
      "Ep 1 (Step 016610): Train loss 2.842, Val loss 2.709\n",
      "Ep 1 (Step 016615): Train loss 2.522, Val loss 2.699\n",
      "Ep 1 (Step 016620): Train loss 2.243, Val loss 2.719\n",
      "Ep 1 (Step 016625): Train loss 2.487, Val loss 2.709\n",
      "Ep 1 (Step 016630): Train loss 2.504, Val loss 2.721\n",
      "Ep 1 (Step 016635): Train loss 2.741, Val loss 2.708\n",
      "Ep 1 (Step 016640): Train loss 2.547, Val loss 2.682\n",
      "Ep 1 (Step 016645): Train loss 2.490, Val loss 2.659\n",
      "Ep 1 (Step 016650): Train loss 2.758, Val loss 2.675\n",
      "Ep 1 (Step 016655): Train loss 2.426, Val loss 2.682\n",
      "Ep 1 (Step 016660): Train loss 2.511, Val loss 2.691\n",
      "Ep 1 (Step 016665): Train loss 2.696, Val loss 2.700\n",
      "Ep 1 (Step 016670): Train loss 2.635, Val loss 2.681\n",
      "Ep 1 (Step 016675): Train loss 2.908, Val loss 2.672\n",
      "Ep 1 (Step 016680): Train loss 2.429, Val loss 2.666\n",
      "Ep 1 (Step 016685): Train loss 2.659, Val loss 2.694\n",
      "Ep 1 (Step 016690): Train loss 2.721, Val loss 2.697\n",
      "Ep 1 (Step 016695): Train loss 2.675, Val loss 2.673\n",
      "Ep 1 (Step 016700): Train loss 2.658, Val loss 2.668\n",
      "Ep 1 (Step 016705): Train loss 2.737, Val loss 2.658\n",
      "Ep 1 (Step 016710): Train loss 2.617, Val loss 2.664\n",
      "Ep 1 (Step 016715): Train loss 2.738, Val loss 2.668\n",
      "Ep 1 (Step 016720): Train loss 2.662, Val loss 2.669\n",
      "Ep 1 (Step 016725): Train loss 2.631, Val loss 2.660\n",
      "Ep 1 (Step 016730): Train loss 2.596, Val loss 2.657\n",
      "Ep 1 (Step 016735): Train loss 2.549, Val loss 2.649\n",
      "Ep 1 (Step 016740): Train loss 3.048, Val loss 2.638\n",
      "Ep 1 (Step 016745): Train loss 2.738, Val loss 2.648\n",
      "Ep 1 (Step 016750): Train loss 2.615, Val loss 2.638\n",
      "Ep 1 (Step 016755): Train loss 2.633, Val loss 2.636\n",
      "Ep 1 (Step 016760): Train loss 2.496, Val loss 2.638\n",
      "Ep 1 (Step 016765): Train loss 2.866, Val loss 2.645\n",
      "Ep 1 (Step 016770): Train loss 2.583, Val loss 2.648\n",
      "Ep 1 (Step 016775): Train loss 2.652, Val loss 2.651\n",
      "Ep 1 (Step 016780): Train loss 2.611, Val loss 2.655\n",
      "Ep 1 (Step 016785): Train loss 2.737, Val loss 2.661\n",
      "Ep 1 (Step 016790): Train loss 2.721, Val loss 2.652\n",
      "Ep 1 (Step 016795): Train loss 2.494, Val loss 2.642\n",
      "Ep 1 (Step 016800): Train loss 2.669, Val loss 2.644\n",
      "Ep 1 (Step 016805): Train loss 2.354, Val loss 2.651\n",
      "Ep 1 (Step 016810): Train loss 2.706, Val loss 2.653\n",
      "Ep 1 (Step 016815): Train loss 2.414, Val loss 2.643\n",
      "Ep 1 (Step 016820): Train loss 3.048, Val loss 2.633\n",
      "Ep 1 (Step 016825): Train loss 2.510, Val loss 2.629\n",
      "Ep 1 (Step 016830): Train loss 2.569, Val loss 2.639\n",
      "Ep 1 (Step 016835): Train loss 2.481, Val loss 2.671\n",
      "Ep 1 (Step 016840): Train loss 2.697, Val loss 2.672\n",
      "Ep 1 (Step 016845): Train loss 2.603, Val loss 2.647\n",
      "Ep 1 (Step 016850): Train loss 2.604, Val loss 2.652\n",
      "Ep 1 (Step 016855): Train loss 2.767, Val loss 2.657\n",
      "Ep 1 (Step 016860): Train loss 2.617, Val loss 2.665\n",
      "Ep 1 (Step 016865): Train loss 2.551, Val loss 2.672\n",
      "Ep 1 (Step 016870): Train loss 2.812, Val loss 2.664\n",
      "Ep 1 (Step 016875): Train loss 2.543, Val loss 2.651\n",
      "Ep 1 (Step 016880): Train loss 2.830, Val loss 2.664\n",
      "Ep 1 (Step 016885): Train loss 2.653, Val loss 2.650\n",
      "Ep 1 (Step 016890): Train loss 2.407, Val loss 2.665\n",
      "Ep 1 (Step 016895): Train loss 2.484, Val loss 2.671\n",
      "Ep 1 (Step 016900): Train loss 2.856, Val loss 2.694\n",
      "Ep 1 (Step 016905): Train loss 2.677, Val loss 2.680\n",
      "Ep 1 (Step 016910): Train loss 2.744, Val loss 2.665\n",
      "Ep 1 (Step 016915): Train loss 2.628, Val loss 2.664\n",
      "Ep 1 (Step 016920): Train loss 2.605, Val loss 2.668\n",
      "Ep 1 (Step 016925): Train loss 2.553, Val loss 2.663\n",
      "Ep 1 (Step 016930): Train loss 2.740, Val loss 2.660\n",
      "Ep 1 (Step 016935): Train loss 2.768, Val loss 2.659\n",
      "Ep 1 (Step 016940): Train loss 2.558, Val loss 2.663\n",
      "Ep 1 (Step 016945): Train loss 2.433, Val loss 2.652\n",
      "Ep 1 (Step 016950): Train loss 2.368, Val loss 2.642\n",
      "Ep 1 (Step 016955): Train loss 2.484, Val loss 2.657\n",
      "Ep 1 (Step 016960): Train loss 2.528, Val loss 2.655\n",
      "Ep 1 (Step 016965): Train loss 2.670, Val loss 2.664\n",
      "Ep 1 (Step 016970): Train loss 2.691, Val loss 2.659\n",
      "Ep 1 (Step 016975): Train loss 2.339, Val loss 2.654\n",
      "Ep 1 (Step 016980): Train loss 2.474, Val loss 2.651\n",
      "Ep 1 (Step 016985): Train loss 2.353, Val loss 2.654\n",
      "Ep 1 (Step 016990): Train loss 2.406, Val loss 2.660\n",
      "Ep 1 (Step 016995): Train loss 2.811, Val loss 2.659\n",
      "Ep 1 (Step 017000): Train loss 2.794, Val loss 2.663\n",
      "Ep 1 (Step 017005): Train loss 2.519, Val loss 2.665\n",
      "Ep 1 (Step 017010): Train loss 2.475, Val loss 2.664\n",
      "Ep 1 (Step 017015): Train loss 2.528, Val loss 2.663\n",
      "Ep 1 (Step 017020): Train loss 2.650, Val loss 2.679\n",
      "Ep 1 (Step 017025): Train loss 2.659, Val loss 2.688\n",
      "Ep 1 (Step 017030): Train loss 2.833, Val loss 2.684\n",
      "Ep 1 (Step 017035): Train loss 2.435, Val loss 2.690\n",
      "Ep 1 (Step 017040): Train loss 2.552, Val loss 2.689\n",
      "Ep 1 (Step 017045): Train loss 2.518, Val loss 2.676\n",
      "Ep 1 (Step 017050): Train loss 2.553, Val loss 2.662\n",
      "Ep 1 (Step 017055): Train loss 2.507, Val loss 2.652\n",
      "Ep 1 (Step 017060): Train loss 2.499, Val loss 2.647\n",
      "Ep 1 (Step 017065): Train loss 2.610, Val loss 2.650\n",
      "Ep 1 (Step 017070): Train loss 2.912, Val loss 2.656\n",
      "Ep 1 (Step 017075): Train loss 2.353, Val loss 2.640\n",
      "Ep 1 (Step 017080): Train loss 2.448, Val loss 2.647\n",
      "Ep 1 (Step 017085): Train loss 2.794, Val loss 2.655\n",
      "Ep 1 (Step 017090): Train loss 2.581, Val loss 2.641\n",
      "Ep 1 (Step 017095): Train loss 2.579, Val loss 2.638\n",
      "Ep 1 (Step 017100): Train loss 2.571, Val loss 2.647\n",
      "Ep 1 (Step 017105): Train loss 2.696, Val loss 2.649\n",
      "Ep 1 (Step 017110): Train loss 2.809, Val loss 2.645\n",
      "Ep 1 (Step 017115): Train loss 2.363, Val loss 2.647\n",
      "Ep 1 (Step 017120): Train loss 2.349, Val loss 2.629\n",
      "Ep 1 (Step 017125): Train loss 2.559, Val loss 2.629\n",
      "Ep 1 (Step 017130): Train loss 2.740, Val loss 2.629\n",
      "Ep 1 (Step 017135): Train loss 2.674, Val loss 2.637\n",
      "Ep 1 (Step 017140): Train loss 2.471, Val loss 2.638\n",
      "Ep 1 (Step 017145): Train loss 2.627, Val loss 2.630\n",
      "Ep 1 (Step 017150): Train loss 2.368, Val loss 2.624\n",
      "Ep 1 (Step 017155): Train loss 2.400, Val loss 2.625\n",
      "Ep 1 (Step 017160): Train loss 2.357, Val loss 2.633\n",
      "Ep 1 (Step 017165): Train loss 2.430, Val loss 2.632\n",
      "Ep 1 (Step 017170): Train loss 2.671, Val loss 2.636\n",
      "Ep 1 (Step 017175): Train loss 2.883, Val loss 2.632\n",
      "Ep 1 (Step 017180): Train loss 2.804, Val loss 2.629\n",
      "Ep 1 (Step 017185): Train loss 2.739, Val loss 2.630\n",
      "Ep 1 (Step 017190): Train loss 2.512, Val loss 2.623\n",
      "Ep 1 (Step 017195): Train loss 2.449, Val loss 2.635\n",
      "Ep 1 (Step 017200): Train loss 2.465, Val loss 2.621\n",
      "Ep 1 (Step 017205): Train loss 2.717, Val loss 2.614\n",
      "Ep 1 (Step 017210): Train loss 2.520, Val loss 2.612\n",
      "Ep 1 (Step 017215): Train loss 2.365, Val loss 2.616\n",
      "Ep 1 (Step 017220): Train loss 2.460, Val loss 2.642\n",
      "Ep 1 (Step 017225): Train loss 2.603, Val loss 2.654\n",
      "Ep 1 (Step 017230): Train loss 2.361, Val loss 2.647\n",
      "Ep 1 (Step 017235): Train loss 2.333, Val loss 2.637\n",
      "Ep 1 (Step 017240): Train loss 2.341, Val loss 2.637\n",
      "Ep 1 (Step 017245): Train loss 2.404, Val loss 2.635\n",
      "Ep 1 (Step 017250): Train loss 2.490, Val loss 2.627\n",
      "Ep 1 (Step 017255): Train loss 2.509, Val loss 2.624\n",
      "Ep 1 (Step 017260): Train loss 2.592, Val loss 2.625\n",
      "Ep 1 (Step 017265): Train loss 2.632, Val loss 2.618\n",
      "Ep 1 (Step 017270): Train loss 2.352, Val loss 2.615\n",
      "Ep 1 (Step 017275): Train loss 2.645, Val loss 2.622\n",
      "Ep 1 (Step 017280): Train loss 2.476, Val loss 2.619\n",
      "Ep 1 (Step 017285): Train loss 2.562, Val loss 2.620\n",
      "Ep 1 (Step 017290): Train loss 2.819, Val loss 2.627\n",
      "Ep 1 (Step 017295): Train loss 2.603, Val loss 2.635\n",
      "Ep 1 (Step 017300): Train loss 2.627, Val loss 2.639\n",
      "Ep 1 (Step 017305): Train loss 2.438, Val loss 2.641\n",
      "Ep 1 (Step 017310): Train loss 2.419, Val loss 2.640\n",
      "Ep 1 (Step 017315): Train loss 2.597, Val loss 2.634\n",
      "Ep 1 (Step 017320): Train loss 2.476, Val loss 2.627\n",
      "Ep 1 (Step 017325): Train loss 2.781, Val loss 2.612\n",
      "Ep 1 (Step 017330): Train loss 2.618, Val loss 2.615\n",
      "Ep 1 (Step 017335): Train loss 2.620, Val loss 2.616\n",
      "Ep 1 (Step 017340): Train loss 2.401, Val loss 2.610\n",
      "Ep 1 (Step 017345): Train loss 2.385, Val loss 2.615\n",
      "Ep 1 (Step 017350): Train loss 2.779, Val loss 2.613\n",
      "Ep 1 (Step 017355): Train loss 2.693, Val loss 2.615\n",
      "Ep 1 (Step 017360): Train loss 2.812, Val loss 2.608\n",
      "Ep 1 (Step 017365): Train loss 2.158, Val loss 2.609\n",
      "Ep 1 (Step 017370): Train loss 2.423, Val loss 2.616\n",
      "Ep 1 (Step 017375): Train loss 2.673, Val loss 2.614\n",
      "Ep 1 (Step 017380): Train loss 2.542, Val loss 2.622\n",
      "Ep 1 (Step 017385): Train loss 2.455, Val loss 2.617\n",
      "Ep 1 (Step 017390): Train loss 2.495, Val loss 2.601\n",
      "Ep 1 (Step 017395): Train loss 2.608, Val loss 2.588\n",
      "Ep 1 (Step 017400): Train loss 2.374, Val loss 2.599\n",
      "Ep 1 (Step 017405): Train loss 2.594, Val loss 2.597\n",
      "Ep 1 (Step 017410): Train loss 2.857, Val loss 2.602\n",
      "Ep 1 (Step 017415): Train loss 2.588, Val loss 2.596\n",
      "Ep 1 (Step 017420): Train loss 2.515, Val loss 2.600\n",
      "Ep 1 (Step 017425): Train loss 2.511, Val loss 2.612\n",
      "Ep 1 (Step 017430): Train loss 2.755, Val loss 2.605\n",
      "Ep 1 (Step 017435): Train loss 2.607, Val loss 2.607\n",
      "Ep 1 (Step 017440): Train loss 2.802, Val loss 2.608\n",
      "Ep 1 (Step 017445): Train loss 2.632, Val loss 2.620\n",
      "Ep 1 (Step 017450): Train loss 2.487, Val loss 2.630\n",
      "Ep 1 (Step 017455): Train loss 2.491, Val loss 2.632\n",
      "Ep 1 (Step 017460): Train loss 2.581, Val loss 2.622\n",
      "Ep 1 (Step 017465): Train loss 2.696, Val loss 2.611\n",
      "Ep 1 (Step 017470): Train loss 2.716, Val loss 2.616\n",
      "Ep 1 (Step 017475): Train loss 2.571, Val loss 2.634\n",
      "Ep 1 (Step 017480): Train loss 2.799, Val loss 2.634\n",
      "Ep 1 (Step 017485): Train loss 2.735, Val loss 2.621\n",
      "Ep 1 (Step 017490): Train loss 2.302, Val loss 2.626\n",
      "Ep 1 (Step 017495): Train loss 2.307, Val loss 2.625\n",
      "Ep 1 (Step 017500): Train loss 2.521, Val loss 2.628\n",
      "Ep 1 (Step 017505): Train loss 2.264, Val loss 2.621\n",
      "Ep 1 (Step 017510): Train loss 2.752, Val loss 2.621\n",
      "Ep 1 (Step 017515): Train loss 2.700, Val loss 2.632\n",
      "Ep 1 (Step 017520): Train loss 2.672, Val loss 2.623\n",
      "Ep 1 (Step 017525): Train loss 2.972, Val loss 2.632\n",
      "Ep 1 (Step 017530): Train loss 2.594, Val loss 2.644\n",
      "Ep 1 (Step 017535): Train loss 2.685, Val loss 2.637\n",
      "Ep 1 (Step 017540): Train loss 2.811, Val loss 2.634\n",
      "Ep 1 (Step 017545): Train loss 2.630, Val loss 2.629\n",
      "Ep 1 (Step 017550): Train loss 2.529, Val loss 2.620\n",
      "Ep 1 (Step 017555): Train loss 2.294, Val loss 2.630\n",
      "Ep 1 (Step 017560): Train loss 2.629, Val loss 2.633\n",
      "Ep 1 (Step 017565): Train loss 2.767, Val loss 2.626\n",
      "Ep 1 (Step 017570): Train loss 2.740, Val loss 2.633\n",
      "Ep 1 (Step 017575): Train loss 2.652, Val loss 2.647\n",
      "Ep 1 (Step 017580): Train loss 2.762, Val loss 2.656\n",
      "Ep 1 (Step 017585): Train loss 2.403, Val loss 2.637\n",
      "Ep 1 (Step 017590): Train loss 2.514, Val loss 2.631\n",
      "Ep 1 (Step 017595): Train loss 2.650, Val loss 2.625\n",
      "Ep 1 (Step 017600): Train loss 2.449, Val loss 2.630\n",
      "Ep 1 (Step 017605): Train loss 2.860, Val loss 2.627\n",
      "Ep 1 (Step 017610): Train loss 2.358, Val loss 2.615\n",
      "Ep 1 (Step 017615): Train loss 2.522, Val loss 2.624\n",
      "Ep 1 (Step 017620): Train loss 2.449, Val loss 2.615\n",
      "Ep 1 (Step 017625): Train loss 2.511, Val loss 2.602\n",
      "Ep 1 (Step 017630): Train loss 2.776, Val loss 2.603\n",
      "Ep 1 (Step 017635): Train loss 2.441, Val loss 2.615\n",
      "Ep 1 (Step 017640): Train loss 2.676, Val loss 2.626\n",
      "Ep 1 (Step 017645): Train loss 2.864, Val loss 2.619\n",
      "Ep 1 (Step 017650): Train loss 2.344, Val loss 2.605\n",
      "Ep 1 (Step 017655): Train loss 2.702, Val loss 2.601\n",
      "Ep 1 (Step 017660): Train loss 2.795, Val loss 2.601\n",
      "Ep 1 (Step 017665): Train loss 2.668, Val loss 2.607\n",
      "Ep 1 (Step 017670): Train loss 2.593, Val loss 2.607\n",
      "Ep 1 (Step 017675): Train loss 2.668, Val loss 2.605\n",
      "Ep 1 (Step 017680): Train loss 2.685, Val loss 2.611\n",
      "Ep 1 (Step 017685): Train loss 2.498, Val loss 2.621\n",
      "Ep 1 (Step 017690): Train loss 2.470, Val loss 2.608\n",
      "Ep 1 (Step 017695): Train loss 2.712, Val loss 2.606\n",
      "Ep 1 (Step 017700): Train loss 2.336, Val loss 2.625\n",
      "Ep 1 (Step 017705): Train loss 2.476, Val loss 2.627\n",
      "Ep 1 (Step 017710): Train loss 2.402, Val loss 2.637\n",
      "Ep 1 (Step 017715): Train loss 2.459, Val loss 2.626\n",
      "Ep 1 (Step 017720): Train loss 2.896, Val loss 2.634\n",
      "Ep 1 (Step 017725): Train loss 2.553, Val loss 2.638\n",
      "Ep 1 (Step 017730): Train loss 2.338, Val loss 2.640\n",
      "Ep 1 (Step 017735): Train loss 2.876, Val loss 2.641\n",
      "Ep 1 (Step 017740): Train loss 2.701, Val loss 2.646\n",
      "Ep 1 (Step 017745): Train loss 2.417, Val loss 2.646\n",
      "Ep 1 (Step 017750): Train loss 2.404, Val loss 2.633\n",
      "Ep 1 (Step 017755): Train loss 2.418, Val loss 2.639\n",
      "Ep 1 (Step 017760): Train loss 2.603, Val loss 2.636\n",
      "Ep 1 (Step 017765): Train loss 2.316, Val loss 2.635\n",
      "Ep 1 (Step 017770): Train loss 2.643, Val loss 2.615\n",
      "Ep 1 (Step 017775): Train loss 2.390, Val loss 2.604\n",
      "Ep 1 (Step 017780): Train loss 2.422, Val loss 2.606\n",
      "Ep 1 (Step 017785): Train loss 2.726, Val loss 2.605\n",
      "Ep 1 (Step 017790): Train loss 2.730, Val loss 2.593\n",
      "Ep 1 (Step 017795): Train loss 2.428, Val loss 2.585\n",
      "Ep 1 (Step 017800): Train loss 2.453, Val loss 2.590\n",
      "Ep 1 (Step 017805): Train loss 2.322, Val loss 2.595\n",
      "Ep 1 (Step 017810): Train loss 2.496, Val loss 2.598\n",
      "Ep 1 (Step 017815): Train loss 2.874, Val loss 2.597\n",
      "Ep 1 (Step 017820): Train loss 2.463, Val loss 2.591\n",
      "Ep 1 (Step 017825): Train loss 2.602, Val loss 2.605\n",
      "Ep 1 (Step 017830): Train loss 2.429, Val loss 2.605\n",
      "Ep 1 (Step 017835): Train loss 2.417, Val loss 2.604\n",
      "Ep 1 (Step 017840): Train loss 2.598, Val loss 2.586\n",
      "Ep 1 (Step 017845): Train loss 2.536, Val loss 2.584\n",
      "Ep 1 (Step 017850): Train loss 2.522, Val loss 2.616\n",
      "Ep 1 (Step 017855): Train loss 2.498, Val loss 2.609\n",
      "Ep 1 (Step 017860): Train loss 2.528, Val loss 2.588\n",
      "Ep 1 (Step 017865): Train loss 2.768, Val loss 2.584\n",
      "Ep 1 (Step 017870): Train loss 2.540, Val loss 2.583\n",
      "Ep 1 (Step 017875): Train loss 2.597, Val loss 2.591\n",
      "Ep 1 (Step 017880): Train loss 2.734, Val loss 2.599\n",
      "Ep 1 (Step 017885): Train loss 2.559, Val loss 2.602\n",
      "Ep 1 (Step 017890): Train loss 2.713, Val loss 2.603\n",
      "Ep 1 (Step 017895): Train loss 2.581, Val loss 2.600\n",
      "Ep 1 (Step 017900): Train loss 2.589, Val loss 2.613\n",
      "Ep 1 (Step 017905): Train loss 2.466, Val loss 2.613\n",
      "Ep 1 (Step 017910): Train loss 2.246, Val loss 2.599\n",
      "Ep 1 (Step 017915): Train loss 2.547, Val loss 2.586\n",
      "Ep 1 (Step 017920): Train loss 2.395, Val loss 2.583\n",
      "Ep 1 (Step 017925): Train loss 2.408, Val loss 2.592\n",
      "Ep 1 (Step 017930): Train loss 2.788, Val loss 2.593\n",
      "Ep 1 (Step 017935): Train loss 2.617, Val loss 2.600\n",
      "Ep 1 (Step 017940): Train loss 2.557, Val loss 2.626\n",
      "Ep 1 (Step 017945): Train loss 2.494, Val loss 2.605\n",
      "Ep 1 (Step 017950): Train loss 2.295, Val loss 2.610\n",
      "Ep 1 (Step 017955): Train loss 2.850, Val loss 2.617\n",
      "Ep 1 (Step 017960): Train loss 2.429, Val loss 2.609\n",
      "Ep 1 (Step 017965): Train loss 2.474, Val loss 2.606\n",
      "Ep 1 (Step 017970): Train loss 2.664, Val loss 2.598\n",
      "Ep 1 (Step 017975): Train loss 2.627, Val loss 2.586\n",
      "Ep 1 (Step 017980): Train loss 2.666, Val loss 2.586\n",
      "Ep 1 (Step 017985): Train loss 2.764, Val loss 2.599\n",
      "Ep 1 (Step 017990): Train loss 2.392, Val loss 2.606\n",
      "Ep 1 (Step 017995): Train loss 2.570, Val loss 2.601\n",
      "Ep 1 (Step 018000): Train loss 2.815, Val loss 2.604\n",
      "Ep 1 (Step 018005): Train loss 2.400, Val loss 2.602\n",
      "Ep 1 (Step 018010): Train loss 2.673, Val loss 2.594\n",
      "Ep 1 (Step 018015): Train loss 2.302, Val loss 2.572\n",
      "Ep 1 (Step 018020): Train loss 2.376, Val loss 2.569\n",
      "Ep 1 (Step 018025): Train loss 2.650, Val loss 2.583\n",
      "Ep 1 (Step 018030): Train loss 2.725, Val loss 2.592\n",
      "Ep 1 (Step 018035): Train loss 2.438, Val loss 2.596\n",
      "Ep 1 (Step 018040): Train loss 2.529, Val loss 2.587\n",
      "Ep 1 (Step 018045): Train loss 2.308, Val loss 2.587\n",
      "Ep 1 (Step 018050): Train loss 2.600, Val loss 2.594\n",
      "Ep 1 (Step 018055): Train loss 2.587, Val loss 2.609\n",
      "Ep 1 (Step 018060): Train loss 2.834, Val loss 2.601\n",
      "Ep 1 (Step 018065): Train loss 2.515, Val loss 2.599\n",
      "Ep 1 (Step 018070): Train loss 2.825, Val loss 2.598\n",
      "Ep 1 (Step 018075): Train loss 2.439, Val loss 2.594\n",
      "Ep 1 (Step 018080): Train loss 2.349, Val loss 2.590\n",
      "Ep 1 (Step 018085): Train loss 2.635, Val loss 2.594\n",
      "Ep 1 (Step 018090): Train loss 2.326, Val loss 2.602\n",
      "Ep 1 (Step 018095): Train loss 2.749, Val loss 2.593\n",
      "Ep 1 (Step 018100): Train loss 2.509, Val loss 2.595\n",
      "Ep 1 (Step 018105): Train loss 2.605, Val loss 2.607\n",
      "Ep 1 (Step 018110): Train loss 2.509, Val loss 2.598\n",
      "Ep 1 (Step 018115): Train loss 2.303, Val loss 2.612\n",
      "Ep 1 (Step 018120): Train loss 2.529, Val loss 2.633\n",
      "Ep 1 (Step 018125): Train loss 2.527, Val loss 2.640\n",
      "Ep 1 (Step 018130): Train loss 2.670, Val loss 2.631\n",
      "Ep 1 (Step 018135): Train loss 2.566, Val loss 2.619\n",
      "Ep 1 (Step 018140): Train loss 2.375, Val loss 2.627\n",
      "Ep 1 (Step 018145): Train loss 2.759, Val loss 2.620\n",
      "Ep 1 (Step 018150): Train loss 2.705, Val loss 2.619\n",
      "Ep 1 (Step 018155): Train loss 2.442, Val loss 2.610\n",
      "Ep 1 (Step 018160): Train loss 2.243, Val loss 2.615\n",
      "Ep 1 (Step 018165): Train loss 2.408, Val loss 2.619\n",
      "Ep 1 (Step 018170): Train loss 2.588, Val loss 2.615\n",
      "Ep 1 (Step 018175): Train loss 2.553, Val loss 2.625\n",
      "Ep 1 (Step 018180): Train loss 2.386, Val loss 2.627\n",
      "Ep 1 (Step 018185): Train loss 2.533, Val loss 2.629\n",
      "Ep 1 (Step 018190): Train loss 2.491, Val loss 2.635\n",
      "Ep 1 (Step 018195): Train loss 2.450, Val loss 2.633\n",
      "Ep 1 (Step 018200): Train loss 2.652, Val loss 2.632\n",
      "Ep 1 (Step 018205): Train loss 2.582, Val loss 2.625\n",
      "Ep 1 (Step 018210): Train loss 2.536, Val loss 2.612\n",
      "Ep 1 (Step 018215): Train loss 2.474, Val loss 2.606\n",
      "Ep 1 (Step 018220): Train loss 2.493, Val loss 2.612\n",
      "Ep 1 (Step 018225): Train loss 2.489, Val loss 2.611\n",
      "Ep 1 (Step 018230): Train loss 2.647, Val loss 2.607\n",
      "Ep 1 (Step 018235): Train loss 2.467, Val loss 2.591\n",
      "Ep 1 (Step 018240): Train loss 2.356, Val loss 2.591\n",
      "Ep 1 (Step 018245): Train loss 2.510, Val loss 2.607\n",
      "Ep 1 (Step 018250): Train loss 2.447, Val loss 2.600\n",
      "Ep 1 (Step 018255): Train loss 2.545, Val loss 2.601\n",
      "Ep 1 (Step 018260): Train loss 2.536, Val loss 2.603\n",
      "Ep 1 (Step 018265): Train loss 2.392, Val loss 2.595\n",
      "Ep 1 (Step 018270): Train loss 2.294, Val loss 2.601\n",
      "Ep 1 (Step 018275): Train loss 2.359, Val loss 2.595\n",
      "Ep 1 (Step 018280): Train loss 2.514, Val loss 2.590\n",
      "Ep 1 (Step 018285): Train loss 2.149, Val loss 2.581\n",
      "Ep 1 (Step 018290): Train loss 2.229, Val loss 2.571\n",
      "Ep 1 (Step 018295): Train loss 2.602, Val loss 2.586\n",
      "Ep 1 (Step 018300): Train loss 2.488, Val loss 2.572\n",
      "Ep 1 (Step 018305): Train loss 2.235, Val loss 2.565\n",
      "Ep 1 (Step 018310): Train loss 2.655, Val loss 2.567\n",
      "Ep 1 (Step 018315): Train loss 2.378, Val loss 2.566\n",
      "Ep 1 (Step 018320): Train loss 2.687, Val loss 2.565\n",
      "Ep 1 (Step 018325): Train loss 2.549, Val loss 2.565\n",
      "Ep 1 (Step 018330): Train loss 2.298, Val loss 2.571\n",
      "Ep 1 (Step 018335): Train loss 2.439, Val loss 2.563\n",
      "Ep 1 (Step 018340): Train loss 2.639, Val loss 2.557\n",
      "Ep 1 (Step 018345): Train loss 2.620, Val loss 2.557\n",
      "Ep 1 (Step 018350): Train loss 2.423, Val loss 2.557\n",
      "Ep 1 (Step 018355): Train loss 2.436, Val loss 2.568\n",
      "Ep 1 (Step 018360): Train loss 2.282, Val loss 2.578\n",
      "Ep 1 (Step 018365): Train loss 2.405, Val loss 2.551\n",
      "Ep 1 (Step 018370): Train loss 2.575, Val loss 2.551\n",
      "Ep 1 (Step 018375): Train loss 2.229, Val loss 2.559\n",
      "Ep 1 (Step 018380): Train loss 2.454, Val loss 2.563\n",
      "Ep 1 (Step 018385): Train loss 2.684, Val loss 2.555\n",
      "Ep 1 (Step 018390): Train loss 2.658, Val loss 2.556\n",
      "Ep 1 (Step 018395): Train loss 2.496, Val loss 2.552\n",
      "Ep 1 (Step 018400): Train loss 2.591, Val loss 2.554\n",
      "Ep 1 (Step 018405): Train loss 2.502, Val loss 2.560\n",
      "Ep 1 (Step 018410): Train loss 2.737, Val loss 2.550\n",
      "Ep 1 (Step 018415): Train loss 2.283, Val loss 2.545\n",
      "Ep 1 (Step 018420): Train loss 2.525, Val loss 2.546\n",
      "Ep 1 (Step 018425): Train loss 2.571, Val loss 2.543\n",
      "Ep 1 (Step 018430): Train loss 2.519, Val loss 2.540\n",
      "Ep 1 (Step 018435): Train loss 2.387, Val loss 2.542\n",
      "Ep 1 (Step 018440): Train loss 2.448, Val loss 2.552\n",
      "Ep 1 (Step 018445): Train loss 2.476, Val loss 2.562\n",
      "Ep 1 (Step 018450): Train loss 2.313, Val loss 2.565\n",
      "Ep 1 (Step 018455): Train loss 2.759, Val loss 2.567\n",
      "Ep 1 (Step 018460): Train loss 2.453, Val loss 2.587\n",
      "Ep 1 (Step 018465): Train loss 2.544, Val loss 2.572\n",
      "Ep 1 (Step 018470): Train loss 2.414, Val loss 2.569\n",
      "Ep 1 (Step 018475): Train loss 2.559, Val loss 2.579\n",
      "Ep 1 (Step 018480): Train loss 2.380, Val loss 2.573\n",
      "Ep 1 (Step 018485): Train loss 2.385, Val loss 2.563\n",
      "Ep 1 (Step 018490): Train loss 2.495, Val loss 2.561\n",
      "Ep 1 (Step 018495): Train loss 2.314, Val loss 2.560\n",
      "Ep 1 (Step 018500): Train loss 2.583, Val loss 2.546\n",
      "Ep 1 (Step 018505): Train loss 2.600, Val loss 2.561\n",
      "Ep 1 (Step 018510): Train loss 2.447, Val loss 2.586\n",
      "Ep 1 (Step 018515): Train loss 2.691, Val loss 2.604\n",
      "Ep 1 (Step 018520): Train loss 2.416, Val loss 2.609\n",
      "Ep 1 (Step 018525): Train loss 2.479, Val loss 2.603\n",
      "Ep 1 (Step 018530): Train loss 2.551, Val loss 2.596\n",
      "Ep 1 (Step 018535): Train loss 2.606, Val loss 2.579\n",
      "Ep 1 (Step 018540): Train loss 2.320, Val loss 2.581\n",
      "Ep 1 (Step 018545): Train loss 2.357, Val loss 2.577\n",
      "Ep 1 (Step 018550): Train loss 2.525, Val loss 2.589\n",
      "Ep 1 (Step 018555): Train loss 2.479, Val loss 2.612\n",
      "Ep 1 (Step 018560): Train loss 2.574, Val loss 2.615\n",
      "Ep 1 (Step 018565): Train loss 2.581, Val loss 2.596\n",
      "Ep 1 (Step 018570): Train loss 2.462, Val loss 2.590\n",
      "Ep 1 (Step 018575): Train loss 2.513, Val loss 2.575\n",
      "Ep 1 (Step 018580): Train loss 2.297, Val loss 2.566\n",
      "Ep 1 (Step 018585): Train loss 2.536, Val loss 2.572\n",
      "Ep 1 (Step 018590): Train loss 2.601, Val loss 2.589\n",
      "Ep 1 (Step 018595): Train loss 2.869, Val loss 2.579\n",
      "Ep 1 (Step 018600): Train loss 2.447, Val loss 2.585\n",
      "Ep 1 (Step 018605): Train loss 2.536, Val loss 2.587\n",
      "Ep 1 (Step 018610): Train loss 2.361, Val loss 2.586\n",
      "Ep 1 (Step 018615): Train loss 2.525, Val loss 2.584\n",
      "Ep 1 (Step 018620): Train loss 2.406, Val loss 2.581\n",
      "Ep 1 (Step 018625): Train loss 2.585, Val loss 2.580\n",
      "Ep 1 (Step 018630): Train loss 2.578, Val loss 2.582\n",
      "Ep 1 (Step 018635): Train loss 2.376, Val loss 2.580\n",
      "Ep 1 (Step 018640): Train loss 2.289, Val loss 2.567\n",
      "Ep 1 (Step 018645): Train loss 2.568, Val loss 2.567\n",
      "Ep 1 (Step 018650): Train loss 2.619, Val loss 2.559\n",
      "Ep 1 (Step 018655): Train loss 2.366, Val loss 2.568\n",
      "Ep 1 (Step 018660): Train loss 2.080, Val loss 2.566\n",
      "Ep 1 (Step 018665): Train loss 2.468, Val loss 2.557\n",
      "Ep 1 (Step 018670): Train loss 2.347, Val loss 2.543\n",
      "Ep 1 (Step 018675): Train loss 2.353, Val loss 2.536\n",
      "Ep 1 (Step 018680): Train loss 2.613, Val loss 2.531\n",
      "Ep 1 (Step 018685): Train loss 2.313, Val loss 2.530\n",
      "Ep 1 (Step 018690): Train loss 2.526, Val loss 2.538\n",
      "Ep 1 (Step 018695): Train loss 2.781, Val loss 2.527\n",
      "Ep 1 (Step 018700): Train loss 2.527, Val loss 2.544\n",
      "Ep 1 (Step 018705): Train loss 2.830, Val loss 2.559\n",
      "Ep 1 (Step 018710): Train loss 2.511, Val loss 2.554\n",
      "Ep 1 (Step 018715): Train loss 2.658, Val loss 2.549\n",
      "Ep 1 (Step 018720): Train loss 2.677, Val loss 2.541\n",
      "Ep 1 (Step 018725): Train loss 2.498, Val loss 2.552\n",
      "Ep 1 (Step 018730): Train loss 2.338, Val loss 2.574\n",
      "Ep 1 (Step 018735): Train loss 2.460, Val loss 2.583\n",
      "Ep 1 (Step 018740): Train loss 2.769, Val loss 2.573\n",
      "Ep 1 (Step 018745): Train loss 2.741, Val loss 2.569\n",
      "Ep 1 (Step 018750): Train loss 2.494, Val loss 2.560\n",
      "Ep 1 (Step 018755): Train loss 2.656, Val loss 2.557\n",
      "Ep 1 (Step 018760): Train loss 2.339, Val loss 2.569\n",
      "Ep 1 (Step 018765): Train loss 2.638, Val loss 2.558\n",
      "Ep 1 (Step 018770): Train loss 2.666, Val loss 2.551\n",
      "Ep 1 (Step 018775): Train loss 2.883, Val loss 2.543\n",
      "Ep 1 (Step 018780): Train loss 2.234, Val loss 2.559\n",
      "Ep 1 (Step 018785): Train loss 2.431, Val loss 2.556\n",
      "Ep 1 (Step 018790): Train loss 2.386, Val loss 2.566\n",
      "Ep 1 (Step 018795): Train loss 2.445, Val loss 2.576\n",
      "Ep 1 (Step 018800): Train loss 2.456, Val loss 2.571\n",
      "Ep 1 (Step 018805): Train loss 2.568, Val loss 2.549\n",
      "Ep 1 (Step 018810): Train loss 2.557, Val loss 2.552\n",
      "Ep 1 (Step 018815): Train loss 2.370, Val loss 2.552\n",
      "Ep 1 (Step 018820): Train loss 2.348, Val loss 2.549\n",
      "Ep 1 (Step 018825): Train loss 2.280, Val loss 2.552\n",
      "Ep 1 (Step 018830): Train loss 2.449, Val loss 2.557\n",
      "Ep 1 (Step 018835): Train loss 2.451, Val loss 2.564\n",
      "Ep 1 (Step 018840): Train loss 2.479, Val loss 2.571\n",
      "Ep 1 (Step 018845): Train loss 2.298, Val loss 2.580\n",
      "Ep 1 (Step 018850): Train loss 2.404, Val loss 2.567\n",
      "Ep 1 (Step 018855): Train loss 2.781, Val loss 2.565\n",
      "Ep 1 (Step 018860): Train loss 2.561, Val loss 2.575\n",
      "Ep 1 (Step 018865): Train loss 2.503, Val loss 2.585\n",
      "Ep 1 (Step 018870): Train loss 2.279, Val loss 2.568\n",
      "Ep 1 (Step 018875): Train loss 2.551, Val loss 2.551\n",
      "Ep 1 (Step 018880): Train loss 2.540, Val loss 2.541\n",
      "Ep 1 (Step 018885): Train loss 2.565, Val loss 2.544\n",
      "Ep 1 (Step 018890): Train loss 2.559, Val loss 2.549\n",
      "Ep 1 (Step 018895): Train loss 2.432, Val loss 2.536\n",
      "Ep 1 (Step 018900): Train loss 2.495, Val loss 2.535\n",
      "Ep 1 (Step 018905): Train loss 2.341, Val loss 2.534\n",
      "Ep 1 (Step 018910): Train loss 2.488, Val loss 2.527\n",
      "Ep 1 (Step 018915): Train loss 2.420, Val loss 2.527\n",
      "Ep 1 (Step 018920): Train loss 2.075, Val loss 2.545\n",
      "Ep 1 (Step 018925): Train loss 2.616, Val loss 2.552\n",
      "Ep 1 (Step 018930): Train loss 2.372, Val loss 2.551\n",
      "Ep 1 (Step 018935): Train loss 2.488, Val loss 2.543\n",
      "Ep 1 (Step 018940): Train loss 2.771, Val loss 2.528\n",
      "Ep 1 (Step 018945): Train loss 2.453, Val loss 2.513\n",
      "Ep 1 (Step 018950): Train loss 2.426, Val loss 2.516\n",
      "Ep 1 (Step 018955): Train loss 2.425, Val loss 2.521\n",
      "Ep 1 (Step 018960): Train loss 2.505, Val loss 2.508\n",
      "Ep 1 (Step 018965): Train loss 2.635, Val loss 2.512\n",
      "Ep 1 (Step 018970): Train loss 2.312, Val loss 2.531\n",
      "Ep 1 (Step 018975): Train loss 2.612, Val loss 2.547\n",
      "Ep 1 (Step 018980): Train loss 2.321, Val loss 2.537\n",
      "Ep 1 (Step 018985): Train loss 2.404, Val loss 2.540\n",
      "Ep 1 (Step 018990): Train loss 2.511, Val loss 2.531\n",
      "Ep 1 (Step 018995): Train loss 2.247, Val loss 2.531\n",
      "Ep 1 (Step 019000): Train loss 2.444, Val loss 2.534\n",
      "Ep 1 (Step 019005): Train loss 2.786, Val loss 2.523\n",
      "Ep 1 (Step 019010): Train loss 2.554, Val loss 2.516\n",
      "Ep 1 (Step 019015): Train loss 2.650, Val loss 2.518\n",
      "Ep 1 (Step 019020): Train loss 2.519, Val loss 2.525\n",
      "Ep 1 (Step 019025): Train loss 2.400, Val loss 2.528\n",
      "Ep 1 (Step 019030): Train loss 2.471, Val loss 2.562\n",
      "Ep 1 (Step 019035): Train loss 2.689, Val loss 2.568\n",
      "Ep 1 (Step 019040): Train loss 2.286, Val loss 2.566\n",
      "Ep 1 (Step 019045): Train loss 2.671, Val loss 2.547\n",
      "Ep 1 (Step 019050): Train loss 2.367, Val loss 2.546\n",
      "Ep 1 (Step 019055): Train loss 2.363, Val loss 2.541\n",
      "Ep 1 (Step 019060): Train loss 2.264, Val loss 2.538\n",
      "Ep 1 (Step 019065): Train loss 2.379, Val loss 2.542\n",
      "Ep 1 (Step 019070): Train loss 2.269, Val loss 2.546\n",
      "Ep 1 (Step 019075): Train loss 2.684, Val loss 2.556\n",
      "Ep 1 (Step 019080): Train loss 2.859, Val loss 2.550\n",
      "Ep 1 (Step 019085): Train loss 2.454, Val loss 2.543\n",
      "Ep 1 (Step 019090): Train loss 2.261, Val loss 2.554\n",
      "Ep 1 (Step 019095): Train loss 2.425, Val loss 2.532\n",
      "Ep 1 (Step 019100): Train loss 2.423, Val loss 2.522\n",
      "Ep 1 (Step 019105): Train loss 2.809, Val loss 2.535\n",
      "Ep 1 (Step 019110): Train loss 2.610, Val loss 2.525\n",
      "Ep 1 (Step 019115): Train loss 2.465, Val loss 2.518\n",
      "Ep 1 (Step 019120): Train loss 2.495, Val loss 2.513\n",
      "Ep 1 (Step 019125): Train loss 2.439, Val loss 2.516\n",
      "Ep 1 (Step 019130): Train loss 2.619, Val loss 2.518\n",
      "Ep 1 (Step 019135): Train loss 2.489, Val loss 2.523\n",
      "Ep 1 (Step 019140): Train loss 2.201, Val loss 2.521\n",
      "Ep 1 (Step 019145): Train loss 2.543, Val loss 2.525\n",
      "Ep 1 (Step 019150): Train loss 2.571, Val loss 2.525\n",
      "Ep 1 (Step 019155): Train loss 2.886, Val loss 2.517\n",
      "Ep 1 (Step 019160): Train loss 2.473, Val loss 2.515\n",
      "Ep 1 (Step 019165): Train loss 2.532, Val loss 2.512\n",
      "Ep 1 (Step 019170): Train loss 2.290, Val loss 2.507\n",
      "Ep 1 (Step 019175): Train loss 2.452, Val loss 2.510\n",
      "Ep 1 (Step 019180): Train loss 2.354, Val loss 2.518\n",
      "Ep 1 (Step 019185): Train loss 2.659, Val loss 2.516\n",
      "Ep 1 (Step 019190): Train loss 2.370, Val loss 2.512\n",
      "Ep 1 (Step 019195): Train loss 2.363, Val loss 2.503\n",
      "Ep 1 (Step 019200): Train loss 2.211, Val loss 2.506\n",
      "Ep 1 (Step 019205): Train loss 2.285, Val loss 2.502\n",
      "Ep 1 (Step 019210): Train loss 2.327, Val loss 2.497\n",
      "Ep 1 (Step 019215): Train loss 2.605, Val loss 2.495\n",
      "Ep 1 (Step 019220): Train loss 2.173, Val loss 2.493\n",
      "Ep 1 (Step 019225): Train loss 2.457, Val loss 2.495\n",
      "Ep 1 (Step 019230): Train loss 2.267, Val loss 2.506\n",
      "Ep 1 (Step 019235): Train loss 2.378, Val loss 2.510\n",
      "Ep 1 (Step 019240): Train loss 2.403, Val loss 2.486\n",
      "Ep 1 (Step 019245): Train loss 2.317, Val loss 2.471\n",
      "Ep 1 (Step 019250): Train loss 2.565, Val loss 2.466\n",
      "Ep 1 (Step 019255): Train loss 2.349, Val loss 2.463\n",
      "Ep 1 (Step 019260): Train loss 2.531, Val loss 2.468\n",
      "Ep 1 (Step 019265): Train loss 2.467, Val loss 2.475\n",
      "Ep 1 (Step 019270): Train loss 2.252, Val loss 2.482\n",
      "Ep 1 (Step 019275): Train loss 2.493, Val loss 2.475\n",
      "Ep 1 (Step 019280): Train loss 2.485, Val loss 2.473\n",
      "Ep 1 (Step 019285): Train loss 2.330, Val loss 2.477\n",
      "Ep 1 (Step 019290): Train loss 2.288, Val loss 2.483\n",
      "Ep 1 (Step 019295): Train loss 2.538, Val loss 2.496\n",
      "Ep 1 (Step 019300): Train loss 2.561, Val loss 2.496\n",
      "Ep 1 (Step 019305): Train loss 2.370, Val loss 2.504\n",
      "Ep 1 (Step 019310): Train loss 2.482, Val loss 2.516\n",
      "Ep 1 (Step 019315): Train loss 2.390, Val loss 2.487\n",
      "Ep 1 (Step 019320): Train loss 2.351, Val loss 2.476\n",
      "Ep 1 (Step 019325): Train loss 2.299, Val loss 2.486\n",
      "Ep 1 (Step 019330): Train loss 2.416, Val loss 2.493\n",
      "Ep 1 (Step 019335): Train loss 2.424, Val loss 2.499\n",
      "Ep 1 (Step 019340): Train loss 2.644, Val loss 2.500\n",
      "Ep 1 (Step 019345): Train loss 2.319, Val loss 2.499\n",
      "Ep 1 (Step 019350): Train loss 2.522, Val loss 2.478\n",
      "Ep 1 (Step 019355): Train loss 2.310, Val loss 2.485\n",
      "Ep 1 (Step 019360): Train loss 2.320, Val loss 2.498\n",
      "Ep 1 (Step 019365): Train loss 2.380, Val loss 2.501\n",
      "Ep 1 (Step 019370): Train loss 2.779, Val loss 2.494\n",
      "Ep 1 (Step 019375): Train loss 2.466, Val loss 2.478\n",
      "Ep 1 (Step 019380): Train loss 2.724, Val loss 2.479\n",
      "Ep 1 (Step 019385): Train loss 2.107, Val loss 2.492\n",
      "Ep 1 (Step 019390): Train loss 2.367, Val loss 2.499\n",
      "Ep 1 (Step 019395): Train loss 2.583, Val loss 2.493\n",
      "Ep 1 (Step 019400): Train loss 2.392, Val loss 2.485\n",
      "Ep 1 (Step 019405): Train loss 2.419, Val loss 2.489\n",
      "Ep 1 (Step 019410): Train loss 2.470, Val loss 2.492\n",
      "Ep 1 (Step 019415): Train loss 2.485, Val loss 2.520\n",
      "Ep 1 (Step 019420): Train loss 2.283, Val loss 2.516\n",
      "Ep 1 (Step 019425): Train loss 2.479, Val loss 2.509\n",
      "Ep 1 (Step 019430): Train loss 2.464, Val loss 2.489\n",
      "Ep 1 (Step 019435): Train loss 2.378, Val loss 2.478\n",
      "Ep 1 (Step 019440): Train loss 2.737, Val loss 2.474\n",
      "Ep 1 (Step 019445): Train loss 2.383, Val loss 2.476\n",
      "Ep 1 (Step 019450): Train loss 2.315, Val loss 2.475\n",
      "Ep 1 (Step 019455): Train loss 2.562, Val loss 2.470\n",
      "Ep 1 (Step 019460): Train loss 2.464, Val loss 2.470\n",
      "Ep 1 (Step 019465): Train loss 2.359, Val loss 2.477\n",
      "Ep 1 (Step 019470): Train loss 2.330, Val loss 2.485\n",
      "Ep 1 (Step 019475): Train loss 2.461, Val loss 2.492\n",
      "Ep 1 (Step 019480): Train loss 2.410, Val loss 2.490\n",
      "Ep 1 (Step 019485): Train loss 2.315, Val loss 2.491\n",
      "Ep 1 (Step 019490): Train loss 2.477, Val loss 2.492\n",
      "Ep 1 (Step 019495): Train loss 2.478, Val loss 2.492\n",
      "Ep 1 (Step 019500): Train loss 2.261, Val loss 2.487\n",
      "Ep 1 (Step 019505): Train loss 2.528, Val loss 2.494\n",
      "Ep 1 (Step 019510): Train loss 2.544, Val loss 2.510\n",
      "Ep 1 (Step 019515): Train loss 2.396, Val loss 2.511\n",
      "Ep 1 (Step 019520): Train loss 2.284, Val loss 2.499\n",
      "Ep 1 (Step 019525): Train loss 2.360, Val loss 2.494\n",
      "Ep 1 (Step 019530): Train loss 2.520, Val loss 2.493\n",
      "Ep 1 (Step 019535): Train loss 2.458, Val loss 2.502\n",
      "Ep 1 (Step 019540): Train loss 2.494, Val loss 2.494\n",
      "Ep 1 (Step 019545): Train loss 2.039, Val loss 2.490\n",
      "Ep 1 (Step 019550): Train loss 2.717, Val loss 2.477\n",
      "Ep 1 (Step 019555): Train loss 2.417, Val loss 2.482\n",
      "Ep 1 (Step 019560): Train loss 2.403, Val loss 2.490\n",
      "Ep 1 (Step 019565): Train loss 2.067, Val loss 2.491\n",
      "Ep 1 (Step 019570): Train loss 2.167, Val loss 2.494\n",
      "Ep 1 (Step 019575): Train loss 2.543, Val loss 2.486\n",
      "Ep 1 (Step 019580): Train loss 2.335, Val loss 2.489\n",
      "Ep 1 (Step 019585): Train loss 2.786, Val loss 2.489\n",
      "Ep 1 (Step 019590): Train loss 2.608, Val loss 2.487\n",
      "Ep 1 (Step 019595): Train loss 2.582, Val loss 2.472\n",
      "Ep 1 (Step 019600): Train loss 2.362, Val loss 2.481\n",
      "Ep 1 (Step 019605): Train loss 2.648, Val loss 2.480\n",
      "Ep 1 (Step 019610): Train loss 2.401, Val loss 2.497\n",
      "Ep 1 (Step 019615): Train loss 2.744, Val loss 2.502\n",
      "Ep 1 (Step 019620): Train loss 2.332, Val loss 2.504\n",
      "Ep 1 (Step 019625): Train loss 2.371, Val loss 2.498\n",
      "Ep 1 (Step 019630): Train loss 2.340, Val loss 2.492\n",
      "Ep 1 (Step 019635): Train loss 2.189, Val loss 2.489\n",
      "Ep 1 (Step 019640): Train loss 2.599, Val loss 2.491\n",
      "Ep 1 (Step 019645): Train loss 2.523, Val loss 2.496\n",
      "Ep 1 (Step 019650): Train loss 2.322, Val loss 2.505\n",
      "Ep 1 (Step 019655): Train loss 2.465, Val loss 2.502\n",
      "Ep 1 (Step 019660): Train loss 2.438, Val loss 2.499\n",
      "Ep 1 (Step 019665): Train loss 2.472, Val loss 2.494\n",
      "Ep 1 (Step 019670): Train loss 2.742, Val loss 2.481\n",
      "Ep 1 (Step 019675): Train loss 2.861, Val loss 2.498\n",
      "Ep 1 (Step 019680): Train loss 2.497, Val loss 2.503\n",
      "Ep 1 (Step 019685): Train loss 2.690, Val loss 2.505\n",
      "Ep 1 (Step 019690): Train loss 2.505, Val loss 2.508\n",
      "Ep 1 (Step 019695): Train loss 2.386, Val loss 2.516\n",
      "Ep 1 (Step 019700): Train loss 2.543, Val loss 2.496\n",
      "Ep 1 (Step 019705): Train loss 2.306, Val loss 2.500\n",
      "Ep 1 (Step 019710): Train loss 2.448, Val loss 2.488\n",
      "Ep 1 (Step 019715): Train loss 2.469, Val loss 2.505\n",
      "Ep 1 (Step 019720): Train loss 2.463, Val loss 2.483\n",
      "Ep 1 (Step 019725): Train loss 2.541, Val loss 2.479\n",
      "Ep 1 (Step 019730): Train loss 2.088, Val loss 2.487\n",
      "Ep 1 (Step 019735): Train loss 2.448, Val loss 2.489\n",
      "Ep 1 (Step 019740): Train loss 2.670, Val loss 2.479\n",
      "Ep 1 (Step 019745): Train loss 2.404, Val loss 2.479\n",
      "Ep 1 (Step 019750): Train loss 2.292, Val loss 2.472\n",
      "Ep 1 (Step 019755): Train loss 2.293, Val loss 2.482\n",
      "Ep 1 (Step 019760): Train loss 2.526, Val loss 2.489\n",
      "Ep 1 (Step 019765): Train loss 2.330, Val loss 2.496\n",
      "Ep 1 (Step 019770): Train loss 2.337, Val loss 2.489\n",
      "Ep 1 (Step 019775): Train loss 2.498, Val loss 2.478\n",
      "Ep 1 (Step 019780): Train loss 2.598, Val loss 2.464\n",
      "Ep 1 (Step 019785): Train loss 2.322, Val loss 2.483\n",
      "Ep 1 (Step 019790): Train loss 2.583, Val loss 2.473\n",
      "Ep 1 (Step 019795): Train loss 2.330, Val loss 2.475\n",
      "Ep 1 (Step 019800): Train loss 2.664, Val loss 2.469\n",
      "Ep 1 (Step 019805): Train loss 2.254, Val loss 2.489\n",
      "Ep 1 (Step 019810): Train loss 2.279, Val loss 2.486\n",
      "Ep 1 (Step 019815): Train loss 2.653, Val loss 2.487\n",
      "Ep 1 (Step 019820): Train loss 2.094, Val loss 2.492\n",
      "Ep 1 (Step 019825): Train loss 2.332, Val loss 2.487\n",
      "Ep 1 (Step 019830): Train loss 2.582, Val loss 2.478\n",
      "Ep 1 (Step 019835): Train loss 2.482, Val loss 2.474\n",
      "Ep 1 (Step 019840): Train loss 2.449, Val loss 2.473\n",
      "Ep 1 (Step 019845): Train loss 2.553, Val loss 2.468\n",
      "Ep 1 (Step 019850): Train loss 2.449, Val loss 2.483\n",
      "Ep 1 (Step 019855): Train loss 2.479, Val loss 2.472\n",
      "Ep 1 (Step 019860): Train loss 2.386, Val loss 2.462\n",
      "Ep 1 (Step 019865): Train loss 2.615, Val loss 2.465\n",
      "Ep 1 (Step 019870): Train loss 2.578, Val loss 2.467\n",
      "Ep 1 (Step 019875): Train loss 2.125, Val loss 2.463\n",
      "Ep 1 (Step 019880): Train loss 2.488, Val loss 2.452\n",
      "Ep 1 (Step 019885): Train loss 2.703, Val loss 2.456\n",
      "Ep 1 (Step 019890): Train loss 2.396, Val loss 2.459\n",
      "Ep 1 (Step 019895): Train loss 2.230, Val loss 2.459\n",
      "Ep 1 (Step 019900): Train loss 2.278, Val loss 2.469\n",
      "Ep 1 (Step 019905): Train loss 2.695, Val loss 2.470\n",
      "Ep 1 (Step 019910): Train loss 2.448, Val loss 2.487\n",
      "Ep 1 (Step 019915): Train loss 2.492, Val loss 2.478\n",
      "Ep 1 (Step 019920): Train loss 2.242, Val loss 2.460\n",
      "Ep 1 (Step 019925): Train loss 2.549, Val loss 2.456\n",
      "Ep 1 (Step 019930): Train loss 2.228, Val loss 2.462\n",
      "Ep 1 (Step 019935): Train loss 2.381, Val loss 2.467\n",
      "Ep 1 (Step 019940): Train loss 2.282, Val loss 2.489\n",
      "Ep 1 (Step 019945): Train loss 2.332, Val loss 2.495\n",
      "Ep 1 (Step 019950): Train loss 2.460, Val loss 2.492\n",
      "Ep 1 (Step 019955): Train loss 2.433, Val loss 2.489\n",
      "Ep 1 (Step 019960): Train loss 2.270, Val loss 2.486\n",
      "Ep 1 (Step 019965): Train loss 2.610, Val loss 2.487\n",
      "Ep 1 (Step 019970): Train loss 2.616, Val loss 2.486\n",
      "Ep 1 (Step 019975): Train loss 2.591, Val loss 2.495\n",
      "Ep 1 (Step 019980): Train loss 2.328, Val loss 2.487\n",
      "Ep 1 (Step 019985): Train loss 2.702, Val loss 2.469\n",
      "Ep 1 (Step 019990): Train loss 2.159, Val loss 2.468\n",
      "Ep 1 (Step 019995): Train loss 2.398, Val loss 2.461\n",
      "Ep 1 (Step 020000): Train loss 2.367, Val loss 2.456\n",
      "Ep 1 (Step 020005): Train loss 2.361, Val loss 2.452\n",
      "Ep 1 (Step 020010): Train loss 2.568, Val loss 2.453\n",
      "Ep 1 (Step 020015): Train loss 2.645, Val loss 2.455\n",
      "Ep 1 (Step 020020): Train loss 2.334, Val loss 2.457\n",
      "Ep 1 (Step 020025): Train loss 2.885, Val loss 2.459\n",
      "Ep 1 (Step 020030): Train loss 2.443, Val loss 2.469\n",
      "Ep 1 (Step 020035): Train loss 2.486, Val loss 2.458\n",
      "Ep 1 (Step 020040): Train loss 2.652, Val loss 2.444\n",
      "Ep 1 (Step 020045): Train loss 2.441, Val loss 2.431\n",
      "Ep 1 (Step 020050): Train loss 2.203, Val loss 2.444\n",
      "Ep 1 (Step 020055): Train loss 2.586, Val loss 2.447\n",
      "Ep 1 (Step 020060): Train loss 2.581, Val loss 2.463\n",
      "Ep 1 (Step 020065): Train loss 2.412, Val loss 2.452\n",
      "Ep 1 (Step 020070): Train loss 2.596, Val loss 2.454\n",
      "Ep 1 (Step 020075): Train loss 2.288, Val loss 2.468\n",
      "Ep 1 (Step 020080): Train loss 2.411, Val loss 2.469\n",
      "Ep 1 (Step 020085): Train loss 2.313, Val loss 2.462\n",
      "Ep 1 (Step 020090): Train loss 2.162, Val loss 2.459\n",
      "Ep 1 (Step 020095): Train loss 2.314, Val loss 2.456\n",
      "Ep 1 (Step 020100): Train loss 2.366, Val loss 2.449\n",
      "Ep 1 (Step 020105): Train loss 2.420, Val loss 2.448\n",
      "Ep 1 (Step 020110): Train loss 2.508, Val loss 2.445\n",
      "Ep 1 (Step 020115): Train loss 2.428, Val loss 2.446\n",
      "Ep 1 (Step 020120): Train loss 2.352, Val loss 2.446\n",
      "Ep 1 (Step 020125): Train loss 2.458, Val loss 2.443\n",
      "Ep 1 (Step 020130): Train loss 2.507, Val loss 2.449\n",
      "Ep 1 (Step 020135): Train loss 2.404, Val loss 2.446\n",
      "Ep 1 (Step 020140): Train loss 2.229, Val loss 2.438\n",
      "Ep 1 (Step 020145): Train loss 2.527, Val loss 2.439\n",
      "Ep 1 (Step 020150): Train loss 2.495, Val loss 2.455\n",
      "Ep 1 (Step 020155): Train loss 2.329, Val loss 2.452\n",
      "Ep 1 (Step 020160): Train loss 2.396, Val loss 2.445\n",
      "Ep 1 (Step 020165): Train loss 2.388, Val loss 2.439\n",
      "Ep 1 (Step 020170): Train loss 2.325, Val loss 2.442\n",
      "Ep 1 (Step 020175): Train loss 2.375, Val loss 2.432\n",
      "Ep 1 (Step 020180): Train loss 2.575, Val loss 2.429\n",
      "Ep 1 (Step 020185): Train loss 2.373, Val loss 2.428\n",
      "Ep 1 (Step 020190): Train loss 2.634, Val loss 2.431\n",
      "Ep 1 (Step 020195): Train loss 2.537, Val loss 2.438\n",
      "Ep 1 (Step 020200): Train loss 2.066, Val loss 2.445\n",
      "Ep 1 (Step 020205): Train loss 2.433, Val loss 2.444\n",
      "Ep 1 (Step 020210): Train loss 2.431, Val loss 2.446\n",
      "Ep 1 (Step 020215): Train loss 2.485, Val loss 2.431\n",
      "Ep 1 (Step 020220): Train loss 2.170, Val loss 2.435\n",
      "Ep 1 (Step 020225): Train loss 2.626, Val loss 2.436\n",
      "Ep 1 (Step 020230): Train loss 2.538, Val loss 2.435\n",
      "Ep 1 (Step 020235): Train loss 2.450, Val loss 2.421\n",
      "Ep 1 (Step 020240): Train loss 2.450, Val loss 2.438\n",
      "Ep 1 (Step 020245): Train loss 2.229, Val loss 2.439\n",
      "Ep 1 (Step 020250): Train loss 2.650, Val loss 2.426\n",
      "Ep 1 (Step 020255): Train loss 2.195, Val loss 2.426\n",
      "Ep 1 (Step 020260): Train loss 2.531, Val loss 2.431\n",
      "Ep 1 (Step 020265): Train loss 2.295, Val loss 2.429\n",
      "Ep 1 (Step 020270): Train loss 2.230, Val loss 2.420\n",
      "Ep 1 (Step 020275): Train loss 2.376, Val loss 2.410\n",
      "Ep 1 (Step 020280): Train loss 2.388, Val loss 2.403\n",
      "Ep 1 (Step 020285): Train loss 2.286, Val loss 2.400\n",
      "Ep 1 (Step 020290): Train loss 2.408, Val loss 2.408\n",
      "Ep 1 (Step 020295): Train loss 2.347, Val loss 2.425\n",
      "Ep 1 (Step 020300): Train loss 2.277, Val loss 2.422\n",
      "Ep 1 (Step 020305): Train loss 2.351, Val loss 2.414\n",
      "Ep 1 (Step 020310): Train loss 2.278, Val loss 2.399\n",
      "Ep 1 (Step 020315): Train loss 2.206, Val loss 2.385\n",
      "Ep 1 (Step 020320): Train loss 2.494, Val loss 2.387\n",
      "Ep 1 (Step 020325): Train loss 2.388, Val loss 2.392\n",
      "Ep 1 (Step 020330): Train loss 2.124, Val loss 2.397\n",
      "Ep 1 (Step 020335): Train loss 2.342, Val loss 2.403\n",
      "Ep 1 (Step 020340): Train loss 2.294, Val loss 2.403\n",
      "Ep 1 (Step 020345): Train loss 2.526, Val loss 2.405\n",
      "Ep 1 (Step 020350): Train loss 2.185, Val loss 2.407\n",
      "Ep 1 (Step 020355): Train loss 2.343, Val loss 2.406\n",
      "Ep 1 (Step 020360): Train loss 2.405, Val loss 2.404\n",
      "Ep 1 (Step 020365): Train loss 2.458, Val loss 2.404\n",
      "Ep 1 (Step 020370): Train loss 2.612, Val loss 2.403\n",
      "Ep 1 (Step 020375): Train loss 2.349, Val loss 2.412\n",
      "Ep 1 (Step 020380): Train loss 2.244, Val loss 2.424\n",
      "Ep 1 (Step 020385): Train loss 2.455, Val loss 2.426\n",
      "Ep 1 (Step 020390): Train loss 2.388, Val loss 2.414\n",
      "Ep 1 (Step 020395): Train loss 2.432, Val loss 2.417\n",
      "Ep 1 (Step 020400): Train loss 2.449, Val loss 2.421\n",
      "Ep 1 (Step 020405): Train loss 2.579, Val loss 2.441\n",
      "Ep 1 (Step 020410): Train loss 2.352, Val loss 2.440\n",
      "Ep 1 (Step 020415): Train loss 2.414, Val loss 2.432\n",
      "Ep 1 (Step 020420): Train loss 2.126, Val loss 2.453\n",
      "Ep 1 (Step 020425): Train loss 2.228, Val loss 2.468\n",
      "Ep 1 (Step 020430): Train loss 2.560, Val loss 2.478\n",
      "Ep 1 (Step 020435): Train loss 2.487, Val loss 2.462\n",
      "Ep 1 (Step 020440): Train loss 2.328, Val loss 2.430\n",
      "Ep 1 (Step 020445): Train loss 2.293, Val loss 2.419\n",
      "Ep 1 (Step 020450): Train loss 2.680, Val loss 2.421\n",
      "Ep 1 (Step 020455): Train loss 2.309, Val loss 2.432\n",
      "Ep 1 (Step 020460): Train loss 2.229, Val loss 2.445\n",
      "Ep 1 (Step 020465): Train loss 2.340, Val loss 2.439\n",
      "Ep 1 (Step 020470): Train loss 2.737, Val loss 2.433\n",
      "Ep 1 (Step 020475): Train loss 2.245, Val loss 2.434\n",
      "Ep 1 (Step 020480): Train loss 2.431, Val loss 2.447\n",
      "Ep 1 (Step 020485): Train loss 2.333, Val loss 2.455\n",
      "Ep 1 (Step 020490): Train loss 2.349, Val loss 2.433\n",
      "Ep 1 (Step 020495): Train loss 2.348, Val loss 2.428\n",
      "Ep 1 (Step 020500): Train loss 2.587, Val loss 2.423\n",
      "Ep 1 (Step 020505): Train loss 2.545, Val loss 2.420\n",
      "Ep 1 (Step 020510): Train loss 2.610, Val loss 2.423\n",
      "Ep 1 (Step 020515): Train loss 2.481, Val loss 2.429\n",
      "Ep 1 (Step 020520): Train loss 2.374, Val loss 2.434\n",
      "Ep 1 (Step 020525): Train loss 2.356, Val loss 2.433\n",
      "Ep 1 (Step 020530): Train loss 2.462, Val loss 2.444\n",
      "Ep 1 (Step 020535): Train loss 2.518, Val loss 2.437\n",
      "Ep 1 (Step 020540): Train loss 2.485, Val loss 2.434\n",
      "Ep 1 (Step 020545): Train loss 2.451, Val loss 2.412\n",
      "Ep 1 (Step 020550): Train loss 2.745, Val loss 2.409\n",
      "Ep 1 (Step 020555): Train loss 2.411, Val loss 2.406\n",
      "Ep 1 (Step 020560): Train loss 2.136, Val loss 2.412\n",
      "Ep 1 (Step 020565): Train loss 2.143, Val loss 2.426\n",
      "Ep 1 (Step 020570): Train loss 2.588, Val loss 2.420\n",
      "Ep 1 (Step 020575): Train loss 2.323, Val loss 2.421\n",
      "Ep 1 (Step 020580): Train loss 2.138, Val loss 2.439\n",
      "Ep 1 (Step 020585): Train loss 2.535, Val loss 2.422\n",
      "Ep 1 (Step 020590): Train loss 2.464, Val loss 2.413\n",
      "Ep 1 (Step 020595): Train loss 2.491, Val loss 2.400\n",
      "Ep 1 (Step 020600): Train loss 2.535, Val loss 2.422\n",
      "Ep 1 (Step 020605): Train loss 2.240, Val loss 2.437\n",
      "Ep 1 (Step 020610): Train loss 2.427, Val loss 2.438\n",
      "Ep 1 (Step 020615): Train loss 2.284, Val loss 2.433\n",
      "Ep 1 (Step 020620): Train loss 2.694, Val loss 2.432\n",
      "Ep 1 (Step 020625): Train loss 2.311, Val loss 2.430\n",
      "Ep 1 (Step 020630): Train loss 2.662, Val loss 2.433\n",
      "Ep 1 (Step 020635): Train loss 2.448, Val loss 2.438\n",
      "Ep 1 (Step 020640): Train loss 2.638, Val loss 2.440\n",
      "Ep 1 (Step 020645): Train loss 2.321, Val loss 2.440\n",
      "Ep 1 (Step 020650): Train loss 2.411, Val loss 2.425\n",
      "Ep 1 (Step 020655): Train loss 2.617, Val loss 2.429\n",
      "Ep 1 (Step 020660): Train loss 2.199, Val loss 2.419\n",
      "Ep 1 (Step 020665): Train loss 2.274, Val loss 2.412\n",
      "Ep 1 (Step 020670): Train loss 2.425, Val loss 2.419\n",
      "Ep 1 (Step 020675): Train loss 2.390, Val loss 2.438\n",
      "Ep 1 (Step 020680): Train loss 2.261, Val loss 2.442\n",
      "Ep 1 (Step 020685): Train loss 2.381, Val loss 2.418\n",
      "Ep 1 (Step 020690): Train loss 2.143, Val loss 2.402\n",
      "Ep 1 (Step 020695): Train loss 2.430, Val loss 2.392\n",
      "Ep 1 (Step 020700): Train loss 2.167, Val loss 2.404\n",
      "Ep 1 (Step 020705): Train loss 2.395, Val loss 2.407\n",
      "Ep 1 (Step 020710): Train loss 2.453, Val loss 2.420\n",
      "Ep 1 (Step 020715): Train loss 2.644, Val loss 2.409\n",
      "Ep 1 (Step 020720): Train loss 2.384, Val loss 2.403\n",
      "Ep 1 (Step 020725): Train loss 2.462, Val loss 2.402\n",
      "Ep 1 (Step 020730): Train loss 2.294, Val loss 2.400\n",
      "Ep 1 (Step 020735): Train loss 2.498, Val loss 2.407\n",
      "Ep 1 (Step 020740): Train loss 2.603, Val loss 2.408\n",
      "Ep 1 (Step 020745): Train loss 2.491, Val loss 2.413\n",
      "Ep 1 (Step 020750): Train loss 2.355, Val loss 2.415\n",
      "Ep 1 (Step 020755): Train loss 2.312, Val loss 2.445\n",
      "Ep 1 (Step 020760): Train loss 2.315, Val loss 2.423\n",
      "Ep 1 (Step 020765): Train loss 2.575, Val loss 2.419\n",
      "Ep 1 (Step 020770): Train loss 2.523, Val loss 2.435\n",
      "Ep 1 (Step 020775): Train loss 2.663, Val loss 2.432\n",
      "Ep 1 (Step 020780): Train loss 2.270, Val loss 2.435\n",
      "Ep 1 (Step 020785): Train loss 2.429, Val loss 2.413\n",
      "Ep 1 (Step 020790): Train loss 2.578, Val loss 2.394\n",
      "Ep 1 (Step 020795): Train loss 2.491, Val loss 2.403\n",
      "Ep 1 (Step 020800): Train loss 2.279, Val loss 2.426\n",
      "Ep 1 (Step 020805): Train loss 2.209, Val loss 2.443\n",
      "Ep 1 (Step 020810): Train loss 2.381, Val loss 2.424\n",
      "Ep 1 (Step 020815): Train loss 2.369, Val loss 2.417\n",
      "Ep 1 (Step 020820): Train loss 2.255, Val loss 2.410\n",
      "Ep 1 (Step 020825): Train loss 2.199, Val loss 2.404\n",
      "Ep 1 (Step 020830): Train loss 2.182, Val loss 2.414\n",
      "Ep 1 (Step 020835): Train loss 2.424, Val loss 2.427\n",
      "Ep 1 (Step 020840): Train loss 2.225, Val loss 2.438\n",
      "Ep 1 (Step 020845): Train loss 2.354, Val loss 2.434\n",
      "Ep 1 (Step 020850): Train loss 2.847, Val loss 2.421\n",
      "Ep 1 (Step 020855): Train loss 2.495, Val loss 2.426\n",
      "Ep 1 (Step 020860): Train loss 2.443, Val loss 2.436\n",
      "Ep 1 (Step 020865): Train loss 2.417, Val loss 2.442\n",
      "Ep 1 (Step 020870): Train loss 2.436, Val loss 2.440\n",
      "Ep 1 (Step 020875): Train loss 2.584, Val loss 2.436\n",
      "Ep 1 (Step 020880): Train loss 2.314, Val loss 2.432\n",
      "Ep 1 (Step 020885): Train loss 2.706, Val loss 2.423\n",
      "Ep 1 (Step 020890): Train loss 2.899, Val loss 2.423\n",
      "Ep 1 (Step 020895): Train loss 2.215, Val loss 2.421\n",
      "Ep 1 (Step 020900): Train loss 2.588, Val loss 2.423\n",
      "Ep 1 (Step 020905): Train loss 2.529, Val loss 2.424\n",
      "Ep 1 (Step 020910): Train loss 2.239, Val loss 2.413\n",
      "Ep 1 (Step 020915): Train loss 2.212, Val loss 2.409\n",
      "Ep 1 (Step 020920): Train loss 2.317, Val loss 2.407\n",
      "Ep 1 (Step 020925): Train loss 2.289, Val loss 2.414\n",
      "Ep 1 (Step 020930): Train loss 2.514, Val loss 2.429\n",
      "Ep 1 (Step 020935): Train loss 2.443, Val loss 2.426\n",
      "Ep 1 (Step 020940): Train loss 2.320, Val loss 2.413\n",
      "Ep 1 (Step 020945): Train loss 2.290, Val loss 2.399\n",
      "Ep 1 (Step 020950): Train loss 2.309, Val loss 2.403\n",
      "Ep 1 (Step 020955): Train loss 2.460, Val loss 2.403\n",
      "Ep 1 (Step 020960): Train loss 2.226, Val loss 2.417\n",
      "Ep 1 (Step 020965): Train loss 2.124, Val loss 2.414\n",
      "Ep 1 (Step 020970): Train loss 2.420, Val loss 2.407\n",
      "Ep 1 (Step 020975): Train loss 2.172, Val loss 2.411\n",
      "Ep 1 (Step 020980): Train loss 2.395, Val loss 2.388\n",
      "Ep 1 (Step 020985): Train loss 2.415, Val loss 2.379\n",
      "Ep 1 (Step 020990): Train loss 2.304, Val loss 2.383\n",
      "Ep 1 (Step 020995): Train loss 2.463, Val loss 2.383\n",
      "Ep 1 (Step 021000): Train loss 2.471, Val loss 2.374\n",
      "Ep 1 (Step 021005): Train loss 2.303, Val loss 2.381\n",
      "Ep 1 (Step 021010): Train loss 2.458, Val loss 2.392\n",
      "Ep 1 (Step 021015): Train loss 2.642, Val loss 2.389\n",
      "Ep 1 (Step 021020): Train loss 2.558, Val loss 2.392\n",
      "Ep 1 (Step 021025): Train loss 2.677, Val loss 2.394\n",
      "Ep 1 (Step 021030): Train loss 2.544, Val loss 2.392\n",
      "Ep 1 (Step 021035): Train loss 2.359, Val loss 2.401\n",
      "Ep 1 (Step 021040): Train loss 2.320, Val loss 2.405\n",
      "Ep 1 (Step 021045): Train loss 2.546, Val loss 2.407\n",
      "Ep 1 (Step 021050): Train loss 2.205, Val loss 2.394\n",
      "Ep 1 (Step 021055): Train loss 2.326, Val loss 2.412\n",
      "Ep 1 (Step 021060): Train loss 2.599, Val loss 2.406\n",
      "Ep 1 (Step 021065): Train loss 2.211, Val loss 2.403\n",
      "Ep 1 (Step 021070): Train loss 2.348, Val loss 2.395\n",
      "Ep 1 (Step 021075): Train loss 2.107, Val loss 2.391\n",
      "Ep 1 (Step 021080): Train loss 2.289, Val loss 2.395\n",
      "Ep 1 (Step 021085): Train loss 2.455, Val loss 2.404\n",
      "Ep 1 (Step 021090): Train loss 2.282, Val loss 2.399\n",
      "Ep 1 (Step 021095): Train loss 2.292, Val loss 2.393\n",
      "Ep 1 (Step 021100): Train loss 2.236, Val loss 2.392\n",
      "Ep 1 (Step 021105): Train loss 2.544, Val loss 2.377\n",
      "Ep 1 (Step 021110): Train loss 2.219, Val loss 2.385\n",
      "Ep 1 (Step 021115): Train loss 2.229, Val loss 2.392\n",
      "Ep 1 (Step 021120): Train loss 2.246, Val loss 2.391\n",
      "Ep 1 (Step 021125): Train loss 2.752, Val loss 2.392\n",
      "Ep 1 (Step 021130): Train loss 2.370, Val loss 2.379\n",
      "Ep 1 (Step 021135): Train loss 2.301, Val loss 2.386\n",
      "Ep 1 (Step 021140): Train loss 2.259, Val loss 2.381\n",
      "Ep 1 (Step 021145): Train loss 2.142, Val loss 2.373\n",
      "Ep 1 (Step 021150): Train loss 2.347, Val loss 2.369\n",
      "Ep 1 (Step 021155): Train loss 2.228, Val loss 2.380\n",
      "Ep 1 (Step 021160): Train loss 2.495, Val loss 2.421\n",
      "Ep 1 (Step 021165): Train loss 2.560, Val loss 2.426\n",
      "Ep 1 (Step 021170): Train loss 2.194, Val loss 2.401\n",
      "Ep 1 (Step 021175): Train loss 2.229, Val loss 2.395\n",
      "Ep 1 (Step 021180): Train loss 2.383, Val loss 2.399\n",
      "Ep 1 (Step 021185): Train loss 2.501, Val loss 2.387\n",
      "Ep 1 (Step 021190): Train loss 2.382, Val loss 2.371\n",
      "Ep 1 (Step 021195): Train loss 2.360, Val loss 2.379\n",
      "Ep 1 (Step 021200): Train loss 2.452, Val loss 2.374\n",
      "Ep 1 (Step 021205): Train loss 2.314, Val loss 2.381\n",
      "Ep 1 (Step 021210): Train loss 2.432, Val loss 2.385\n",
      "Ep 1 (Step 021215): Train loss 2.259, Val loss 2.386\n",
      "Ep 1 (Step 021220): Train loss 2.210, Val loss 2.385\n",
      "Ep 1 (Step 021225): Train loss 2.359, Val loss 2.400\n",
      "Ep 1 (Step 021230): Train loss 2.257, Val loss 2.406\n",
      "Ep 1 (Step 021235): Train loss 2.392, Val loss 2.415\n",
      "Ep 1 (Step 021240): Train loss 2.601, Val loss 2.404\n",
      "Ep 1 (Step 021245): Train loss 2.506, Val loss 2.395\n",
      "Ep 1 (Step 021250): Train loss 2.216, Val loss 2.393\n",
      "Ep 1 (Step 021255): Train loss 2.422, Val loss 2.405\n",
      "Ep 1 (Step 021260): Train loss 2.297, Val loss 2.404\n",
      "Ep 1 (Step 021265): Train loss 2.409, Val loss 2.398\n",
      "Ep 1 (Step 021270): Train loss 2.351, Val loss 2.390\n",
      "Ep 1 (Step 021275): Train loss 2.365, Val loss 2.379\n",
      "Ep 1 (Step 021280): Train loss 2.410, Val loss 2.370\n",
      "Ep 1 (Step 021285): Train loss 2.251, Val loss 2.373\n",
      "Ep 1 (Step 021290): Train loss 2.342, Val loss 2.385\n",
      "Ep 1 (Step 021295): Train loss 2.577, Val loss 2.408\n",
      "Ep 1 (Step 021300): Train loss 2.460, Val loss 2.420\n",
      "Ep 1 (Step 021305): Train loss 2.382, Val loss 2.392\n",
      "Ep 1 (Step 021310): Train loss 2.667, Val loss 2.399\n",
      "Ep 1 (Step 021315): Train loss 2.470, Val loss 2.404\n",
      "Ep 1 (Step 021320): Train loss 2.249, Val loss 2.399\n",
      "Ep 1 (Step 021325): Train loss 2.200, Val loss 2.393\n",
      "Ep 1 (Step 021330): Train loss 2.436, Val loss 2.383\n",
      "Ep 1 (Step 021335): Train loss 2.441, Val loss 2.365\n",
      "Ep 1 (Step 021340): Train loss 2.284, Val loss 2.370\n",
      "Ep 1 (Step 021345): Train loss 2.321, Val loss 2.378\n",
      "Ep 1 (Step 021350): Train loss 2.493, Val loss 2.390\n",
      "Ep 1 (Step 021355): Train loss 2.196, Val loss 2.399\n",
      "Ep 1 (Step 021360): Train loss 2.383, Val loss 2.408\n",
      "Ep 1 (Step 021365): Train loss 2.230, Val loss 2.403\n",
      "Ep 1 (Step 021370): Train loss 2.080, Val loss 2.401\n",
      "Ep 1 (Step 021375): Train loss 2.606, Val loss 2.407\n",
      "Ep 1 (Step 021380): Train loss 2.426, Val loss 2.417\n",
      "Ep 1 (Step 021385): Train loss 2.637, Val loss 2.422\n",
      "Ep 1 (Step 021390): Train loss 2.179, Val loss 2.413\n",
      "Ep 1 (Step 021395): Train loss 2.579, Val loss 2.418\n",
      "Ep 1 (Step 021400): Train loss 2.395, Val loss 2.420\n",
      "Ep 1 (Step 021405): Train loss 2.255, Val loss 2.423\n",
      "Ep 1 (Step 021410): Train loss 2.126, Val loss 2.422\n",
      "Ep 1 (Step 021415): Train loss 2.235, Val loss 2.409\n",
      "Ep 1 (Step 021420): Train loss 2.540, Val loss 2.403\n",
      "Ep 1 (Step 021425): Train loss 2.413, Val loss 2.403\n",
      "Ep 1 (Step 021430): Train loss 2.150, Val loss 2.394\n",
      "Ep 1 (Step 021435): Train loss 2.574, Val loss 2.407\n",
      "Ep 1 (Step 021440): Train loss 2.550, Val loss 2.404\n",
      "Ep 1 (Step 021445): Train loss 2.487, Val loss 2.419\n",
      "Ep 1 (Step 021450): Train loss 2.534, Val loss 2.411\n",
      "Ep 1 (Step 021455): Train loss 2.458, Val loss 2.402\n",
      "Ep 1 (Step 021460): Train loss 2.507, Val loss 2.398\n",
      "Ep 1 (Step 021465): Train loss 2.440, Val loss 2.391\n",
      "Ep 1 (Step 021470): Train loss 2.170, Val loss 2.390\n",
      "Ep 1 (Step 021475): Train loss 2.622, Val loss 2.385\n",
      "Ep 1 (Step 021480): Train loss 2.430, Val loss 2.387\n",
      "Ep 1 (Step 021485): Train loss 2.409, Val loss 2.391\n",
      "Ep 1 (Step 021490): Train loss 2.363, Val loss 2.394\n",
      "Ep 1 (Step 021495): Train loss 2.142, Val loss 2.391\n",
      "Ep 1 (Step 021500): Train loss 2.376, Val loss 2.376\n",
      "Ep 1 (Step 021505): Train loss 2.422, Val loss 2.368\n",
      "Ep 1 (Step 021510): Train loss 2.269, Val loss 2.364\n",
      "Ep 1 (Step 021515): Train loss 2.280, Val loss 2.366\n",
      "Ep 1 (Step 021520): Train loss 2.356, Val loss 2.368\n",
      "Ep 1 (Step 021525): Train loss 2.600, Val loss 2.368\n",
      "Ep 1 (Step 021530): Train loss 2.068, Val loss 2.376\n",
      "Ep 1 (Step 021535): Train loss 2.217, Val loss 2.398\n",
      "Ep 1 (Step 021540): Train loss 2.255, Val loss 2.387\n",
      "Ep 1 (Step 021545): Train loss 2.306, Val loss 2.390\n",
      "Ep 1 (Step 021550): Train loss 2.274, Val loss 2.368\n",
      "Ep 1 (Step 021555): Train loss 2.547, Val loss 2.368\n",
      "Ep 1 (Step 021560): Train loss 2.280, Val loss 2.370\n",
      "Ep 1 (Step 021565): Train loss 2.263, Val loss 2.366\n",
      "Ep 1 (Step 021570): Train loss 2.132, Val loss 2.375\n",
      "Ep 1 (Step 021575): Train loss 2.493, Val loss 2.375\n",
      "Ep 1 (Step 021580): Train loss 2.099, Val loss 2.388\n",
      "Ep 1 (Step 021585): Train loss 2.518, Val loss 2.397\n",
      "Ep 1 (Step 021590): Train loss 2.551, Val loss 2.386\n",
      "Ep 1 (Step 021595): Train loss 2.338, Val loss 2.390\n",
      "Ep 1 (Step 021600): Train loss 2.419, Val loss 2.398\n",
      "Ep 1 (Step 021605): Train loss 2.405, Val loss 2.403\n",
      "Ep 1 (Step 021610): Train loss 2.682, Val loss 2.397\n",
      "Ep 1 (Step 021615): Train loss 2.376, Val loss 2.399\n",
      "Ep 1 (Step 021620): Train loss 2.380, Val loss 2.396\n",
      "Ep 1 (Step 021625): Train loss 2.228, Val loss 2.396\n",
      "Ep 1 (Step 021630): Train loss 2.368, Val loss 2.415\n",
      "Ep 1 (Step 021635): Train loss 2.431, Val loss 2.402\n",
      "Ep 1 (Step 021640): Train loss 2.224, Val loss 2.388\n",
      "Ep 1 (Step 021645): Train loss 2.201, Val loss 2.389\n",
      "Ep 1 (Step 021650): Train loss 2.604, Val loss 2.395\n",
      "Ep 1 (Step 021655): Train loss 2.248, Val loss 2.404\n",
      "Ep 1 (Step 021660): Train loss 2.259, Val loss 2.407\n",
      "Ep 1 (Step 021665): Train loss 2.610, Val loss 2.383\n",
      "Ep 1 (Step 021670): Train loss 2.451, Val loss 2.376\n",
      "Ep 1 (Step 021675): Train loss 2.216, Val loss 2.372\n",
      "Ep 1 (Step 021680): Train loss 2.393, Val loss 2.365\n",
      "Ep 1 (Step 021685): Train loss 2.054, Val loss 2.369\n",
      "Ep 1 (Step 021690): Train loss 2.273, Val loss 2.376\n",
      "Ep 1 (Step 021695): Train loss 2.267, Val loss 2.373\n",
      "Ep 1 (Step 021700): Train loss 2.506, Val loss 2.381\n",
      "Ep 1 (Step 021705): Train loss 2.237, Val loss 2.378\n",
      "Ep 1 (Step 021710): Train loss 2.294, Val loss 2.391\n",
      "Ep 1 (Step 021715): Train loss 2.007, Val loss 2.381\n",
      "Ep 1 (Step 021720): Train loss 2.086, Val loss 2.393\n",
      "Ep 1 (Step 021725): Train loss 2.275, Val loss 2.388\n",
      "Ep 1 (Step 021730): Train loss 2.301, Val loss 2.378\n",
      "Ep 1 (Step 021735): Train loss 2.402, Val loss 2.372\n",
      "Ep 1 (Step 021740): Train loss 2.228, Val loss 2.380\n",
      "Ep 1 (Step 021745): Train loss 2.366, Val loss 2.392\n",
      "Ep 1 (Step 021750): Train loss 2.369, Val loss 2.397\n",
      "Ep 1 (Step 021755): Train loss 2.469, Val loss 2.396\n",
      "Ep 1 (Step 021760): Train loss 2.536, Val loss 2.403\n",
      "Ep 1 (Step 021765): Train loss 2.885, Val loss 2.390\n",
      "Ep 1 (Step 021770): Train loss 2.444, Val loss 2.370\n",
      "Ep 1 (Step 021775): Train loss 2.286, Val loss 2.389\n",
      "Ep 1 (Step 021780): Train loss 2.487, Val loss 2.399\n",
      "Ep 1 (Step 021785): Train loss 2.362, Val loss 2.400\n",
      "Ep 1 (Step 021790): Train loss 2.386, Val loss 2.381\n",
      "Ep 1 (Step 021795): Train loss 2.241, Val loss 2.368\n",
      "Ep 1 (Step 021800): Train loss 2.806, Val loss 2.373\n",
      "Ep 1 (Step 021805): Train loss 2.230, Val loss 2.380\n",
      "Ep 1 (Step 021810): Train loss 2.309, Val loss 2.380\n",
      "Ep 1 (Step 021815): Train loss 2.631, Val loss 2.377\n",
      "Ep 1 (Step 021820): Train loss 2.296, Val loss 2.368\n",
      "Ep 1 (Step 021825): Train loss 2.692, Val loss 2.375\n",
      "Ep 1 (Step 021830): Train loss 2.245, Val loss 2.372\n",
      "Ep 1 (Step 021835): Train loss 2.334, Val loss 2.368\n",
      "Ep 1 (Step 021840): Train loss 2.718, Val loss 2.375\n",
      "Ep 1 (Step 021845): Train loss 2.205, Val loss 2.376\n",
      "Ep 1 (Step 021850): Train loss 2.379, Val loss 2.367\n",
      "Ep 1 (Step 021855): Train loss 2.439, Val loss 2.378\n",
      "Ep 1 (Step 021860): Train loss 2.520, Val loss 2.379\n",
      "Ep 1 (Step 021865): Train loss 2.356, Val loss 2.387\n",
      "Ep 1 (Step 021870): Train loss 2.581, Val loss 2.383\n",
      "Ep 1 (Step 021875): Train loss 2.218, Val loss 2.372\n",
      "Ep 1 (Step 021880): Train loss 2.368, Val loss 2.371\n",
      "Ep 1 (Step 021885): Train loss 2.134, Val loss 2.377\n",
      "Ep 1 (Step 021890): Train loss 2.236, Val loss 2.381\n",
      "Ep 1 (Step 021895): Train loss 2.270, Val loss 2.374\n",
      "Ep 1 (Step 021900): Train loss 2.392, Val loss 2.364\n",
      "Ep 1 (Step 021905): Train loss 2.265, Val loss 2.366\n",
      "Ep 1 (Step 021910): Train loss 2.451, Val loss 2.370\n",
      "Ep 1 (Step 021915): Train loss 2.480, Val loss 2.366\n",
      "Ep 1 (Step 021920): Train loss 2.550, Val loss 2.366\n",
      "Ep 1 (Step 021925): Train loss 2.656, Val loss 2.360\n",
      "Ep 1 (Step 021930): Train loss 2.339, Val loss 2.364\n",
      "Ep 1 (Step 021935): Train loss 2.307, Val loss 2.371\n",
      "Ep 1 (Step 021940): Train loss 2.454, Val loss 2.379\n",
      "Ep 1 (Step 021945): Train loss 2.679, Val loss 2.377\n",
      "Ep 1 (Step 021950): Train loss 2.240, Val loss 2.367\n",
      "Ep 1 (Step 021955): Train loss 2.515, Val loss 2.362\n",
      "Ep 1 (Step 021960): Train loss 2.338, Val loss 2.352\n",
      "Ep 1 (Step 021965): Train loss 2.510, Val loss 2.351\n",
      "Ep 1 (Step 021970): Train loss 2.498, Val loss 2.355\n",
      "Ep 1 (Step 021975): Train loss 2.137, Val loss 2.366\n",
      "Ep 1 (Step 021980): Train loss 2.524, Val loss 2.374\n",
      "Ep 1 (Step 021985): Train loss 2.210, Val loss 2.375\n",
      "Ep 1 (Step 021990): Train loss 2.484, Val loss 2.372\n",
      "Ep 1 (Step 021995): Train loss 2.275, Val loss 2.384\n",
      "Ep 1 (Step 022000): Train loss 2.218, Val loss 2.386\n",
      "Ep 1 (Step 022005): Train loss 2.263, Val loss 2.388\n",
      "Ep 1 (Step 022010): Train loss 2.096, Val loss 2.393\n",
      "Ep 1 (Step 022015): Train loss 2.509, Val loss 2.394\n",
      "Ep 1 (Step 022020): Train loss 2.540, Val loss 2.395\n",
      "Ep 1 (Step 022025): Train loss 2.031, Val loss 2.402\n",
      "Ep 1 (Step 022030): Train loss 2.211, Val loss 2.386\n",
      "Ep 1 (Step 022035): Train loss 2.509, Val loss 2.381\n",
      "Ep 1 (Step 022040): Train loss 2.263, Val loss 2.387\n",
      "Ep 1 (Step 022045): Train loss 2.510, Val loss 2.390\n",
      "Ep 1 (Step 022050): Train loss 2.331, Val loss 2.388\n",
      "Ep 1 (Step 022055): Train loss 2.228, Val loss 2.385\n",
      "Ep 1 (Step 022060): Train loss 2.268, Val loss 2.372\n",
      "Ep 1 (Step 022065): Train loss 2.324, Val loss 2.371\n",
      "Ep 1 (Step 022070): Train loss 2.214, Val loss 2.361\n",
      "Ep 1 (Step 022075): Train loss 2.464, Val loss 2.350\n",
      "Ep 1 (Step 022080): Train loss 2.379, Val loss 2.346\n",
      "Ep 1 (Step 022085): Train loss 2.712, Val loss 2.337\n",
      "Ep 1 (Step 022090): Train loss 2.232, Val loss 2.344\n",
      "Ep 1 (Step 022095): Train loss 2.530, Val loss 2.352\n",
      "Ep 1 (Step 022100): Train loss 2.263, Val loss 2.355\n",
      "Ep 1 (Step 022105): Train loss 2.515, Val loss 2.377\n",
      "Ep 1 (Step 022110): Train loss 2.164, Val loss 2.367\n",
      "Ep 1 (Step 022115): Train loss 2.507, Val loss 2.360\n",
      "Ep 1 (Step 022120): Train loss 2.448, Val loss 2.357\n",
      "Ep 1 (Step 022125): Train loss 2.046, Val loss 2.364\n",
      "Ep 1 (Step 022130): Train loss 2.551, Val loss 2.362\n",
      "Ep 1 (Step 022135): Train loss 2.034, Val loss 2.358\n",
      "Ep 1 (Step 022140): Train loss 2.122, Val loss 2.353\n",
      "Ep 1 (Step 022145): Train loss 2.141, Val loss 2.359\n",
      "Ep 1 (Step 022150): Train loss 2.231, Val loss 2.359\n",
      "Ep 1 (Step 022155): Train loss 2.324, Val loss 2.350\n",
      "Ep 1 (Step 022160): Train loss 2.479, Val loss 2.336\n",
      "Ep 1 (Step 022165): Train loss 2.034, Val loss 2.330\n",
      "Ep 1 (Step 022170): Train loss 2.246, Val loss 2.321\n",
      "Ep 1 (Step 022175): Train loss 2.434, Val loss 2.334\n",
      "Ep 1 (Step 022180): Train loss 2.771, Val loss 2.355\n",
      "Ep 1 (Step 022185): Train loss 2.394, Val loss 2.353\n",
      "Ep 1 (Step 022190): Train loss 2.519, Val loss 2.336\n",
      "Ep 1 (Step 022195): Train loss 2.610, Val loss 2.330\n",
      "Ep 1 (Step 022200): Train loss 2.339, Val loss 2.329\n",
      "Ep 1 (Step 022205): Train loss 2.623, Val loss 2.330\n",
      "Ep 1 (Step 022210): Train loss 2.316, Val loss 2.327\n",
      "Ep 1 (Step 022215): Train loss 2.183, Val loss 2.332\n",
      "Ep 1 (Step 022220): Train loss 2.191, Val loss 2.339\n",
      "Ep 1 (Step 022225): Train loss 2.178, Val loss 2.341\n",
      "Ep 1 (Step 022230): Train loss 2.332, Val loss 2.349\n",
      "Ep 1 (Step 022235): Train loss 2.402, Val loss 2.351\n",
      "Ep 1 (Step 022240): Train loss 2.181, Val loss 2.352\n",
      "Ep 1 (Step 022245): Train loss 2.238, Val loss 2.355\n",
      "Ep 1 (Step 022250): Train loss 2.433, Val loss 2.349\n",
      "Ep 1 (Step 022255): Train loss 2.054, Val loss 2.339\n",
      "Ep 1 (Step 022260): Train loss 2.171, Val loss 2.335\n",
      "Ep 1 (Step 022265): Train loss 2.422, Val loss 2.333\n",
      "Ep 1 (Step 022270): Train loss 2.365, Val loss 2.335\n",
      "Ep 1 (Step 022275): Train loss 2.773, Val loss 2.335\n",
      "Ep 1 (Step 022280): Train loss 2.462, Val loss 2.344\n",
      "Ep 1 (Step 022285): Train loss 2.177, Val loss 2.345\n",
      "Ep 1 (Step 022290): Train loss 2.411, Val loss 2.325\n",
      "Ep 1 (Step 022295): Train loss 2.332, Val loss 2.317\n",
      "Ep 1 (Step 022300): Train loss 2.362, Val loss 2.327\n",
      "Ep 1 (Step 022305): Train loss 2.444, Val loss 2.333\n",
      "Ep 1 (Step 022310): Train loss 2.265, Val loss 2.343\n",
      "Ep 1 (Step 022315): Train loss 2.081, Val loss 2.343\n",
      "Ep 1 (Step 022320): Train loss 2.536, Val loss 2.340\n",
      "Ep 1 (Step 022325): Train loss 2.103, Val loss 2.353\n",
      "Ep 1 (Step 022330): Train loss 2.349, Val loss 2.363\n",
      "Ep 1 (Step 022335): Train loss 2.097, Val loss 2.352\n",
      "Ep 1 (Step 022340): Train loss 2.179, Val loss 2.339\n",
      "Ep 1 (Step 022345): Train loss 2.479, Val loss 2.338\n",
      "Ep 1 (Step 022350): Train loss 2.206, Val loss 2.337\n",
      "Ep 1 (Step 022355): Train loss 2.580, Val loss 2.323\n",
      "Ep 1 (Step 022360): Train loss 2.389, Val loss 2.321\n",
      "Ep 1 (Step 022365): Train loss 2.470, Val loss 2.319\n",
      "Ep 1 (Step 022370): Train loss 2.316, Val loss 2.328\n",
      "Ep 1 (Step 022375): Train loss 2.174, Val loss 2.336\n",
      "Ep 1 (Step 022380): Train loss 2.098, Val loss 2.336\n",
      "Ep 1 (Step 022385): Train loss 2.400, Val loss 2.330\n",
      "Ep 1 (Step 022390): Train loss 2.170, Val loss 2.330\n",
      "Ep 1 (Step 022395): Train loss 2.433, Val loss 2.332\n",
      "Ep 1 (Step 022400): Train loss 2.231, Val loss 2.330\n",
      "Ep 1 (Step 022405): Train loss 2.319, Val loss 2.330\n",
      "Ep 1 (Step 022410): Train loss 2.333, Val loss 2.336\n",
      "Ep 1 (Step 022415): Train loss 2.334, Val loss 2.339\n",
      "Ep 1 (Step 022420): Train loss 2.208, Val loss 2.334\n",
      "Ep 1 (Step 022425): Train loss 2.553, Val loss 2.327\n",
      "Ep 1 (Step 022430): Train loss 2.679, Val loss 2.315\n",
      "Ep 1 (Step 022435): Train loss 2.394, Val loss 2.317\n",
      "Ep 1 (Step 022440): Train loss 2.009, Val loss 2.317\n",
      "Ep 1 (Step 022445): Train loss 2.187, Val loss 2.322\n",
      "Ep 1 (Step 022450): Train loss 2.125, Val loss 2.299\n",
      "Ep 1 (Step 022455): Train loss 2.295, Val loss 2.302\n",
      "Ep 1 (Step 022460): Train loss 2.390, Val loss 2.317\n",
      "Ep 1 (Step 022465): Train loss 2.294, Val loss 2.320\n",
      "Ep 1 (Step 022470): Train loss 2.598, Val loss 2.326\n",
      "Ep 1 (Step 022475): Train loss 2.771, Val loss 2.338\n",
      "Ep 1 (Step 022480): Train loss 2.610, Val loss 2.338\n",
      "Ep 1 (Step 022485): Train loss 2.206, Val loss 2.325\n",
      "Ep 1 (Step 022490): Train loss 2.523, Val loss 2.329\n",
      "Ep 1 (Step 022495): Train loss 2.205, Val loss 2.331\n",
      "Ep 1 (Step 022500): Train loss 2.640, Val loss 2.331\n",
      "Ep 1 (Step 022505): Train loss 2.284, Val loss 2.328\n",
      "Ep 1 (Step 022510): Train loss 2.145, Val loss 2.333\n",
      "Ep 1 (Step 022515): Train loss 2.314, Val loss 2.351\n",
      "Ep 1 (Step 022520): Train loss 2.105, Val loss 2.360\n",
      "Ep 1 (Step 022525): Train loss 2.462, Val loss 2.361\n",
      "Ep 1 (Step 022530): Train loss 2.432, Val loss 2.359\n",
      "Ep 1 (Step 022535): Train loss 2.407, Val loss 2.357\n",
      "Ep 1 (Step 022540): Train loss 2.423, Val loss 2.342\n",
      "Ep 1 (Step 022545): Train loss 2.415, Val loss 2.332\n",
      "Ep 1 (Step 022550): Train loss 2.540, Val loss 2.348\n",
      "Ep 1 (Step 022555): Train loss 2.165, Val loss 2.348\n",
      "Ep 1 (Step 022560): Train loss 2.415, Val loss 2.340\n",
      "Ep 1 (Step 022565): Train loss 2.201, Val loss 2.341\n",
      "Ep 1 (Step 022570): Train loss 2.291, Val loss 2.337\n",
      "Ep 1 (Step 022575): Train loss 2.379, Val loss 2.334\n",
      "Ep 1 (Step 022580): Train loss 2.531, Val loss 2.323\n",
      "Ep 1 (Step 022585): Train loss 2.300, Val loss 2.321\n",
      "Ep 1 (Step 022590): Train loss 2.153, Val loss 2.315\n",
      "Ep 1 (Step 022595): Train loss 2.199, Val loss 2.323\n",
      "Ep 1 (Step 022600): Train loss 2.300, Val loss 2.326\n",
      "Ep 1 (Step 022605): Train loss 2.231, Val loss 2.321\n",
      "Ep 1 (Step 022610): Train loss 1.998, Val loss 2.324\n",
      "Ep 1 (Step 022615): Train loss 2.249, Val loss 2.328\n",
      "Ep 1 (Step 022620): Train loss 2.435, Val loss 2.315\n",
      "Ep 1 (Step 022625): Train loss 2.350, Val loss 2.307\n",
      "Ep 1 (Step 022630): Train loss 2.281, Val loss 2.309\n",
      "Ep 1 (Step 022635): Train loss 2.444, Val loss 2.322\n",
      "Ep 1 (Step 022640): Train loss 2.180, Val loss 2.343\n",
      "Ep 1 (Step 022645): Train loss 2.384, Val loss 2.352\n",
      "Ep 1 (Step 022650): Train loss 2.418, Val loss 2.346\n",
      "Ep 1 (Step 022655): Train loss 2.501, Val loss 2.329\n",
      "Ep 1 (Step 022660): Train loss 2.220, Val loss 2.329\n",
      "Ep 1 (Step 022665): Train loss 2.321, Val loss 2.326\n",
      "Ep 1 (Step 022670): Train loss 2.156, Val loss 2.323\n",
      "Ep 1 (Step 022675): Train loss 2.562, Val loss 2.314\n",
      "Ep 1 (Step 022680): Train loss 2.098, Val loss 2.324\n",
      "Ep 1 (Step 022685): Train loss 2.587, Val loss 2.333\n",
      "Ep 1 (Step 022690): Train loss 2.312, Val loss 2.350\n",
      "Ep 1 (Step 022695): Train loss 2.255, Val loss 2.339\n",
      "Ep 1 (Step 022700): Train loss 2.176, Val loss 2.331\n",
      "Ep 1 (Step 022705): Train loss 2.011, Val loss 2.329\n",
      "Ep 1 (Step 022710): Train loss 2.304, Val loss 2.335\n",
      "Ep 1 (Step 022715): Train loss 2.351, Val loss 2.339\n",
      "Ep 1 (Step 022720): Train loss 2.342, Val loss 2.335\n",
      "Ep 1 (Step 022725): Train loss 2.158, Val loss 2.342\n",
      "Ep 1 (Step 022730): Train loss 2.251, Val loss 2.337\n",
      "Ep 1 (Step 022735): Train loss 2.088, Val loss 2.324\n",
      "Ep 1 (Step 022740): Train loss 2.306, Val loss 2.308\n",
      "Ep 1 (Step 022745): Train loss 2.541, Val loss 2.307\n",
      "Ep 1 (Step 022750): Train loss 2.364, Val loss 2.312\n",
      "Ep 1 (Step 022755): Train loss 2.498, Val loss 2.314\n",
      "Ep 1 (Step 022760): Train loss 2.069, Val loss 2.319\n",
      "Ep 1 (Step 022765): Train loss 2.488, Val loss 2.318\n",
      "Ep 1 (Step 022770): Train loss 2.266, Val loss 2.314\n",
      "Ep 1 (Step 022775): Train loss 2.630, Val loss 2.311\n",
      "Ep 1 (Step 022780): Train loss 2.431, Val loss 2.320\n",
      "Ep 1 (Step 022785): Train loss 2.257, Val loss 2.320\n",
      "Ep 1 (Step 022790): Train loss 2.206, Val loss 2.315\n",
      "Ep 1 (Step 022795): Train loss 2.137, Val loss 2.327\n",
      "Ep 1 (Step 022800): Train loss 2.213, Val loss 2.331\n",
      "Ep 1 (Step 022805): Train loss 2.246, Val loss 2.329\n",
      "Ep 1 (Step 022810): Train loss 2.147, Val loss 2.331\n",
      "Ep 1 (Step 022815): Train loss 2.658, Val loss 2.323\n",
      "Ep 1 (Step 022820): Train loss 2.025, Val loss 2.314\n",
      "Ep 1 (Step 022825): Train loss 2.315, Val loss 2.294\n",
      "Ep 1 (Step 022830): Train loss 2.035, Val loss 2.284\n",
      "Ep 1 (Step 022835): Train loss 2.454, Val loss 2.292\n",
      "Ep 1 (Step 022840): Train loss 2.001, Val loss 2.303\n",
      "Ep 1 (Step 022845): Train loss 2.197, Val loss 2.304\n",
      "Ep 1 (Step 022850): Train loss 2.314, Val loss 2.294\n",
      "Ep 1 (Step 022855): Train loss 2.238, Val loss 2.288\n",
      "Ep 1 (Step 022860): Train loss 2.233, Val loss 2.277\n",
      "Ep 1 (Step 022865): Train loss 1.965, Val loss 2.275\n",
      "Ep 1 (Step 022870): Train loss 2.245, Val loss 2.284\n",
      "Ep 1 (Step 022875): Train loss 2.384, Val loss 2.295\n",
      "Ep 1 (Step 022880): Train loss 2.403, Val loss 2.300\n",
      "Ep 1 (Step 022885): Train loss 2.574, Val loss 2.312\n",
      "Ep 1 (Step 022890): Train loss 2.459, Val loss 2.322\n",
      "Ep 1 (Step 022895): Train loss 2.345, Val loss 2.320\n",
      "Ep 1 (Step 022900): Train loss 2.260, Val loss 2.318\n",
      "Ep 1 (Step 022905): Train loss 2.550, Val loss 2.305\n",
      "Ep 1 (Step 022910): Train loss 2.074, Val loss 2.307\n",
      "Ep 1 (Step 022915): Train loss 2.192, Val loss 2.314\n",
      "Ep 1 (Step 022920): Train loss 2.372, Val loss 2.320\n",
      "Ep 1 (Step 022925): Train loss 2.366, Val loss 2.317\n",
      "Ep 1 (Step 022930): Train loss 2.451, Val loss 2.314\n",
      "Ep 1 (Step 022935): Train loss 2.382, Val loss 2.307\n",
      "Ep 1 (Step 022940): Train loss 2.041, Val loss 2.294\n",
      "Ep 1 (Step 022945): Train loss 2.125, Val loss 2.299\n",
      "Ep 1 (Step 022950): Train loss 2.014, Val loss 2.303\n",
      "Ep 1 (Step 022955): Train loss 2.088, Val loss 2.320\n",
      "Ep 1 (Step 022960): Train loss 2.806, Val loss 2.319\n",
      "Ep 1 (Step 022965): Train loss 2.324, Val loss 2.324\n",
      "Ep 1 (Step 022970): Train loss 2.273, Val loss 2.337\n",
      "Ep 1 (Step 022975): Train loss 2.090, Val loss 2.322\n",
      "Ep 1 (Step 022980): Train loss 2.275, Val loss 2.303\n",
      "Ep 1 (Step 022985): Train loss 2.261, Val loss 2.336\n",
      "Ep 1 (Step 022990): Train loss 2.161, Val loss 2.337\n",
      "Ep 1 (Step 022995): Train loss 2.169, Val loss 2.339\n",
      "Ep 1 (Step 023000): Train loss 2.347, Val loss 2.343\n",
      "Ep 1 (Step 023005): Train loss 2.233, Val loss 2.334\n",
      "Ep 1 (Step 023010): Train loss 2.508, Val loss 2.327\n",
      "Ep 1 (Step 023015): Train loss 2.129, Val loss 2.313\n",
      "Ep 1 (Step 023020): Train loss 2.733, Val loss 2.299\n",
      "Ep 1 (Step 023025): Train loss 2.173, Val loss 2.306\n",
      "Ep 1 (Step 023030): Train loss 2.329, Val loss 2.306\n",
      "Ep 1 (Step 023035): Train loss 2.186, Val loss 2.301\n",
      "Ep 1 (Step 023040): Train loss 2.563, Val loss 2.305\n",
      "Ep 1 (Step 023045): Train loss 2.195, Val loss 2.295\n",
      "Ep 1 (Step 023050): Train loss 2.406, Val loss 2.293\n",
      "Ep 1 (Step 023055): Train loss 2.143, Val loss 2.300\n",
      "Ep 1 (Step 023060): Train loss 2.089, Val loss 2.294\n",
      "Ep 1 (Step 023065): Train loss 2.217, Val loss 2.314\n",
      "Ep 1 (Step 023070): Train loss 2.120, Val loss 2.318\n",
      "Ep 1 (Step 023075): Train loss 2.281, Val loss 2.325\n",
      "Ep 1 (Step 023080): Train loss 2.600, Val loss 2.323\n",
      "Ep 1 (Step 023085): Train loss 2.539, Val loss 2.329\n",
      "Ep 1 (Step 023090): Train loss 2.367, Val loss 2.334\n",
      "Ep 1 (Step 023095): Train loss 2.457, Val loss 2.325\n",
      "Ep 1 (Step 023100): Train loss 2.099, Val loss 2.322\n",
      "Ep 1 (Step 023105): Train loss 2.313, Val loss 2.319\n",
      "Ep 1 (Step 023110): Train loss 2.280, Val loss 2.320\n",
      "Ep 1 (Step 023115): Train loss 2.184, Val loss 2.327\n",
      "Ep 1 (Step 023120): Train loss 2.417, Val loss 2.323\n",
      "Ep 1 (Step 023125): Train loss 2.389, Val loss 2.309\n",
      "Ep 1 (Step 023130): Train loss 2.536, Val loss 2.329\n",
      "Ep 1 (Step 023135): Train loss 2.150, Val loss 2.331\n",
      "Ep 1 (Step 023140): Train loss 2.560, Val loss 2.339\n",
      "Ep 1 (Step 023145): Train loss 2.251, Val loss 2.344\n",
      "Ep 1 (Step 023150): Train loss 2.520, Val loss 2.333\n",
      "Ep 1 (Step 023155): Train loss 2.258, Val loss 2.324\n",
      "Ep 1 (Step 023160): Train loss 2.508, Val loss 2.325\n",
      "Ep 1 (Step 023165): Train loss 2.179, Val loss 2.321\n",
      "Ep 1 (Step 023170): Train loss 2.233, Val loss 2.310\n",
      "Ep 1 (Step 023175): Train loss 2.381, Val loss 2.301\n",
      "Ep 1 (Step 023180): Train loss 2.110, Val loss 2.302\n",
      "Ep 1 (Step 023185): Train loss 2.175, Val loss 2.306\n",
      "Ep 1 (Step 023190): Train loss 2.378, Val loss 2.309\n",
      "Ep 1 (Step 023195): Train loss 2.333, Val loss 2.315\n",
      "Ep 1 (Step 023200): Train loss 2.001, Val loss 2.324\n",
      "Ep 1 (Step 023205): Train loss 2.300, Val loss 2.325\n",
      "Ep 1 (Step 023210): Train loss 2.085, Val loss 2.320\n",
      "Ep 1 (Step 023215): Train loss 2.195, Val loss 2.326\n",
      "Ep 1 (Step 023220): Train loss 2.548, Val loss 2.313\n",
      "Ep 1 (Step 023225): Train loss 2.166, Val loss 2.314\n",
      "Ep 1 (Step 023230): Train loss 2.249, Val loss 2.312\n",
      "Ep 1 (Step 023235): Train loss 2.490, Val loss 2.310\n",
      "Ep 1 (Step 023240): Train loss 2.448, Val loss 2.318\n",
      "Ep 1 (Step 023245): Train loss 2.395, Val loss 2.316\n",
      "Ep 1 (Step 023250): Train loss 2.525, Val loss 2.300\n",
      "Ep 1 (Step 023255): Train loss 2.304, Val loss 2.297\n",
      "Ep 1 (Step 023260): Train loss 2.139, Val loss 2.307\n",
      "Ep 1 (Step 023265): Train loss 2.322, Val loss 2.301\n",
      "Ep 1 (Step 023270): Train loss 2.359, Val loss 2.301\n",
      "Ep 1 (Step 023275): Train loss 2.258, Val loss 2.306\n",
      "Ep 1 (Step 023280): Train loss 2.119, Val loss 2.304\n",
      "Ep 1 (Step 023285): Train loss 2.390, Val loss 2.314\n",
      "Ep 1 (Step 023290): Train loss 2.260, Val loss 2.312\n",
      "Ep 1 (Step 023295): Train loss 2.167, Val loss 2.310\n",
      "Ep 1 (Step 023300): Train loss 2.137, Val loss 2.301\n",
      "Ep 1 (Step 023305): Train loss 2.348, Val loss 2.308\n",
      "Ep 1 (Step 023310): Train loss 2.119, Val loss 2.309\n",
      "Ep 1 (Step 023315): Train loss 2.482, Val loss 2.307\n",
      "Ep 1 (Step 023320): Train loss 2.203, Val loss 2.301\n",
      "Ep 1 (Step 023325): Train loss 2.222, Val loss 2.293\n",
      "Ep 1 (Step 023330): Train loss 2.167, Val loss 2.286\n",
      "Ep 1 (Step 023335): Train loss 2.583, Val loss 2.287\n",
      "Ep 1 (Step 023340): Train loss 2.209, Val loss 2.271\n",
      "Ep 1 (Step 023345): Train loss 2.220, Val loss 2.261\n",
      "Ep 1 (Step 023350): Train loss 2.593, Val loss 2.255\n",
      "Ep 1 (Step 023355): Train loss 2.459, Val loss 2.248\n",
      "Ep 1 (Step 023360): Train loss 2.239, Val loss 2.248\n",
      "Ep 1 (Step 023365): Train loss 2.188, Val loss 2.264\n",
      "Ep 1 (Step 023370): Train loss 2.181, Val loss 2.274\n",
      "Ep 1 (Step 023375): Train loss 2.272, Val loss 2.281\n",
      "Ep 1 (Step 023380): Train loss 2.189, Val loss 2.275\n",
      "Ep 1 (Step 023385): Train loss 2.514, Val loss 2.282\n",
      "Ep 1 (Step 023390): Train loss 2.379, Val loss 2.271\n",
      "Ep 1 (Step 023395): Train loss 2.286, Val loss 2.269\n",
      "Ep 1 (Step 023400): Train loss 2.194, Val loss 2.264\n",
      "Ep 1 (Step 023405): Train loss 2.253, Val loss 2.264\n",
      "Ep 1 (Step 023410): Train loss 2.276, Val loss 2.270\n",
      "Ep 1 (Step 023415): Train loss 2.364, Val loss 2.270\n",
      "Ep 1 (Step 023420): Train loss 2.111, Val loss 2.276\n",
      "Ep 1 (Step 023425): Train loss 2.429, Val loss 2.281\n",
      "Ep 1 (Step 023430): Train loss 2.320, Val loss 2.292\n",
      "Ep 1 (Step 023435): Train loss 1.959, Val loss 2.288\n",
      "Ep 1 (Step 023440): Train loss 2.156, Val loss 2.276\n",
      "Ep 1 (Step 023445): Train loss 2.347, Val loss 2.270\n",
      "Ep 1 (Step 023450): Train loss 2.193, Val loss 2.261\n",
      "Ep 1 (Step 023455): Train loss 2.596, Val loss 2.265\n",
      "Ep 1 (Step 023460): Train loss 2.603, Val loss 2.275\n",
      "Ep 1 (Step 023465): Train loss 1.924, Val loss 2.274\n",
      "Ep 1 (Step 023470): Train loss 2.440, Val loss 2.272\n",
      "Ep 1 (Step 023475): Train loss 2.369, Val loss 2.271\n",
      "Ep 1 (Step 023480): Train loss 2.341, Val loss 2.280\n",
      "Ep 1 (Step 023485): Train loss 2.366, Val loss 2.270\n",
      "Ep 1 (Step 023490): Train loss 2.167, Val loss 2.267\n",
      "Ep 1 (Step 023495): Train loss 2.346, Val loss 2.269\n",
      "Ep 1 (Step 023500): Train loss 2.134, Val loss 2.259\n",
      "Ep 1 (Step 023505): Train loss 2.261, Val loss 2.258\n",
      "Ep 1 (Step 023510): Train loss 1.965, Val loss 2.260\n",
      "Ep 1 (Step 023515): Train loss 2.319, Val loss 2.251\n",
      "Ep 1 (Step 023520): Train loss 2.142, Val loss 2.253\n",
      "Ep 1 (Step 023525): Train loss 2.134, Val loss 2.252\n",
      "Ep 1 (Step 023530): Train loss 2.170, Val loss 2.248\n",
      "Ep 1 (Step 023535): Train loss 2.362, Val loss 2.245\n",
      "Ep 1 (Step 023540): Train loss 2.241, Val loss 2.243\n",
      "Ep 1 (Step 023545): Train loss 2.493, Val loss 2.260\n",
      "Ep 1 (Step 023550): Train loss 2.351, Val loss 2.259\n",
      "Ep 1 (Step 023555): Train loss 2.502, Val loss 2.262\n",
      "Ep 1 (Step 023560): Train loss 2.349, Val loss 2.264\n",
      "Ep 1 (Step 023565): Train loss 2.202, Val loss 2.263\n",
      "Ep 1 (Step 023570): Train loss 2.216, Val loss 2.265\n",
      "Ep 1 (Step 023575): Train loss 2.329, Val loss 2.270\n",
      "Ep 1 (Step 023580): Train loss 2.360, Val loss 2.267\n",
      "Ep 1 (Step 023585): Train loss 2.233, Val loss 2.260\n",
      "Ep 1 (Step 023590): Train loss 2.315, Val loss 2.265\n",
      "Ep 1 (Step 023595): Train loss 2.156, Val loss 2.262\n",
      "Ep 1 (Step 023600): Train loss 2.175, Val loss 2.265\n",
      "Ep 1 (Step 023605): Train loss 2.311, Val loss 2.275\n",
      "Ep 1 (Step 023610): Train loss 2.408, Val loss 2.283\n",
      "Ep 1 (Step 023615): Train loss 2.065, Val loss 2.274\n",
      "Ep 1 (Step 023620): Train loss 2.232, Val loss 2.263\n",
      "Ep 1 (Step 023625): Train loss 2.275, Val loss 2.267\n",
      "Ep 1 (Step 023630): Train loss 2.178, Val loss 2.265\n",
      "Ep 1 (Step 023635): Train loss 2.552, Val loss 2.267\n",
      "Ep 1 (Step 023640): Train loss 2.017, Val loss 2.270\n",
      "Ep 1 (Step 023645): Train loss 2.191, Val loss 2.271\n",
      "Ep 1 (Step 023650): Train loss 2.476, Val loss 2.252\n",
      "Ep 1 (Step 023655): Train loss 2.330, Val loss 2.241\n",
      "Ep 1 (Step 023660): Train loss 1.974, Val loss 2.252\n",
      "Ep 1 (Step 023665): Train loss 2.490, Val loss 2.252\n",
      "Ep 1 (Step 023670): Train loss 2.165, Val loss 2.257\n",
      "Ep 1 (Step 023675): Train loss 2.123, Val loss 2.256\n",
      "Ep 1 (Step 023680): Train loss 2.307, Val loss 2.249\n",
      "Ep 1 (Step 023685): Train loss 2.296, Val loss 2.249\n",
      "Ep 1 (Step 023690): Train loss 2.570, Val loss 2.243\n",
      "Ep 1 (Step 023695): Train loss 2.365, Val loss 2.234\n",
      "Ep 1 (Step 023700): Train loss 2.409, Val loss 2.248\n",
      "Ep 1 (Step 023705): Train loss 2.167, Val loss 2.238\n",
      "Ep 1 (Step 023710): Train loss 2.518, Val loss 2.243\n",
      "Ep 1 (Step 023715): Train loss 2.303, Val loss 2.219\n",
      "Ep 1 (Step 023720): Train loss 2.149, Val loss 2.217\n",
      "Ep 1 (Step 023725): Train loss 2.338, Val loss 2.212\n",
      "Ep 1 (Step 023730): Train loss 2.097, Val loss 2.228\n",
      "Ep 1 (Step 023735): Train loss 2.430, Val loss 2.232\n",
      "Ep 1 (Step 023740): Train loss 2.266, Val loss 2.234\n",
      "Ep 1 (Step 023745): Train loss 2.650, Val loss 2.241\n",
      "Ep 1 (Step 023750): Train loss 2.397, Val loss 2.239\n",
      "Ep 1 (Step 023755): Train loss 2.149, Val loss 2.235\n",
      "Ep 1 (Step 023760): Train loss 2.164, Val loss 2.233\n",
      "Ep 1 (Step 023765): Train loss 2.408, Val loss 2.231\n",
      "Ep 1 (Step 023770): Train loss 2.069, Val loss 2.214\n",
      "Ep 1 (Step 023775): Train loss 2.351, Val loss 2.208\n",
      "Ep 1 (Step 023780): Train loss 2.173, Val loss 2.218\n",
      "Ep 1 (Step 023785): Train loss 2.596, Val loss 2.223\n",
      "Ep 1 (Step 023790): Train loss 2.300, Val loss 2.223\n",
      "Ep 1 (Step 023795): Train loss 2.159, Val loss 2.223\n",
      "Ep 1 (Step 023800): Train loss 2.373, Val loss 2.227\n",
      "Ep 1 (Step 023805): Train loss 2.143, Val loss 2.217\n",
      "Ep 1 (Step 023810): Train loss 2.270, Val loss 2.215\n",
      "Ep 1 (Step 023815): Train loss 2.381, Val loss 2.234\n",
      "Ep 1 (Step 023820): Train loss 2.240, Val loss 2.242\n",
      "Ep 1 (Step 023825): Train loss 2.080, Val loss 2.245\n",
      "Ep 1 (Step 023830): Train loss 2.118, Val loss 2.241\n",
      "Ep 1 (Step 023835): Train loss 2.411, Val loss 2.245\n",
      "Ep 1 (Step 023840): Train loss 1.969, Val loss 2.236\n",
      "Ep 1 (Step 023845): Train loss 2.305, Val loss 2.223\n",
      "Ep 1 (Step 023850): Train loss 2.161, Val loss 2.227\n",
      "Ep 1 (Step 023855): Train loss 2.449, Val loss 2.230\n",
      "Ep 1 (Step 023860): Train loss 2.331, Val loss 2.231\n",
      "Ep 1 (Step 023865): Train loss 2.208, Val loss 2.232\n",
      "Ep 1 (Step 023870): Train loss 2.232, Val loss 2.234\n",
      "Ep 1 (Step 023875): Train loss 2.282, Val loss 2.229\n",
      "Ep 1 (Step 023880): Train loss 2.164, Val loss 2.231\n",
      "Ep 1 (Step 023885): Train loss 2.472, Val loss 2.238\n",
      "Ep 1 (Step 023890): Train loss 2.352, Val loss 2.239\n",
      "Ep 1 (Step 023895): Train loss 2.035, Val loss 2.240\n",
      "Ep 1 (Step 023900): Train loss 2.329, Val loss 2.237\n",
      "Ep 1 (Step 023905): Train loss 2.705, Val loss 2.240\n",
      "Ep 1 (Step 023910): Train loss 2.282, Val loss 2.243\n",
      "Ep 1 (Step 023915): Train loss 2.421, Val loss 2.247\n",
      "Ep 1 (Step 023920): Train loss 2.289, Val loss 2.257\n",
      "Ep 1 (Step 023925): Train loss 1.985, Val loss 2.270\n",
      "Ep 1 (Step 023930): Train loss 2.306, Val loss 2.282\n",
      "Ep 1 (Step 023935): Train loss 2.082, Val loss 2.263\n",
      "Ep 1 (Step 023940): Train loss 2.370, Val loss 2.247\n",
      "Ep 1 (Step 023945): Train loss 2.089, Val loss 2.246\n",
      "Ep 1 (Step 023950): Train loss 2.444, Val loss 2.244\n",
      "Ep 1 (Step 023955): Train loss 2.231, Val loss 2.252\n",
      "Ep 1 (Step 023960): Train loss 2.437, Val loss 2.255\n",
      "Ep 1 (Step 023965): Train loss 2.330, Val loss 2.243\n",
      "Ep 1 (Step 023970): Train loss 2.197, Val loss 2.249\n",
      "Ep 1 (Step 023975): Train loss 2.125, Val loss 2.244\n",
      "Ep 1 (Step 023980): Train loss 2.075, Val loss 2.236\n",
      "Ep 1 (Step 023985): Train loss 2.154, Val loss 2.242\n",
      "Ep 1 (Step 023990): Train loss 2.477, Val loss 2.242\n",
      "Ep 1 (Step 023995): Train loss 2.176, Val loss 2.241\n",
      "Ep 1 (Step 024000): Train loss 2.425, Val loss 2.238\n",
      "Ep 1 (Step 024005): Train loss 2.062, Val loss 2.254\n",
      "Ep 1 (Step 024010): Train loss 2.101, Val loss 2.254\n",
      "Ep 1 (Step 024015): Train loss 2.335, Val loss 2.267\n",
      "Ep 1 (Step 024020): Train loss 2.662, Val loss 2.265\n",
      "Ep 1 (Step 024025): Train loss 2.268, Val loss 2.254\n",
      "Ep 1 (Step 024030): Train loss 2.277, Val loss 2.257\n",
      "Ep 1 (Step 024035): Train loss 2.560, Val loss 2.262\n",
      "Ep 1 (Step 024040): Train loss 2.321, Val loss 2.258\n",
      "Ep 1 (Step 024045): Train loss 2.071, Val loss 2.247\n",
      "Ep 1 (Step 024050): Train loss 2.231, Val loss 2.242\n",
      "Ep 1 (Step 024055): Train loss 2.453, Val loss 2.242\n",
      "Ep 1 (Step 024060): Train loss 2.351, Val loss 2.243\n",
      "Ep 1 (Step 024065): Train loss 2.339, Val loss 2.227\n",
      "Ep 1 (Step 024070): Train loss 2.004, Val loss 2.222\n",
      "Ep 1 (Step 024075): Train loss 2.240, Val loss 2.221\n",
      "Ep 1 (Step 024080): Train loss 2.256, Val loss 2.222\n",
      "Ep 1 (Step 024085): Train loss 2.246, Val loss 2.227\n",
      "Ep 1 (Step 024090): Train loss 1.986, Val loss 2.226\n",
      "Ep 1 (Step 024095): Train loss 2.237, Val loss 2.244\n",
      "Ep 1 (Step 024100): Train loss 2.116, Val loss 2.235\n",
      "Ep 1 (Step 024105): Train loss 2.230, Val loss 2.239\n",
      "Ep 1 (Step 024110): Train loss 2.167, Val loss 2.241\n",
      "Ep 1 (Step 024115): Train loss 2.200, Val loss 2.233\n",
      "Ep 1 (Step 024120): Train loss 2.252, Val loss 2.230\n",
      "Ep 1 (Step 024125): Train loss 2.310, Val loss 2.236\n",
      "Ep 1 (Step 024130): Train loss 2.506, Val loss 2.252\n",
      "Ep 1 (Step 024135): Train loss 2.032, Val loss 2.254\n",
      "Ep 1 (Step 024140): Train loss 2.349, Val loss 2.240\n",
      "Ep 1 (Step 024145): Train loss 2.150, Val loss 2.242\n",
      "Ep 1 (Step 024150): Train loss 2.447, Val loss 2.238\n",
      "Ep 1 (Step 024155): Train loss 2.327, Val loss 2.242\n",
      "Ep 1 (Step 024160): Train loss 2.326, Val loss 2.243\n",
      "Ep 1 (Step 024165): Train loss 2.143, Val loss 2.232\n",
      "Ep 1 (Step 024170): Train loss 2.276, Val loss 2.228\n",
      "Ep 1 (Step 024175): Train loss 2.228, Val loss 2.241\n",
      "Ep 1 (Step 024180): Train loss 2.275, Val loss 2.242\n",
      "Ep 1 (Step 024185): Train loss 2.267, Val loss 2.231\n",
      "Ep 1 (Step 024190): Train loss 2.368, Val loss 2.230\n",
      "Ep 1 (Step 024195): Train loss 2.214, Val loss 2.232\n",
      "Ep 1 (Step 024200): Train loss 2.520, Val loss 2.244\n",
      "Ep 1 (Step 024205): Train loss 2.266, Val loss 2.250\n",
      "Ep 1 (Step 024210): Train loss 2.215, Val loss 2.239\n",
      "Ep 1 (Step 024215): Train loss 2.328, Val loss 2.227\n",
      "Ep 1 (Step 024220): Train loss 2.144, Val loss 2.211\n",
      "Ep 1 (Step 024225): Train loss 2.219, Val loss 2.216\n",
      "Ep 1 (Step 024230): Train loss 1.988, Val loss 2.230\n",
      "Ep 1 (Step 024235): Train loss 2.398, Val loss 2.237\n",
      "Ep 1 (Step 024240): Train loss 2.158, Val loss 2.243\n",
      "Ep 1 (Step 024245): Train loss 2.337, Val loss 2.254\n",
      "Ep 1 (Step 024250): Train loss 2.919, Val loss 2.269\n",
      "Ep 1 (Step 024255): Train loss 2.088, Val loss 2.269\n",
      "Ep 1 (Step 024260): Train loss 2.321, Val loss 2.277\n",
      "Ep 1 (Step 024265): Train loss 2.065, Val loss 2.277\n",
      "Ep 1 (Step 024270): Train loss 2.164, Val loss 2.274\n",
      "Ep 1 (Step 024275): Train loss 2.243, Val loss 2.257\n",
      "Ep 1 (Step 024280): Train loss 2.018, Val loss 2.244\n",
      "Ep 1 (Step 024285): Train loss 2.331, Val loss 2.245\n",
      "Ep 1 (Step 024290): Train loss 2.475, Val loss 2.261\n",
      "Ep 1 (Step 024295): Train loss 2.179, Val loss 2.254\n",
      "Ep 1 (Step 024300): Train loss 2.308, Val loss 2.258\n",
      "Ep 1 (Step 024305): Train loss 2.064, Val loss 2.265\n",
      "Ep 1 (Step 024310): Train loss 2.189, Val loss 2.264\n",
      "Ep 1 (Step 024315): Train loss 2.141, Val loss 2.262\n",
      "Ep 1 (Step 024320): Train loss 2.081, Val loss 2.251\n",
      "Ep 1 (Step 024325): Train loss 2.316, Val loss 2.243\n",
      "Ep 1 (Step 024330): Train loss 2.306, Val loss 2.226\n",
      "Ep 1 (Step 024335): Train loss 2.128, Val loss 2.218\n",
      "Ep 1 (Step 024340): Train loss 2.093, Val loss 2.220\n",
      "Ep 1 (Step 024345): Train loss 2.043, Val loss 2.224\n",
      "Ep 1 (Step 024350): Train loss 2.264, Val loss 2.226\n",
      "Ep 1 (Step 024355): Train loss 1.932, Val loss 2.240\n",
      "Ep 1 (Step 024360): Train loss 2.344, Val loss 2.244\n",
      "Ep 1 (Step 024365): Train loss 2.418, Val loss 2.232\n",
      "Ep 1 (Step 024370): Train loss 2.015, Val loss 2.236\n",
      "Ep 1 (Step 024375): Train loss 2.244, Val loss 2.250\n",
      "Ep 1 (Step 024380): Train loss 2.371, Val loss 2.261\n",
      "Ep 1 (Step 024385): Train loss 2.236, Val loss 2.258\n",
      "Ep 1 (Step 024390): Train loss 2.317, Val loss 2.237\n",
      "Ep 1 (Step 024395): Train loss 1.908, Val loss 2.227\n",
      "Ep 1 (Step 024400): Train loss 2.123, Val loss 2.223\n",
      "Ep 1 (Step 024405): Train loss 2.258, Val loss 2.221\n",
      "Ep 1 (Step 024410): Train loss 2.257, Val loss 2.227\n",
      "Ep 1 (Step 024415): Train loss 2.429, Val loss 2.236\n",
      "Ep 1 (Step 024420): Train loss 2.189, Val loss 2.238\n",
      "Ep 1 (Step 024425): Train loss 2.360, Val loss 2.229\n",
      "Ep 1 (Step 024430): Train loss 2.501, Val loss 2.221\n",
      "Ep 1 (Step 024435): Train loss 2.245, Val loss 2.211\n",
      "Ep 1 (Step 024440): Train loss 2.214, Val loss 2.217\n",
      "Ep 1 (Step 024445): Train loss 2.195, Val loss 2.213\n",
      "Ep 1 (Step 024450): Train loss 2.101, Val loss 2.214\n",
      "Ep 1 (Step 024455): Train loss 2.421, Val loss 2.219\n",
      "Ep 1 (Step 024460): Train loss 2.158, Val loss 2.228\n",
      "Ep 1 (Step 024465): Train loss 2.167, Val loss 2.232\n",
      "Ep 1 (Step 024470): Train loss 2.133, Val loss 2.240\n",
      "Ep 1 (Step 024475): Train loss 2.176, Val loss 2.232\n",
      "Ep 1 (Step 024480): Train loss 2.107, Val loss 2.237\n",
      "Ep 1 (Step 024485): Train loss 2.159, Val loss 2.242\n",
      "Ep 1 (Step 024490): Train loss 2.254, Val loss 2.229\n",
      "Ep 1 (Step 024495): Train loss 2.342, Val loss 2.228\n",
      "Ep 1 (Step 024500): Train loss 2.206, Val loss 2.210\n",
      "Ep 1 (Step 024505): Train loss 2.136, Val loss 2.196\n",
      "Ep 1 (Step 024510): Train loss 2.127, Val loss 2.191\n",
      "Ep 1 (Step 024515): Train loss 2.340, Val loss 2.192\n",
      "Ep 1 (Step 024520): Train loss 2.210, Val loss 2.209\n",
      "Ep 1 (Step 024525): Train loss 2.128, Val loss 2.219\n",
      "Ep 1 (Step 024530): Train loss 2.174, Val loss 2.216\n",
      "Ep 1 (Step 024535): Train loss 2.280, Val loss 2.222\n",
      "Ep 1 (Step 024540): Train loss 2.225, Val loss 2.219\n",
      "Ep 1 (Step 024545): Train loss 2.226, Val loss 2.222\n",
      "Ep 1 (Step 024550): Train loss 2.202, Val loss 2.224\n",
      "Ep 1 (Step 024555): Train loss 2.246, Val loss 2.219\n",
      "Ep 1 (Step 024560): Train loss 2.146, Val loss 2.222\n",
      "Ep 1 (Step 024565): Train loss 2.177, Val loss 2.231\n",
      "Ep 1 (Step 024570): Train loss 2.106, Val loss 2.237\n",
      "Ep 1 (Step 024575): Train loss 2.012, Val loss 2.229\n",
      "Ep 1 (Step 024580): Train loss 2.011, Val loss 2.236\n",
      "Ep 1 (Step 024585): Train loss 2.184, Val loss 2.242\n",
      "Ep 1 (Step 024590): Train loss 2.301, Val loss 2.241\n",
      "Ep 1 (Step 024595): Train loss 2.122, Val loss 2.230\n",
      "Ep 1 (Step 024600): Train loss 2.029, Val loss 2.225\n",
      "Ep 1 (Step 024605): Train loss 2.107, Val loss 2.224\n",
      "Ep 1 (Step 024610): Train loss 2.540, Val loss 2.233\n",
      "Ep 1 (Step 024615): Train loss 2.286, Val loss 2.237\n",
      "Ep 1 (Step 024620): Train loss 2.138, Val loss 2.236\n",
      "Ep 1 (Step 024625): Train loss 2.408, Val loss 2.237\n",
      "Ep 1 (Step 024630): Train loss 2.164, Val loss 2.239\n",
      "Ep 1 (Step 024635): Train loss 2.192, Val loss 2.235\n",
      "Ep 1 (Step 024640): Train loss 2.252, Val loss 2.228\n",
      "Ep 1 (Step 024645): Train loss 2.257, Val loss 2.229\n",
      "Ep 1 (Step 024650): Train loss 2.096, Val loss 2.232\n",
      "Ep 1 (Step 024655): Train loss 2.366, Val loss 2.233\n",
      "Ep 1 (Step 024660): Train loss 2.337, Val loss 2.221\n",
      "Ep 1 (Step 024665): Train loss 2.257, Val loss 2.209\n",
      "Ep 1 (Step 024670): Train loss 2.404, Val loss 2.211\n",
      "Ep 1 (Step 024675): Train loss 2.264, Val loss 2.212\n",
      "Ep 1 (Step 024680): Train loss 2.427, Val loss 2.208\n",
      "Ep 1 (Step 024685): Train loss 2.133, Val loss 2.225\n",
      "Ep 1 (Step 024690): Train loss 2.200, Val loss 2.231\n",
      "Ep 1 (Step 024695): Train loss 2.238, Val loss 2.242\n",
      "Ep 1 (Step 024700): Train loss 2.268, Val loss 2.242\n",
      "Ep 1 (Step 024705): Train loss 2.496, Val loss 2.244\n",
      "Ep 1 (Step 024710): Train loss 2.322, Val loss 2.241\n",
      "Ep 1 (Step 024715): Train loss 2.213, Val loss 2.225\n",
      "Ep 1 (Step 024720): Train loss 2.076, Val loss 2.237\n",
      "Ep 1 (Step 024725): Train loss 2.236, Val loss 2.244\n",
      "Ep 1 (Step 024730): Train loss 2.277, Val loss 2.246\n",
      "Ep 1 (Step 024735): Train loss 1.987, Val loss 2.256\n",
      "Ep 1 (Step 024740): Train loss 2.325, Val loss 2.237\n",
      "Ep 1 (Step 024745): Train loss 2.273, Val loss 2.236\n",
      "Ep 1 (Step 024750): Train loss 2.036, Val loss 2.222\n",
      "Ep 1 (Step 024755): Train loss 2.379, Val loss 2.218\n",
      "Ep 1 (Step 024760): Train loss 2.139, Val loss 2.219\n",
      "Ep 1 (Step 024765): Train loss 2.400, Val loss 2.216\n",
      "Ep 1 (Step 024770): Train loss 2.236, Val loss 2.214\n",
      "Ep 1 (Step 024775): Train loss 2.126, Val loss 2.211\n",
      "Ep 1 (Step 024780): Train loss 2.009, Val loss 2.205\n",
      "Ep 1 (Step 024785): Train loss 2.323, Val loss 2.217\n",
      "Ep 1 (Step 024790): Train loss 2.270, Val loss 2.227\n",
      "Ep 1 (Step 024795): Train loss 2.318, Val loss 2.225\n",
      "Ep 1 (Step 024800): Train loss 2.231, Val loss 2.221\n",
      "Ep 1 (Step 024805): Train loss 2.174, Val loss 2.211\n",
      "Ep 1 (Step 024810): Train loss 2.189, Val loss 2.206\n",
      "Ep 1 (Step 024815): Train loss 2.217, Val loss 2.207\n",
      "Ep 1 (Step 024820): Train loss 2.097, Val loss 2.218\n",
      "Ep 1 (Step 024825): Train loss 2.218, Val loss 2.230\n",
      "Ep 1 (Step 024830): Train loss 2.210, Val loss 2.222\n",
      "Ep 1 (Step 024835): Train loss 2.163, Val loss 2.226\n",
      "Ep 1 (Step 024840): Train loss 2.421, Val loss 2.231\n",
      "Ep 1 (Step 024845): Train loss 2.312, Val loss 2.233\n",
      "Ep 1 (Step 024850): Train loss 2.362, Val loss 2.227\n",
      "Ep 1 (Step 024855): Train loss 2.300, Val loss 2.220\n",
      "Ep 1 (Step 024860): Train loss 1.969, Val loss 2.222\n",
      "Ep 1 (Step 024865): Train loss 1.909, Val loss 2.223\n",
      "Ep 1 (Step 024870): Train loss 2.187, Val loss 2.211\n",
      "Ep 1 (Step 024875): Train loss 2.271, Val loss 2.213\n",
      "Ep 1 (Step 024880): Train loss 2.124, Val loss 2.223\n",
      "Ep 1 (Step 024885): Train loss 2.191, Val loss 2.216\n",
      "Ep 1 (Step 024890): Train loss 2.013, Val loss 2.208\n",
      "Ep 1 (Step 024895): Train loss 2.269, Val loss 2.213\n",
      "Ep 1 (Step 024900): Train loss 2.271, Val loss 2.219\n",
      "Ep 1 (Step 024905): Train loss 2.245, Val loss 2.223\n",
      "Ep 1 (Step 024910): Train loss 2.236, Val loss 2.223\n",
      "Ep 1 (Step 024915): Train loss 2.124, Val loss 2.229\n",
      "Ep 1 (Step 024920): Train loss 2.069, Val loss 2.235\n",
      "Ep 1 (Step 024925): Train loss 2.384, Val loss 2.239\n",
      "Ep 1 (Step 024930): Train loss 2.032, Val loss 2.230\n",
      "Ep 1 (Step 024935): Train loss 2.170, Val loss 2.225\n",
      "Ep 1 (Step 024940): Train loss 2.103, Val loss 2.227\n",
      "Ep 1 (Step 024945): Train loss 2.267, Val loss 2.225\n",
      "Ep 1 (Step 024950): Train loss 2.119, Val loss 2.216\n",
      "Ep 1 (Step 024955): Train loss 2.342, Val loss 2.212\n",
      "Ep 1 (Step 024960): Train loss 2.213, Val loss 2.210\n",
      "Ep 1 (Step 024965): Train loss 2.588, Val loss 2.224\n",
      "Ep 1 (Step 024970): Train loss 2.341, Val loss 2.206\n",
      "Ep 1 (Step 024975): Train loss 2.422, Val loss 2.207\n",
      "Ep 1 (Step 024980): Train loss 2.351, Val loss 2.191\n",
      "Ep 1 (Step 024985): Train loss 2.474, Val loss 2.197\n",
      "Ep 1 (Step 024990): Train loss 2.369, Val loss 2.208\n",
      "Ep 1 (Step 024995): Train loss 2.221, Val loss 2.214\n",
      "Ep 1 (Step 025000): Train loss 2.171, Val loss 2.210\n",
      "Ep 1 (Step 025005): Train loss 2.354, Val loss 2.207\n",
      "Ep 1 (Step 025010): Train loss 2.229, Val loss 2.211\n",
      "Ep 1 (Step 025015): Train loss 2.320, Val loss 2.215\n",
      "Ep 1 (Step 025020): Train loss 2.284, Val loss 2.214\n",
      "Ep 1 (Step 025025): Train loss 2.214, Val loss 2.213\n",
      "Ep 1 (Step 025030): Train loss 2.241, Val loss 2.206\n",
      "Ep 1 (Step 025035): Train loss 2.103, Val loss 2.207\n",
      "Ep 1 (Step 025040): Train loss 2.168, Val loss 2.211\n",
      "Ep 1 (Step 025045): Train loss 1.976, Val loss 2.194\n",
      "Ep 1 (Step 025050): Train loss 2.110, Val loss 2.195\n",
      "Ep 1 (Step 025055): Train loss 2.425, Val loss 2.205\n",
      "Ep 1 (Step 025060): Train loss 2.015, Val loss 2.201\n",
      "Ep 1 (Step 025065): Train loss 2.139, Val loss 2.209\n",
      "Ep 1 (Step 025070): Train loss 1.945, Val loss 2.215\n",
      "Ep 1 (Step 025075): Train loss 1.904, Val loss 2.215\n",
      "Ep 1 (Step 025080): Train loss 2.443, Val loss 2.212\n",
      "Ep 1 (Step 025085): Train loss 2.249, Val loss 2.210\n",
      "Ep 1 (Step 025090): Train loss 2.253, Val loss 2.209\n",
      "Ep 1 (Step 025095): Train loss 2.001, Val loss 2.204\n",
      "Ep 1 (Step 025100): Train loss 2.316, Val loss 2.201\n",
      "Ep 1 (Step 025105): Train loss 2.243, Val loss 2.210\n",
      "Ep 1 (Step 025110): Train loss 2.314, Val loss 2.219\n",
      "Ep 1 (Step 025115): Train loss 2.311, Val loss 2.218\n",
      "Ep 1 (Step 025120): Train loss 2.290, Val loss 2.214\n",
      "Ep 1 (Step 025125): Train loss 2.440, Val loss 2.229\n",
      "Ep 1 (Step 025130): Train loss 2.153, Val loss 2.233\n",
      "Ep 1 (Step 025135): Train loss 2.207, Val loss 2.225\n",
      "Ep 1 (Step 025140): Train loss 2.346, Val loss 2.235\n",
      "Ep 1 (Step 025145): Train loss 2.519, Val loss 2.235\n",
      "Ep 1 (Step 025150): Train loss 2.042, Val loss 2.236\n",
      "Ep 1 (Step 025155): Train loss 1.821, Val loss 2.228\n",
      "Ep 1 (Step 025160): Train loss 2.219, Val loss 2.225\n",
      "Ep 1 (Step 025165): Train loss 2.422, Val loss 2.215\n",
      "Ep 1 (Step 025170): Train loss 2.273, Val loss 2.216\n",
      "Ep 1 (Step 025175): Train loss 2.070, Val loss 2.214\n",
      "Ep 1 (Step 025180): Train loss 2.450, Val loss 2.207\n",
      "Ep 1 (Step 025185): Train loss 2.004, Val loss 2.206\n",
      "Ep 1 (Step 025190): Train loss 2.319, Val loss 2.206\n",
      "Ep 1 (Step 025195): Train loss 2.407, Val loss 2.204\n",
      "Ep 1 (Step 025200): Train loss 2.094, Val loss 2.218\n",
      "Ep 1 (Step 025205): Train loss 2.193, Val loss 2.225\n",
      "Ep 1 (Step 025210): Train loss 1.984, Val loss 2.232\n",
      "Ep 1 (Step 025215): Train loss 2.136, Val loss 2.233\n",
      "Ep 1 (Step 025220): Train loss 2.336, Val loss 2.221\n",
      "Ep 1 (Step 025225): Train loss 2.324, Val loss 2.234\n",
      "Ep 1 (Step 025230): Train loss 2.390, Val loss 2.251\n",
      "Ep 1 (Step 025235): Train loss 2.090, Val loss 2.235\n",
      "Ep 1 (Step 025240): Train loss 2.164, Val loss 2.222\n",
      "Ep 1 (Step 025245): Train loss 2.762, Val loss 2.219\n",
      "Ep 1 (Step 025250): Train loss 2.232, Val loss 2.216\n",
      "Ep 1 (Step 025255): Train loss 2.358, Val loss 2.225\n",
      "Ep 1 (Step 025260): Train loss 2.116, Val loss 2.219\n",
      "Ep 1 (Step 025265): Train loss 2.137, Val loss 2.226\n",
      "Ep 1 (Step 025270): Train loss 2.172, Val loss 2.221\n",
      "Ep 1 (Step 025275): Train loss 2.124, Val loss 2.215\n",
      "Ep 1 (Step 025280): Train loss 1.853, Val loss 2.215\n",
      "Ep 1 (Step 025285): Train loss 2.433, Val loss 2.216\n",
      "Ep 1 (Step 025290): Train loss 2.418, Val loss 2.217\n",
      "Ep 1 (Step 025295): Train loss 2.294, Val loss 2.215\n",
      "Ep 1 (Step 025300): Train loss 2.251, Val loss 2.222\n",
      "Ep 1 (Step 025305): Train loss 2.547, Val loss 2.231\n",
      "Ep 1 (Step 025310): Train loss 2.195, Val loss 2.242\n",
      "Ep 1 (Step 025315): Train loss 2.045, Val loss 2.242\n",
      "Ep 1 (Step 025320): Train loss 2.268, Val loss 2.239\n",
      "Ep 1 (Step 025325): Train loss 2.298, Val loss 2.227\n",
      "Ep 1 (Step 025330): Train loss 2.192, Val loss 2.223\n",
      "Ep 1 (Step 025335): Train loss 2.073, Val loss 2.218\n",
      "Ep 1 (Step 025340): Train loss 1.846, Val loss 2.217\n",
      "Ep 1 (Step 025345): Train loss 2.152, Val loss 2.209\n",
      "Ep 1 (Step 025350): Train loss 2.023, Val loss 2.216\n",
      "Ep 1 (Step 025355): Train loss 2.355, Val loss 2.226\n",
      "Ep 1 (Step 025360): Train loss 2.232, Val loss 2.212\n",
      "Ep 1 (Step 025365): Train loss 2.087, Val loss 2.218\n",
      "Ep 1 (Step 025370): Train loss 2.074, Val loss 2.221\n",
      "Ep 1 (Step 025375): Train loss 2.187, Val loss 2.226\n",
      "Ep 1 (Step 025380): Train loss 2.233, Val loss 2.226\n",
      "Ep 1 (Step 025385): Train loss 2.331, Val loss 2.223\n",
      "Ep 1 (Step 025390): Train loss 2.202, Val loss 2.236\n",
      "Ep 1 (Step 025395): Train loss 2.258, Val loss 2.224\n",
      "Ep 1 (Step 025400): Train loss 2.197, Val loss 2.225\n",
      "Ep 1 (Step 025405): Train loss 2.125, Val loss 2.216\n",
      "Ep 1 (Step 025410): Train loss 2.400, Val loss 2.218\n",
      "Ep 1 (Step 025415): Train loss 2.279, Val loss 2.220\n",
      "Ep 1 (Step 025420): Train loss 2.216, Val loss 2.212\n",
      "Ep 1 (Step 025425): Train loss 2.177, Val loss 2.202\n",
      "Ep 1 (Step 025430): Train loss 2.328, Val loss 2.202\n",
      "Ep 1 (Step 025435): Train loss 2.100, Val loss 2.223\n",
      "Ep 1 (Step 025440): Train loss 2.227, Val loss 2.221\n",
      "Ep 1 (Step 025445): Train loss 2.215, Val loss 2.212\n",
      "Ep 1 (Step 025450): Train loss 2.092, Val loss 2.205\n",
      "Ep 1 (Step 025455): Train loss 2.222, Val loss 2.211\n",
      "Ep 1 (Step 025460): Train loss 2.253, Val loss 2.216\n",
      "Ep 1 (Step 025465): Train loss 2.213, Val loss 2.202\n",
      "Ep 1 (Step 025470): Train loss 2.034, Val loss 2.199\n",
      "Ep 1 (Step 025475): Train loss 2.576, Val loss 2.201\n",
      "Ep 1 (Step 025480): Train loss 2.487, Val loss 2.214\n",
      "Ep 1 (Step 025485): Train loss 2.321, Val loss 2.212\n",
      "Ep 1 (Step 025490): Train loss 2.434, Val loss 2.227\n",
      "Ep 1 (Step 025495): Train loss 2.304, Val loss 2.210\n",
      "Ep 1 (Step 025500): Train loss 2.230, Val loss 2.206\n",
      "Ep 1 (Step 025505): Train loss 2.298, Val loss 2.208\n",
      "Ep 1 (Step 025510): Train loss 2.191, Val loss 2.202\n",
      "Ep 1 (Step 025515): Train loss 2.063, Val loss 2.199\n",
      "Ep 1 (Step 025520): Train loss 1.913, Val loss 2.211\n",
      "Ep 1 (Step 025525): Train loss 2.265, Val loss 2.202\n",
      "Ep 1 (Step 025530): Train loss 2.252, Val loss 2.207\n",
      "Ep 1 (Step 025535): Train loss 1.956, Val loss 2.208\n",
      "Ep 1 (Step 025540): Train loss 2.478, Val loss 2.196\n",
      "Ep 1 (Step 025545): Train loss 2.038, Val loss 2.192\n",
      "Ep 1 (Step 025550): Train loss 2.315, Val loss 2.191\n",
      "Ep 1 (Step 025555): Train loss 2.175, Val loss 2.192\n",
      "Ep 1 (Step 025560): Train loss 2.161, Val loss 2.196\n",
      "Ep 1 (Step 025565): Train loss 2.259, Val loss 2.198\n",
      "Ep 1 (Step 025570): Train loss 2.091, Val loss 2.193\n",
      "Ep 1 (Step 025575): Train loss 2.235, Val loss 2.198\n",
      "Ep 1 (Step 025580): Train loss 2.344, Val loss 2.199\n",
      "Ep 1 (Step 025585): Train loss 2.056, Val loss 2.207\n",
      "Ep 1 (Step 025590): Train loss 2.350, Val loss 2.216\n",
      "Ep 1 (Step 025595): Train loss 2.153, Val loss 2.215\n",
      "Ep 1 (Step 025600): Train loss 2.175, Val loss 2.214\n",
      "Ep 1 (Step 025605): Train loss 2.434, Val loss 2.208\n",
      "Ep 1 (Step 025610): Train loss 1.984, Val loss 2.213\n",
      "Ep 1 (Step 025615): Train loss 2.326, Val loss 2.223\n",
      "Ep 1 (Step 025620): Train loss 2.177, Val loss 2.227\n",
      "Ep 1 (Step 025625): Train loss 2.142, Val loss 2.208\n",
      "Ep 1 (Step 025630): Train loss 2.485, Val loss 2.205\n",
      "Ep 1 (Step 025635): Train loss 2.190, Val loss 2.214\n",
      "Ep 1 (Step 025640): Train loss 2.281, Val loss 2.217\n",
      "Ep 1 (Step 025645): Train loss 2.412, Val loss 2.226\n",
      "Ep 1 (Step 025650): Train loss 2.191, Val loss 2.227\n",
      "Ep 1 (Step 025655): Train loss 2.266, Val loss 2.222\n",
      "Ep 1 (Step 025660): Train loss 2.025, Val loss 2.215\n",
      "Ep 1 (Step 025665): Train loss 1.943, Val loss 2.212\n",
      "Ep 1 (Step 025670): Train loss 2.023, Val loss 2.206\n",
      "Ep 1 (Step 025675): Train loss 2.004, Val loss 2.189\n",
      "Ep 1 (Step 025680): Train loss 2.227, Val loss 2.194\n",
      "Ep 1 (Step 025685): Train loss 2.080, Val loss 2.194\n",
      "Ep 1 (Step 025690): Train loss 1.894, Val loss 2.195\n",
      "Ep 1 (Step 025695): Train loss 2.017, Val loss 2.209\n",
      "Ep 1 (Step 025700): Train loss 2.304, Val loss 2.218\n",
      "Ep 1 (Step 025705): Train loss 2.573, Val loss 2.214\n",
      "Ep 1 (Step 025710): Train loss 2.303, Val loss 2.207\n",
      "Ep 1 (Step 025715): Train loss 2.080, Val loss 2.208\n",
      "Ep 1 (Step 025720): Train loss 2.414, Val loss 2.209\n",
      "Ep 1 (Step 025725): Train loss 2.254, Val loss 2.210\n",
      "Ep 1 (Step 025730): Train loss 1.902, Val loss 2.213\n",
      "Ep 1 (Step 025735): Train loss 2.378, Val loss 2.202\n",
      "Ep 1 (Step 025740): Train loss 2.403, Val loss 2.204\n",
      "Ep 1 (Step 025745): Train loss 1.804, Val loss 2.212\n",
      "Ep 1 (Step 025750): Train loss 2.241, Val loss 2.212\n",
      "Ep 1 (Step 025755): Train loss 2.169, Val loss 2.215\n",
      "Ep 1 (Step 025760): Train loss 2.337, Val loss 2.220\n",
      "Ep 1 (Step 025765): Train loss 2.149, Val loss 2.212\n",
      "Ep 1 (Step 025770): Train loss 2.191, Val loss 2.206\n",
      "Ep 1 (Step 025775): Train loss 2.119, Val loss 2.210\n",
      "Ep 1 (Step 025780): Train loss 2.140, Val loss 2.216\n",
      "Ep 1 (Step 025785): Train loss 2.033, Val loss 2.207\n",
      "Ep 1 (Step 025790): Train loss 2.078, Val loss 2.211\n",
      "Ep 1 (Step 025795): Train loss 2.334, Val loss 2.214\n",
      "Ep 1 (Step 025800): Train loss 2.132, Val loss 2.205\n",
      "Ep 1 (Step 025805): Train loss 2.111, Val loss 2.196\n",
      "Ep 1 (Step 025810): Train loss 2.013, Val loss 2.190\n",
      "Ep 1 (Step 025815): Train loss 2.427, Val loss 2.190\n",
      "Ep 1 (Step 025820): Train loss 2.171, Val loss 2.193\n",
      "Ep 1 (Step 025825): Train loss 2.055, Val loss 2.198\n",
      "Ep 1 (Step 025830): Train loss 2.181, Val loss 2.191\n",
      "Ep 1 (Step 025835): Train loss 2.198, Val loss 2.185\n",
      "Ep 1 (Step 025840): Train loss 2.047, Val loss 2.191\n",
      "Ep 1 (Step 025845): Train loss 2.178, Val loss 2.190\n",
      "Ep 1 (Step 025850): Train loss 2.309, Val loss 2.195\n",
      "Ep 1 (Step 025855): Train loss 2.186, Val loss 2.204\n",
      "Ep 1 (Step 025860): Train loss 1.925, Val loss 2.211\n",
      "Ep 1 (Step 025865): Train loss 2.447, Val loss 2.198\n",
      "Ep 1 (Step 025870): Train loss 2.374, Val loss 2.195\n",
      "Ep 1 (Step 025875): Train loss 2.516, Val loss 2.198\n",
      "Ep 1 (Step 025880): Train loss 2.267, Val loss 2.208\n",
      "Ep 1 (Step 025885): Train loss 1.989, Val loss 2.211\n",
      "Ep 1 (Step 025890): Train loss 2.162, Val loss 2.207\n",
      "Ep 1 (Step 025895): Train loss 2.276, Val loss 2.203\n",
      "Ep 1 (Step 025900): Train loss 2.124, Val loss 2.203\n",
      "Ep 1 (Step 025905): Train loss 2.415, Val loss 2.204\n",
      "Ep 1 (Step 025910): Train loss 2.350, Val loss 2.200\n",
      "Ep 1 (Step 025915): Train loss 2.149, Val loss 2.191\n",
      "Ep 1 (Step 025920): Train loss 2.208, Val loss 2.186\n",
      "Ep 1 (Step 025925): Train loss 2.354, Val loss 2.177\n",
      "Ep 1 (Step 025930): Train loss 2.287, Val loss 2.168\n",
      "Ep 1 (Step 025935): Train loss 2.423, Val loss 2.161\n",
      "Ep 1 (Step 025940): Train loss 2.025, Val loss 2.175\n",
      "Ep 1 (Step 025945): Train loss 2.090, Val loss 2.198\n",
      "Ep 1 (Step 025950): Train loss 2.302, Val loss 2.200\n",
      "Ep 1 (Step 025955): Train loss 2.228, Val loss 2.198\n",
      "Ep 1 (Step 025960): Train loss 2.090, Val loss 2.190\n",
      "Ep 1 (Step 025965): Train loss 2.028, Val loss 2.195\n",
      "Ep 1 (Step 025970): Train loss 2.032, Val loss 2.188\n",
      "Ep 1 (Step 025975): Train loss 2.443, Val loss 2.182\n",
      "Ep 1 (Step 025980): Train loss 2.325, Val loss 2.177\n",
      "Ep 1 (Step 025985): Train loss 2.129, Val loss 2.178\n",
      "Ep 1 (Step 025990): Train loss 2.071, Val loss 2.175\n",
      "Ep 1 (Step 025995): Train loss 2.278, Val loss 2.173\n",
      "Ep 1 (Step 026000): Train loss 1.967, Val loss 2.179\n",
      "Ep 1 (Step 026005): Train loss 2.006, Val loss 2.187\n",
      "Ep 1 (Step 026010): Train loss 2.091, Val loss 2.187\n",
      "Ep 1 (Step 026015): Train loss 2.194, Val loss 2.181\n",
      "Ep 1 (Step 026020): Train loss 2.016, Val loss 2.179\n",
      "Ep 1 (Step 026025): Train loss 2.096, Val loss 2.174\n",
      "Ep 1 (Step 026030): Train loss 2.120, Val loss 2.175\n",
      "Ep 1 (Step 026035): Train loss 2.190, Val loss 2.187\n",
      "Ep 1 (Step 026040): Train loss 2.423, Val loss 2.193\n",
      "Ep 1 (Step 026045): Train loss 2.123, Val loss 2.191\n",
      "Ep 1 (Step 026050): Train loss 2.159, Val loss 2.200\n",
      "Ep 1 (Step 026055): Train loss 2.014, Val loss 2.195\n",
      "Ep 1 (Step 026060): Train loss 1.988, Val loss 2.186\n",
      "Ep 1 (Step 026065): Train loss 2.286, Val loss 2.186\n",
      "Ep 1 (Step 026070): Train loss 2.052, Val loss 2.178\n",
      "Ep 1 (Step 026075): Train loss 2.113, Val loss 2.175\n",
      "Ep 1 (Step 026080): Train loss 2.302, Val loss 2.171\n",
      "Ep 1 (Step 026085): Train loss 2.415, Val loss 2.173\n",
      "Ep 1 (Step 026090): Train loss 2.265, Val loss 2.179\n",
      "Ep 1 (Step 026095): Train loss 2.650, Val loss 2.174\n",
      "Ep 1 (Step 026100): Train loss 2.368, Val loss 2.175\n",
      "Ep 1 (Step 026105): Train loss 2.080, Val loss 2.179\n",
      "Ep 1 (Step 026110): Train loss 1.967, Val loss 2.167\n",
      "Ep 1 (Step 026115): Train loss 1.885, Val loss 2.153\n",
      "Ep 1 (Step 026120): Train loss 1.956, Val loss 2.148\n",
      "Ep 1 (Step 026125): Train loss 1.976, Val loss 2.142\n",
      "Ep 1 (Step 026130): Train loss 2.330, Val loss 2.136\n",
      "Ep 1 (Step 026135): Train loss 2.437, Val loss 2.133\n",
      "Ep 1 (Step 026140): Train loss 2.192, Val loss 2.131\n",
      "Ep 1 (Step 026145): Train loss 1.929, Val loss 2.142\n",
      "Ep 1 (Step 026150): Train loss 2.411, Val loss 2.143\n",
      "Ep 1 (Step 026155): Train loss 1.963, Val loss 2.137\n",
      "Ep 1 (Step 026160): Train loss 2.201, Val loss 2.133\n",
      "Ep 1 (Step 026165): Train loss 2.130, Val loss 2.132\n",
      "Ep 1 (Step 026170): Train loss 2.233, Val loss 2.134\n",
      "Ep 1 (Step 026175): Train loss 2.195, Val loss 2.142\n",
      "Ep 1 (Step 026180): Train loss 2.622, Val loss 2.149\n",
      "Ep 1 (Step 026185): Train loss 1.965, Val loss 2.154\n",
      "Ep 1 (Step 026190): Train loss 2.197, Val loss 2.158\n",
      "Ep 1 (Step 026195): Train loss 2.135, Val loss 2.171\n",
      "Ep 1 (Step 026200): Train loss 2.177, Val loss 2.177\n",
      "Ep 1 (Step 026205): Train loss 2.255, Val loss 2.172\n",
      "Ep 1 (Step 026210): Train loss 2.500, Val loss 2.157\n",
      "Ep 1 (Step 026215): Train loss 2.204, Val loss 2.156\n",
      "Ep 1 (Step 026220): Train loss 2.167, Val loss 2.148\n",
      "Ep 1 (Step 026225): Train loss 2.048, Val loss 2.153\n",
      "Ep 1 (Step 026230): Train loss 2.142, Val loss 2.156\n",
      "Ep 1 (Step 026235): Train loss 2.121, Val loss 2.145\n",
      "Ep 1 (Step 026240): Train loss 2.227, Val loss 2.149\n",
      "Ep 1 (Step 026245): Train loss 2.246, Val loss 2.154\n",
      "Ep 1 (Step 026250): Train loss 2.314, Val loss 2.153\n",
      "Ep 1 (Step 026255): Train loss 2.219, Val loss 2.147\n",
      "Ep 1 (Step 026260): Train loss 1.884, Val loss 2.145\n",
      "Ep 1 (Step 026265): Train loss 2.056, Val loss 2.144\n",
      "Ep 1 (Step 026270): Train loss 2.339, Val loss 2.152\n",
      "Ep 1 (Step 026275): Train loss 2.335, Val loss 2.157\n",
      "Ep 1 (Step 026280): Train loss 2.381, Val loss 2.145\n",
      "Ep 1 (Step 026285): Train loss 2.332, Val loss 2.144\n",
      "Ep 1 (Step 026290): Train loss 2.270, Val loss 2.137\n",
      "Ep 1 (Step 026295): Train loss 2.275, Val loss 2.141\n",
      "Ep 1 (Step 026300): Train loss 2.183, Val loss 2.148\n",
      "Ep 1 (Step 026305): Train loss 2.161, Val loss 2.154\n",
      "Ep 1 (Step 026310): Train loss 1.962, Val loss 2.151\n",
      "Ep 1 (Step 026315): Train loss 2.081, Val loss 2.160\n",
      "Ep 1 (Step 026320): Train loss 2.074, Val loss 2.164\n",
      "Ep 1 (Step 026325): Train loss 1.872, Val loss 2.166\n",
      "Ep 1 (Step 026330): Train loss 2.332, Val loss 2.162\n",
      "Ep 1 (Step 026335): Train loss 2.099, Val loss 2.171\n",
      "Ep 1 (Step 026340): Train loss 2.040, Val loss 2.173\n",
      "Ep 1 (Step 026345): Train loss 1.994, Val loss 2.169\n",
      "Ep 1 (Step 026350): Train loss 2.328, Val loss 2.156\n",
      "Ep 1 (Step 026355): Train loss 2.136, Val loss 2.146\n",
      "Ep 1 (Step 026360): Train loss 2.248, Val loss 2.154\n",
      "Ep 1 (Step 026365): Train loss 2.246, Val loss 2.160\n",
      "Ep 1 (Step 026370): Train loss 1.891, Val loss 2.150\n",
      "Ep 1 (Step 026375): Train loss 2.523, Val loss 2.149\n",
      "Ep 1 (Step 026380): Train loss 2.385, Val loss 2.147\n",
      "Ep 1 (Step 026385): Train loss 1.964, Val loss 2.144\n",
      "Ep 1 (Step 026390): Train loss 2.132, Val loss 2.140\n",
      "Ep 1 (Step 026395): Train loss 2.186, Val loss 2.129\n",
      "Ep 1 (Step 026400): Train loss 2.239, Val loss 2.128\n",
      "Ep 1 (Step 026405): Train loss 2.103, Val loss 2.131\n",
      "Ep 1 (Step 026410): Train loss 2.387, Val loss 2.135\n",
      "Ep 1 (Step 026415): Train loss 2.091, Val loss 2.141\n",
      "Ep 1 (Step 026420): Train loss 2.146, Val loss 2.147\n",
      "Ep 1 (Step 026425): Train loss 2.224, Val loss 2.161\n",
      "Ep 1 (Step 026430): Train loss 1.940, Val loss 2.154\n",
      "Ep 1 (Step 026435): Train loss 2.108, Val loss 2.143\n",
      "Ep 1 (Step 026440): Train loss 1.980, Val loss 2.151\n",
      "Ep 1 (Step 026445): Train loss 1.836, Val loss 2.161\n",
      "Ep 1 (Step 026450): Train loss 2.120, Val loss 2.162\n",
      "Ep 1 (Step 026455): Train loss 2.149, Val loss 2.164\n",
      "Ep 1 (Step 026460): Train loss 1.952, Val loss 2.173\n",
      "Ep 1 (Step 026465): Train loss 1.982, Val loss 2.181\n",
      "Ep 1 (Step 026470): Train loss 2.265, Val loss 2.183\n",
      "Ep 1 (Step 026475): Train loss 2.384, Val loss 2.173\n",
      "Ep 1 (Step 026480): Train loss 2.105, Val loss 2.158\n",
      "Ep 1 (Step 026485): Train loss 2.288, Val loss 2.163\n",
      "Ep 1 (Step 026490): Train loss 2.277, Val loss 2.179\n",
      "Ep 1 (Step 026495): Train loss 1.828, Val loss 2.169\n",
      "Ep 1 (Step 026500): Train loss 2.214, Val loss 2.169\n",
      "Ep 1 (Step 026505): Train loss 2.240, Val loss 2.166\n",
      "Ep 1 (Step 026510): Train loss 2.098, Val loss 2.157\n",
      "Ep 1 (Step 026515): Train loss 1.951, Val loss 2.156\n",
      "Ep 1 (Step 026520): Train loss 2.137, Val loss 2.149\n",
      "Ep 1 (Step 026525): Train loss 2.071, Val loss 2.139\n",
      "Ep 1 (Step 026530): Train loss 1.999, Val loss 2.138\n",
      "Ep 1 (Step 026535): Train loss 2.227, Val loss 2.141\n",
      "Ep 1 (Step 026540): Train loss 2.002, Val loss 2.154\n",
      "Ep 1 (Step 026545): Train loss 2.088, Val loss 2.149\n",
      "Ep 1 (Step 026550): Train loss 2.059, Val loss 2.143\n",
      "Ep 1 (Step 026555): Train loss 2.293, Val loss 2.137\n",
      "Ep 1 (Step 026560): Train loss 2.127, Val loss 2.132\n",
      "Ep 1 (Step 026565): Train loss 2.219, Val loss 2.123\n",
      "Ep 1 (Step 026570): Train loss 2.439, Val loss 2.126\n",
      "Ep 1 (Step 026575): Train loss 2.377, Val loss 2.117\n",
      "Ep 1 (Step 026580): Train loss 2.326, Val loss 2.124\n",
      "Ep 1 (Step 026585): Train loss 1.959, Val loss 2.123\n",
      "Ep 1 (Step 026590): Train loss 2.079, Val loss 2.133\n",
      "Ep 1 (Step 026595): Train loss 2.115, Val loss 2.135\n",
      "Ep 1 (Step 026600): Train loss 2.295, Val loss 2.129\n",
      "Ep 1 (Step 026605): Train loss 2.118, Val loss 2.127\n",
      "Ep 1 (Step 026610): Train loss 2.216, Val loss 2.133\n",
      "Ep 1 (Step 026615): Train loss 2.236, Val loss 2.142\n",
      "Ep 1 (Step 026620): Train loss 2.088, Val loss 2.138\n",
      "Ep 1 (Step 026625): Train loss 2.302, Val loss 2.138\n",
      "Ep 1 (Step 026630): Train loss 2.347, Val loss 2.130\n",
      "Ep 1 (Step 026635): Train loss 2.305, Val loss 2.134\n",
      "Ep 1 (Step 026640): Train loss 2.180, Val loss 2.141\n",
      "Ep 1 (Step 026645): Train loss 2.410, Val loss 2.147\n",
      "Ep 1 (Step 026650): Train loss 2.169, Val loss 2.151\n",
      "Ep 1 (Step 026655): Train loss 1.973, Val loss 2.157\n",
      "Ep 1 (Step 026660): Train loss 2.195, Val loss 2.155\n",
      "Ep 1 (Step 026665): Train loss 2.199, Val loss 2.137\n",
      "Ep 1 (Step 026670): Train loss 2.115, Val loss 2.130\n",
      "Ep 1 (Step 026675): Train loss 2.382, Val loss 2.118\n",
      "Ep 1 (Step 026680): Train loss 2.189, Val loss 2.119\n",
      "Ep 1 (Step 026685): Train loss 2.386, Val loss 2.112\n",
      "Ep 1 (Step 026690): Train loss 2.170, Val loss 2.112\n",
      "Ep 1 (Step 026695): Train loss 2.204, Val loss 2.125\n",
      "Ep 1 (Step 026700): Train loss 1.983, Val loss 2.128\n",
      "Ep 1 (Step 026705): Train loss 2.143, Val loss 2.131\n",
      "Ep 1 (Step 026710): Train loss 2.623, Val loss 2.123\n",
      "Ep 1 (Step 026715): Train loss 2.507, Val loss 2.121\n",
      "Ep 1 (Step 026720): Train loss 2.028, Val loss 2.128\n",
      "Ep 1 (Step 026725): Train loss 2.394, Val loss 2.136\n",
      "Ep 1 (Step 026730): Train loss 2.338, Val loss 2.139\n",
      "Ep 1 (Step 026735): Train loss 2.122, Val loss 2.134\n",
      "Ep 1 (Step 026740): Train loss 2.096, Val loss 2.123\n",
      "Ep 1 (Step 026745): Train loss 2.279, Val loss 2.123\n",
      "Ep 1 (Step 026750): Train loss 2.125, Val loss 2.116\n",
      "Ep 1 (Step 026755): Train loss 2.002, Val loss 2.117\n",
      "Ep 1 (Step 026760): Train loss 2.082, Val loss 2.123\n",
      "Ep 1 (Step 026765): Train loss 2.276, Val loss 2.121\n",
      "Ep 1 (Step 026770): Train loss 2.156, Val loss 2.117\n",
      "Ep 1 (Step 026775): Train loss 2.103, Val loss 2.124\n",
      "Ep 1 (Step 026780): Train loss 2.052, Val loss 2.121\n",
      "Ep 1 (Step 026785): Train loss 2.131, Val loss 2.133\n",
      "Ep 1 (Step 026790): Train loss 2.135, Val loss 2.147\n",
      "Ep 1 (Step 026795): Train loss 2.143, Val loss 2.155\n",
      "Ep 1 (Step 026800): Train loss 2.553, Val loss 2.165\n",
      "Ep 1 (Step 026805): Train loss 2.299, Val loss 2.153\n",
      "Ep 1 (Step 026810): Train loss 2.548, Val loss 2.146\n",
      "Ep 1 (Step 026815): Train loss 2.165, Val loss 2.140\n",
      "Ep 1 (Step 026820): Train loss 2.080, Val loss 2.137\n",
      "Ep 1 (Step 026825): Train loss 2.281, Val loss 2.130\n",
      "Ep 1 (Step 026830): Train loss 2.060, Val loss 2.133\n",
      "Ep 1 (Step 026835): Train loss 2.220, Val loss 2.146\n",
      "Ep 1 (Step 026840): Train loss 2.267, Val loss 2.164\n",
      "Ep 1 (Step 026845): Train loss 2.071, Val loss 2.163\n",
      "Ep 1 (Step 026850): Train loss 2.114, Val loss 2.151\n",
      "Ep 1 (Step 026855): Train loss 2.261, Val loss 2.140\n",
      "Ep 1 (Step 026860): Train loss 2.303, Val loss 2.147\n",
      "Ep 1 (Step 026865): Train loss 2.384, Val loss 2.150\n",
      "Ep 1 (Step 026870): Train loss 1.822, Val loss 2.141\n",
      "Ep 1 (Step 026875): Train loss 2.445, Val loss 2.133\n",
      "Ep 1 (Step 026880): Train loss 2.149, Val loss 2.128\n",
      "Ep 1 (Step 026885): Train loss 2.128, Val loss 2.134\n",
      "Ep 1 (Step 026890): Train loss 2.158, Val loss 2.133\n",
      "Ep 1 (Step 026895): Train loss 2.404, Val loss 2.134\n",
      "Ep 1 (Step 026900): Train loss 2.453, Val loss 2.130\n",
      "Ep 1 (Step 026905): Train loss 2.021, Val loss 2.130\n",
      "Ep 1 (Step 026910): Train loss 2.218, Val loss 2.140\n",
      "Ep 1 (Step 026915): Train loss 2.115, Val loss 2.139\n",
      "Ep 1 (Step 026920): Train loss 2.073, Val loss 2.138\n",
      "Ep 1 (Step 026925): Train loss 2.043, Val loss 2.134\n",
      "Ep 1 (Step 026930): Train loss 2.141, Val loss 2.116\n",
      "Ep 1 (Step 026935): Train loss 2.194, Val loss 2.117\n",
      "Ep 1 (Step 026940): Train loss 2.259, Val loss 2.124\n",
      "Ep 1 (Step 026945): Train loss 2.069, Val loss 2.149\n",
      "Ep 1 (Step 026950): Train loss 1.969, Val loss 2.143\n",
      "Ep 1 (Step 026955): Train loss 2.150, Val loss 2.142\n",
      "Ep 1 (Step 026960): Train loss 2.278, Val loss 2.144\n",
      "Ep 1 (Step 026965): Train loss 2.176, Val loss 2.140\n",
      "Ep 1 (Step 026970): Train loss 2.146, Val loss 2.135\n",
      "Ep 1 (Step 026975): Train loss 2.378, Val loss 2.126\n",
      "Ep 1 (Step 026980): Train loss 2.167, Val loss 2.131\n",
      "Ep 1 (Step 026985): Train loss 2.498, Val loss 2.142\n",
      "Ep 1 (Step 026990): Train loss 2.167, Val loss 2.153\n",
      "Ep 1 (Step 026995): Train loss 2.036, Val loss 2.148\n",
      "Ep 1 (Step 027000): Train loss 2.192, Val loss 2.140\n",
      "Ep 1 (Step 027005): Train loss 2.267, Val loss 2.129\n",
      "Ep 1 (Step 027010): Train loss 2.050, Val loss 2.120\n",
      "Ep 1 (Step 027015): Train loss 2.071, Val loss 2.118\n",
      "Ep 1 (Step 027020): Train loss 2.081, Val loss 2.120\n",
      "Ep 1 (Step 027025): Train loss 2.121, Val loss 2.128\n",
      "Ep 1 (Step 027030): Train loss 2.064, Val loss 2.125\n",
      "Ep 1 (Step 027035): Train loss 2.104, Val loss 2.124\n",
      "Ep 1 (Step 027040): Train loss 2.326, Val loss 2.126\n",
      "Ep 1 (Step 027045): Train loss 2.403, Val loss 2.124\n",
      "Ep 1 (Step 027050): Train loss 2.068, Val loss 2.126\n",
      "Ep 1 (Step 027055): Train loss 2.136, Val loss 2.122\n",
      "Ep 1 (Step 027060): Train loss 2.216, Val loss 2.131\n",
      "Ep 1 (Step 027065): Train loss 2.176, Val loss 2.134\n",
      "Ep 1 (Step 027070): Train loss 2.023, Val loss 2.133\n",
      "Ep 1 (Step 027075): Train loss 2.227, Val loss 2.123\n",
      "Ep 1 (Step 027080): Train loss 2.372, Val loss 2.122\n",
      "Ep 1 (Step 027085): Train loss 2.543, Val loss 2.122\n",
      "Ep 1 (Step 027090): Train loss 2.324, Val loss 2.125\n",
      "Ep 1 (Step 027095): Train loss 2.134, Val loss 2.125\n",
      "Ep 1 (Step 027100): Train loss 2.293, Val loss 2.130\n",
      "Ep 1 (Step 027105): Train loss 1.986, Val loss 2.126\n",
      "Ep 1 (Step 027110): Train loss 2.428, Val loss 2.123\n",
      "Ep 1 (Step 027115): Train loss 2.197, Val loss 2.113\n",
      "Ep 1 (Step 027120): Train loss 2.464, Val loss 2.109\n",
      "Ep 1 (Step 027125): Train loss 2.297, Val loss 2.109\n",
      "Ep 1 (Step 027130): Train loss 2.293, Val loss 2.115\n",
      "Ep 1 (Step 027135): Train loss 2.084, Val loss 2.125\n",
      "Ep 1 (Step 027140): Train loss 2.001, Val loss 2.118\n",
      "Ep 1 (Step 027145): Train loss 2.253, Val loss 2.116\n",
      "Ep 1 (Step 027150): Train loss 2.017, Val loss 2.114\n",
      "Ep 1 (Step 027155): Train loss 2.325, Val loss 2.119\n",
      "Ep 1 (Step 027160): Train loss 2.094, Val loss 2.106\n",
      "Ep 1 (Step 027165): Train loss 2.144, Val loss 2.102\n",
      "Ep 1 (Step 027170): Train loss 1.959, Val loss 2.097\n",
      "Ep 1 (Step 027175): Train loss 2.139, Val loss 2.087\n",
      "Ep 1 (Step 027180): Train loss 2.222, Val loss 2.094\n",
      "Ep 1 (Step 027185): Train loss 2.075, Val loss 2.108\n",
      "Ep 1 (Step 027190): Train loss 2.237, Val loss 2.110\n",
      "Ep 1 (Step 027195): Train loss 2.455, Val loss 2.118\n",
      "Ep 1 (Step 027200): Train loss 2.098, Val loss 2.125\n",
      "Ep 1 (Step 027205): Train loss 2.238, Val loss 2.124\n",
      "Ep 1 (Step 027210): Train loss 2.282, Val loss 2.116\n",
      "Ep 1 (Step 027215): Train loss 2.204, Val loss 2.100\n",
      "Ep 1 (Step 027220): Train loss 2.066, Val loss 2.100\n",
      "Ep 1 (Step 027225): Train loss 2.144, Val loss 2.103\n",
      "Ep 1 (Step 027230): Train loss 2.136, Val loss 2.108\n",
      "Ep 1 (Step 027235): Train loss 2.152, Val loss 2.106\n",
      "Ep 1 (Step 027240): Train loss 2.091, Val loss 2.110\n",
      "Ep 1 (Step 027245): Train loss 2.000, Val loss 2.102\n",
      "Ep 1 (Step 027250): Train loss 2.210, Val loss 2.095\n",
      "Ep 1 (Step 027255): Train loss 2.455, Val loss 2.096\n",
      "Ep 1 (Step 027260): Train loss 2.334, Val loss 2.105\n",
      "Ep 1 (Step 027265): Train loss 2.307, Val loss 2.114\n",
      "Ep 1 (Step 027270): Train loss 1.983, Val loss 2.110\n",
      "Ep 1 (Step 027275): Train loss 2.194, Val loss 2.100\n",
      "Ep 1 (Step 027280): Train loss 2.304, Val loss 2.103\n",
      "Ep 1 (Step 027285): Train loss 2.295, Val loss 2.120\n",
      "Ep 1 (Step 027290): Train loss 2.284, Val loss 2.121\n",
      "Ep 1 (Step 027295): Train loss 2.223, Val loss 2.112\n",
      "Ep 1 (Step 027300): Train loss 2.200, Val loss 2.103\n",
      "Ep 1 (Step 027305): Train loss 2.048, Val loss 2.100\n",
      "Ep 1 (Step 027310): Train loss 2.056, Val loss 2.100\n",
      "Ep 1 (Step 027315): Train loss 1.992, Val loss 2.094\n",
      "Ep 1 (Step 027320): Train loss 2.077, Val loss 2.091\n",
      "Ep 1 (Step 027325): Train loss 2.193, Val loss 2.098\n",
      "Ep 1 (Step 027330): Train loss 1.840, Val loss 2.100\n",
      "Ep 1 (Step 027335): Train loss 2.278, Val loss 2.094\n",
      "Ep 1 (Step 027340): Train loss 2.196, Val loss 2.093\n",
      "Ep 1 (Step 027345): Train loss 2.176, Val loss 2.103\n",
      "Ep 1 (Step 027350): Train loss 2.437, Val loss 2.098\n",
      "Ep 1 (Step 027355): Train loss 2.102, Val loss 2.088\n",
      "Ep 1 (Step 027360): Train loss 2.017, Val loss 2.092\n",
      "Ep 1 (Step 027365): Train loss 2.209, Val loss 2.091\n",
      "Ep 1 (Step 027370): Train loss 2.041, Val loss 2.095\n",
      "Ep 1 (Step 027375): Train loss 2.189, Val loss 2.091\n",
      "Ep 1 (Step 027380): Train loss 2.077, Val loss 2.091\n",
      "Ep 1 (Step 027385): Train loss 2.504, Val loss 2.099\n",
      "Ep 1 (Step 027390): Train loss 2.357, Val loss 2.109\n",
      "Ep 1 (Step 027395): Train loss 2.195, Val loss 2.122\n",
      "Ep 1 (Step 027400): Train loss 2.234, Val loss 2.114\n",
      "Ep 1 (Step 027405): Train loss 1.904, Val loss 2.098\n",
      "Ep 1 (Step 027410): Train loss 2.289, Val loss 2.086\n",
      "Ep 1 (Step 027415): Train loss 2.253, Val loss 2.088\n",
      "Ep 1 (Step 027420): Train loss 2.312, Val loss 2.097\n",
      "Ep 1 (Step 027425): Train loss 1.912, Val loss 2.089\n",
      "Ep 1 (Step 027430): Train loss 2.330, Val loss 2.096\n",
      "Ep 1 (Step 027435): Train loss 1.980, Val loss 2.111\n",
      "Ep 1 (Step 027440): Train loss 2.054, Val loss 2.114\n",
      "Ep 1 (Step 027445): Train loss 2.082, Val loss 2.110\n",
      "Ep 1 (Step 027450): Train loss 2.060, Val loss 2.103\n",
      "Ep 1 (Step 027455): Train loss 2.369, Val loss 2.099\n",
      "Ep 1 (Step 027460): Train loss 1.959, Val loss 2.091\n",
      "Ep 1 (Step 027465): Train loss 2.247, Val loss 2.096\n",
      "Ep 1 (Step 027470): Train loss 2.140, Val loss 2.095\n",
      "Ep 1 (Step 027475): Train loss 2.133, Val loss 2.097\n",
      "Ep 1 (Step 027480): Train loss 2.342, Val loss 2.098\n",
      "Ep 1 (Step 027485): Train loss 1.998, Val loss 2.089\n",
      "Ep 1 (Step 027490): Train loss 1.979, Val loss 2.084\n",
      "Ep 1 (Step 027495): Train loss 2.339, Val loss 2.085\n",
      "Ep 1 (Step 027500): Train loss 1.995, Val loss 2.093\n",
      "Ep 1 (Step 027505): Train loss 2.171, Val loss 2.094\n",
      "Ep 1 (Step 027510): Train loss 1.918, Val loss 2.100\n",
      "Ep 1 (Step 027515): Train loss 2.058, Val loss 2.093\n",
      "Ep 1 (Step 027520): Train loss 2.249, Val loss 2.088\n",
      "Ep 1 (Step 027525): Train loss 2.117, Val loss 2.091\n",
      "Ep 1 (Step 027530): Train loss 2.000, Val loss 2.097\n",
      "Ep 1 (Step 027535): Train loss 2.423, Val loss 2.088\n",
      "Ep 1 (Step 027540): Train loss 2.408, Val loss 2.081\n",
      "Ep 1 (Step 027545): Train loss 2.368, Val loss 2.093\n",
      "Ep 1 (Step 027550): Train loss 2.124, Val loss 2.096\n",
      "Ep 1 (Step 027555): Train loss 2.072, Val loss 2.105\n",
      "Ep 1 (Step 027560): Train loss 2.439, Val loss 2.109\n",
      "Ep 1 (Step 027565): Train loss 2.136, Val loss 2.105\n",
      "Ep 1 (Step 027570): Train loss 2.028, Val loss 2.102\n",
      "Ep 1 (Step 027575): Train loss 2.003, Val loss 2.095\n",
      "Ep 1 (Step 027580): Train loss 2.080, Val loss 2.096\n",
      "Ep 1 (Step 027585): Train loss 2.200, Val loss 2.094\n",
      "Ep 1 (Step 027590): Train loss 2.284, Val loss 2.090\n",
      "Ep 1 (Step 027595): Train loss 2.060, Val loss 2.085\n",
      "Ep 1 (Step 027600): Train loss 1.833, Val loss 2.085\n",
      "Ep 1 (Step 027605): Train loss 2.225, Val loss 2.094\n",
      "Ep 1 (Step 027610): Train loss 2.139, Val loss 2.099\n",
      "Ep 1 (Step 027615): Train loss 1.860, Val loss 2.092\n",
      "Ep 1 (Step 027620): Train loss 2.133, Val loss 2.096\n",
      "Ep 1 (Step 027625): Train loss 2.039, Val loss 2.103\n",
      "Ep 1 (Step 027630): Train loss 2.058, Val loss 2.108\n",
      "Ep 1 (Step 027635): Train loss 2.158, Val loss 2.103\n",
      "Ep 1 (Step 027640): Train loss 2.180, Val loss 2.097\n",
      "Ep 1 (Step 027645): Train loss 2.312, Val loss 2.098\n",
      "Ep 1 (Step 027650): Train loss 2.053, Val loss 2.102\n",
      "Ep 1 (Step 027655): Train loss 2.367, Val loss 2.100\n",
      "Ep 1 (Step 027660): Train loss 2.018, Val loss 2.101\n",
      "Ep 1 (Step 027665): Train loss 2.024, Val loss 2.099\n",
      "Ep 1 (Step 027670): Train loss 2.025, Val loss 2.106\n",
      "Ep 1 (Step 027675): Train loss 2.148, Val loss 2.109\n",
      "Ep 1 (Step 027680): Train loss 1.948, Val loss 2.108\n",
      "Ep 1 (Step 027685): Train loss 2.276, Val loss 2.102\n",
      "Ep 1 (Step 027690): Train loss 1.977, Val loss 2.093\n",
      "Ep 1 (Step 027695): Train loss 2.500, Val loss 2.098\n",
      "Ep 1 (Step 027700): Train loss 2.333, Val loss 2.103\n",
      "Ep 1 (Step 027705): Train loss 2.046, Val loss 2.091\n",
      "Ep 1 (Step 027710): Train loss 2.166, Val loss 2.099\n",
      "Ep 1 (Step 027715): Train loss 2.194, Val loss 2.099\n",
      "Ep 1 (Step 027720): Train loss 2.074, Val loss 2.098\n",
      "Ep 1 (Step 027725): Train loss 2.471, Val loss 2.083\n",
      "Ep 1 (Step 027730): Train loss 2.262, Val loss 2.089\n",
      "Ep 1 (Step 027735): Train loss 1.924, Val loss 2.091\n",
      "Ep 1 (Step 027740): Train loss 2.168, Val loss 2.088\n",
      "Ep 1 (Step 027745): Train loss 2.146, Val loss 2.082\n",
      "Ep 1 (Step 027750): Train loss 2.323, Val loss 2.086\n",
      "Ep 1 (Step 027755): Train loss 2.028, Val loss 2.086\n",
      "Ep 1 (Step 027760): Train loss 2.458, Val loss 2.079\n",
      "Ep 1 (Step 027765): Train loss 2.192, Val loss 2.087\n",
      "Ep 1 (Step 027770): Train loss 2.280, Val loss 2.087\n",
      "Ep 1 (Step 027775): Train loss 2.397, Val loss 2.083\n",
      "Ep 1 (Step 027780): Train loss 2.045, Val loss 2.077\n",
      "Ep 1 (Step 027785): Train loss 2.194, Val loss 2.086\n",
      "Ep 1 (Step 027790): Train loss 1.790, Val loss 2.079\n",
      "Ep 1 (Step 027795): Train loss 2.057, Val loss 2.084\n",
      "Ep 1 (Step 027800): Train loss 2.284, Val loss 2.082\n",
      "Ep 1 (Step 027805): Train loss 2.029, Val loss 2.078\n",
      "Ep 1 (Step 027810): Train loss 2.073, Val loss 2.079\n",
      "Ep 1 (Step 027815): Train loss 2.018, Val loss 2.089\n",
      "Ep 1 (Step 027820): Train loss 2.028, Val loss 2.099\n",
      "Ep 1 (Step 027825): Train loss 2.253, Val loss 2.100\n",
      "Ep 1 (Step 027830): Train loss 2.057, Val loss 2.104\n",
      "Ep 1 (Step 027835): Train loss 2.302, Val loss 2.105\n",
      "Ep 1 (Step 027840): Train loss 2.203, Val loss 2.097\n",
      "Ep 1 (Step 027845): Train loss 2.356, Val loss 2.097\n",
      "Ep 1 (Step 027850): Train loss 2.136, Val loss 2.098\n",
      "Ep 1 (Step 027855): Train loss 2.081, Val loss 2.103\n",
      "Ep 1 (Step 027860): Train loss 2.025, Val loss 2.094\n",
      "Ep 1 (Step 027865): Train loss 1.919, Val loss 2.087\n",
      "Ep 1 (Step 027870): Train loss 2.458, Val loss 2.086\n",
      "Ep 1 (Step 027875): Train loss 2.093, Val loss 2.101\n",
      "Ep 1 (Step 027880): Train loss 2.209, Val loss 2.096\n",
      "Ep 1 (Step 027885): Train loss 2.140, Val loss 2.092\n",
      "Ep 1 (Step 027890): Train loss 2.348, Val loss 2.074\n",
      "Ep 1 (Step 027895): Train loss 2.446, Val loss 2.083\n",
      "Ep 1 (Step 027900): Train loss 1.839, Val loss 2.088\n",
      "Ep 1 (Step 027905): Train loss 2.040, Val loss 2.073\n",
      "Ep 1 (Step 027910): Train loss 2.036, Val loss 2.070\n",
      "Ep 1 (Step 027915): Train loss 2.016, Val loss 2.081\n",
      "Ep 1 (Step 027920): Train loss 2.029, Val loss 2.084\n",
      "Ep 1 (Step 027925): Train loss 2.120, Val loss 2.078\n",
      "Ep 1 (Step 027930): Train loss 2.384, Val loss 2.075\n",
      "Ep 1 (Step 027935): Train loss 2.286, Val loss 2.088\n",
      "Ep 1 (Step 027940): Train loss 2.101, Val loss 2.091\n",
      "Ep 1 (Step 027945): Train loss 2.179, Val loss 2.089\n",
      "Ep 1 (Step 027950): Train loss 2.369, Val loss 2.087\n",
      "Ep 1 (Step 027955): Train loss 2.310, Val loss 2.077\n",
      "Ep 1 (Step 027960): Train loss 2.001, Val loss 2.082\n",
      "Ep 1 (Step 027965): Train loss 2.061, Val loss 2.079\n",
      "Ep 1 (Step 027970): Train loss 2.143, Val loss 2.076\n",
      "Ep 1 (Step 027975): Train loss 2.270, Val loss 2.074\n",
      "Ep 1 (Step 027980): Train loss 2.241, Val loss 2.075\n",
      "Ep 1 (Step 027985): Train loss 1.931, Val loss 2.081\n",
      "Ep 1 (Step 027990): Train loss 1.968, Val loss 2.078\n",
      "Ep 1 (Step 027995): Train loss 2.010, Val loss 2.080\n",
      "Ep 1 (Step 028000): Train loss 2.161, Val loss 2.088\n",
      "Ep 1 (Step 028005): Train loss 2.079, Val loss 2.098\n",
      "Ep 1 (Step 028010): Train loss 2.371, Val loss 2.088\n",
      "Ep 1 (Step 028015): Train loss 2.127, Val loss 2.085\n",
      "Ep 1 (Step 028020): Train loss 2.368, Val loss 2.088\n",
      "Ep 1 (Step 028025): Train loss 2.429, Val loss 2.087\n",
      "Ep 1 (Step 028030): Train loss 2.343, Val loss 2.094\n",
      "Ep 1 (Step 028035): Train loss 2.217, Val loss 2.101\n",
      "Ep 1 (Step 028040): Train loss 2.608, Val loss 2.100\n",
      "Ep 1 (Step 028045): Train loss 2.231, Val loss 2.100\n",
      "Ep 1 (Step 028050): Train loss 1.907, Val loss 2.105\n",
      "Ep 1 (Step 028055): Train loss 2.125, Val loss 2.107\n",
      "Ep 1 (Step 028060): Train loss 1.991, Val loss 2.098\n",
      "Ep 1 (Step 028065): Train loss 2.428, Val loss 2.087\n",
      "Ep 1 (Step 028070): Train loss 2.101, Val loss 2.087\n",
      "Ep 1 (Step 028075): Train loss 2.046, Val loss 2.093\n",
      "Ep 1 (Step 028080): Train loss 2.494, Val loss 2.102\n",
      "Ep 1 (Step 028085): Train loss 2.317, Val loss 2.092\n",
      "Ep 1 (Step 028090): Train loss 2.224, Val loss 2.078\n",
      "Ep 1 (Step 028095): Train loss 2.167, Val loss 2.078\n",
      "Ep 1 (Step 028100): Train loss 2.361, Val loss 2.081\n",
      "Ep 1 (Step 028105): Train loss 2.190, Val loss 2.084\n",
      "Ep 1 (Step 028110): Train loss 2.206, Val loss 2.096\n",
      "Ep 1 (Step 028115): Train loss 2.001, Val loss 2.104\n",
      "Ep 1 (Step 028120): Train loss 2.185, Val loss 2.100\n",
      "Ep 1 (Step 028125): Train loss 2.014, Val loss 2.110\n",
      "Ep 1 (Step 028130): Train loss 1.970, Val loss 2.110\n",
      "Ep 1 (Step 028135): Train loss 1.943, Val loss 2.098\n",
      "Ep 1 (Step 028140): Train loss 2.296, Val loss 2.091\n",
      "Ep 1 (Step 028145): Train loss 2.499, Val loss 2.077\n",
      "Ep 1 (Step 028150): Train loss 1.854, Val loss 2.069\n",
      "Ep 1 (Step 028155): Train loss 2.134, Val loss 2.059\n",
      "Ep 1 (Step 028160): Train loss 1.878, Val loss 2.057\n",
      "Ep 1 (Step 028165): Train loss 2.286, Val loss 2.060\n",
      "Ep 1 (Step 028170): Train loss 2.249, Val loss 2.065\n",
      "Ep 1 (Step 028175): Train loss 2.300, Val loss 2.064\n",
      "Ep 1 (Step 028180): Train loss 2.112, Val loss 2.066\n",
      "Ep 1 (Step 028185): Train loss 2.222, Val loss 2.070\n",
      "Ep 1 (Step 028190): Train loss 2.119, Val loss 2.073\n",
      "Ep 1 (Step 028195): Train loss 2.118, Val loss 2.072\n",
      "Ep 1 (Step 028200): Train loss 2.099, Val loss 2.073\n",
      "Ep 1 (Step 028205): Train loss 2.015, Val loss 2.075\n",
      "Ep 1 (Step 028210): Train loss 2.362, Val loss 2.079\n",
      "Ep 1 (Step 028215): Train loss 2.041, Val loss 2.082\n",
      "Ep 1 (Step 028220): Train loss 2.202, Val loss 2.087\n",
      "Ep 1 (Step 028225): Train loss 2.171, Val loss 2.089\n",
      "Ep 1 (Step 028230): Train loss 2.529, Val loss 2.087\n",
      "Ep 1 (Step 028235): Train loss 1.992, Val loss 2.083\n",
      "Ep 1 (Step 028240): Train loss 2.270, Val loss 2.087\n",
      "Ep 1 (Step 028245): Train loss 2.247, Val loss 2.089\n",
      "Ep 1 (Step 028250): Train loss 1.857, Val loss 2.094\n",
      "Ep 1 (Step 028255): Train loss 1.942, Val loss 2.098\n",
      "Ep 1 (Step 028260): Train loss 2.073, Val loss 2.101\n",
      "Ep 1 (Step 028265): Train loss 2.206, Val loss 2.091\n",
      "Ep 1 (Step 028270): Train loss 1.748, Val loss 2.087\n",
      "Ep 1 (Step 028275): Train loss 2.613, Val loss 2.076\n",
      "Ep 1 (Step 028280): Train loss 2.210, Val loss 2.077\n",
      "Ep 1 (Step 028285): Train loss 2.082, Val loss 2.078\n",
      "Ep 1 (Step 028290): Train loss 2.349, Val loss 2.078\n",
      "Ep 1 (Step 028295): Train loss 2.186, Val loss 2.086\n",
      "Ep 1 (Step 028300): Train loss 2.222, Val loss 2.093\n",
      "Ep 1 (Step 028305): Train loss 2.127, Val loss 2.089\n",
      "Ep 1 (Step 028310): Train loss 2.104, Val loss 2.088\n",
      "Ep 1 (Step 028315): Train loss 2.152, Val loss 2.080\n",
      "Ep 1 (Step 028320): Train loss 2.076, Val loss 2.076\n",
      "Ep 1 (Step 028325): Train loss 2.124, Val loss 2.091\n",
      "Ep 1 (Step 028330): Train loss 2.142, Val loss 2.095\n",
      "Ep 1 (Step 028335): Train loss 2.234, Val loss 2.106\n",
      "Ep 1 (Step 028340): Train loss 2.398, Val loss 2.106\n",
      "Ep 1 (Step 028345): Train loss 2.246, Val loss 2.104\n",
      "Ep 1 (Step 028350): Train loss 1.985, Val loss 2.106\n",
      "Ep 1 (Step 028355): Train loss 2.069, Val loss 2.106\n",
      "Ep 1 (Step 028360): Train loss 1.917, Val loss 2.096\n",
      "Ep 1 (Step 028365): Train loss 2.205, Val loss 2.100\n",
      "Ep 1 (Step 028370): Train loss 2.358, Val loss 2.109\n",
      "Ep 1 (Step 028375): Train loss 1.872, Val loss 2.104\n",
      "Ep 1 (Step 028380): Train loss 2.187, Val loss 2.098\n",
      "Ep 1 (Step 028385): Train loss 2.083, Val loss 2.100\n",
      "Ep 1 (Step 028390): Train loss 1.923, Val loss 2.103\n",
      "Ep 1 (Step 028395): Train loss 2.446, Val loss 2.094\n",
      "Ep 1 (Step 028400): Train loss 2.134, Val loss 2.095\n",
      "Ep 1 (Step 028405): Train loss 1.983, Val loss 2.092\n",
      "Ep 1 (Step 028410): Train loss 2.069, Val loss 2.098\n",
      "Ep 1 (Step 028415): Train loss 2.251, Val loss 2.104\n",
      "Ep 1 (Step 028420): Train loss 2.166, Val loss 2.090\n",
      "Ep 1 (Step 028425): Train loss 1.977, Val loss 2.082\n",
      "Ep 1 (Step 028430): Train loss 1.950, Val loss 2.079\n",
      "Ep 1 (Step 028435): Train loss 2.120, Val loss 2.090\n",
      "Ep 1 (Step 028440): Train loss 1.809, Val loss 2.100\n",
      "Ep 1 (Step 028445): Train loss 1.838, Val loss 2.107\n",
      "Ep 1 (Step 028450): Train loss 2.311, Val loss 2.109\n",
      "Ep 1 (Step 028455): Train loss 2.430, Val loss 2.118\n",
      "Ep 1 (Step 028460): Train loss 2.172, Val loss 2.117\n",
      "Ep 1 (Step 028465): Train loss 2.203, Val loss 2.125\n",
      "Ep 1 (Step 028470): Train loss 2.130, Val loss 2.122\n",
      "Ep 1 (Step 028475): Train loss 2.298, Val loss 2.123\n",
      "Ep 1 (Step 028480): Train loss 2.165, Val loss 2.110\n",
      "Ep 1 (Step 028485): Train loss 2.036, Val loss 2.096\n",
      "Ep 1 (Step 028490): Train loss 2.430, Val loss 2.090\n",
      "Ep 1 (Step 028495): Train loss 2.259, Val loss 2.094\n",
      "Ep 1 (Step 028500): Train loss 2.029, Val loss 2.095\n",
      "Ep 1 (Step 028505): Train loss 2.016, Val loss 2.095\n",
      "Ep 1 (Step 028510): Train loss 2.049, Val loss 2.093\n",
      "Ep 1 (Step 028515): Train loss 2.027, Val loss 2.097\n",
      "Ep 1 (Step 028520): Train loss 2.340, Val loss 2.099\n",
      "Ep 1 (Step 028525): Train loss 2.065, Val loss 2.093\n",
      "Ep 1 (Step 028530): Train loss 2.025, Val loss 2.081\n",
      "Ep 1 (Step 028535): Train loss 2.154, Val loss 2.079\n",
      "Ep 1 (Step 028540): Train loss 2.559, Val loss 2.076\n",
      "Ep 1 (Step 028545): Train loss 2.129, Val loss 2.081\n",
      "Ep 1 (Step 028550): Train loss 2.205, Val loss 2.088\n",
      "Ep 1 (Step 028555): Train loss 2.217, Val loss 2.084\n",
      "Ep 1 (Step 028560): Train loss 2.162, Val loss 2.085\n",
      "Ep 1 (Step 028565): Train loss 2.091, Val loss 2.087\n",
      "Ep 1 (Step 028570): Train loss 2.041, Val loss 2.087\n",
      "Ep 1 (Step 028575): Train loss 2.278, Val loss 2.093\n",
      "Ep 1 (Step 028580): Train loss 2.245, Val loss 2.092\n",
      "Ep 1 (Step 028585): Train loss 2.191, Val loss 2.095\n",
      "Ep 1 (Step 028590): Train loss 1.918, Val loss 2.097\n",
      "Ep 1 (Step 028595): Train loss 2.029, Val loss 2.093\n",
      "Ep 1 (Step 028600): Train loss 2.062, Val loss 2.089\n",
      "Ep 1 (Step 028605): Train loss 2.261, Val loss 2.094\n",
      "Ep 1 (Step 028610): Train loss 2.261, Val loss 2.086\n",
      "Ep 1 (Step 028615): Train loss 2.100, Val loss 2.091\n",
      "Ep 1 (Step 028620): Train loss 2.183, Val loss 2.086\n",
      "Ep 1 (Step 028625): Train loss 2.205, Val loss 2.079\n",
      "Ep 1 (Step 028630): Train loss 2.190, Val loss 2.083\n",
      "Ep 1 (Step 028635): Train loss 2.218, Val loss 2.091\n",
      "Ep 1 (Step 028640): Train loss 1.897, Val loss 2.087\n",
      "Ep 1 (Step 028645): Train loss 2.385, Val loss 2.081\n",
      "Ep 1 (Step 028650): Train loss 2.314, Val loss 2.074\n",
      "Ep 1 (Step 028655): Train loss 2.134, Val loss 2.079\n",
      "Ep 1 (Step 028660): Train loss 1.878, Val loss 2.074\n",
      "Ep 1 (Step 028665): Train loss 2.121, Val loss 2.063\n",
      "Ep 1 (Step 028670): Train loss 1.890, Val loss 2.068\n",
      "Ep 1 (Step 028675): Train loss 2.276, Val loss 2.058\n",
      "Ep 1 (Step 028680): Train loss 2.174, Val loss 2.061\n",
      "Ep 1 (Step 028685): Train loss 1.829, Val loss 2.073\n",
      "Ep 1 (Step 028690): Train loss 1.991, Val loss 2.077\n",
      "Ep 1 (Step 028695): Train loss 2.046, Val loss 2.084\n",
      "Ep 1 (Step 028700): Train loss 2.148, Val loss 2.077\n",
      "Ep 1 (Step 028705): Train loss 2.367, Val loss 2.078\n",
      "Ep 1 (Step 028710): Train loss 2.054, Val loss 2.080\n",
      "Ep 1 (Step 028715): Train loss 2.053, Val loss 2.095\n",
      "Ep 1 (Step 028720): Train loss 2.181, Val loss 2.092\n",
      "Ep 1 (Step 028725): Train loss 2.301, Val loss 2.089\n",
      "Ep 1 (Step 028730): Train loss 1.903, Val loss 2.092\n",
      "Ep 1 (Step 028735): Train loss 1.897, Val loss 2.087\n",
      "Ep 1 (Step 028740): Train loss 2.070, Val loss 2.090\n",
      "Ep 1 (Step 028745): Train loss 2.221, Val loss 2.096\n",
      "Ep 1 (Step 028750): Train loss 2.113, Val loss 2.097\n",
      "Ep 1 (Step 028755): Train loss 2.198, Val loss 2.093\n",
      "Ep 1 (Step 028760): Train loss 2.107, Val loss 2.089\n",
      "Ep 1 (Step 028765): Train loss 1.965, Val loss 2.089\n",
      "Ep 1 (Step 028770): Train loss 2.104, Val loss 2.085\n",
      "Ep 1 (Step 028775): Train loss 2.169, Val loss 2.091\n",
      "Ep 1 (Step 028780): Train loss 1.827, Val loss 2.101\n",
      "Ep 1 (Step 028785): Train loss 1.958, Val loss 2.110\n",
      "Ep 1 (Step 028790): Train loss 2.225, Val loss 2.109\n",
      "Ep 1 (Step 028795): Train loss 2.093, Val loss 2.101\n",
      "Ep 1 (Step 028800): Train loss 2.140, Val loss 2.096\n",
      "Ep 1 (Step 028805): Train loss 2.157, Val loss 2.110\n",
      "Ep 1 (Step 028810): Train loss 2.023, Val loss 2.103\n",
      "Ep 1 (Step 028815): Train loss 2.208, Val loss 2.097\n",
      "Ep 1 (Step 028820): Train loss 2.149, Val loss 2.095\n",
      "Ep 1 (Step 028825): Train loss 2.166, Val loss 2.096\n",
      "Ep 1 (Step 028830): Train loss 2.006, Val loss 2.105\n",
      "Ep 1 (Step 028835): Train loss 2.162, Val loss 2.098\n",
      "Ep 1 (Step 028840): Train loss 2.313, Val loss 2.095\n",
      "Ep 1 (Step 028845): Train loss 2.180, Val loss 2.098\n",
      "Ep 1 (Step 028850): Train loss 2.290, Val loss 2.086\n",
      "Ep 1 (Step 028855): Train loss 1.927, Val loss 2.079\n",
      "Ep 1 (Step 028860): Train loss 2.161, Val loss 2.085\n",
      "Ep 1 (Step 028865): Train loss 1.801, Val loss 2.090\n",
      "Ep 1 (Step 028870): Train loss 2.116, Val loss 2.100\n",
      "Ep 1 (Step 028875): Train loss 1.910, Val loss 2.095\n",
      "Ep 1 (Step 028880): Train loss 2.199, Val loss 2.090\n",
      "Ep 1 (Step 028885): Train loss 2.350, Val loss 2.096\n",
      "Ep 1 (Step 028890): Train loss 2.255, Val loss 2.104\n",
      "Ep 1 (Step 028895): Train loss 2.066, Val loss 2.091\n",
      "Ep 1 (Step 028900): Train loss 1.850, Val loss 2.090\n",
      "Ep 1 (Step 028905): Train loss 2.252, Val loss 2.098\n",
      "Ep 1 (Step 028910): Train loss 2.092, Val loss 2.094\n",
      "Ep 1 (Step 028915): Train loss 2.025, Val loss 2.089\n",
      "Ep 1 (Step 028920): Train loss 2.244, Val loss 2.090\n",
      "Ep 1 (Step 028925): Train loss 1.966, Val loss 2.097\n",
      "Ep 1 (Step 028930): Train loss 2.056, Val loss 2.099\n",
      "Ep 1 (Step 028935): Train loss 2.133, Val loss 2.090\n",
      "Ep 1 (Step 028940): Train loss 2.029, Val loss 2.090\n",
      "Ep 1 (Step 028945): Train loss 2.196, Val loss 2.093\n",
      "Ep 1 (Step 028950): Train loss 2.157, Val loss 2.105\n",
      "Ep 1 (Step 028955): Train loss 2.466, Val loss 2.102\n",
      "Ep 1 (Step 028960): Train loss 1.883, Val loss 2.098\n",
      "Ep 1 (Step 028965): Train loss 2.214, Val loss 2.091\n",
      "Ep 1 (Step 028970): Train loss 2.024, Val loss 2.089\n",
      "Ep 1 (Step 028975): Train loss 2.092, Val loss 2.088\n",
      "Ep 1 (Step 028980): Train loss 2.486, Val loss 2.084\n",
      "Ep 1 (Step 028985): Train loss 2.060, Val loss 2.091\n",
      "Ep 1 (Step 028990): Train loss 2.207, Val loss 2.082\n",
      "Ep 1 (Step 028995): Train loss 2.063, Val loss 2.084\n",
      "Ep 1 (Step 029000): Train loss 1.949, Val loss 2.076\n",
      "Ep 1 (Step 029005): Train loss 2.162, Val loss 2.066\n",
      "Ep 1 (Step 029010): Train loss 2.334, Val loss 2.070\n",
      "Ep 1 (Step 029015): Train loss 2.211, Val loss 2.075\n",
      "Ep 1 (Step 029020): Train loss 2.350, Val loss 2.077\n",
      "Ep 1 (Step 029025): Train loss 2.358, Val loss 2.082\n",
      "Ep 1 (Step 029030): Train loss 2.346, Val loss 2.094\n",
      "Ep 1 (Step 029035): Train loss 1.744, Val loss 2.092\n",
      "Ep 1 (Step 029040): Train loss 2.280, Val loss 2.089\n",
      "Ep 1 (Step 029045): Train loss 2.283, Val loss 2.103\n",
      "Ep 1 (Step 029050): Train loss 2.286, Val loss 2.106\n",
      "Ep 1 (Step 029055): Train loss 2.145, Val loss 2.099\n",
      "Ep 1 (Step 029060): Train loss 2.344, Val loss 2.091\n",
      "Ep 1 (Step 029065): Train loss 2.332, Val loss 2.082\n",
      "Ep 1 (Step 029070): Train loss 2.182, Val loss 2.078\n",
      "Ep 1 (Step 029075): Train loss 1.943, Val loss 2.086\n",
      "Ep 1 (Step 029080): Train loss 2.105, Val loss 2.102\n",
      "Ep 1 (Step 029085): Train loss 2.231, Val loss 2.101\n",
      "Ep 1 (Step 029090): Train loss 1.974, Val loss 2.103\n",
      "Ep 1 (Step 029095): Train loss 1.821, Val loss 2.096\n",
      "Ep 1 (Step 029100): Train loss 2.245, Val loss 2.084\n",
      "Ep 1 (Step 029105): Train loss 2.177, Val loss 2.093\n",
      "Ep 1 (Step 029110): Train loss 1.920, Val loss 2.094\n",
      "Ep 1 (Step 029115): Train loss 2.048, Val loss 2.107\n",
      "Ep 1 (Step 029120): Train loss 1.835, Val loss 2.092\n",
      "Ep 1 (Step 029125): Train loss 2.222, Val loss 2.084\n",
      "Ep 1 (Step 029130): Train loss 2.063, Val loss 2.078\n",
      "Ep 1 (Step 029135): Train loss 1.900, Val loss 2.078\n",
      "Ep 1 (Step 029140): Train loss 2.260, Val loss 2.080\n",
      "Ep 1 (Step 029145): Train loss 2.107, Val loss 2.081\n",
      "Ep 1 (Step 029150): Train loss 2.026, Val loss 2.080\n",
      "Ep 1 (Step 029155): Train loss 1.924, Val loss 2.087\n",
      "Ep 1 (Step 029160): Train loss 1.931, Val loss 2.073\n",
      "Ep 1 (Step 029165): Train loss 2.067, Val loss 2.067\n",
      "Ep 1 (Step 029170): Train loss 1.857, Val loss 2.076\n",
      "Ep 1 (Step 029175): Train loss 2.102, Val loss 2.091\n",
      "Ep 1 (Step 029180): Train loss 2.037, Val loss 2.091\n",
      "Ep 1 (Step 029185): Train loss 1.898, Val loss 2.081\n",
      "Ep 1 (Step 029190): Train loss 1.849, Val loss 2.089\n",
      "Ep 1 (Step 029195): Train loss 2.156, Val loss 2.083\n",
      "Ep 1 (Step 029200): Train loss 2.143, Val loss 2.071\n",
      "Ep 1 (Step 029205): Train loss 2.063, Val loss 2.063\n",
      "Ep 1 (Step 029210): Train loss 2.250, Val loss 2.068\n",
      "Ep 1 (Step 029215): Train loss 2.120, Val loss 2.060\n",
      "Ep 1 (Step 029220): Train loss 2.161, Val loss 2.050\n",
      "Ep 1 (Step 029225): Train loss 2.084, Val loss 2.055\n",
      "Ep 1 (Step 029230): Train loss 2.080, Val loss 2.069\n",
      "Ep 1 (Step 029235): Train loss 2.202, Val loss 2.068\n",
      "Ep 1 (Step 029240): Train loss 2.186, Val loss 2.062\n",
      "Ep 1 (Step 029245): Train loss 2.166, Val loss 2.050\n",
      "Ep 1 (Step 029250): Train loss 1.945, Val loss 2.055\n",
      "Ep 1 (Step 029255): Train loss 2.261, Val loss 2.056\n",
      "Ep 1 (Step 029260): Train loss 2.072, Val loss 2.057\n",
      "Ep 1 (Step 029265): Train loss 2.208, Val loss 2.057\n",
      "Ep 1 (Step 029270): Train loss 2.290, Val loss 2.056\n",
      "Ep 1 (Step 029275): Train loss 2.235, Val loss 2.051\n",
      "Ep 1 (Step 029280): Train loss 2.144, Val loss 2.054\n",
      "Ep 1 (Step 029285): Train loss 2.229, Val loss 2.057\n",
      "Ep 1 (Step 029290): Train loss 1.882, Val loss 2.063\n",
      "Ep 1 (Step 029295): Train loss 2.372, Val loss 2.068\n",
      "Ep 1 (Step 029300): Train loss 2.197, Val loss 2.069\n",
      "Ep 1 (Step 029305): Train loss 2.133, Val loss 2.074\n",
      "Ep 1 (Step 029310): Train loss 2.044, Val loss 2.068\n",
      "Ep 1 (Step 029315): Train loss 1.972, Val loss 2.065\n",
      "Ep 1 (Step 029320): Train loss 2.051, Val loss 2.063\n",
      "Ep 1 (Step 029325): Train loss 2.168, Val loss 2.071\n",
      "Ep 1 (Step 029330): Train loss 2.098, Val loss 2.092\n",
      "Ep 1 (Step 029335): Train loss 2.080, Val loss 2.088\n",
      "Ep 1 (Step 029340): Train loss 2.104, Val loss 2.068\n",
      "Ep 1 (Step 029345): Train loss 2.032, Val loss 2.060\n",
      "Ep 1 (Step 029350): Train loss 2.062, Val loss 2.056\n",
      "Ep 1 (Step 029355): Train loss 1.978, Val loss 2.055\n",
      "Ep 1 (Step 029360): Train loss 1.810, Val loss 2.050\n",
      "Ep 1 (Step 029365): Train loss 1.992, Val loss 2.049\n",
      "Ep 1 (Step 029370): Train loss 1.864, Val loss 2.055\n",
      "Ep 1 (Step 029375): Train loss 2.312, Val loss 2.061\n",
      "Ep 1 (Step 029380): Train loss 2.307, Val loss 2.056\n",
      "Ep 1 (Step 029385): Train loss 2.102, Val loss 2.058\n",
      "Ep 1 (Step 029390): Train loss 1.919, Val loss 2.059\n",
      "Ep 1 (Step 029395): Train loss 2.307, Val loss 2.061\n",
      "Ep 1 (Step 029400): Train loss 1.953, Val loss 2.061\n",
      "Ep 1 (Step 029405): Train loss 2.206, Val loss 2.060\n",
      "Ep 1 (Step 029410): Train loss 2.215, Val loss 2.053\n",
      "Ep 1 (Step 029415): Train loss 2.038, Val loss 2.051\n",
      "Ep 1 (Step 029420): Train loss 2.005, Val loss 2.051\n",
      "Ep 1 (Step 029425): Train loss 2.043, Val loss 2.068\n",
      "Ep 1 (Step 029430): Train loss 2.044, Val loss 2.043\n",
      "Ep 1 (Step 029435): Train loss 1.830, Val loss 2.043\n",
      "Ep 1 (Step 029440): Train loss 2.284, Val loss 2.048\n",
      "Ep 1 (Step 029445): Train loss 1.867, Val loss 2.048\n",
      "Ep 1 (Step 029450): Train loss 2.097, Val loss 2.051\n",
      "Ep 1 (Step 029455): Train loss 1.941, Val loss 2.057\n",
      "Ep 1 (Step 029460): Train loss 2.116, Val loss 2.073\n",
      "Ep 1 (Step 029465): Train loss 2.178, Val loss 2.079\n",
      "Ep 1 (Step 029470): Train loss 2.144, Val loss 2.073\n",
      "Ep 1 (Step 029475): Train loss 2.028, Val loss 2.075\n",
      "Ep 1 (Step 029480): Train loss 2.232, Val loss 2.077\n",
      "Ep 1 (Step 029485): Train loss 2.293, Val loss 2.077\n",
      "Ep 1 (Step 029490): Train loss 1.991, Val loss 2.069\n",
      "Ep 1 (Step 029495): Train loss 1.958, Val loss 2.076\n",
      "Ep 1 (Step 029500): Train loss 2.056, Val loss 2.083\n",
      "Ep 1 (Step 029505): Train loss 2.153, Val loss 2.078\n",
      "Ep 1 (Step 029510): Train loss 2.056, Val loss 2.074\n",
      "Ep 1 (Step 029515): Train loss 2.261, Val loss 2.082\n",
      "Ep 1 (Step 029520): Train loss 1.932, Val loss 2.081\n",
      "Ep 1 (Step 029525): Train loss 2.274, Val loss 2.066\n",
      "Ep 1 (Step 029530): Train loss 2.051, Val loss 2.062\n",
      "Ep 1 (Step 029535): Train loss 2.193, Val loss 2.062\n",
      "Ep 1 (Step 029540): Train loss 1.897, Val loss 2.063\n",
      "Ep 1 (Step 029545): Train loss 2.254, Val loss 2.064\n",
      "Ep 1 (Step 029550): Train loss 2.041, Val loss 2.072\n",
      "Ep 1 (Step 029555): Train loss 2.075, Val loss 2.079\n",
      "Ep 1 (Step 029560): Train loss 1.860, Val loss 2.075\n",
      "Ep 1 (Step 029565): Train loss 2.010, Val loss 2.062\n",
      "Ep 1 (Step 029570): Train loss 2.068, Val loss 2.050\n",
      "Ep 1 (Step 029575): Train loss 2.108, Val loss 2.043\n",
      "Ep 1 (Step 029580): Train loss 2.157, Val loss 2.039\n",
      "Ep 1 (Step 029585): Train loss 2.094, Val loss 2.049\n",
      "Ep 1 (Step 029590): Train loss 2.172, Val loss 2.047\n",
      "Ep 1 (Step 029595): Train loss 2.140, Val loss 2.045\n",
      "Ep 1 (Step 029600): Train loss 2.253, Val loss 2.042\n",
      "Ep 1 (Step 029605): Train loss 2.211, Val loss 2.047\n",
      "Ep 1 (Step 029610): Train loss 2.175, Val loss 2.057\n",
      "Ep 1 (Step 029615): Train loss 2.137, Val loss 2.063\n",
      "Ep 1 (Step 029620): Train loss 1.875, Val loss 2.057\n",
      "Ep 1 (Step 029625): Train loss 2.388, Val loss 2.055\n",
      "Ep 1 (Step 029630): Train loss 1.991, Val loss 2.039\n",
      "Ep 1 (Step 029635): Train loss 1.988, Val loss 2.026\n",
      "Ep 1 (Step 029640): Train loss 1.889, Val loss 2.033\n",
      "Ep 1 (Step 029645): Train loss 2.096, Val loss 2.041\n",
      "Ep 1 (Step 029650): Train loss 2.124, Val loss 2.055\n",
      "Ep 1 (Step 029655): Train loss 2.045, Val loss 2.066\n",
      "Ep 1 (Step 029660): Train loss 2.067, Val loss 2.061\n",
      "Ep 1 (Step 029665): Train loss 2.053, Val loss 2.053\n",
      "Ep 1 (Step 029670): Train loss 2.057, Val loss 2.049\n",
      "Ep 1 (Step 029675): Train loss 2.183, Val loss 2.054\n",
      "Ep 1 (Step 029680): Train loss 2.173, Val loss 2.051\n",
      "Ep 1 (Step 029685): Train loss 2.206, Val loss 2.052\n",
      "Ep 1 (Step 029690): Train loss 1.892, Val loss 2.050\n",
      "Ep 1 (Step 029695): Train loss 2.173, Val loss 2.044\n",
      "Ep 1 (Step 029700): Train loss 1.921, Val loss 2.054\n",
      "Ep 1 (Step 029705): Train loss 2.204, Val loss 2.074\n",
      "Ep 1 (Step 029710): Train loss 2.521, Val loss 2.070\n",
      "Ep 1 (Step 029715): Train loss 2.038, Val loss 2.057\n",
      "Ep 1 (Step 029720): Train loss 2.259, Val loss 2.054\n",
      "Ep 1 (Step 029725): Train loss 2.008, Val loss 2.056\n",
      "Ep 1 (Step 029730): Train loss 2.053, Val loss 2.053\n",
      "Ep 1 (Step 029735): Train loss 1.925, Val loss 2.054\n",
      "Ep 1 (Step 029740): Train loss 1.937, Val loss 2.050\n",
      "Ep 1 (Step 029745): Train loss 2.170, Val loss 2.046\n",
      "Ep 1 (Step 029750): Train loss 2.049, Val loss 2.044\n",
      "Ep 1 (Step 029755): Train loss 2.352, Val loss 2.039\n",
      "Ep 1 (Step 029760): Train loss 2.353, Val loss 2.037\n",
      "Ep 1 (Step 029765): Train loss 2.184, Val loss 2.046\n",
      "Ep 1 (Step 029770): Train loss 1.955, Val loss 2.042\n",
      "Ep 1 (Step 029775): Train loss 2.035, Val loss 2.037\n",
      "Ep 1 (Step 029780): Train loss 2.111, Val loss 2.036\n",
      "Ep 1 (Step 029785): Train loss 2.036, Val loss 2.042\n",
      "Ep 1 (Step 029790): Train loss 2.255, Val loss 2.033\n",
      "Ep 1 (Step 029795): Train loss 2.237, Val loss 2.032\n",
      "Ep 1 (Step 029800): Train loss 2.224, Val loss 2.028\n",
      "Ep 1 (Step 029805): Train loss 2.286, Val loss 2.034\n",
      "Ep 1 (Step 029810): Train loss 2.341, Val loss 2.044\n",
      "Ep 1 (Step 029815): Train loss 2.416, Val loss 2.048\n",
      "Ep 1 (Step 029820): Train loss 2.082, Val loss 2.055\n",
      "Ep 1 (Step 029825): Train loss 2.196, Val loss 2.052\n",
      "Ep 1 (Step 029830): Train loss 2.249, Val loss 2.047\n",
      "Ep 1 (Step 029835): Train loss 2.138, Val loss 2.046\n",
      "Ep 1 (Step 029840): Train loss 2.004, Val loss 2.051\n",
      "Ep 1 (Step 029845): Train loss 2.282, Val loss 2.047\n",
      "Ep 1 (Step 029850): Train loss 2.000, Val loss 2.041\n",
      "Ep 1 (Step 029855): Train loss 2.099, Val loss 2.042\n",
      "Ep 1 (Step 029860): Train loss 2.084, Val loss 2.047\n",
      "Ep 1 (Step 029865): Train loss 2.039, Val loss 2.057\n",
      "Ep 1 (Step 029870): Train loss 2.114, Val loss 2.053\n",
      "Ep 1 (Step 029875): Train loss 2.266, Val loss 2.053\n",
      "Ep 1 (Step 029880): Train loss 2.336, Val loss 2.058\n",
      "Ep 1 (Step 029885): Train loss 1.984, Val loss 2.056\n",
      "Ep 1 (Step 029890): Train loss 2.070, Val loss 2.065\n",
      "Ep 1 (Step 029895): Train loss 2.118, Val loss 2.073\n",
      "Ep 1 (Step 029900): Train loss 2.131, Val loss 2.068\n",
      "Ep 1 (Step 029905): Train loss 1.946, Val loss 2.066\n",
      "Ep 1 (Step 029910): Train loss 1.984, Val loss 2.057\n",
      "Ep 1 (Step 029915): Train loss 2.140, Val loss 2.052\n",
      "Ep 1 (Step 029920): Train loss 2.189, Val loss 2.047\n",
      "Ep 1 (Step 029925): Train loss 2.028, Val loss 2.055\n",
      "Ep 1 (Step 029930): Train loss 1.976, Val loss 2.060\n",
      "Ep 1 (Step 029935): Train loss 2.207, Val loss 2.058\n",
      "Ep 1 (Step 029940): Train loss 2.072, Val loss 2.058\n",
      "Ep 1 (Step 029945): Train loss 2.063, Val loss 2.056\n",
      "Ep 1 (Step 029950): Train loss 2.003, Val loss 2.060\n",
      "Ep 1 (Step 029955): Train loss 1.987, Val loss 2.060\n",
      "Ep 1 (Step 029960): Train loss 2.133, Val loss 2.047\n",
      "Ep 1 (Step 029965): Train loss 1.933, Val loss 2.046\n",
      "Ep 1 (Step 029970): Train loss 1.963, Val loss 2.055\n",
      "Ep 1 (Step 029975): Train loss 2.247, Val loss 2.065\n",
      "Ep 1 (Step 029980): Train loss 2.101, Val loss 2.054\n",
      "Ep 1 (Step 029985): Train loss 2.218, Val loss 2.058\n",
      "Ep 1 (Step 029990): Train loss 2.156, Val loss 2.056\n",
      "Ep 1 (Step 029995): Train loss 2.260, Val loss 2.056\n",
      "Ep 1 (Step 030000): Train loss 2.192, Val loss 2.053\n",
      "Ep 1 (Step 030005): Train loss 2.107, Val loss 2.063\n",
      "Ep 1 (Step 030010): Train loss 1.920, Val loss 2.067\n",
      "Ep 1 (Step 030015): Train loss 2.089, Val loss 2.067\n",
      "Ep 1 (Step 030020): Train loss 2.419, Val loss 2.073\n",
      "Ep 1 (Step 030025): Train loss 1.818, Val loss 2.062\n",
      "Ep 1 (Step 030030): Train loss 2.087, Val loss 2.060\n",
      "Ep 1 (Step 030035): Train loss 2.022, Val loss 2.063\n",
      "Ep 1 (Step 030040): Train loss 2.799, Val loss 2.053\n",
      "Ep 1 (Step 030045): Train loss 2.129, Val loss 2.047\n",
      "Ep 1 (Step 030050): Train loss 2.007, Val loss 2.040\n",
      "Ep 1 (Step 030055): Train loss 2.185, Val loss 2.032\n",
      "Ep 1 (Step 030060): Train loss 2.216, Val loss 2.029\n",
      "Ep 1 (Step 030065): Train loss 2.031, Val loss 2.027\n",
      "Ep 1 (Step 030070): Train loss 2.329, Val loss 2.031\n",
      "Ep 1 (Step 030075): Train loss 2.008, Val loss 2.027\n",
      "Ep 1 (Step 030080): Train loss 2.052, Val loss 2.020\n",
      "Ep 1 (Step 030085): Train loss 1.947, Val loss 2.030\n",
      "Ep 1 (Step 030090): Train loss 2.172, Val loss 2.036\n",
      "Ep 1 (Step 030095): Train loss 2.090, Val loss 2.030\n",
      "Ep 1 (Step 030100): Train loss 1.886, Val loss 2.043\n",
      "Ep 1 (Step 030105): Train loss 1.863, Val loss 2.043\n",
      "Ep 1 (Step 030110): Train loss 1.845, Val loss 2.043\n",
      "Ep 1 (Step 030115): Train loss 1.832, Val loss 2.049\n",
      "Ep 1 (Step 030120): Train loss 2.036, Val loss 2.053\n",
      "Ep 1 (Step 030125): Train loss 2.033, Val loss 2.050\n",
      "Ep 1 (Step 030130): Train loss 1.797, Val loss 2.049\n",
      "Ep 1 (Step 030135): Train loss 2.154, Val loss 2.045\n",
      "Ep 1 (Step 030140): Train loss 2.395, Val loss 2.042\n",
      "Ep 1 (Step 030145): Train loss 2.331, Val loss 2.043\n",
      "Ep 1 (Step 030150): Train loss 1.895, Val loss 2.039\n",
      "Ep 1 (Step 030155): Train loss 2.343, Val loss 2.031\n",
      "Ep 1 (Step 030160): Train loss 2.054, Val loss 2.027\n",
      "Ep 1 (Step 030165): Train loss 2.257, Val loss 2.036\n",
      "Ep 1 (Step 030170): Train loss 2.138, Val loss 2.052\n",
      "Ep 1 (Step 030175): Train loss 2.185, Val loss 2.051\n",
      "Ep 1 (Step 030180): Train loss 2.201, Val loss 2.041\n",
      "Ep 1 (Step 030185): Train loss 2.195, Val loss 2.043\n",
      "Ep 1 (Step 030190): Train loss 2.076, Val loss 2.051\n",
      "Ep 1 (Step 030195): Train loss 1.871, Val loss 2.057\n",
      "Ep 1 (Step 030200): Train loss 2.062, Val loss 2.059\n",
      "Ep 1 (Step 030205): Train loss 1.956, Val loss 2.064\n",
      "Ep 1 (Step 030210): Train loss 2.141, Val loss 2.060\n",
      "Ep 1 (Step 030215): Train loss 1.864, Val loss 2.061\n",
      "Ep 1 (Step 030220): Train loss 1.921, Val loss 2.065\n",
      "Ep 1 (Step 030225): Train loss 2.310, Val loss 2.062\n",
      "Ep 1 (Step 030230): Train loss 2.188, Val loss 2.061\n",
      "Ep 1 (Step 030235): Train loss 1.973, Val loss 2.069\n",
      "Ep 1 (Step 030240): Train loss 2.500, Val loss 2.066\n",
      "Ep 1 (Step 030245): Train loss 2.212, Val loss 2.056\n",
      "Ep 1 (Step 030250): Train loss 2.130, Val loss 2.044\n",
      "Ep 1 (Step 030255): Train loss 2.014, Val loss 2.041\n",
      "Ep 1 (Step 030260): Train loss 2.071, Val loss 2.031\n",
      "Ep 1 (Step 030265): Train loss 1.819, Val loss 2.036\n",
      "Ep 1 (Step 030270): Train loss 2.234, Val loss 2.049\n",
      "Ep 1 (Step 030275): Train loss 2.125, Val loss 2.062\n",
      "Ep 1 (Step 030280): Train loss 2.263, Val loss 2.061\n",
      "Ep 1 (Step 030285): Train loss 2.159, Val loss 2.063\n",
      "Ep 1 (Step 030290): Train loss 1.898, Val loss 2.069\n",
      "Ep 1 (Step 030295): Train loss 1.853, Val loss 2.070\n",
      "Ep 1 (Step 030300): Train loss 1.892, Val loss 2.061\n",
      "Ep 1 (Step 030305): Train loss 2.020, Val loss 2.049\n",
      "Ep 1 (Step 030310): Train loss 1.950, Val loss 2.042\n",
      "Ep 1 (Step 030315): Train loss 2.168, Val loss 2.039\n",
      "Ep 1 (Step 030320): Train loss 2.056, Val loss 2.035\n",
      "Ep 1 (Step 030325): Train loss 2.051, Val loss 2.030\n",
      "Ep 1 (Step 030330): Train loss 2.014, Val loss 2.038\n",
      "Ep 1 (Step 030335): Train loss 1.932, Val loss 2.043\n",
      "Ep 1 (Step 030340): Train loss 2.046, Val loss 2.044\n",
      "Ep 1 (Step 030345): Train loss 1.875, Val loss 2.038\n",
      "Ep 1 (Step 030350): Train loss 1.852, Val loss 2.038\n",
      "Ep 1 (Step 030355): Train loss 2.166, Val loss 2.042\n",
      "Ep 1 (Step 030360): Train loss 1.992, Val loss 2.053\n",
      "Ep 1 (Step 030365): Train loss 2.146, Val loss 2.051\n",
      "Ep 1 (Step 030370): Train loss 2.051, Val loss 2.047\n",
      "Ep 1 (Step 030375): Train loss 1.964, Val loss 2.053\n",
      "Ep 1 (Step 030380): Train loss 1.907, Val loss 2.066\n",
      "Ep 1 (Step 030385): Train loss 2.004, Val loss 2.059\n",
      "Ep 1 (Step 030390): Train loss 1.865, Val loss 2.047\n",
      "Ep 1 (Step 030395): Train loss 1.964, Val loss 2.036\n",
      "Ep 1 (Step 030400): Train loss 1.760, Val loss 2.035\n",
      "Ep 1 (Step 030405): Train loss 2.040, Val loss 2.042\n",
      "Ep 1 (Step 030410): Train loss 2.158, Val loss 2.046\n",
      "Ep 1 (Step 030415): Train loss 2.537, Val loss 2.064\n",
      "Ep 1 (Step 030420): Train loss 2.202, Val loss 2.058\n",
      "Ep 1 (Step 030425): Train loss 2.570, Val loss 2.048\n",
      "Ep 1 (Step 030430): Train loss 2.165, Val loss 2.044\n",
      "Ep 1 (Step 030435): Train loss 2.232, Val loss 2.049\n",
      "Ep 1 (Step 030440): Train loss 2.009, Val loss 2.056\n",
      "Ep 1 (Step 030445): Train loss 1.863, Val loss 2.061\n",
      "Ep 1 (Step 030450): Train loss 2.113, Val loss 2.059\n",
      "Ep 1 (Step 030455): Train loss 2.308, Val loss 2.055\n",
      "Ep 1 (Step 030460): Train loss 1.937, Val loss 2.064\n",
      "Ep 1 (Step 030465): Train loss 2.064, Val loss 2.076\n",
      "Ep 1 (Step 030470): Train loss 2.115, Val loss 2.067\n",
      "Ep 1 (Step 030475): Train loss 2.363, Val loss 2.065\n",
      "Ep 1 (Step 030480): Train loss 1.985, Val loss 2.072\n",
      "Ep 1 (Step 030485): Train loss 2.005, Val loss 2.078\n",
      "Ep 1 (Step 030490): Train loss 1.962, Val loss 2.092\n",
      "Ep 1 (Step 030495): Train loss 2.054, Val loss 2.097\n",
      "Ep 1 (Step 030500): Train loss 2.144, Val loss 2.090\n",
      "Ep 1 (Step 030505): Train loss 2.097, Val loss 2.084\n",
      "Ep 1 (Step 030510): Train loss 1.857, Val loss 2.078\n",
      "Ep 1 (Step 030515): Train loss 2.195, Val loss 2.072\n",
      "Ep 1 (Step 030520): Train loss 2.306, Val loss 2.070\n",
      "Ep 1 (Step 030525): Train loss 2.057, Val loss 2.069\n",
      "Ep 1 (Step 030530): Train loss 2.103, Val loss 2.074\n",
      "Ep 1 (Step 030535): Train loss 1.869, Val loss 2.078\n",
      "Ep 1 (Step 030540): Train loss 2.290, Val loss 2.064\n",
      "Ep 1 (Step 030545): Train loss 1.963, Val loss 2.065\n",
      "Ep 1 (Step 030550): Train loss 2.391, Val loss 2.063\n",
      "Ep 1 (Step 030555): Train loss 2.061, Val loss 2.065\n",
      "Ep 1 (Step 030560): Train loss 2.172, Val loss 2.071\n",
      "Ep 1 (Step 030565): Train loss 1.940, Val loss 2.072\n",
      "Ep 1 (Step 030570): Train loss 2.148, Val loss 2.069\n",
      "Ep 1 (Step 030575): Train loss 2.010, Val loss 2.062\n",
      "Ep 1 (Step 030580): Train loss 2.156, Val loss 2.065\n",
      "Ep 1 (Step 030585): Train loss 1.915, Val loss 2.063\n",
      "Ep 1 (Step 030590): Train loss 2.087, Val loss 2.062\n",
      "Ep 1 (Step 030595): Train loss 2.054, Val loss 2.063\n",
      "Ep 1 (Step 030600): Train loss 1.888, Val loss 2.072\n",
      "Ep 1 (Step 030605): Train loss 1.809, Val loss 2.080\n",
      "Ep 1 (Step 030610): Train loss 1.934, Val loss 2.089\n",
      "Ep 1 (Step 030615): Train loss 2.308, Val loss 2.086\n",
      "Ep 1 (Step 030620): Train loss 2.054, Val loss 2.074\n",
      "Ep 1 (Step 030625): Train loss 1.976, Val loss 2.073\n",
      "Ep 1 (Step 030630): Train loss 1.810, Val loss 2.075\n",
      "Ep 1 (Step 030635): Train loss 2.167, Val loss 2.079\n",
      "Ep 1 (Step 030640): Train loss 2.030, Val loss 2.087\n",
      "Ep 1 (Step 030645): Train loss 2.252, Val loss 2.081\n",
      "Ep 1 (Step 030650): Train loss 2.248, Val loss 2.069\n",
      "Ep 1 (Step 030655): Train loss 1.994, Val loss 2.058\n",
      "Ep 1 (Step 030660): Train loss 2.247, Val loss 2.065\n",
      "Ep 1 (Step 030665): Train loss 2.020, Val loss 2.062\n",
      "Ep 1 (Step 030670): Train loss 2.112, Val loss 2.051\n",
      "Ep 1 (Step 030675): Train loss 1.988, Val loss 2.052\n",
      "Ep 1 (Step 030680): Train loss 2.024, Val loss 2.059\n",
      "Ep 1 (Step 030685): Train loss 1.716, Val loss 2.062\n",
      "Ep 1 (Step 030690): Train loss 2.044, Val loss 2.066\n",
      "Ep 1 (Step 030695): Train loss 2.251, Val loss 2.067\n",
      "Ep 1 (Step 030700): Train loss 2.017, Val loss 2.063\n",
      "Ep 1 (Step 030705): Train loss 2.091, Val loss 2.073\n",
      "Ep 1 (Step 030710): Train loss 2.054, Val loss 2.062\n",
      "Ep 1 (Step 030715): Train loss 1.991, Val loss 2.064\n",
      "Ep 1 (Step 030720): Train loss 1.964, Val loss 2.070\n",
      "Ep 1 (Step 030725): Train loss 1.713, Val loss 2.069\n",
      "Ep 1 (Step 030730): Train loss 2.078, Val loss 2.066\n",
      "Ep 1 (Step 030735): Train loss 1.841, Val loss 2.059\n",
      "Ep 1 (Step 030740): Train loss 1.804, Val loss 2.072\n",
      "Ep 1 (Step 030745): Train loss 2.043, Val loss 2.075\n",
      "Ep 1 (Step 030750): Train loss 1.869, Val loss 2.075\n",
      "Ep 1 (Step 030755): Train loss 2.069, Val loss 2.066\n",
      "Ep 1 (Step 030760): Train loss 1.719, Val loss 2.064\n",
      "Ep 1 (Step 030765): Train loss 2.139, Val loss 2.063\n",
      "Ep 1 (Step 030770): Train loss 2.086, Val loss 2.053\n",
      "Ep 1 (Step 030775): Train loss 2.088, Val loss 2.049\n",
      "Ep 1 (Step 030780): Train loss 2.193, Val loss 2.054\n",
      "Ep 1 (Step 030785): Train loss 2.244, Val loss 2.066\n",
      "Ep 1 (Step 030790): Train loss 2.267, Val loss 2.051\n",
      "Ep 1 (Step 030795): Train loss 1.997, Val loss 2.049\n",
      "Ep 1 (Step 030800): Train loss 2.096, Val loss 2.052\n",
      "Ep 1 (Step 030805): Train loss 1.911, Val loss 2.049\n",
      "Ep 1 (Step 030810): Train loss 1.986, Val loss 2.045\n",
      "Ep 1 (Step 030815): Train loss 2.116, Val loss 2.042\n",
      "Ep 1 (Step 030820): Train loss 2.257, Val loss 2.047\n",
      "Ep 1 (Step 030825): Train loss 1.947, Val loss 2.055\n",
      "Ep 1 (Step 030830): Train loss 2.076, Val loss 2.058\n",
      "Ep 1 (Step 030835): Train loss 2.191, Val loss 2.053\n",
      "Ep 1 (Step 030840): Train loss 1.884, Val loss 2.048\n",
      "Ep 1 (Step 030845): Train loss 2.209, Val loss 2.042\n",
      "Ep 1 (Step 030850): Train loss 2.169, Val loss 2.036\n",
      "Ep 1 (Step 030855): Train loss 2.332, Val loss 2.040\n",
      "Ep 1 (Step 030860): Train loss 1.989, Val loss 2.038\n",
      "Ep 1 (Step 030865): Train loss 2.041, Val loss 2.031\n",
      "Ep 1 (Step 030870): Train loss 2.103, Val loss 2.024\n",
      "Ep 1 (Step 030875): Train loss 1.958, Val loss 2.023\n",
      "Ep 1 (Step 030880): Train loss 2.052, Val loss 2.033\n",
      "Ep 1 (Step 030885): Train loss 2.098, Val loss 2.028\n",
      "Ep 1 (Step 030890): Train loss 2.238, Val loss 2.020\n",
      "Ep 1 (Step 030895): Train loss 1.837, Val loss 2.015\n",
      "Ep 1 (Step 030900): Train loss 1.913, Val loss 2.019\n",
      "Ep 1 (Step 030905): Train loss 2.070, Val loss 2.024\n",
      "Ep 1 (Step 030910): Train loss 2.095, Val loss 2.024\n",
      "Ep 1 (Step 030915): Train loss 1.915, Val loss 2.035\n",
      "Ep 1 (Step 030920): Train loss 2.035, Val loss 2.043\n",
      "Ep 1 (Step 030925): Train loss 2.008, Val loss 2.042\n",
      "Ep 1 (Step 030930): Train loss 2.377, Val loss 2.040\n",
      "Ep 1 (Step 030935): Train loss 2.160, Val loss 2.040\n",
      "Ep 1 (Step 030940): Train loss 2.193, Val loss 2.043\n",
      "Ep 1 (Step 030945): Train loss 2.352, Val loss 2.049\n",
      "Ep 1 (Step 030950): Train loss 2.284, Val loss 2.051\n",
      "Ep 1 (Step 030955): Train loss 2.255, Val loss 2.049\n",
      "Ep 1 (Step 030960): Train loss 2.256, Val loss 2.051\n",
      "Ep 1 (Step 030965): Train loss 2.209, Val loss 2.041\n",
      "Ep 1 (Step 030970): Train loss 2.098, Val loss 2.041\n",
      "Ep 1 (Step 030975): Train loss 2.138, Val loss 2.042\n",
      "Ep 1 (Step 030980): Train loss 2.043, Val loss 2.043\n",
      "Ep 1 (Step 030985): Train loss 2.316, Val loss 2.044\n",
      "Ep 1 (Step 030990): Train loss 1.987, Val loss 2.047\n",
      "Ep 1 (Step 030995): Train loss 2.297, Val loss 2.046\n",
      "Ep 1 (Step 031000): Train loss 2.166, Val loss 2.053\n",
      "Ep 1 (Step 031005): Train loss 2.052, Val loss 2.053\n",
      "Ep 1 (Step 031010): Train loss 2.405, Val loss 2.044\n",
      "Ep 1 (Step 031015): Train loss 2.159, Val loss 2.036\n",
      "Ep 1 (Step 031020): Train loss 2.089, Val loss 2.032\n",
      "Ep 1 (Step 031025): Train loss 2.216, Val loss 2.042\n",
      "Ep 1 (Step 031030): Train loss 1.815, Val loss 2.039\n",
      "Ep 1 (Step 031035): Train loss 2.050, Val loss 2.030\n",
      "Ep 1 (Step 031040): Train loss 2.263, Val loss 2.023\n",
      "Ep 1 (Step 031045): Train loss 2.246, Val loss 2.018\n",
      "Ep 1 (Step 031050): Train loss 2.108, Val loss 2.018\n",
      "Ep 1 (Step 031055): Train loss 2.117, Val loss 2.022\n",
      "Ep 1 (Step 031060): Train loss 2.360, Val loss 2.030\n",
      "Ep 1 (Step 031065): Train loss 2.369, Val loss 2.028\n",
      "Ep 1 (Step 031070): Train loss 2.115, Val loss 2.013\n",
      "Ep 1 (Step 031075): Train loss 2.095, Val loss 2.008\n",
      "Ep 1 (Step 031080): Train loss 1.735, Val loss 2.018\n",
      "Ep 1 (Step 031085): Train loss 2.145, Val loss 2.026\n",
      "Ep 1 (Step 031090): Train loss 2.290, Val loss 2.036\n",
      "Ep 1 (Step 031095): Train loss 1.916, Val loss 2.036\n",
      "Ep 1 (Step 031100): Train loss 2.156, Val loss 2.029\n",
      "Ep 1 (Step 031105): Train loss 2.343, Val loss 2.036\n",
      "Ep 1 (Step 031110): Train loss 2.355, Val loss 2.037\n",
      "Ep 1 (Step 031115): Train loss 1.992, Val loss 2.032\n",
      "Ep 1 (Step 031120): Train loss 2.167, Val loss 2.037\n",
      "Ep 1 (Step 031125): Train loss 1.958, Val loss 2.032\n",
      "Ep 1 (Step 031130): Train loss 1.831, Val loss 2.034\n",
      "Ep 1 (Step 031135): Train loss 1.923, Val loss 2.032\n",
      "Ep 1 (Step 031140): Train loss 2.168, Val loss 2.034\n",
      "Ep 1 (Step 031145): Train loss 2.081, Val loss 2.041\n",
      "Ep 1 (Step 031150): Train loss 1.923, Val loss 2.032\n",
      "Ep 1 (Step 031155): Train loss 1.950, Val loss 2.024\n",
      "Ep 1 (Step 031160): Train loss 2.054, Val loss 2.027\n",
      "Ep 1 (Step 031165): Train loss 1.946, Val loss 2.027\n",
      "Ep 1 (Step 031170): Train loss 2.078, Val loss 2.026\n",
      "Ep 1 (Step 031175): Train loss 1.989, Val loss 2.028\n",
      "Ep 1 (Step 031180): Train loss 2.022, Val loss 2.029\n",
      "Ep 1 (Step 031185): Train loss 1.973, Val loss 2.033\n",
      "Ep 1 (Step 031190): Train loss 2.106, Val loss 2.032\n",
      "Ep 1 (Step 031195): Train loss 1.916, Val loss 2.033\n",
      "Ep 1 (Step 031200): Train loss 2.026, Val loss 2.042\n",
      "Ep 1 (Step 031205): Train loss 2.188, Val loss 2.040\n",
      "Ep 1 (Step 031210): Train loss 2.182, Val loss 2.021\n",
      "Ep 1 (Step 031215): Train loss 1.920, Val loss 2.011\n",
      "Ep 1 (Step 031220): Train loss 1.990, Val loss 2.014\n",
      "Ep 1 (Step 031225): Train loss 2.311, Val loss 2.026\n",
      "Ep 1 (Step 031230): Train loss 1.992, Val loss 2.034\n",
      "Ep 1 (Step 031235): Train loss 1.970, Val loss 2.032\n",
      "Ep 1 (Step 031240): Train loss 2.128, Val loss 2.025\n",
      "Ep 1 (Step 031245): Train loss 1.939, Val loss 2.022\n",
      "Ep 1 (Step 031250): Train loss 2.284, Val loss 2.023\n",
      "Ep 1 (Step 031255): Train loss 2.236, Val loss 2.018\n",
      "Ep 1 (Step 031260): Train loss 1.923, Val loss 2.007\n",
      "Ep 1 (Step 031265): Train loss 1.889, Val loss 2.005\n",
      "Ep 1 (Step 031270): Train loss 2.075, Val loss 2.000\n",
      "Ep 1 (Step 031275): Train loss 1.969, Val loss 1.996\n",
      "Ep 1 (Step 031280): Train loss 2.139, Val loss 2.002\n",
      "Ep 1 (Step 031285): Train loss 1.941, Val loss 2.007\n",
      "Ep 1 (Step 031290): Train loss 2.053, Val loss 2.001\n",
      "Ep 1 (Step 031295): Train loss 2.059, Val loss 1.999\n",
      "Ep 1 (Step 031300): Train loss 1.994, Val loss 2.015\n",
      "Ep 1 (Step 031305): Train loss 1.992, Val loss 2.027\n",
      "Ep 1 (Step 031310): Train loss 1.853, Val loss 2.024\n",
      "Ep 1 (Step 031315): Train loss 1.850, Val loss 2.022\n",
      "Ep 1 (Step 031320): Train loss 1.803, Val loss 2.025\n",
      "Ep 1 (Step 031325): Train loss 2.251, Val loss 2.022\n",
      "Ep 1 (Step 031330): Train loss 2.177, Val loss 2.034\n",
      "Ep 1 (Step 031335): Train loss 1.986, Val loss 2.033\n",
      "Ep 1 (Step 031340): Train loss 2.193, Val loss 2.037\n",
      "Ep 1 (Step 031345): Train loss 2.038, Val loss 2.022\n",
      "Ep 1 (Step 031350): Train loss 2.011, Val loss 2.010\n",
      "Ep 1 (Step 031355): Train loss 2.073, Val loss 2.003\n",
      "Ep 1 (Step 031360): Train loss 2.016, Val loss 2.007\n",
      "Ep 1 (Step 031365): Train loss 2.082, Val loss 2.011\n",
      "Ep 1 (Step 031370): Train loss 1.798, Val loss 2.020\n",
      "Ep 1 (Step 031375): Train loss 1.974, Val loss 2.023\n",
      "Ep 1 (Step 031380): Train loss 1.935, Val loss 2.032\n",
      "Ep 1 (Step 031385): Train loss 2.028, Val loss 2.029\n",
      "Ep 1 (Step 031390): Train loss 2.029, Val loss 2.034\n",
      "Ep 1 (Step 031395): Train loss 1.883, Val loss 2.030\n",
      "Ep 1 (Step 031400): Train loss 1.995, Val loss 2.025\n",
      "Ep 1 (Step 031405): Train loss 2.311, Val loss 2.022\n",
      "Ep 1 (Step 031410): Train loss 1.938, Val loss 2.019\n",
      "Ep 1 (Step 031415): Train loss 2.127, Val loss 2.015\n",
      "Ep 1 (Step 031420): Train loss 2.216, Val loss 2.011\n",
      "Ep 1 (Step 031425): Train loss 2.268, Val loss 2.011\n",
      "Ep 1 (Step 031430): Train loss 1.875, Val loss 2.006\n",
      "Ep 1 (Step 031435): Train loss 1.992, Val loss 2.000\n",
      "Ep 1 (Step 031440): Train loss 1.990, Val loss 2.014\n",
      "Ep 1 (Step 031445): Train loss 2.102, Val loss 2.020\n",
      "Ep 1 (Step 031450): Train loss 1.976, Val loss 2.018\n",
      "Ep 1 (Step 031455): Train loss 1.917, Val loss 2.025\n",
      "Ep 1 (Step 031460): Train loss 2.157, Val loss 2.016\n",
      "Ep 1 (Step 031465): Train loss 1.887, Val loss 2.010\n",
      "Ep 1 (Step 031470): Train loss 2.091, Val loss 2.011\n",
      "Ep 1 (Step 031475): Train loss 1.933, Val loss 2.006\n",
      "Ep 1 (Step 031480): Train loss 2.188, Val loss 2.003\n",
      "Ep 1 (Step 031485): Train loss 2.026, Val loss 2.001\n",
      "Ep 1 (Step 031490): Train loss 2.434, Val loss 2.012\n",
      "Ep 1 (Step 031495): Train loss 1.871, Val loss 2.005\n",
      "Ep 1 (Step 031500): Train loss 2.108, Val loss 2.005\n",
      "Ep 1 (Step 031505): Train loss 2.046, Val loss 2.013\n",
      "Ep 1 (Step 031510): Train loss 2.138, Val loss 2.034\n",
      "Ep 1 (Step 031515): Train loss 2.151, Val loss 2.040\n",
      "Ep 1 (Step 031520): Train loss 2.309, Val loss 2.026\n",
      "Ep 1 (Step 031525): Train loss 1.915, Val loss 2.018\n",
      "Ep 1 (Step 031530): Train loss 1.977, Val loss 2.007\n",
      "Ep 1 (Step 031535): Train loss 2.043, Val loss 2.008\n",
      "Ep 1 (Step 031540): Train loss 2.013, Val loss 2.013\n",
      "Ep 1 (Step 031545): Train loss 2.052, Val loss 2.014\n",
      "Ep 1 (Step 031550): Train loss 2.020, Val loss 2.020\n",
      "Ep 1 (Step 031555): Train loss 2.429, Val loss 2.025\n",
      "Ep 1 (Step 031560): Train loss 1.869, Val loss 2.032\n",
      "Ep 1 (Step 031565): Train loss 2.035, Val loss 2.040\n",
      "Ep 1 (Step 031570): Train loss 2.135, Val loss 2.039\n",
      "Ep 1 (Step 031575): Train loss 2.087, Val loss 2.042\n",
      "Ep 1 (Step 031580): Train loss 2.092, Val loss 2.037\n",
      "Ep 1 (Step 031585): Train loss 2.009, Val loss 2.032\n",
      "Ep 1 (Step 031590): Train loss 2.034, Val loss 2.028\n",
      "Ep 1 (Step 031595): Train loss 2.310, Val loss 2.038\n",
      "Ep 1 (Step 031600): Train loss 1.998, Val loss 2.037\n",
      "Ep 1 (Step 031605): Train loss 2.027, Val loss 2.026\n",
      "Ep 1 (Step 031610): Train loss 2.044, Val loss 2.022\n",
      "Ep 1 (Step 031615): Train loss 2.197, Val loss 2.016\n",
      "Ep 1 (Step 031620): Train loss 2.297, Val loss 2.033\n",
      "Ep 1 (Step 031625): Train loss 2.126, Val loss 2.033\n",
      "Ep 1 (Step 031630): Train loss 1.896, Val loss 2.025\n",
      "Ep 1 (Step 031635): Train loss 2.256, Val loss 2.024\n",
      "Ep 1 (Step 031640): Train loss 2.206, Val loss 2.036\n",
      "Ep 1 (Step 031645): Train loss 2.208, Val loss 2.045\n",
      "Ep 1 (Step 031650): Train loss 2.370, Val loss 2.038\n",
      "Ep 1 (Step 031655): Train loss 2.123, Val loss 2.037\n",
      "Ep 1 (Step 031660): Train loss 2.190, Val loss 2.032\n",
      "Ep 1 (Step 031665): Train loss 1.988, Val loss 2.026\n",
      "Ep 1 (Step 031670): Train loss 1.998, Val loss 2.022\n",
      "Ep 1 (Step 031675): Train loss 2.099, Val loss 2.033\n",
      "Ep 1 (Step 031680): Train loss 1.944, Val loss 2.046\n",
      "Ep 1 (Step 031685): Train loss 2.170, Val loss 2.047\n",
      "Ep 1 (Step 031690): Train loss 2.071, Val loss 2.034\n",
      "Ep 1 (Step 031695): Train loss 2.034, Val loss 2.035\n",
      "Ep 1 (Step 031700): Train loss 2.125, Val loss 2.042\n",
      "Ep 1 (Step 031705): Train loss 2.371, Val loss 2.035\n",
      "Ep 1 (Step 031710): Train loss 1.758, Val loss 2.026\n",
      "Ep 1 (Step 031715): Train loss 1.982, Val loss 2.022\n",
      "Ep 1 (Step 031720): Train loss 1.833, Val loss 2.022\n",
      "Ep 1 (Step 031725): Train loss 2.234, Val loss 2.020\n",
      "Ep 1 (Step 031730): Train loss 1.875, Val loss 2.024\n",
      "Ep 1 (Step 031735): Train loss 1.906, Val loss 2.022\n",
      "Ep 1 (Step 031740): Train loss 2.109, Val loss 2.014\n",
      "Ep 1 (Step 031745): Train loss 2.210, Val loss 2.001\n",
      "Ep 1 (Step 031750): Train loss 1.974, Val loss 1.992\n",
      "Ep 1 (Step 031755): Train loss 1.982, Val loss 1.999\n",
      "Ep 1 (Step 031760): Train loss 1.955, Val loss 2.005\n",
      "Ep 1 (Step 031765): Train loss 1.963, Val loss 2.010\n",
      "Ep 1 (Step 031770): Train loss 2.201, Val loss 2.002\n",
      "Ep 1 (Step 031775): Train loss 1.915, Val loss 2.005\n",
      "Ep 1 (Step 031780): Train loss 1.833, Val loss 2.008\n",
      "Ep 1 (Step 031785): Train loss 1.947, Val loss 2.005\n",
      "Ep 1 (Step 031790): Train loss 2.194, Val loss 2.005\n",
      "Ep 1 (Step 031795): Train loss 2.049, Val loss 2.018\n",
      "Ep 1 (Step 031800): Train loss 1.926, Val loss 2.017\n",
      "Ep 1 (Step 031805): Train loss 2.171, Val loss 2.021\n",
      "Ep 1 (Step 031810): Train loss 2.063, Val loss 2.023\n",
      "Ep 1 (Step 031815): Train loss 1.871, Val loss 2.022\n",
      "Ep 1 (Step 031820): Train loss 1.976, Val loss 2.011\n",
      "Ep 1 (Step 031825): Train loss 2.057, Val loss 2.003\n",
      "Ep 1 (Step 031830): Train loss 2.233, Val loss 1.998\n",
      "Ep 1 (Step 031835): Train loss 1.977, Val loss 2.004\n",
      "Ep 1 (Step 031840): Train loss 1.989, Val loss 2.003\n",
      "Ep 1 (Step 031845): Train loss 1.796, Val loss 2.009\n",
      "Ep 1 (Step 031850): Train loss 2.142, Val loss 2.004\n",
      "Ep 1 (Step 031855): Train loss 2.202, Val loss 2.008\n",
      "Ep 1 (Step 031860): Train loss 1.855, Val loss 2.008\n",
      "Ep 1 (Step 031865): Train loss 2.231, Val loss 2.005\n",
      "Ep 1 (Step 031870): Train loss 2.042, Val loss 2.006\n",
      "Ep 1 (Step 031875): Train loss 2.078, Val loss 2.009\n",
      "Ep 1 (Step 031880): Train loss 1.974, Val loss 2.010\n",
      "Ep 1 (Step 031885): Train loss 1.847, Val loss 2.018\n",
      "Ep 1 (Step 031890): Train loss 1.852, Val loss 2.024\n",
      "Ep 1 (Step 031895): Train loss 2.374, Val loss 2.014\n",
      "Ep 1 (Step 031900): Train loss 1.773, Val loss 2.007\n",
      "Ep 1 (Step 031905): Train loss 2.153, Val loss 2.015\n",
      "Ep 1 (Step 031910): Train loss 1.994, Val loss 2.009\n",
      "Ep 1 (Step 031915): Train loss 1.871, Val loss 2.016\n",
      "Ep 1 (Step 031920): Train loss 1.865, Val loss 2.019\n",
      "Ep 1 (Step 031925): Train loss 1.985, Val loss 2.017\n",
      "Ep 1 (Step 031930): Train loss 1.948, Val loss 2.027\n",
      "Ep 1 (Step 031935): Train loss 2.043, Val loss 2.014\n",
      "Ep 1 (Step 031940): Train loss 1.933, Val loss 2.006\n",
      "Ep 1 (Step 031945): Train loss 2.200, Val loss 1.992\n",
      "Ep 1 (Step 031950): Train loss 2.296, Val loss 1.991\n",
      "Ep 1 (Step 031955): Train loss 2.058, Val loss 1.999\n",
      "Ep 1 (Step 031960): Train loss 2.189, Val loss 2.006\n",
      "Ep 1 (Step 031965): Train loss 1.898, Val loss 2.007\n",
      "Ep 1 (Step 031970): Train loss 1.962, Val loss 2.013\n",
      "Ep 1 (Step 031975): Train loss 2.052, Val loss 2.024\n",
      "Ep 1 (Step 031980): Train loss 2.321, Val loss 2.010\n",
      "Ep 1 (Step 031985): Train loss 2.137, Val loss 2.006\n",
      "Ep 1 (Step 031990): Train loss 1.994, Val loss 2.016\n",
      "Ep 1 (Step 031995): Train loss 2.058, Val loss 2.016\n",
      "Ep 1 (Step 032000): Train loss 2.186, Val loss 2.017\n",
      "Ep 1 (Step 032005): Train loss 1.971, Val loss 2.018\n",
      "Ep 1 (Step 032010): Train loss 2.015, Val loss 2.030\n",
      "Ep 1 (Step 032015): Train loss 2.202, Val loss 2.035\n",
      "Ep 1 (Step 032020): Train loss 2.070, Val loss 2.032\n",
      "Ep 1 (Step 032025): Train loss 1.778, Val loss 2.036\n",
      "Ep 1 (Step 032030): Train loss 2.057, Val loss 2.045\n",
      "Ep 1 (Step 032035): Train loss 2.027, Val loss 2.040\n",
      "Ep 1 (Step 032040): Train loss 2.083, Val loss 2.028\n",
      "Ep 1 (Step 032045): Train loss 2.183, Val loss 2.016\n",
      "Ep 1 (Step 032050): Train loss 1.800, Val loss 2.013\n",
      "Ep 1 (Step 032055): Train loss 2.081, Val loss 2.034\n",
      "Ep 1 (Step 032060): Train loss 2.152, Val loss 2.012\n",
      "Ep 1 (Step 032065): Train loss 1.775, Val loss 2.016\n",
      "Ep 1 (Step 032070): Train loss 2.024, Val loss 2.021\n",
      "Ep 1 (Step 032075): Train loss 2.558, Val loss 2.029\n",
      "Ep 1 (Step 032080): Train loss 1.814, Val loss 2.024\n",
      "Ep 1 (Step 032085): Train loss 2.060, Val loss 2.038\n",
      "Ep 1 (Step 032090): Train loss 1.966, Val loss 2.035\n",
      "Ep 1 (Step 032095): Train loss 1.779, Val loss 2.035\n",
      "Ep 1 (Step 032100): Train loss 2.395, Val loss 2.031\n",
      "Ep 1 (Step 032105): Train loss 2.025, Val loss 2.015\n",
      "Ep 1 (Step 032110): Train loss 1.860, Val loss 2.009\n",
      "Ep 1 (Step 032115): Train loss 1.928, Val loss 2.012\n",
      "Ep 1 (Step 032120): Train loss 2.028, Val loss 1.999\n",
      "Ep 1 (Step 032125): Train loss 1.857, Val loss 2.004\n",
      "Ep 1 (Step 032130): Train loss 2.351, Val loss 2.016\n",
      "Ep 1 (Step 032135): Train loss 2.208, Val loss 2.025\n",
      "Ep 1 (Step 032140): Train loss 1.983, Val loss 2.031\n",
      "Ep 1 (Step 032145): Train loss 1.977, Val loss 2.027\n",
      "Ep 1 (Step 032150): Train loss 1.949, Val loss 2.020\n",
      "Ep 1 (Step 032155): Train loss 1.995, Val loss 2.022\n",
      "Ep 1 (Step 032160): Train loss 2.095, Val loss 2.020\n",
      "Ep 1 (Step 032165): Train loss 1.927, Val loss 2.012\n",
      "Ep 1 (Step 032170): Train loss 2.024, Val loss 2.020\n",
      "Ep 1 (Step 032175): Train loss 1.854, Val loss 2.026\n",
      "Ep 1 (Step 032180): Train loss 2.075, Val loss 2.024\n",
      "Ep 1 (Step 032185): Train loss 1.833, Val loss 2.027\n",
      "Ep 1 (Step 032190): Train loss 2.184, Val loss 2.025\n",
      "Ep 1 (Step 032195): Train loss 2.188, Val loss 2.015\n",
      "Ep 1 (Step 032200): Train loss 2.070, Val loss 2.018\n",
      "Ep 1 (Step 032205): Train loss 1.961, Val loss 2.032\n",
      "Ep 1 (Step 032210): Train loss 1.943, Val loss 2.036\n",
      "Ep 1 (Step 032215): Train loss 1.949, Val loss 2.032\n",
      "Ep 1 (Step 032220): Train loss 2.094, Val loss 2.028\n",
      "Ep 1 (Step 032225): Train loss 1.701, Val loss 2.019\n",
      "Ep 1 (Step 032230): Train loss 1.794, Val loss 2.014\n",
      "Ep 1 (Step 032235): Train loss 2.070, Val loss 2.010\n",
      "Ep 1 (Step 032240): Train loss 1.954, Val loss 2.016\n",
      "Ep 1 (Step 032245): Train loss 2.034, Val loss 2.032\n",
      "Ep 1 (Step 032250): Train loss 1.886, Val loss 2.040\n",
      "Ep 1 (Step 032255): Train loss 2.217, Val loss 2.031\n",
      "Ep 1 (Step 032260): Train loss 2.047, Val loss 2.024\n",
      "Ep 1 (Step 032265): Train loss 2.125, Val loss 2.008\n",
      "Ep 1 (Step 032270): Train loss 2.384, Val loss 2.010\n",
      "Ep 1 (Step 032275): Train loss 1.963, Val loss 2.018\n",
      "Ep 1 (Step 032280): Train loss 2.033, Val loss 2.020\n",
      "Ep 1 (Step 032285): Train loss 1.988, Val loss 2.010\n",
      "Ep 1 (Step 032290): Train loss 2.393, Val loss 2.002\n",
      "Ep 1 (Step 032295): Train loss 2.130, Val loss 2.004\n",
      "Ep 1 (Step 032300): Train loss 2.375, Val loss 2.003\n",
      "Ep 1 (Step 032305): Train loss 1.846, Val loss 1.996\n",
      "Ep 1 (Step 032310): Train loss 1.882, Val loss 1.990\n",
      "Ep 1 (Step 032315): Train loss 2.043, Val loss 1.990\n",
      "Ep 1 (Step 032320): Train loss 2.052, Val loss 1.995\n",
      "Ep 1 (Step 032325): Train loss 2.119, Val loss 1.993\n",
      "Ep 1 (Step 032330): Train loss 1.999, Val loss 1.984\n",
      "Ep 1 (Step 032335): Train loss 2.330, Val loss 1.994\n",
      "Ep 1 (Step 032340): Train loss 1.734, Val loss 2.013\n",
      "Ep 1 (Step 032345): Train loss 2.018, Val loss 2.023\n",
      "Ep 1 (Step 032350): Train loss 2.290, Val loss 2.025\n",
      "Ep 1 (Step 032355): Train loss 1.897, Val loss 2.020\n",
      "Ep 1 (Step 032360): Train loss 1.889, Val loss 2.031\n",
      "Ep 1 (Step 032365): Train loss 2.003, Val loss 2.030\n",
      "Ep 1 (Step 032370): Train loss 2.207, Val loss 2.037\n",
      "Ep 1 (Step 032375): Train loss 2.055, Val loss 2.034\n",
      "Ep 1 (Step 032380): Train loss 1.894, Val loss 2.033\n",
      "Ep 1 (Step 032385): Train loss 2.038, Val loss 2.033\n",
      "Ep 1 (Step 032390): Train loss 2.185, Val loss 2.037\n",
      "Ep 1 (Step 032395): Train loss 1.861, Val loss 2.025\n",
      "Ep 1 (Step 032400): Train loss 2.038, Val loss 2.015\n",
      "Ep 1 (Step 032405): Train loss 2.424, Val loss 2.004\n",
      "Ep 1 (Step 032410): Train loss 1.930, Val loss 2.013\n",
      "Ep 1 (Step 032415): Train loss 1.719, Val loss 2.027\n",
      "Ep 1 (Step 032420): Train loss 2.176, Val loss 2.026\n",
      "Ep 1 (Step 032425): Train loss 2.039, Val loss 2.036\n",
      "Ep 1 (Step 032430): Train loss 2.144, Val loss 2.023\n",
      "Ep 1 (Step 032435): Train loss 2.205, Val loss 2.035\n",
      "Ep 1 (Step 032440): Train loss 2.038, Val loss 2.028\n",
      "Ep 1 (Step 032445): Train loss 2.095, Val loss 2.034\n",
      "Ep 1 (Step 032450): Train loss 2.071, Val loss 2.043\n",
      "Ep 1 (Step 032455): Train loss 2.284, Val loss 2.037\n",
      "Ep 1 (Step 032460): Train loss 2.331, Val loss 2.038\n",
      "Ep 1 (Step 032465): Train loss 2.163, Val loss 2.032\n",
      "Ep 1 (Step 032470): Train loss 2.218, Val loss 2.034\n",
      "Ep 1 (Step 032475): Train loss 2.124, Val loss 2.031\n",
      "Ep 1 (Step 032480): Train loss 2.051, Val loss 2.035\n",
      "Ep 1 (Step 032485): Train loss 2.157, Val loss 2.030\n",
      "Ep 1 (Step 032490): Train loss 2.340, Val loss 2.036\n",
      "Ep 1 (Step 032495): Train loss 2.142, Val loss 2.039\n",
      "Ep 1 (Step 032500): Train loss 2.386, Val loss 2.035\n",
      "Ep 1 (Step 032505): Train loss 2.146, Val loss 2.035\n",
      "Ep 1 (Step 032510): Train loss 2.347, Val loss 2.034\n",
      "Ep 1 (Step 032515): Train loss 1.898, Val loss 2.046\n",
      "Ep 1 (Step 032520): Train loss 2.102, Val loss 2.033\n",
      "Ep 1 (Step 032525): Train loss 1.857, Val loss 2.030\n",
      "Ep 1 (Step 032530): Train loss 2.062, Val loss 2.025\n",
      "Ep 1 (Step 032535): Train loss 2.207, Val loss 2.037\n",
      "Ep 1 (Step 032540): Train loss 2.164, Val loss 2.031\n",
      "Ep 1 (Step 032545): Train loss 2.066, Val loss 2.021\n",
      "Ep 1 (Step 032550): Train loss 2.034, Val loss 2.022\n",
      "Ep 1 (Step 032555): Train loss 2.165, Val loss 2.026\n",
      "Ep 1 (Step 032560): Train loss 1.995, Val loss 2.029\n",
      "Ep 1 (Step 032565): Train loss 2.109, Val loss 2.038\n",
      "Ep 1 (Step 032570): Train loss 2.148, Val loss 2.028\n",
      "Ep 1 (Step 032575): Train loss 2.324, Val loss 2.027\n",
      "Ep 1 (Step 032580): Train loss 2.175, Val loss 2.037\n",
      "Ep 1 (Step 032585): Train loss 2.282, Val loss 2.026\n",
      "Ep 1 (Step 032590): Train loss 2.005, Val loss 2.029\n",
      "Ep 1 (Step 032595): Train loss 1.919, Val loss 2.044\n",
      "Ep 1 (Step 032600): Train loss 2.140, Val loss 2.037\n",
      "Ep 1 (Step 032605): Train loss 2.108, Val loss 2.042\n",
      "Ep 1 (Step 032610): Train loss 1.820, Val loss 2.043\n",
      "Ep 1 (Step 032615): Train loss 2.159, Val loss 2.034\n",
      "Ep 1 (Step 032620): Train loss 2.322, Val loss 2.036\n",
      "Ep 1 (Step 032625): Train loss 2.028, Val loss 2.043\n",
      "Ep 1 (Step 032630): Train loss 1.974, Val loss 2.045\n",
      "Ep 1 (Step 032635): Train loss 1.929, Val loss 2.032\n",
      "Ep 1 (Step 032640): Train loss 1.987, Val loss 2.029\n",
      "Ep 1 (Step 032645): Train loss 1.952, Val loss 2.025\n",
      "Ep 1 (Step 032650): Train loss 2.011, Val loss 2.029\n",
      "Ep 1 (Step 032655): Train loss 1.998, Val loss 2.041\n",
      "Ep 1 (Step 032660): Train loss 2.021, Val loss 2.040\n",
      "Ep 1 (Step 032665): Train loss 2.239, Val loss 2.031\n",
      "Ep 1 (Step 032670): Train loss 2.137, Val loss 2.030\n",
      "Ep 1 (Step 032675): Train loss 1.703, Val loss 2.033\n",
      "Ep 1 (Step 032680): Train loss 2.223, Val loss 2.032\n",
      "Ep 1 (Step 032685): Train loss 2.112, Val loss 2.027\n",
      "Ep 1 (Step 032690): Train loss 1.737, Val loss 2.020\n",
      "Ep 1 (Step 032695): Train loss 2.175, Val loss 2.020\n",
      "Ep 1 (Step 032700): Train loss 1.933, Val loss 2.030\n",
      "Ep 1 (Step 032705): Train loss 2.022, Val loss 2.037\n",
      "Ep 1 (Step 032710): Train loss 2.187, Val loss 2.035\n",
      "Ep 1 (Step 032715): Train loss 2.038, Val loss 2.028\n",
      "Ep 1 (Step 032720): Train loss 2.173, Val loss 2.025\n",
      "Ep 1 (Step 032725): Train loss 1.962, Val loss 2.022\n",
      "Ep 1 (Step 032730): Train loss 1.883, Val loss 2.013\n",
      "Ep 1 (Step 032735): Train loss 2.036, Val loss 2.011\n",
      "Ep 1 (Step 032740): Train loss 2.306, Val loss 2.017\n",
      "Ep 1 (Step 032745): Train loss 2.309, Val loss 2.018\n",
      "Ep 1 (Step 032750): Train loss 2.096, Val loss 2.020\n",
      "Ep 1 (Step 032755): Train loss 2.099, Val loss 2.019\n",
      "Ep 1 (Step 032760): Train loss 1.910, Val loss 2.032\n",
      "Ep 1 (Step 032765): Train loss 2.128, Val loss 2.041\n",
      "Ep 1 (Step 032770): Train loss 1.964, Val loss 2.038\n",
      "Ep 1 (Step 032775): Train loss 2.144, Val loss 2.039\n",
      "Ep 1 (Step 032780): Train loss 1.900, Val loss 2.038\n",
      "Ep 1 (Step 032785): Train loss 2.208, Val loss 2.034\n",
      "Ep 1 (Step 032790): Train loss 2.062, Val loss 2.039\n",
      "Ep 1 (Step 032795): Train loss 2.136, Val loss 2.033\n",
      "Ep 1 (Step 032800): Train loss 2.204, Val loss 2.034\n",
      "Ep 1 (Step 032805): Train loss 2.322, Val loss 2.034\n",
      "Ep 1 (Step 032810): Train loss 1.947, Val loss 2.037\n",
      "Ep 1 (Step 032815): Train loss 2.005, Val loss 2.040\n",
      "Ep 1 (Step 032820): Train loss 2.151, Val loss 2.033\n",
      "Ep 1 (Step 032825): Train loss 2.017, Val loss 2.038\n",
      "Ep 1 (Step 032830): Train loss 1.937, Val loss 2.055\n",
      "Ep 1 (Step 032835): Train loss 2.247, Val loss 2.060\n",
      "Ep 1 (Step 032840): Train loss 1.992, Val loss 2.058\n",
      "Ep 1 (Step 032845): Train loss 2.023, Val loss 2.057\n",
      "Ep 1 (Step 032850): Train loss 2.099, Val loss 2.057\n",
      "Ep 1 (Step 032855): Train loss 2.207, Val loss 2.052\n",
      "Ep 1 (Step 032860): Train loss 2.063, Val loss 2.048\n",
      "Ep 1 (Step 032865): Train loss 1.987, Val loss 2.054\n",
      "Ep 1 (Step 032870): Train loss 1.959, Val loss 2.044\n",
      "Ep 1 (Step 032875): Train loss 1.907, Val loss 2.025\n",
      "Ep 1 (Step 032880): Train loss 2.046, Val loss 2.023\n",
      "Ep 1 (Step 032885): Train loss 2.008, Val loss 2.025\n",
      "Ep 1 (Step 032890): Train loss 2.079, Val loss 2.024\n",
      "Ep 1 (Step 032895): Train loss 1.716, Val loss 2.029\n",
      "Ep 1 (Step 032900): Train loss 2.233, Val loss 2.042\n",
      "Ep 1 (Step 032905): Train loss 1.913, Val loss 2.050\n",
      "Ep 1 (Step 032910): Train loss 1.788, Val loss 2.037\n",
      "Ep 1 (Step 032915): Train loss 2.243, Val loss 2.034\n",
      "Ep 1 (Step 032920): Train loss 2.051, Val loss 2.034\n",
      "Ep 1 (Step 032925): Train loss 2.067, Val loss 2.031\n",
      "Ep 1 (Step 032930): Train loss 1.976, Val loss 2.040\n",
      "Ep 1 (Step 032935): Train loss 2.093, Val loss 2.037\n",
      "Ep 1 (Step 032940): Train loss 2.103, Val loss 2.032\n",
      "Ep 1 (Step 032945): Train loss 1.840, Val loss 2.022\n",
      "Ep 1 (Step 032950): Train loss 2.075, Val loss 2.022\n",
      "Ep 1 (Step 032955): Train loss 2.219, Val loss 2.018\n",
      "Ep 1 (Step 032960): Train loss 2.008, Val loss 2.014\n",
      "Ep 1 (Step 032965): Train loss 2.291, Val loss 2.017\n",
      "Ep 1 (Step 032970): Train loss 2.058, Val loss 2.016\n",
      "Ep 1 (Step 032975): Train loss 1.873, Val loss 2.010\n",
      "Ep 1 (Step 032980): Train loss 2.158, Val loss 2.007\n",
      "Ep 1 (Step 032985): Train loss 2.017, Val loss 2.009\n",
      "Ep 1 (Step 032990): Train loss 2.070, Val loss 2.013\n",
      "Ep 1 (Step 032995): Train loss 2.069, Val loss 2.013\n",
      "Ep 1 (Step 033000): Train loss 2.145, Val loss 2.012\n",
      "Ep 1 (Step 033005): Train loss 2.348, Val loss 2.018\n",
      "Ep 1 (Step 033010): Train loss 2.210, Val loss 2.027\n",
      "Ep 1 (Step 033015): Train loss 1.809, Val loss 2.030\n",
      "Ep 1 (Step 033020): Train loss 1.998, Val loss 2.027\n",
      "Ep 1 (Step 033025): Train loss 2.178, Val loss 2.028\n",
      "Ep 1 (Step 033030): Train loss 1.879, Val loss 2.030\n",
      "Ep 1 (Step 033035): Train loss 1.877, Val loss 2.038\n",
      "Ep 1 (Step 033040): Train loss 2.366, Val loss 2.044\n",
      "Ep 1 (Step 033045): Train loss 1.859, Val loss 2.042\n",
      "Ep 1 (Step 033050): Train loss 1.809, Val loss 2.040\n",
      "Ep 1 (Step 033055): Train loss 2.089, Val loss 2.032\n",
      "Ep 1 (Step 033060): Train loss 2.032, Val loss 2.023\n",
      "Ep 1 (Step 033065): Train loss 2.080, Val loss 2.017\n",
      "Ep 1 (Step 033070): Train loss 2.065, Val loss 2.007\n",
      "Ep 1 (Step 033075): Train loss 2.101, Val loss 2.011\n",
      "Ep 1 (Step 033080): Train loss 1.980, Val loss 2.017\n",
      "Ep 1 (Step 033085): Train loss 2.345, Val loss 2.020\n",
      "Ep 1 (Step 033090): Train loss 1.696, Val loss 2.030\n",
      "Ep 1 (Step 033095): Train loss 2.056, Val loss 2.034\n",
      "Ep 1 (Step 033100): Train loss 2.151, Val loss 2.034\n",
      "Ep 1 (Step 033105): Train loss 2.080, Val loss 2.028\n",
      "Ep 1 (Step 033110): Train loss 1.985, Val loss 2.019\n",
      "Ep 1 (Step 033115): Train loss 1.851, Val loss 2.020\n",
      "Ep 1 (Step 033120): Train loss 1.824, Val loss 2.022\n",
      "Ep 1 (Step 033125): Train loss 2.182, Val loss 2.014\n",
      "Ep 1 (Step 033130): Train loss 1.903, Val loss 1.999\n",
      "Ep 1 (Step 033135): Train loss 2.200, Val loss 1.999\n",
      "Ep 1 (Step 033140): Train loss 2.085, Val loss 2.016\n",
      "Ep 1 (Step 033145): Train loss 2.189, Val loss 2.022\n",
      "Ep 1 (Step 033150): Train loss 2.051, Val loss 2.023\n",
      "Ep 1 (Step 033155): Train loss 1.781, Val loss 2.023\n",
      "Ep 1 (Step 033160): Train loss 2.049, Val loss 2.027\n",
      "Ep 1 (Step 033165): Train loss 1.914, Val loss 2.020\n",
      "Ep 1 (Step 033170): Train loss 2.075, Val loss 2.017\n",
      "Ep 1 (Step 033175): Train loss 2.039, Val loss 2.009\n",
      "Ep 1 (Step 033180): Train loss 1.925, Val loss 2.002\n",
      "Ep 1 (Step 033185): Train loss 1.953, Val loss 2.009\n",
      "Ep 1 (Step 033190): Train loss 1.958, Val loss 2.005\n",
      "Ep 1 (Step 033195): Train loss 2.071, Val loss 2.004\n",
      "Ep 1 (Step 033200): Train loss 1.870, Val loss 2.014\n",
      "Ep 1 (Step 033205): Train loss 1.915, Val loss 2.000\n",
      "Ep 1 (Step 033210): Train loss 1.875, Val loss 2.001\n",
      "Ep 1 (Step 033215): Train loss 2.033, Val loss 2.001\n",
      "Ep 1 (Step 033220): Train loss 2.122, Val loss 2.005\n",
      "Ep 1 (Step 033225): Train loss 2.034, Val loss 2.001\n",
      "Ep 1 (Step 033230): Train loss 1.973, Val loss 1.991\n",
      "Ep 1 (Step 033235): Train loss 2.060, Val loss 1.996\n",
      "Ep 1 (Step 033240): Train loss 2.013, Val loss 2.009\n",
      "Ep 1 (Step 033245): Train loss 2.421, Val loss 2.002\n",
      "Ep 1 (Step 033250): Train loss 2.319, Val loss 1.998\n",
      "Ep 1 (Step 033255): Train loss 1.826, Val loss 2.004\n",
      "Ep 1 (Step 033260): Train loss 1.887, Val loss 2.009\n",
      "Ep 1 (Step 033265): Train loss 2.038, Val loss 2.013\n",
      "Ep 1 (Step 033270): Train loss 2.162, Val loss 2.004\n",
      "Ep 1 (Step 033275): Train loss 2.077, Val loss 1.994\n",
      "Ep 1 (Step 033280): Train loss 2.055, Val loss 2.002\n",
      "Ep 1 (Step 033285): Train loss 2.039, Val loss 2.001\n",
      "Ep 1 (Step 033290): Train loss 1.924, Val loss 1.995\n",
      "Ep 1 (Step 033295): Train loss 2.066, Val loss 1.997\n",
      "Ep 1 (Step 033300): Train loss 2.130, Val loss 2.001\n",
      "Ep 1 (Step 033305): Train loss 2.148, Val loss 2.000\n",
      "Ep 1 (Step 033310): Train loss 2.169, Val loss 1.991\n",
      "Ep 1 (Step 033315): Train loss 1.885, Val loss 1.994\n",
      "Ep 1 (Step 033320): Train loss 2.090, Val loss 2.003\n",
      "Ep 1 (Step 033325): Train loss 2.477, Val loss 2.001\n",
      "Ep 1 (Step 033330): Train loss 2.099, Val loss 2.000\n",
      "Ep 1 (Step 033335): Train loss 1.997, Val loss 2.007\n",
      "Ep 1 (Step 033340): Train loss 1.960, Val loss 2.009\n",
      "Ep 1 (Step 033345): Train loss 2.134, Val loss 2.004\n",
      "Ep 1 (Step 033350): Train loss 2.022, Val loss 2.006\n",
      "Ep 1 (Step 033355): Train loss 1.860, Val loss 2.010\n",
      "Ep 1 (Step 033360): Train loss 1.968, Val loss 2.014\n",
      "Ep 1 (Step 033365): Train loss 1.981, Val loss 2.013\n",
      "Ep 1 (Step 033370): Train loss 1.810, Val loss 2.012\n",
      "Ep 1 (Step 033375): Train loss 2.056, Val loss 2.005\n",
      "Ep 1 (Step 033380): Train loss 1.817, Val loss 2.021\n",
      "Ep 1 (Step 033385): Train loss 2.015, Val loss 2.030\n",
      "Ep 1 (Step 033390): Train loss 2.226, Val loss 2.030\n",
      "Ep 1 (Step 033395): Train loss 1.987, Val loss 2.041\n",
      "Ep 1 (Step 033400): Train loss 2.143, Val loss 2.030\n",
      "Ep 1 (Step 033405): Train loss 2.293, Val loss 2.022\n",
      "Ep 1 (Step 033410): Train loss 2.114, Val loss 2.016\n",
      "Ep 1 (Step 033415): Train loss 2.030, Val loss 2.016\n",
      "Ep 1 (Step 033420): Train loss 2.068, Val loss 2.014\n",
      "Ep 1 (Step 033425): Train loss 2.131, Val loss 2.015\n",
      "Ep 1 (Step 033430): Train loss 2.058, Val loss 2.023\n",
      "Ep 1 (Step 033435): Train loss 2.132, Val loss 2.030\n",
      "Ep 1 (Step 033440): Train loss 1.600, Val loss 2.036\n",
      "Ep 1 (Step 033445): Train loss 2.026, Val loss 2.035\n",
      "Ep 1 (Step 033450): Train loss 2.139, Val loss 2.025\n",
      "Ep 1 (Step 033455): Train loss 2.036, Val loss 2.032\n",
      "Ep 1 (Step 033460): Train loss 2.222, Val loss 2.033\n",
      "Ep 1 (Step 033465): Train loss 2.115, Val loss 2.031\n",
      "Ep 1 (Step 033470): Train loss 1.951, Val loss 2.028\n",
      "Ep 1 (Step 033475): Train loss 1.864, Val loss 2.024\n",
      "Ep 1 (Step 033480): Train loss 1.992, Val loss 2.024\n",
      "Ep 1 (Step 033485): Train loss 1.927, Val loss 2.027\n",
      "Ep 1 (Step 033490): Train loss 2.157, Val loss 2.030\n",
      "Ep 1 (Step 033495): Train loss 1.928, Val loss 2.018\n",
      "Ep 1 (Step 033500): Train loss 1.894, Val loss 2.022\n",
      "Ep 1 (Step 033505): Train loss 2.047, Val loss 2.034\n",
      "Ep 1 (Step 033510): Train loss 1.912, Val loss 2.026\n",
      "Ep 1 (Step 033515): Train loss 1.959, Val loss 2.018\n",
      "Ep 1 (Step 033520): Train loss 1.911, Val loss 2.010\n",
      "Ep 1 (Step 033525): Train loss 1.877, Val loss 2.011\n",
      "Ep 1 (Step 033530): Train loss 2.075, Val loss 2.008\n",
      "Ep 1 (Step 033535): Train loss 1.969, Val loss 2.008\n",
      "Ep 1 (Step 033540): Train loss 2.126, Val loss 1.991\n",
      "Ep 1 (Step 033545): Train loss 1.970, Val loss 1.975\n",
      "Ep 1 (Step 033550): Train loss 1.899, Val loss 1.974\n",
      "Ep 1 (Step 033555): Train loss 1.902, Val loss 1.989\n",
      "Ep 1 (Step 033560): Train loss 1.885, Val loss 1.993\n",
      "Ep 1 (Step 033565): Train loss 2.312, Val loss 1.983\n",
      "Ep 1 (Step 033570): Train loss 2.097, Val loss 1.987\n",
      "Ep 1 (Step 033575): Train loss 2.087, Val loss 1.984\n",
      "Ep 1 (Step 033580): Train loss 1.904, Val loss 1.980\n",
      "Ep 1 (Step 033585): Train loss 2.395, Val loss 1.975\n",
      "Ep 1 (Step 033590): Train loss 1.985, Val loss 1.983\n",
      "Ep 1 (Step 033595): Train loss 1.876, Val loss 1.982\n",
      "Ep 1 (Step 033600): Train loss 2.365, Val loss 1.972\n",
      "Ep 1 (Step 033605): Train loss 2.106, Val loss 1.979\n",
      "Ep 1 (Step 033610): Train loss 1.899, Val loss 1.993\n",
      "Ep 1 (Step 033615): Train loss 2.082, Val loss 1.997\n",
      "Ep 1 (Step 033620): Train loss 2.636, Val loss 1.991\n",
      "Ep 1 (Step 033625): Train loss 1.831, Val loss 1.984\n",
      "Ep 1 (Step 033630): Train loss 2.080, Val loss 1.982\n",
      "Ep 1 (Step 033635): Train loss 1.802, Val loss 1.987\n",
      "Ep 1 (Step 033640): Train loss 1.986, Val loss 1.989\n",
      "Ep 1 (Step 033645): Train loss 1.859, Val loss 1.997\n",
      "Ep 1 (Step 033650): Train loss 1.978, Val loss 1.996\n",
      "Ep 1 (Step 033655): Train loss 2.050, Val loss 1.988\n",
      "Ep 1 (Step 033660): Train loss 1.964, Val loss 1.982\n",
      "Ep 1 (Step 033665): Train loss 2.017, Val loss 1.979\n",
      "Ep 1 (Step 033670): Train loss 2.183, Val loss 1.976\n",
      "Ep 1 (Step 033675): Train loss 1.817, Val loss 1.983\n",
      "Ep 1 (Step 033680): Train loss 2.001, Val loss 1.988\n",
      "Ep 1 (Step 033685): Train loss 2.466, Val loss 1.993\n",
      "Ep 1 (Step 033690): Train loss 1.865, Val loss 1.995\n",
      "Ep 1 (Step 033695): Train loss 2.009, Val loss 1.981\n",
      "Ep 1 (Step 033700): Train loss 1.877, Val loss 1.976\n",
      "Ep 1 (Step 033705): Train loss 2.045, Val loss 1.975\n",
      "Ep 1 (Step 033710): Train loss 1.951, Val loss 1.977\n",
      "Ep 1 (Step 033715): Train loss 2.013, Val loss 1.986\n",
      "Ep 1 (Step 033720): Train loss 2.067, Val loss 1.993\n",
      "Ep 1 (Step 033725): Train loss 1.971, Val loss 1.997\n",
      "Ep 1 (Step 033730): Train loss 1.894, Val loss 1.997\n",
      "Ep 1 (Step 033735): Train loss 2.203, Val loss 1.989\n",
      "Ep 1 (Step 033740): Train loss 2.001, Val loss 1.986\n",
      "Ep 1 (Step 033745): Train loss 2.055, Val loss 1.983\n",
      "Ep 1 (Step 033750): Train loss 2.044, Val loss 1.987\n",
      "Ep 1 (Step 033755): Train loss 2.152, Val loss 1.990\n",
      "Ep 1 (Step 033760): Train loss 2.029, Val loss 1.984\n",
      "Ep 1 (Step 033765): Train loss 1.750, Val loss 1.989\n",
      "Ep 1 (Step 033770): Train loss 1.950, Val loss 1.997\n",
      "Ep 1 (Step 033775): Train loss 2.220, Val loss 1.995\n",
      "Ep 1 (Step 033780): Train loss 2.037, Val loss 1.990\n",
      "Ep 1 (Step 033785): Train loss 1.717, Val loss 1.992\n",
      "Ep 1 (Step 033790): Train loss 2.182, Val loss 1.999\n",
      "Ep 1 (Step 033795): Train loss 2.135, Val loss 2.003\n",
      "Ep 1 (Step 033800): Train loss 1.929, Val loss 2.013\n",
      "Ep 1 (Step 033805): Train loss 2.088, Val loss 2.015\n",
      "Ep 1 (Step 033810): Train loss 2.032, Val loss 1.999\n",
      "Ep 1 (Step 033815): Train loss 1.751, Val loss 1.993\n",
      "Ep 1 (Step 033820): Train loss 1.849, Val loss 1.979\n",
      "Ep 1 (Step 033825): Train loss 1.898, Val loss 1.978\n",
      "Ep 1 (Step 033830): Train loss 2.012, Val loss 1.975\n",
      "Ep 1 (Step 033835): Train loss 2.202, Val loss 1.976\n",
      "Ep 1 (Step 033840): Train loss 2.055, Val loss 1.986\n",
      "Ep 1 (Step 033845): Train loss 1.745, Val loss 1.984\n",
      "Ep 1 (Step 033850): Train loss 2.007, Val loss 1.969\n",
      "Ep 1 (Step 033855): Train loss 2.063, Val loss 1.967\n",
      "Ep 1 (Step 033860): Train loss 1.979, Val loss 1.965\n",
      "Ep 1 (Step 033865): Train loss 2.122, Val loss 1.969\n",
      "Ep 1 (Step 033870): Train loss 1.994, Val loss 1.965\n",
      "Ep 1 (Step 033875): Train loss 2.052, Val loss 1.950\n",
      "Ep 1 (Step 033880): Train loss 1.892, Val loss 1.950\n",
      "Ep 1 (Step 033885): Train loss 2.049, Val loss 1.958\n",
      "Ep 1 (Step 033890): Train loss 1.880, Val loss 1.961\n",
      "Ep 1 (Step 033895): Train loss 2.050, Val loss 1.970\n",
      "Ep 1 (Step 033900): Train loss 1.917, Val loss 1.969\n",
      "Ep 1 (Step 033905): Train loss 2.150, Val loss 1.965\n",
      "Ep 1 (Step 033910): Train loss 2.063, Val loss 1.972\n",
      "Ep 1 (Step 033915): Train loss 2.097, Val loss 1.983\n",
      "Ep 1 (Step 033920): Train loss 2.033, Val loss 1.988\n",
      "Ep 1 (Step 033925): Train loss 1.802, Val loss 1.982\n",
      "Ep 1 (Step 033930): Train loss 2.221, Val loss 1.983\n",
      "Ep 1 (Step 033935): Train loss 2.119, Val loss 1.977\n",
      "Ep 1 (Step 033940): Train loss 1.872, Val loss 1.972\n",
      "Ep 1 (Step 033945): Train loss 1.818, Val loss 1.979\n",
      "Ep 1 (Step 033950): Train loss 2.021, Val loss 1.987\n",
      "Ep 1 (Step 033955): Train loss 1.974, Val loss 1.995\n",
      "Ep 1 (Step 033960): Train loss 1.997, Val loss 1.984\n",
      "Ep 1 (Step 033965): Train loss 1.913, Val loss 1.980\n",
      "Ep 1 (Step 033970): Train loss 1.929, Val loss 1.974\n",
      "Ep 1 (Step 033975): Train loss 2.094, Val loss 1.986\n",
      "Ep 1 (Step 033980): Train loss 1.957, Val loss 1.997\n",
      "Ep 1 (Step 033985): Train loss 2.120, Val loss 2.001\n",
      "Ep 1 (Step 033990): Train loss 2.119, Val loss 2.002\n",
      "Ep 1 (Step 033995): Train loss 2.015, Val loss 2.003\n",
      "Ep 1 (Step 034000): Train loss 1.938, Val loss 2.005\n",
      "Ep 1 (Step 034005): Train loss 1.960, Val loss 2.007\n",
      "Ep 1 (Step 034010): Train loss 1.951, Val loss 1.998\n",
      "Ep 1 (Step 034015): Train loss 1.768, Val loss 1.998\n",
      "Ep 1 (Step 034020): Train loss 1.966, Val loss 2.011\n",
      "Ep 1 (Step 034025): Train loss 2.062, Val loss 2.022\n",
      "Ep 1 (Step 034030): Train loss 2.103, Val loss 2.012\n",
      "Ep 1 (Step 034035): Train loss 1.828, Val loss 2.011\n",
      "Ep 1 (Step 034040): Train loss 2.078, Val loss 2.008\n",
      "Ep 1 (Step 034045): Train loss 2.287, Val loss 2.009\n",
      "Ep 1 (Step 034050): Train loss 1.860, Val loss 2.021\n",
      "Ep 1 (Step 034055): Train loss 2.053, Val loss 2.025\n",
      "Ep 1 (Step 034060): Train loss 1.818, Val loss 2.008\n",
      "Ep 1 (Step 034065): Train loss 1.943, Val loss 1.992\n",
      "Ep 1 (Step 034070): Train loss 2.049, Val loss 1.991\n",
      "Ep 1 (Step 034075): Train loss 2.150, Val loss 1.993\n",
      "Ep 1 (Step 034080): Train loss 1.982, Val loss 1.991\n",
      "Ep 1 (Step 034085): Train loss 2.081, Val loss 1.996\n",
      "Ep 1 (Step 034090): Train loss 1.993, Val loss 1.999\n",
      "Ep 1 (Step 034095): Train loss 2.007, Val loss 2.003\n",
      "Ep 1 (Step 034100): Train loss 1.966, Val loss 2.002\n",
      "Ep 1 (Step 034105): Train loss 2.203, Val loss 2.002\n",
      "Ep 1 (Step 034110): Train loss 1.797, Val loss 2.001\n",
      "Ep 1 (Step 034115): Train loss 2.113, Val loss 1.987\n",
      "Ep 1 (Step 034120): Train loss 2.057, Val loss 1.985\n",
      "Ep 1 (Step 034125): Train loss 2.090, Val loss 1.988\n",
      "Ep 1 (Step 034130): Train loss 2.113, Val loss 1.991\n",
      "Ep 1 (Step 034135): Train loss 2.156, Val loss 1.998\n",
      "Ep 1 (Step 034140): Train loss 1.923, Val loss 2.012\n",
      "Ep 1 (Step 034145): Train loss 1.958, Val loss 2.007\n",
      "Ep 1 (Step 034150): Train loss 2.125, Val loss 2.001\n",
      "Ep 1 (Step 034155): Train loss 1.971, Val loss 1.993\n",
      "Ep 1 (Step 034160): Train loss 1.822, Val loss 1.997\n",
      "Ep 1 (Step 034165): Train loss 1.854, Val loss 2.006\n",
      "Ep 1 (Step 034170): Train loss 2.030, Val loss 2.010\n",
      "Ep 1 (Step 034175): Train loss 1.965, Val loss 2.002\n",
      "Ep 1 (Step 034180): Train loss 2.017, Val loss 2.008\n",
      "Ep 1 (Step 034185): Train loss 2.034, Val loss 2.001\n",
      "Ep 1 (Step 034190): Train loss 2.320, Val loss 2.001\n",
      "Ep 1 (Step 034195): Train loss 1.977, Val loss 2.002\n",
      "Ep 1 (Step 034200): Train loss 1.931, Val loss 1.990\n",
      "Ep 1 (Step 034205): Train loss 1.914, Val loss 1.987\n",
      "Ep 1 (Step 034210): Train loss 1.863, Val loss 1.994\n",
      "Ep 1 (Step 034215): Train loss 2.020, Val loss 1.998\n",
      "Ep 1 (Step 034220): Train loss 2.047, Val loss 2.005\n",
      "Ep 1 (Step 034225): Train loss 1.929, Val loss 2.014\n",
      "Ep 1 (Step 034230): Train loss 1.918, Val loss 2.010\n",
      "Ep 1 (Step 034235): Train loss 1.816, Val loss 2.005\n",
      "Ep 1 (Step 034240): Train loss 2.046, Val loss 1.997\n",
      "Ep 1 (Step 034245): Train loss 2.036, Val loss 1.994\n",
      "Ep 1 (Step 034250): Train loss 1.982, Val loss 1.987\n",
      "Ep 1 (Step 034255): Train loss 1.889, Val loss 1.985\n",
      "Ep 1 (Step 034260): Train loss 2.380, Val loss 1.974\n",
      "Ep 1 (Step 034265): Train loss 2.028, Val loss 1.975\n",
      "Ep 1 (Step 034270): Train loss 2.022, Val loss 1.985\n",
      "Ep 1 (Step 034275): Train loss 2.096, Val loss 1.985\n",
      "Ep 1 (Step 034280): Train loss 1.818, Val loss 1.988\n",
      "Ep 1 (Step 034285): Train loss 1.966, Val loss 1.993\n",
      "Ep 1 (Step 034290): Train loss 1.938, Val loss 1.989\n",
      "Ep 1 (Step 034295): Train loss 2.075, Val loss 1.991\n",
      "Ep 1 (Step 034300): Train loss 1.895, Val loss 1.988\n",
      "Ep 1 (Step 034305): Train loss 1.927, Val loss 1.986\n",
      "Ep 1 (Step 034310): Train loss 2.016, Val loss 1.984\n",
      "Ep 1 (Step 034315): Train loss 2.231, Val loss 2.003\n",
      "Ep 1 (Step 034320): Train loss 1.976, Val loss 2.011\n",
      "Ep 1 (Step 034325): Train loss 1.958, Val loss 1.992\n",
      "Ep 1 (Step 034330): Train loss 1.817, Val loss 1.986\n",
      "Ep 1 (Step 034335): Train loss 2.120, Val loss 1.986\n",
      "Ep 1 (Step 034340): Train loss 2.157, Val loss 1.998\n",
      "Ep 1 (Step 034345): Train loss 1.995, Val loss 2.012\n",
      "Ep 1 (Step 034350): Train loss 1.916, Val loss 1.999\n",
      "Ep 1 (Step 034355): Train loss 2.227, Val loss 1.987\n",
      "Ep 1 (Step 034360): Train loss 2.071, Val loss 1.981\n",
      "Ep 1 (Step 034365): Train loss 2.019, Val loss 1.997\n",
      "Ep 1 (Step 034370): Train loss 1.991, Val loss 1.993\n",
      "Ep 1 (Step 034375): Train loss 2.053, Val loss 1.982\n",
      "Ep 1 (Step 034380): Train loss 1.960, Val loss 1.977\n",
      "Ep 1 (Step 034385): Train loss 2.025, Val loss 1.985\n",
      "Ep 1 (Step 034390): Train loss 2.032, Val loss 1.991\n",
      "Ep 1 (Step 034395): Train loss 1.885, Val loss 1.992\n",
      "Ep 1 (Step 034400): Train loss 1.981, Val loss 1.997\n",
      "Ep 1 (Step 034405): Train loss 2.122, Val loss 1.999\n",
      "Ep 1 (Step 034410): Train loss 1.793, Val loss 1.992\n",
      "Ep 1 (Step 034415): Train loss 1.795, Val loss 1.988\n",
      "Ep 1 (Step 034420): Train loss 1.852, Val loss 1.986\n",
      "Ep 1 (Step 034425): Train loss 1.966, Val loss 1.984\n",
      "Ep 1 (Step 034430): Train loss 1.904, Val loss 1.992\n",
      "Ep 1 (Step 034435): Train loss 1.791, Val loss 1.995\n",
      "Ep 1 (Step 034440): Train loss 2.206, Val loss 1.994\n",
      "Ep 1 (Step 034445): Train loss 2.154, Val loss 1.993\n",
      "Ep 1 (Step 034450): Train loss 2.164, Val loss 2.002\n",
      "Ep 1 (Step 034455): Train loss 1.816, Val loss 2.009\n",
      "Ep 1 (Step 034460): Train loss 2.258, Val loss 2.000\n",
      "Ep 1 (Step 034465): Train loss 1.871, Val loss 2.002\n",
      "Ep 1 (Step 034470): Train loss 1.962, Val loss 2.012\n",
      "Ep 1 (Step 034475): Train loss 1.924, Val loss 2.018\n",
      "Ep 1 (Step 034480): Train loss 2.019, Val loss 2.012\n",
      "Ep 1 (Step 034485): Train loss 2.110, Val loss 2.019\n",
      "Ep 1 (Step 034490): Train loss 2.008, Val loss 2.008\n",
      "Ep 1 (Step 034495): Train loss 2.100, Val loss 2.010\n",
      "Ep 1 (Step 034500): Train loss 1.971, Val loss 2.013\n",
      "Ep 1 (Step 034505): Train loss 2.061, Val loss 2.015\n",
      "Ep 1 (Step 034510): Train loss 1.945, Val loss 2.006\n",
      "Ep 1 (Step 034515): Train loss 1.902, Val loss 1.993\n",
      "Ep 1 (Step 034520): Train loss 2.318, Val loss 1.988\n",
      "Ep 1 (Step 034525): Train loss 1.884, Val loss 1.978\n",
      "Ep 1 (Step 034530): Train loss 1.946, Val loss 1.991\n",
      "Ep 1 (Step 034535): Train loss 2.054, Val loss 2.009\n",
      "Ep 1 (Step 034540): Train loss 1.802, Val loss 1.994\n",
      "Ep 1 (Step 034545): Train loss 1.836, Val loss 1.984\n",
      "Ep 1 (Step 034550): Train loss 1.788, Val loss 1.993\n",
      "Ep 1 (Step 034555): Train loss 2.313, Val loss 1.998\n",
      "Ep 1 (Step 034560): Train loss 2.036, Val loss 1.991\n",
      "Ep 1 (Step 034565): Train loss 2.032, Val loss 1.989\n",
      "Ep 1 (Step 034570): Train loss 1.922, Val loss 1.983\n",
      "Ep 1 (Step 034575): Train loss 1.858, Val loss 1.989\n",
      "Ep 1 (Step 034580): Train loss 1.761, Val loss 1.996\n",
      "Ep 1 (Step 034585): Train loss 1.861, Val loss 2.011\n",
      "Ep 1 (Step 034590): Train loss 1.875, Val loss 2.017\n",
      "Ep 1 (Step 034595): Train loss 2.047, Val loss 2.007\n",
      "Ep 1 (Step 034600): Train loss 2.307, Val loss 2.001\n",
      "Ep 1 (Step 034605): Train loss 1.836, Val loss 2.003\n",
      "Ep 1 (Step 034610): Train loss 1.960, Val loss 1.996\n",
      "Ep 1 (Step 034615): Train loss 1.891, Val loss 2.000\n",
      "Ep 1 (Step 034620): Train loss 2.105, Val loss 1.982\n",
      "Ep 1 (Step 034625): Train loss 1.905, Val loss 1.978\n",
      "Ep 1 (Step 034630): Train loss 2.101, Val loss 1.982\n",
      "Ep 1 (Step 034635): Train loss 2.213, Val loss 1.985\n",
      "Ep 1 (Step 034640): Train loss 2.030, Val loss 1.991\n",
      "Ep 1 (Step 034645): Train loss 2.114, Val loss 2.002\n",
      "Ep 1 (Step 034650): Train loss 2.021, Val loss 1.997\n",
      "Ep 1 (Step 034655): Train loss 2.262, Val loss 1.988\n",
      "Ep 1 (Step 034660): Train loss 2.000, Val loss 1.980\n",
      "Ep 1 (Step 034665): Train loss 2.119, Val loss 1.980\n",
      "Ep 1 (Step 034670): Train loss 1.790, Val loss 1.983\n",
      "Ep 1 (Step 034675): Train loss 1.930, Val loss 1.993\n",
      "Ep 1 (Step 034680): Train loss 1.717, Val loss 1.989\n",
      "Ep 1 (Step 034685): Train loss 2.091, Val loss 1.987\n",
      "Ep 1 (Step 034690): Train loss 2.169, Val loss 1.990\n",
      "Ep 1 (Step 034695): Train loss 1.899, Val loss 1.990\n",
      "Ep 1 (Step 034700): Train loss 2.030, Val loss 1.994\n",
      "Ep 1 (Step 034705): Train loss 2.124, Val loss 1.997\n",
      "Ep 1 (Step 034710): Train loss 1.948, Val loss 1.993\n",
      "Ep 1 (Step 034715): Train loss 1.848, Val loss 2.000\n",
      "Ep 1 (Step 034720): Train loss 1.944, Val loss 2.006\n",
      "Ep 1 (Step 034725): Train loss 2.011, Val loss 1.996\n",
      "Ep 1 (Step 034730): Train loss 1.895, Val loss 1.993\n",
      "Ep 1 (Step 034735): Train loss 2.325, Val loss 1.990\n",
      "Ep 1 (Step 034740): Train loss 1.765, Val loss 1.987\n",
      "Ep 1 (Step 034745): Train loss 1.933, Val loss 1.985\n",
      "Ep 1 (Step 034750): Train loss 2.037, Val loss 1.982\n",
      "Ep 1 (Step 034755): Train loss 1.987, Val loss 1.975\n",
      "Ep 1 (Step 034760): Train loss 2.279, Val loss 1.971\n",
      "Ep 1 (Step 034765): Train loss 2.237, Val loss 1.976\n",
      "Ep 1 (Step 034770): Train loss 2.224, Val loss 1.978\n",
      "Ep 1 (Step 034775): Train loss 1.823, Val loss 1.977\n",
      "Ep 1 (Step 034780): Train loss 2.177, Val loss 1.973\n",
      "Ep 1 (Step 034785): Train loss 2.026, Val loss 1.977\n",
      "Ep 1 (Step 034790): Train loss 2.041, Val loss 1.981\n",
      "Ep 1 (Step 034795): Train loss 1.669, Val loss 1.980\n",
      "Ep 1 (Step 034800): Train loss 1.996, Val loss 1.979\n",
      "Ep 1 (Step 034805): Train loss 2.118, Val loss 1.986\n",
      "Ep 1 (Step 034810): Train loss 2.032, Val loss 1.994\n",
      "Ep 1 (Step 034815): Train loss 1.708, Val loss 1.994\n",
      "Ep 1 (Step 034820): Train loss 1.924, Val loss 1.985\n",
      "Ep 1 (Step 034825): Train loss 1.995, Val loss 1.989\n",
      "Ep 1 (Step 034830): Train loss 1.856, Val loss 2.000\n",
      "Ep 1 (Step 034835): Train loss 1.992, Val loss 1.997\n",
      "Ep 1 (Step 034840): Train loss 1.912, Val loss 1.995\n",
      "Ep 1 (Step 034845): Train loss 1.888, Val loss 1.986\n",
      "Ep 1 (Step 034850): Train loss 1.956, Val loss 1.988\n",
      "Ep 1 (Step 034855): Train loss 1.948, Val loss 1.984\n",
      "Ep 1 (Step 034860): Train loss 2.301, Val loss 1.977\n",
      "Ep 1 (Step 034865): Train loss 2.086, Val loss 1.980\n",
      "Ep 1 (Step 034870): Train loss 2.186, Val loss 1.986\n",
      "Ep 1 (Step 034875): Train loss 2.142, Val loss 1.983\n",
      "Ep 1 (Step 034880): Train loss 2.025, Val loss 1.980\n",
      "Ep 1 (Step 034885): Train loss 2.112, Val loss 1.992\n",
      "Ep 1 (Step 034890): Train loss 2.273, Val loss 1.999\n",
      "Ep 1 (Step 034895): Train loss 2.092, Val loss 1.993\n",
      "Ep 1 (Step 034900): Train loss 1.913, Val loss 1.970\n",
      "Ep 1 (Step 034905): Train loss 1.889, Val loss 1.974\n",
      "Ep 1 (Step 034910): Train loss 1.763, Val loss 1.976\n",
      "Ep 1 (Step 034915): Train loss 1.919, Val loss 1.971\n",
      "Ep 1 (Step 034920): Train loss 2.029, Val loss 1.975\n",
      "Ep 1 (Step 034925): Train loss 2.107, Val loss 1.979\n",
      "Ep 1 (Step 034930): Train loss 1.824, Val loss 1.979\n",
      "Ep 1 (Step 034935): Train loss 2.192, Val loss 1.972\n",
      "Ep 1 (Step 034940): Train loss 2.242, Val loss 1.982\n",
      "Ep 1 (Step 034945): Train loss 1.804, Val loss 1.986\n",
      "Ep 1 (Step 034950): Train loss 2.084, Val loss 1.987\n",
      "Ep 1 (Step 034955): Train loss 2.119, Val loss 1.978\n",
      "Ep 1 (Step 034960): Train loss 1.923, Val loss 1.979\n",
      "Ep 1 (Step 034965): Train loss 2.235, Val loss 1.982\n",
      "Ep 1 (Step 034970): Train loss 2.040, Val loss 1.981\n",
      "Ep 1 (Step 034975): Train loss 2.176, Val loss 1.979\n",
      "Ep 1 (Step 034980): Train loss 1.888, Val loss 1.980\n",
      "Ep 1 (Step 034985): Train loss 2.239, Val loss 1.980\n",
      "Ep 1 (Step 034990): Train loss 2.085, Val loss 1.983\n",
      "Ep 1 (Step 034995): Train loss 2.024, Val loss 1.974\n",
      "Ep 1 (Step 035000): Train loss 1.773, Val loss 1.966\n",
      "Ep 1 (Step 035005): Train loss 1.883, Val loss 1.961\n",
      "Ep 1 (Step 035010): Train loss 2.201, Val loss 1.964\n",
      "Ep 1 (Step 035015): Train loss 1.947, Val loss 1.978\n",
      "Ep 1 (Step 035020): Train loss 2.043, Val loss 1.979\n",
      "Ep 1 (Step 035025): Train loss 2.038, Val loss 1.977\n",
      "Ep 1 (Step 035030): Train loss 2.106, Val loss 1.977\n",
      "Ep 1 (Step 035035): Train loss 2.381, Val loss 1.983\n",
      "Ep 1 (Step 035040): Train loss 2.252, Val loss 1.977\n",
      "Ep 1 (Step 035045): Train loss 2.153, Val loss 1.967\n",
      "Ep 1 (Step 035050): Train loss 1.828, Val loss 1.961\n",
      "Ep 1 (Step 035055): Train loss 2.182, Val loss 1.962\n",
      "Ep 1 (Step 035060): Train loss 1.890, Val loss 1.961\n",
      "Ep 1 (Step 035065): Train loss 2.212, Val loss 1.960\n",
      "Ep 1 (Step 035070): Train loss 1.918, Val loss 1.969\n",
      "Ep 1 (Step 035075): Train loss 2.070, Val loss 1.982\n",
      "Ep 1 (Step 035080): Train loss 1.879, Val loss 1.976\n",
      "Ep 1 (Step 035085): Train loss 1.966, Val loss 1.974\n",
      "Ep 1 (Step 035090): Train loss 1.828, Val loss 1.974\n",
      "Ep 1 (Step 035095): Train loss 2.004, Val loss 1.985\n",
      "Ep 1 (Step 035100): Train loss 1.898, Val loss 2.000\n",
      "Ep 1 (Step 035105): Train loss 2.211, Val loss 2.001\n",
      "Ep 1 (Step 035110): Train loss 1.898, Val loss 1.992\n",
      "Ep 1 (Step 035115): Train loss 2.058, Val loss 1.984\n",
      "Ep 1 (Step 035120): Train loss 1.962, Val loss 1.982\n",
      "Ep 1 (Step 035125): Train loss 1.946, Val loss 1.984\n",
      "Ep 1 (Step 035130): Train loss 1.792, Val loss 1.983\n",
      "Ep 1 (Step 035135): Train loss 1.851, Val loss 1.982\n",
      "Ep 1 (Step 035140): Train loss 2.078, Val loss 1.994\n",
      "Ep 1 (Step 035145): Train loss 1.785, Val loss 1.998\n",
      "Ep 1 (Step 035150): Train loss 2.020, Val loss 2.007\n",
      "Ep 1 (Step 035155): Train loss 2.089, Val loss 2.015\n",
      "Ep 1 (Step 035160): Train loss 1.974, Val loss 2.011\n",
      "Ep 1 (Step 035165): Train loss 1.915, Val loss 1.992\n",
      "Ep 1 (Step 035170): Train loss 1.621, Val loss 1.987\n",
      "Ep 1 (Step 035175): Train loss 2.021, Val loss 1.991\n",
      "Ep 1 (Step 035180): Train loss 1.917, Val loss 1.991\n",
      "Ep 1 (Step 035185): Train loss 2.144, Val loss 1.981\n",
      "Ep 1 (Step 035190): Train loss 2.059, Val loss 1.981\n",
      "Ep 1 (Step 035195): Train loss 1.997, Val loss 1.995\n",
      "Ep 1 (Step 035200): Train loss 1.803, Val loss 1.995\n",
      "Ep 1 (Step 035205): Train loss 1.960, Val loss 1.991\n",
      "Ep 1 (Step 035210): Train loss 1.968, Val loss 1.985\n",
      "Ep 1 (Step 035215): Train loss 2.128, Val loss 1.984\n",
      "Ep 1 (Step 035220): Train loss 2.210, Val loss 1.983\n",
      "Ep 1 (Step 035225): Train loss 2.211, Val loss 1.986\n",
      "Ep 1 (Step 035230): Train loss 1.950, Val loss 1.990\n",
      "Ep 1 (Step 035235): Train loss 1.818, Val loss 1.980\n",
      "Ep 1 (Step 035240): Train loss 2.021, Val loss 1.964\n",
      "Ep 1 (Step 035245): Train loss 1.812, Val loss 1.963\n",
      "Ep 1 (Step 035250): Train loss 2.131, Val loss 1.965\n",
      "Ep 1 (Step 035255): Train loss 2.171, Val loss 1.964\n",
      "Ep 1 (Step 035260): Train loss 2.319, Val loss 1.963\n",
      "Ep 1 (Step 035265): Train loss 1.674, Val loss 1.970\n",
      "Ep 1 (Step 035270): Train loss 2.043, Val loss 1.984\n",
      "Ep 1 (Step 035275): Train loss 2.311, Val loss 1.988\n",
      "Ep 1 (Step 035280): Train loss 2.124, Val loss 1.964\n",
      "Ep 1 (Step 035285): Train loss 2.357, Val loss 1.969\n",
      "Ep 1 (Step 035290): Train loss 2.207, Val loss 1.975\n",
      "Ep 1 (Step 035295): Train loss 2.357, Val loss 1.974\n",
      "Ep 1 (Step 035300): Train loss 2.225, Val loss 1.977\n",
      "Ep 1 (Step 035305): Train loss 1.849, Val loss 1.971\n",
      "Ep 1 (Step 035310): Train loss 1.908, Val loss 1.964\n",
      "Ep 1 (Step 035315): Train loss 1.953, Val loss 1.967\n",
      "Ep 1 (Step 035320): Train loss 1.972, Val loss 1.977\n",
      "Ep 1 (Step 035325): Train loss 2.095, Val loss 1.986\n",
      "Ep 1 (Step 035330): Train loss 1.932, Val loss 1.991\n",
      "Ep 1 (Step 035335): Train loss 1.911, Val loss 1.977\n",
      "Ep 1 (Step 035340): Train loss 2.239, Val loss 1.970\n",
      "Ep 1 (Step 035345): Train loss 2.111, Val loss 1.974\n",
      "Ep 1 (Step 035350): Train loss 2.089, Val loss 1.977\n",
      "Ep 1 (Step 035355): Train loss 1.781, Val loss 1.978\n",
      "Ep 1 (Step 035360): Train loss 2.176, Val loss 1.970\n",
      "Ep 1 (Step 035365): Train loss 2.090, Val loss 1.968\n",
      "Ep 1 (Step 035370): Train loss 2.007, Val loss 1.965\n",
      "Ep 1 (Step 035375): Train loss 2.058, Val loss 1.971\n",
      "Ep 1 (Step 035380): Train loss 1.989, Val loss 1.982\n",
      "Ep 1 (Step 035385): Train loss 2.037, Val loss 1.977\n",
      "Ep 1 (Step 035390): Train loss 2.133, Val loss 1.976\n",
      "Ep 1 (Step 035395): Train loss 1.941, Val loss 1.973\n",
      "Ep 1 (Step 035400): Train loss 2.129, Val loss 1.978\n",
      "Ep 1 (Step 035405): Train loss 2.035, Val loss 1.982\n",
      "Ep 1 (Step 035410): Train loss 2.162, Val loss 1.978\n",
      "Ep 1 (Step 035415): Train loss 1.999, Val loss 1.972\n",
      "Ep 1 (Step 035420): Train loss 2.126, Val loss 1.987\n",
      "Ep 1 (Step 035425): Train loss 1.975, Val loss 1.985\n",
      "Ep 1 (Step 035430): Train loss 2.104, Val loss 1.980\n",
      "Ep 1 (Step 035435): Train loss 1.917, Val loss 1.980\n",
      "Ep 1 (Step 035440): Train loss 1.842, Val loss 1.976\n",
      "Ep 1 (Step 035445): Train loss 2.059, Val loss 1.983\n",
      "Ep 1 (Step 035450): Train loss 2.096, Val loss 1.989\n",
      "Ep 1 (Step 035455): Train loss 1.966, Val loss 1.985\n",
      "Ep 1 (Step 035460): Train loss 2.093, Val loss 1.983\n",
      "Ep 1 (Step 035465): Train loss 2.061, Val loss 1.978\n",
      "Ep 1 (Step 035470): Train loss 2.218, Val loss 1.976\n",
      "Ep 1 (Step 035475): Train loss 2.096, Val loss 1.974\n",
      "Ep 1 (Step 035480): Train loss 1.811, Val loss 1.978\n",
      "Ep 1 (Step 035485): Train loss 1.900, Val loss 1.981\n",
      "Ep 1 (Step 035490): Train loss 1.737, Val loss 1.998\n",
      "Ep 1 (Step 035495): Train loss 1.878, Val loss 2.009\n",
      "Ep 1 (Step 035500): Train loss 1.872, Val loss 2.008\n",
      "Ep 1 (Step 035505): Train loss 1.818, Val loss 2.009\n",
      "Ep 1 (Step 035510): Train loss 2.056, Val loss 2.018\n",
      "Ep 1 (Step 035515): Train loss 1.982, Val loss 2.018\n",
      "Ep 1 (Step 035520): Train loss 2.016, Val loss 2.012\n",
      "Ep 1 (Step 035525): Train loss 2.116, Val loss 2.012\n",
      "Ep 1 (Step 035530): Train loss 1.881, Val loss 1.999\n",
      "Ep 1 (Step 035535): Train loss 1.923, Val loss 1.995\n",
      "Ep 1 (Step 035540): Train loss 1.883, Val loss 2.003\n",
      "Ep 1 (Step 035545): Train loss 1.673, Val loss 2.004\n",
      "Ep 1 (Step 035550): Train loss 2.028, Val loss 2.002\n",
      "Ep 1 (Step 035555): Train loss 1.929, Val loss 1.992\n",
      "Ep 1 (Step 035560): Train loss 1.871, Val loss 1.993\n",
      "Ep 1 (Step 035565): Train loss 1.866, Val loss 1.987\n",
      "Ep 1 (Step 035570): Train loss 2.231, Val loss 1.983\n",
      "Ep 1 (Step 035575): Train loss 1.929, Val loss 1.975\n",
      "Ep 1 (Step 035580): Train loss 2.082, Val loss 1.976\n",
      "Ep 1 (Step 035585): Train loss 2.189, Val loss 1.972\n",
      "Ep 1 (Step 035590): Train loss 2.024, Val loss 1.974\n",
      "Ep 1 (Step 035595): Train loss 1.994, Val loss 1.981\n",
      "Ep 1 (Step 035600): Train loss 2.159, Val loss 1.977\n",
      "Ep 1 (Step 035605): Train loss 1.792, Val loss 1.983\n",
      "Ep 1 (Step 035610): Train loss 1.913, Val loss 1.981\n",
      "Ep 1 (Step 035615): Train loss 1.834, Val loss 1.979\n",
      "Ep 1 (Step 035620): Train loss 1.873, Val loss 1.974\n",
      "Ep 1 (Step 035625): Train loss 2.024, Val loss 1.976\n",
      "Ep 1 (Step 035630): Train loss 2.118, Val loss 1.978\n",
      "Ep 1 (Step 035635): Train loss 2.344, Val loss 1.977\n",
      "Ep 1 (Step 035640): Train loss 1.793, Val loss 1.980\n",
      "Ep 1 (Step 035645): Train loss 1.931, Val loss 1.981\n",
      "Ep 1 (Step 035650): Train loss 1.910, Val loss 1.971\n",
      "Ep 1 (Step 035655): Train loss 1.959, Val loss 1.971\n",
      "Ep 1 (Step 035660): Train loss 2.203, Val loss 1.993\n",
      "Ep 1 (Step 035665): Train loss 2.200, Val loss 2.010\n",
      "Ep 1 (Step 035670): Train loss 1.947, Val loss 1.990\n",
      "Ep 1 (Step 035675): Train loss 1.843, Val loss 1.984\n",
      "Ep 1 (Step 035680): Train loss 1.804, Val loss 1.980\n",
      "Ep 1 (Step 035685): Train loss 2.255, Val loss 1.987\n",
      "Ep 1 (Step 035690): Train loss 1.927, Val loss 1.983\n",
      "Ep 1 (Step 035695): Train loss 2.232, Val loss 1.977\n",
      "Ep 1 (Step 035700): Train loss 2.025, Val loss 1.975\n",
      "Ep 1 (Step 035705): Train loss 1.921, Val loss 1.973\n",
      "Ep 1 (Step 035710): Train loss 2.065, Val loss 1.976\n",
      "Ep 1 (Step 035715): Train loss 1.968, Val loss 1.965\n",
      "Ep 1 (Step 035720): Train loss 2.180, Val loss 1.957\n",
      "Ep 1 (Step 035725): Train loss 2.103, Val loss 1.961\n",
      "Ep 1 (Step 035730): Train loss 1.923, Val loss 1.960\n",
      "Ep 1 (Step 035735): Train loss 2.398, Val loss 1.964\n",
      "Ep 1 (Step 035740): Train loss 1.926, Val loss 1.960\n",
      "Ep 1 (Step 035745): Train loss 1.733, Val loss 1.958\n",
      "Ep 1 (Step 035750): Train loss 1.793, Val loss 1.966\n",
      "Ep 1 (Step 035755): Train loss 1.931, Val loss 1.968\n",
      "Ep 1 (Step 035760): Train loss 1.815, Val loss 1.972\n",
      "Ep 1 (Step 035765): Train loss 2.232, Val loss 1.980\n",
      "Ep 1 (Step 035770): Train loss 1.998, Val loss 1.974\n",
      "Ep 1 (Step 035775): Train loss 2.073, Val loss 1.974\n",
      "Ep 1 (Step 035780): Train loss 1.976, Val loss 1.969\n",
      "Ep 1 (Step 035785): Train loss 1.927, Val loss 1.950\n",
      "Ep 1 (Step 035790): Train loss 1.868, Val loss 1.950\n",
      "Ep 1 (Step 035795): Train loss 2.001, Val loss 1.952\n",
      "Ep 1 (Step 035800): Train loss 1.792, Val loss 1.945\n",
      "Ep 1 (Step 035805): Train loss 2.206, Val loss 1.953\n",
      "Ep 1 (Step 035810): Train loss 2.025, Val loss 1.954\n",
      "Ep 1 (Step 035815): Train loss 2.021, Val loss 1.974\n",
      "Ep 1 (Step 035820): Train loss 2.043, Val loss 1.977\n",
      "Ep 1 (Step 035825): Train loss 2.057, Val loss 1.972\n",
      "Ep 1 (Step 035830): Train loss 2.069, Val loss 1.969\n",
      "Ep 1 (Step 035835): Train loss 1.893, Val loss 1.980\n",
      "Ep 1 (Step 035840): Train loss 2.341, Val loss 1.993\n",
      "Ep 1 (Step 035845): Train loss 2.087, Val loss 1.984\n",
      "Ep 1 (Step 035850): Train loss 1.976, Val loss 1.968\n",
      "Ep 1 (Step 035855): Train loss 2.002, Val loss 2.032\n",
      "Ep 1 (Step 035860): Train loss 2.055, Val loss 2.058\n",
      "Ep 1 (Step 035865): Train loss 2.192, Val loss 2.185\n",
      "Ep 1 (Step 035870): Train loss 2.146, Val loss 2.126\n",
      "Ep 1 (Step 035875): Train loss 2.098, Val loss 2.092\n",
      "Ep 1 (Step 035880): Train loss 2.466, Val loss 2.044\n",
      "Ep 1 (Step 035885): Train loss 2.037, Val loss 2.075\n",
      "Ep 1 (Step 035890): Train loss 2.427, Val loss 2.127\n",
      "Ep 1 (Step 035895): Train loss 2.268, Val loss 2.104\n",
      "Ep 1 (Step 035900): Train loss 2.203, Val loss 2.178\n",
      "Ep 1 (Step 035905): Train loss 2.325, Val loss 2.111\n",
      "Ep 1 (Step 035910): Train loss 2.096, Val loss 2.047\n",
      "Ep 1 (Step 035915): Train loss 1.880, Val loss 2.035\n",
      "Ep 1 (Step 035920): Train loss 1.842, Val loss 2.038\n",
      "Ep 1 (Step 035925): Train loss 1.835, Val loss 2.017\n",
      "Ep 1 (Step 035930): Train loss 2.136, Val loss 2.017\n",
      "Ep 1 (Step 035935): Train loss 2.010, Val loss 2.006\n",
      "Ep 1 (Step 035940): Train loss 2.347, Val loss 2.002\n",
      "Ep 1 (Step 035945): Train loss 2.098, Val loss 1.981\n",
      "Ep 1 (Step 035950): Train loss 1.903, Val loss 1.962\n",
      "Ep 1 (Step 035955): Train loss 1.850, Val loss 1.954\n",
      "Ep 1 (Step 035960): Train loss 1.881, Val loss 1.963\n",
      "Ep 1 (Step 035965): Train loss 2.029, Val loss 1.960\n",
      "Ep 1 (Step 035970): Train loss 2.076, Val loss 1.957\n",
      "Ep 1 (Step 035975): Train loss 1.850, Val loss 1.964\n",
      "Ep 1 (Step 035980): Train loss 2.227, Val loss 1.968\n",
      "Ep 1 (Step 035985): Train loss 2.162, Val loss 1.971\n",
      "Ep 1 (Step 035990): Train loss 1.749, Val loss 1.967\n",
      "Ep 1 (Step 035995): Train loss 1.917, Val loss 1.963\n",
      "Ep 1 (Step 036000): Train loss 2.006, Val loss 1.962\n",
      "Ep 1 (Step 036005): Train loss 1.997, Val loss 1.960\n",
      "Ep 1 (Step 036010): Train loss 2.041, Val loss 1.971\n",
      "Ep 1 (Step 036015): Train loss 1.895, Val loss 1.973\n",
      "Ep 1 (Step 036020): Train loss 1.958, Val loss 1.976\n",
      "Ep 1 (Step 036025): Train loss 2.047, Val loss 1.985\n",
      "Ep 1 (Step 036030): Train loss 2.053, Val loss 1.990\n",
      "Ep 1 (Step 036035): Train loss 2.241, Val loss 1.994\n",
      "Ep 1 (Step 036040): Train loss 1.926, Val loss 1.999\n",
      "Ep 1 (Step 036045): Train loss 1.918, Val loss 1.993\n",
      "Ep 1 (Step 036050): Train loss 1.970, Val loss 1.992\n",
      "Ep 1 (Step 036055): Train loss 2.103, Val loss 1.979\n",
      "Ep 1 (Step 036060): Train loss 2.081, Val loss 1.978\n",
      "Ep 1 (Step 036065): Train loss 1.788, Val loss 1.979\n",
      "Ep 1 (Step 036070): Train loss 1.910, Val loss 1.990\n",
      "Ep 1 (Step 036075): Train loss 1.845, Val loss 1.989\n",
      "Ep 1 (Step 036080): Train loss 2.168, Val loss 1.980\n",
      "Ep 1 (Step 036085): Train loss 1.948, Val loss 1.975\n",
      "Ep 1 (Step 036090): Train loss 2.064, Val loss 1.974\n",
      "Ep 1 (Step 036095): Train loss 1.839, Val loss 1.979\n",
      "Ep 1 (Step 036100): Train loss 1.911, Val loss 1.982\n",
      "Ep 1 (Step 036105): Train loss 1.921, Val loss 1.979\n",
      "Ep 1 (Step 036110): Train loss 1.943, Val loss 1.969\n",
      "Ep 1 (Step 036115): Train loss 2.051, Val loss 1.976\n",
      "Ep 1 (Step 036120): Train loss 2.361, Val loss 1.977\n",
      "Ep 1 (Step 036125): Train loss 1.780, Val loss 1.979\n",
      "Ep 1 (Step 036130): Train loss 1.934, Val loss 1.979\n",
      "Ep 1 (Step 036135): Train loss 2.301, Val loss 1.982\n",
      "Ep 1 (Step 036140): Train loss 1.945, Val loss 1.976\n",
      "Ep 1 (Step 036145): Train loss 1.913, Val loss 1.968\n",
      "Ep 1 (Step 036150): Train loss 2.014, Val loss 1.966\n",
      "Ep 1 (Step 036155): Train loss 2.013, Val loss 1.963\n",
      "Ep 1 (Step 036160): Train loss 1.889, Val loss 1.957\n",
      "Ep 1 (Step 036165): Train loss 2.032, Val loss 1.955\n",
      "Ep 1 (Step 036170): Train loss 1.968, Val loss 1.953\n",
      "Ep 1 (Step 036175): Train loss 2.188, Val loss 1.940\n",
      "Ep 1 (Step 036180): Train loss 1.843, Val loss 1.932\n",
      "Ep 1 (Step 036185): Train loss 2.258, Val loss 1.931\n",
      "Ep 1 (Step 036190): Train loss 2.255, Val loss 1.925\n",
      "Ep 1 (Step 036195): Train loss 2.241, Val loss 1.928\n",
      "Ep 1 (Step 036200): Train loss 1.872, Val loss 1.930\n",
      "Ep 1 (Step 036205): Train loss 2.063, Val loss 1.932\n",
      "Ep 1 (Step 036210): Train loss 2.196, Val loss 1.935\n",
      "Ep 1 (Step 036215): Train loss 1.906, Val loss 1.937\n",
      "Ep 1 (Step 036220): Train loss 1.848, Val loss 1.932\n",
      "Ep 1 (Step 036225): Train loss 2.157, Val loss 1.929\n",
      "Ep 1 (Step 036230): Train loss 2.280, Val loss 1.930\n",
      "Ep 1 (Step 036235): Train loss 2.040, Val loss 1.944\n",
      "Ep 1 (Step 036240): Train loss 1.945, Val loss 1.937\n",
      "Ep 1 (Step 036245): Train loss 1.928, Val loss 1.930\n",
      "Ep 1 (Step 036250): Train loss 1.840, Val loss 1.932\n",
      "Ep 1 (Step 036255): Train loss 2.046, Val loss 1.941\n",
      "Ep 1 (Step 036260): Train loss 2.254, Val loss 1.947\n",
      "Ep 1 (Step 036265): Train loss 2.177, Val loss 1.956\n",
      "Ep 1 (Step 036270): Train loss 2.162, Val loss 1.952\n",
      "Ep 1 (Step 036275): Train loss 1.755, Val loss 1.955\n",
      "Ep 1 (Step 036280): Train loss 2.012, Val loss 1.948\n",
      "Ep 1 (Step 036285): Train loss 2.065, Val loss 1.956\n",
      "Ep 1 (Step 036290): Train loss 1.973, Val loss 1.949\n",
      "Ep 1 (Step 036295): Train loss 1.919, Val loss 1.939\n",
      "Ep 1 (Step 036300): Train loss 1.822, Val loss 1.935\n",
      "Ep 1 (Step 036305): Train loss 1.781, Val loss 1.940\n",
      "Ep 1 (Step 036310): Train loss 2.016, Val loss 1.927\n",
      "Ep 1 (Step 036315): Train loss 1.740, Val loss 1.926\n",
      "Ep 1 (Step 036320): Train loss 2.330, Val loss 1.928\n",
      "Ep 1 (Step 036325): Train loss 2.093, Val loss 1.926\n",
      "Ep 1 (Step 036330): Train loss 2.067, Val loss 1.924\n",
      "Ep 1 (Step 036335): Train loss 1.741, Val loss 1.930\n",
      "Ep 1 (Step 036340): Train loss 2.099, Val loss 1.927\n",
      "Ep 1 (Step 036345): Train loss 2.027, Val loss 1.923\n",
      "Ep 1 (Step 036350): Train loss 2.210, Val loss 1.928\n",
      "Ep 1 (Step 036355): Train loss 2.076, Val loss 1.939\n",
      "Ep 1 (Step 036360): Train loss 1.941, Val loss 1.943\n",
      "Ep 1 (Step 036365): Train loss 2.078, Val loss 1.935\n",
      "Ep 1 (Step 036370): Train loss 2.080, Val loss 1.936\n",
      "Ep 1 (Step 036375): Train loss 1.937, Val loss 1.936\n",
      "Ep 1 (Step 036380): Train loss 1.774, Val loss 1.937\n",
      "Ep 1 (Step 036385): Train loss 2.076, Val loss 1.938\n",
      "Ep 1 (Step 036390): Train loss 1.876, Val loss 1.946\n",
      "Ep 1 (Step 036395): Train loss 1.978, Val loss 1.941\n",
      "Ep 1 (Step 036400): Train loss 1.925, Val loss 1.940\n",
      "Ep 1 (Step 036405): Train loss 1.972, Val loss 1.948\n",
      "Ep 1 (Step 036410): Train loss 1.982, Val loss 1.943\n",
      "Ep 1 (Step 036415): Train loss 1.965, Val loss 1.946\n",
      "Ep 1 (Step 036420): Train loss 1.935, Val loss 1.951\n",
      "Ep 1 (Step 036425): Train loss 2.094, Val loss 1.951\n",
      "Ep 1 (Step 036430): Train loss 2.054, Val loss 1.945\n",
      "Ep 1 (Step 036435): Train loss 1.922, Val loss 1.955\n",
      "Ep 1 (Step 036440): Train loss 2.053, Val loss 1.971\n",
      "Ep 1 (Step 036445): Train loss 1.905, Val loss 1.968\n",
      "Ep 1 (Step 036450): Train loss 1.829, Val loss 1.954\n",
      "Ep 1 (Step 036455): Train loss 2.005, Val loss 1.951\n",
      "Ep 1 (Step 036460): Train loss 1.828, Val loss 1.946\n",
      "Ep 1 (Step 036465): Train loss 1.815, Val loss 1.938\n",
      "Ep 1 (Step 036470): Train loss 1.727, Val loss 1.933\n",
      "Ep 1 (Step 036475): Train loss 1.852, Val loss 1.934\n",
      "Ep 1 (Step 036480): Train loss 2.136, Val loss 1.932\n",
      "Ep 1 (Step 036485): Train loss 2.088, Val loss 1.939\n",
      "Ep 1 (Step 036490): Train loss 2.013, Val loss 1.949\n",
      "Ep 1 (Step 036495): Train loss 1.996, Val loss 1.959\n",
      "Ep 1 (Step 036500): Train loss 1.743, Val loss 1.960\n",
      "Ep 1 (Step 036505): Train loss 2.153, Val loss 1.964\n",
      "Ep 1 (Step 036510): Train loss 2.159, Val loss 1.962\n",
      "Ep 1 (Step 036515): Train loss 2.041, Val loss 1.954\n",
      "Ep 1 (Step 036520): Train loss 2.026, Val loss 1.957\n",
      "Ep 1 (Step 036525): Train loss 1.909, Val loss 1.959\n",
      "Ep 1 (Step 036530): Train loss 2.189, Val loss 1.949\n",
      "Ep 1 (Step 036535): Train loss 2.122, Val loss 1.937\n",
      "Ep 1 (Step 036540): Train loss 1.962, Val loss 1.939\n",
      "Ep 1 (Step 036545): Train loss 2.043, Val loss 1.949\n",
      "Ep 1 (Step 036550): Train loss 1.896, Val loss 1.939\n",
      "Ep 1 (Step 036555): Train loss 2.032, Val loss 1.936\n",
      "Ep 1 (Step 036560): Train loss 2.345, Val loss 1.938\n",
      "Ep 1 (Step 036565): Train loss 1.963, Val loss 1.942\n",
      "Ep 1 (Step 036570): Train loss 2.083, Val loss 1.941\n",
      "Ep 1 (Step 036575): Train loss 1.988, Val loss 1.945\n",
      "Ep 1 (Step 036580): Train loss 1.786, Val loss 1.944\n",
      "Ep 1 (Step 036585): Train loss 1.623, Val loss 1.945\n",
      "Ep 1 (Step 036590): Train loss 1.863, Val loss 1.950\n",
      "Ep 1 (Step 036595): Train loss 1.886, Val loss 1.951\n",
      "Ep 1 (Step 036600): Train loss 2.200, Val loss 1.956\n",
      "Ep 1 (Step 036605): Train loss 2.216, Val loss 1.951\n",
      "Ep 1 (Step 036610): Train loss 2.047, Val loss 1.940\n",
      "Ep 1 (Step 036615): Train loss 1.883, Val loss 1.939\n",
      "Ep 1 (Step 036620): Train loss 2.058, Val loss 1.943\n",
      "Ep 1 (Step 036625): Train loss 1.990, Val loss 1.957\n",
      "Ep 1 (Step 036630): Train loss 1.779, Val loss 1.959\n",
      "Ep 1 (Step 036635): Train loss 1.782, Val loss 1.962\n",
      "Ep 1 (Step 036640): Train loss 2.001, Val loss 1.956\n",
      "Ep 1 (Step 036645): Train loss 2.071, Val loss 1.952\n",
      "Ep 1 (Step 036650): Train loss 1.845, Val loss 1.950\n",
      "Ep 1 (Step 036655): Train loss 1.938, Val loss 1.952\n",
      "Ep 1 (Step 036660): Train loss 2.017, Val loss 1.952\n",
      "Ep 1 (Step 036665): Train loss 1.789, Val loss 1.953\n",
      "Ep 1 (Step 036670): Train loss 1.765, Val loss 1.948\n",
      "Ep 1 (Step 036675): Train loss 2.384, Val loss 1.949\n",
      "Ep 1 (Step 036680): Train loss 2.036, Val loss 1.950\n",
      "Ep 1 (Step 036685): Train loss 2.134, Val loss 1.947\n",
      "Ep 1 (Step 036690): Train loss 2.186, Val loss 1.939\n",
      "Ep 1 (Step 036695): Train loss 1.901, Val loss 1.934\n",
      "Ep 1 (Step 036700): Train loss 1.626, Val loss 1.936\n",
      "Ep 1 (Step 036705): Train loss 1.823, Val loss 1.938\n",
      "Ep 1 (Step 036710): Train loss 2.012, Val loss 1.945\n",
      "Ep 1 (Step 036715): Train loss 1.951, Val loss 1.942\n",
      "Ep 1 (Step 036720): Train loss 1.956, Val loss 1.942\n",
      "Ep 1 (Step 036725): Train loss 1.784, Val loss 1.949\n",
      "Ep 1 (Step 036730): Train loss 1.766, Val loss 1.948\n",
      "Ep 1 (Step 036735): Train loss 1.946, Val loss 1.956\n",
      "Ep 1 (Step 036740): Train loss 2.031, Val loss 1.965\n",
      "Ep 1 (Step 036745): Train loss 1.822, Val loss 1.962\n",
      "Ep 1 (Step 036750): Train loss 1.753, Val loss 1.961\n",
      "Ep 1 (Step 036755): Train loss 2.285, Val loss 1.963\n",
      "Ep 1 (Step 036760): Train loss 2.119, Val loss 1.965\n",
      "Ep 1 (Step 036765): Train loss 2.024, Val loss 1.949\n",
      "Ep 1 (Step 036770): Train loss 1.811, Val loss 1.939\n",
      "Ep 1 (Step 036775): Train loss 1.873, Val loss 1.948\n",
      "Ep 1 (Step 036780): Train loss 1.982, Val loss 1.959\n",
      "Ep 1 (Step 036785): Train loss 2.046, Val loss 1.956\n",
      "Ep 1 (Step 036790): Train loss 2.307, Val loss 1.944\n",
      "Ep 1 (Step 036795): Train loss 1.882, Val loss 1.956\n",
      "Ep 1 (Step 036800): Train loss 2.036, Val loss 1.960\n",
      "Ep 1 (Step 036805): Train loss 1.956, Val loss 1.953\n",
      "Ep 1 (Step 036810): Train loss 2.141, Val loss 1.947\n",
      "Ep 1 (Step 036815): Train loss 2.037, Val loss 1.959\n",
      "Ep 1 (Step 036820): Train loss 1.915, Val loss 1.955\n",
      "Ep 1 (Step 036825): Train loss 1.860, Val loss 1.955\n",
      "Ep 1 (Step 036830): Train loss 1.871, Val loss 1.950\n",
      "Ep 1 (Step 036835): Train loss 2.062, Val loss 1.944\n",
      "Ep 1 (Step 036840): Train loss 1.862, Val loss 1.949\n",
      "Ep 1 (Step 036845): Train loss 1.937, Val loss 1.959\n",
      "Ep 1 (Step 036850): Train loss 1.674, Val loss 1.958\n",
      "Ep 1 (Step 036855): Train loss 1.849, Val loss 1.953\n",
      "Ep 1 (Step 036860): Train loss 1.977, Val loss 1.944\n",
      "Ep 1 (Step 036865): Train loss 1.945, Val loss 1.946\n",
      "Ep 1 (Step 036870): Train loss 1.839, Val loss 1.957\n",
      "Ep 1 (Step 036875): Train loss 2.098, Val loss 1.968\n",
      "Ep 1 (Step 036880): Train loss 1.872, Val loss 1.969\n",
      "Ep 1 (Step 036885): Train loss 1.932, Val loss 1.959\n",
      "Ep 1 (Step 036890): Train loss 1.882, Val loss 1.958\n",
      "Ep 1 (Step 036895): Train loss 2.014, Val loss 1.954\n",
      "Ep 1 (Step 036900): Train loss 2.095, Val loss 1.956\n",
      "Ep 1 (Step 036905): Train loss 1.803, Val loss 1.956\n",
      "Ep 1 (Step 036910): Train loss 1.930, Val loss 1.958\n",
      "Ep 1 (Step 036915): Train loss 1.918, Val loss 1.954\n",
      "Ep 1 (Step 036920): Train loss 2.132, Val loss 1.955\n",
      "Ep 1 (Step 036925): Train loss 1.952, Val loss 1.951\n",
      "Ep 1 (Step 036930): Train loss 1.712, Val loss 1.949\n",
      "Ep 1 (Step 036935): Train loss 1.895, Val loss 1.954\n",
      "Ep 1 (Step 036940): Train loss 2.045, Val loss 1.950\n",
      "Ep 1 (Step 036945): Train loss 1.682, Val loss 1.950\n",
      "Ep 1 (Step 036950): Train loss 2.348, Val loss 1.974\n",
      "Ep 1 (Step 036955): Train loss 1.950, Val loss 1.996\n",
      "Ep 1 (Step 036960): Train loss 2.208, Val loss 1.998\n",
      "Ep 1 (Step 036965): Train loss 1.857, Val loss 1.980\n",
      "Ep 1 (Step 036970): Train loss 1.901, Val loss 1.964\n",
      "Ep 1 (Step 036975): Train loss 1.802, Val loss 1.960\n",
      "Ep 1 (Step 036980): Train loss 1.919, Val loss 1.965\n",
      "Ep 1 (Step 036985): Train loss 1.946, Val loss 1.970\n",
      "Ep 1 (Step 036990): Train loss 2.148, Val loss 1.984\n",
      "Ep 1 (Step 036995): Train loss 2.102, Val loss 1.987\n",
      "Ep 1 (Step 037000): Train loss 2.075, Val loss 1.978\n",
      "Ep 1 (Step 037005): Train loss 1.852, Val loss 1.972\n",
      "Ep 1 (Step 037010): Train loss 1.946, Val loss 1.986\n",
      "Ep 1 (Step 037015): Train loss 1.906, Val loss 2.003\n",
      "Ep 1 (Step 037020): Train loss 2.004, Val loss 1.998\n",
      "Ep 1 (Step 037025): Train loss 2.047, Val loss 1.978\n",
      "Ep 1 (Step 037030): Train loss 1.806, Val loss 1.966\n",
      "Ep 1 (Step 037035): Train loss 1.988, Val loss 1.965\n",
      "Ep 1 (Step 037040): Train loss 1.729, Val loss 1.957\n",
      "Ep 1 (Step 037045): Train loss 1.888, Val loss 1.949\n",
      "Ep 1 (Step 037050): Train loss 1.631, Val loss 1.944\n",
      "Ep 1 (Step 037055): Train loss 1.777, Val loss 1.955\n",
      "Ep 1 (Step 037060): Train loss 2.034, Val loss 1.962\n",
      "Ep 1 (Step 037065): Train loss 1.854, Val loss 1.948\n",
      "Ep 1 (Step 037070): Train loss 1.995, Val loss 1.947\n",
      "Ep 1 (Step 037075): Train loss 1.920, Val loss 1.950\n",
      "Ep 1 (Step 037080): Train loss 1.814, Val loss 1.956\n",
      "Ep 1 (Step 037085): Train loss 1.988, Val loss 1.959\n",
      "Ep 1 (Step 037090): Train loss 2.121, Val loss 1.949\n",
      "Ep 1 (Step 037095): Train loss 2.151, Val loss 1.954\n",
      "Ep 1 (Step 037100): Train loss 2.064, Val loss 1.962\n",
      "Ep 1 (Step 037105): Train loss 1.997, Val loss 1.970\n",
      "Ep 1 (Step 037110): Train loss 1.867, Val loss 1.968\n",
      "Ep 1 (Step 037115): Train loss 1.766, Val loss 1.971\n",
      "Ep 1 (Step 037120): Train loss 1.880, Val loss 1.989\n",
      "Ep 1 (Step 037125): Train loss 2.099, Val loss 2.001\n",
      "Ep 1 (Step 037130): Train loss 1.975, Val loss 1.995\n",
      "Ep 1 (Step 037135): Train loss 1.994, Val loss 1.978\n",
      "Ep 1 (Step 037140): Train loss 1.819, Val loss 1.966\n",
      "Ep 1 (Step 037145): Train loss 2.077, Val loss 1.965\n",
      "Ep 1 (Step 037150): Train loss 2.102, Val loss 1.976\n",
      "Ep 1 (Step 037155): Train loss 2.098, Val loss 1.980\n",
      "Ep 1 (Step 037160): Train loss 1.844, Val loss 1.986\n",
      "Ep 1 (Step 037165): Train loss 2.142, Val loss 1.980\n",
      "Ep 1 (Step 037170): Train loss 1.658, Val loss 1.982\n",
      "Ep 1 (Step 037175): Train loss 1.863, Val loss 1.965\n",
      "Ep 1 (Step 037180): Train loss 1.798, Val loss 1.957\n",
      "Ep 1 (Step 037185): Train loss 2.201, Val loss 1.950\n",
      "Ep 1 (Step 037190): Train loss 1.975, Val loss 1.941\n",
      "Ep 1 (Step 037195): Train loss 2.036, Val loss 1.939\n",
      "Ep 1 (Step 037200): Train loss 1.940, Val loss 1.931\n",
      "Ep 1 (Step 037205): Train loss 1.872, Val loss 1.931\n",
      "Ep 1 (Step 037210): Train loss 2.204, Val loss 1.941\n",
      "Ep 1 (Step 037215): Train loss 1.540, Val loss 1.947\n",
      "Ep 1 (Step 037220): Train loss 2.225, Val loss 1.962\n",
      "Ep 1 (Step 037225): Train loss 1.787, Val loss 1.948\n",
      "Ep 1 (Step 037230): Train loss 2.145, Val loss 1.947\n",
      "Ep 1 (Step 037235): Train loss 1.974, Val loss 1.943\n",
      "Ep 1 (Step 037240): Train loss 2.098, Val loss 1.956\n",
      "Ep 1 (Step 037245): Train loss 2.071, Val loss 1.954\n",
      "Ep 1 (Step 037250): Train loss 1.689, Val loss 1.955\n",
      "Ep 1 (Step 037255): Train loss 1.958, Val loss 1.947\n",
      "Ep 1 (Step 037260): Train loss 1.792, Val loss 1.943\n",
      "Ep 1 (Step 037265): Train loss 1.778, Val loss 1.942\n",
      "Ep 1 (Step 037270): Train loss 1.853, Val loss 1.950\n",
      "Ep 1 (Step 037275): Train loss 1.987, Val loss 1.956\n",
      "Ep 1 (Step 037280): Train loss 2.141, Val loss 1.948\n",
      "Ep 1 (Step 037285): Train loss 1.865, Val loss 1.952\n",
      "Ep 1 (Step 037290): Train loss 1.831, Val loss 1.952\n",
      "Ep 1 (Step 037295): Train loss 2.271, Val loss 1.951\n",
      "Ep 1 (Step 037300): Train loss 1.806, Val loss 1.949\n",
      "Ep 1 (Step 037305): Train loss 2.084, Val loss 1.939\n",
      "Ep 1 (Step 037310): Train loss 1.986, Val loss 1.941\n",
      "Ep 1 (Step 037315): Train loss 2.203, Val loss 1.936\n",
      "Ep 1 (Step 037320): Train loss 2.319, Val loss 1.938\n",
      "Ep 1 (Step 037325): Train loss 2.040, Val loss 1.932\n",
      "Ep 1 (Step 037330): Train loss 2.029, Val loss 1.931\n",
      "Ep 1 (Step 037335): Train loss 1.811, Val loss 1.935\n",
      "Ep 1 (Step 037340): Train loss 1.858, Val loss 1.935\n",
      "Ep 1 (Step 037345): Train loss 1.944, Val loss 1.935\n",
      "Ep 1 (Step 037350): Train loss 1.944, Val loss 1.938\n",
      "Ep 1 (Step 037355): Train loss 2.049, Val loss 1.942\n",
      "Ep 1 (Step 037360): Train loss 2.002, Val loss 1.949\n",
      "Ep 1 (Step 037365): Train loss 2.033, Val loss 1.950\n",
      "Ep 1 (Step 037370): Train loss 2.228, Val loss 1.947\n",
      "Ep 1 (Step 037375): Train loss 2.237, Val loss 1.945\n",
      "Ep 1 (Step 037380): Train loss 2.224, Val loss 1.942\n",
      "Ep 1 (Step 037385): Train loss 2.163, Val loss 1.955\n",
      "Ep 1 (Step 037390): Train loss 1.780, Val loss 1.967\n",
      "Ep 1 (Step 037395): Train loss 1.904, Val loss 1.955\n",
      "Ep 1 (Step 037400): Train loss 1.755, Val loss 1.943\n",
      "Ep 1 (Step 037405): Train loss 1.976, Val loss 1.941\n",
      "Ep 1 (Step 037410): Train loss 2.052, Val loss 1.945\n",
      "Ep 1 (Step 037415): Train loss 1.823, Val loss 1.948\n",
      "Ep 1 (Step 037420): Train loss 1.919, Val loss 1.951\n",
      "Ep 1 (Step 037425): Train loss 1.787, Val loss 1.950\n",
      "Ep 1 (Step 037430): Train loss 2.129, Val loss 1.943\n",
      "Ep 1 (Step 037435): Train loss 2.098, Val loss 1.947\n",
      "Ep 1 (Step 037440): Train loss 1.621, Val loss 1.951\n",
      "Ep 1 (Step 037445): Train loss 2.016, Val loss 1.947\n",
      "Ep 1 (Step 037450): Train loss 1.814, Val loss 1.945\n",
      "Ep 1 (Step 037455): Train loss 2.071, Val loss 1.947\n",
      "Ep 1 (Step 037460): Train loss 1.878, Val loss 1.957\n",
      "Ep 1 (Step 037465): Train loss 2.078, Val loss 1.957\n",
      "Ep 1 (Step 037470): Train loss 2.042, Val loss 1.953\n",
      "Ep 1 (Step 037475): Train loss 2.042, Val loss 1.951\n",
      "Ep 1 (Step 037480): Train loss 1.915, Val loss 1.946\n",
      "Ep 1 (Step 037485): Train loss 1.883, Val loss 1.945\n",
      "Ep 1 (Step 037490): Train loss 2.104, Val loss 1.941\n",
      "Ep 1 (Step 037495): Train loss 1.948, Val loss 1.945\n",
      "Ep 1 (Step 037500): Train loss 1.999, Val loss 1.948\n",
      "Ep 1 (Step 037505): Train loss 2.025, Val loss 1.953\n",
      "Ep 1 (Step 037510): Train loss 2.002, Val loss 1.954\n",
      "Ep 1 (Step 037515): Train loss 2.038, Val loss 1.944\n",
      "Ep 1 (Step 037520): Train loss 1.966, Val loss 1.930\n",
      "Ep 1 (Step 037525): Train loss 1.811, Val loss 1.934\n",
      "Ep 1 (Step 037530): Train loss 2.022, Val loss 1.944\n",
      "Ep 1 (Step 037535): Train loss 2.371, Val loss 1.947\n",
      "Ep 1 (Step 037540): Train loss 1.884, Val loss 1.951\n",
      "Ep 1 (Step 037545): Train loss 2.051, Val loss 1.957\n",
      "Ep 1 (Step 037550): Train loss 2.045, Val loss 1.956\n",
      "Ep 1 (Step 037555): Train loss 1.655, Val loss 1.957\n",
      "Ep 1 (Step 037560): Train loss 2.083, Val loss 1.956\n",
      "Ep 1 (Step 037565): Train loss 2.162, Val loss 1.950\n",
      "Ep 1 (Step 037570): Train loss 1.946, Val loss 1.934\n",
      "Ep 1 (Step 037575): Train loss 1.795, Val loss 1.923\n",
      "Ep 1 (Step 037580): Train loss 1.935, Val loss 1.925\n",
      "Ep 1 (Step 037585): Train loss 2.065, Val loss 1.932\n",
      "Ep 1 (Step 037590): Train loss 2.009, Val loss 1.923\n",
      "Ep 1 (Step 037595): Train loss 1.691, Val loss 1.924\n",
      "Ep 1 (Step 037600): Train loss 2.041, Val loss 1.939\n",
      "Ep 1 (Step 037605): Train loss 1.991, Val loss 1.951\n",
      "Ep 1 (Step 037610): Train loss 1.784, Val loss 1.946\n",
      "Ep 1 (Step 037615): Train loss 1.702, Val loss 1.944\n",
      "Ep 1 (Step 037620): Train loss 1.906, Val loss 1.945\n",
      "Ep 1 (Step 037625): Train loss 1.962, Val loss 1.957\n",
      "Ep 1 (Step 037630): Train loss 1.884, Val loss 1.965\n",
      "Ep 1 (Step 037635): Train loss 1.980, Val loss 1.960\n",
      "Ep 1 (Step 037640): Train loss 1.723, Val loss 1.960\n",
      "Ep 1 (Step 037645): Train loss 1.967, Val loss 1.955\n",
      "Ep 1 (Step 037650): Train loss 1.742, Val loss 1.942\n",
      "Ep 1 (Step 037655): Train loss 2.146, Val loss 1.939\n",
      "Ep 1 (Step 037660): Train loss 1.930, Val loss 1.943\n",
      "Ep 1 (Step 037665): Train loss 2.044, Val loss 1.933\n",
      "Ep 1 (Step 037670): Train loss 2.309, Val loss 1.921\n",
      "Ep 1 (Step 037675): Train loss 1.692, Val loss 1.920\n",
      "Ep 1 (Step 037680): Train loss 1.819, Val loss 1.930\n",
      "Ep 1 (Step 037685): Train loss 1.982, Val loss 1.936\n",
      "Ep 1 (Step 037690): Train loss 1.956, Val loss 1.934\n",
      "Ep 1 (Step 037695): Train loss 1.938, Val loss 1.922\n",
      "Ep 1 (Step 037700): Train loss 1.726, Val loss 1.924\n",
      "Ep 1 (Step 037705): Train loss 1.633, Val loss 1.931\n",
      "Ep 1 (Step 037710): Train loss 2.001, Val loss 1.930\n",
      "Ep 1 (Step 037715): Train loss 1.881, Val loss 1.919\n",
      "Ep 1 (Step 037720): Train loss 1.724, Val loss 1.908\n",
      "Ep 1 (Step 037725): Train loss 2.195, Val loss 1.911\n",
      "Ep 1 (Step 037730): Train loss 1.953, Val loss 1.920\n",
      "Ep 1 (Step 037735): Train loss 1.797, Val loss 1.921\n",
      "Ep 1 (Step 037740): Train loss 1.928, Val loss 1.914\n",
      "Ep 1 (Step 037745): Train loss 2.150, Val loss 1.912\n",
      "Ep 1 (Step 037750): Train loss 1.908, Val loss 1.907\n",
      "Ep 1 (Step 037755): Train loss 1.971, Val loss 1.902\n",
      "Ep 1 (Step 037760): Train loss 1.823, Val loss 1.903\n",
      "Ep 1 (Step 037765): Train loss 1.756, Val loss 1.914\n",
      "Ep 1 (Step 037770): Train loss 1.735, Val loss 1.931\n",
      "Ep 1 (Step 037775): Train loss 1.923, Val loss 1.929\n",
      "Ep 1 (Step 037780): Train loss 2.273, Val loss 1.920\n",
      "Ep 1 (Step 037785): Train loss 1.873, Val loss 1.923\n",
      "Ep 1 (Step 037790): Train loss 1.798, Val loss 1.921\n",
      "Ep 1 (Step 037795): Train loss 1.865, Val loss 1.921\n",
      "Ep 1 (Step 037800): Train loss 2.001, Val loss 1.916\n",
      "Ep 1 (Step 037805): Train loss 1.824, Val loss 1.917\n",
      "Ep 1 (Step 037810): Train loss 1.995, Val loss 1.921\n",
      "Ep 1 (Step 037815): Train loss 1.915, Val loss 1.927\n",
      "Ep 1 (Step 037820): Train loss 2.094, Val loss 1.922\n",
      "Ep 1 (Step 037825): Train loss 1.928, Val loss 1.930\n",
      "Ep 1 (Step 037830): Train loss 2.086, Val loss 1.939\n",
      "Ep 1 (Step 037835): Train loss 2.086, Val loss 1.940\n",
      "Ep 1 (Step 037840): Train loss 2.002, Val loss 1.943\n",
      "Ep 1 (Step 037845): Train loss 1.923, Val loss 1.938\n",
      "Ep 1 (Step 037850): Train loss 2.015, Val loss 1.935\n",
      "Ep 1 (Step 037855): Train loss 2.055, Val loss 1.944\n",
      "Ep 1 (Step 037860): Train loss 1.721, Val loss 1.943\n",
      "Ep 1 (Step 037865): Train loss 1.981, Val loss 1.939\n",
      "Ep 1 (Step 037870): Train loss 2.223, Val loss 1.932\n",
      "Ep 1 (Step 037875): Train loss 1.963, Val loss 1.933\n",
      "Ep 1 (Step 037880): Train loss 2.107, Val loss 1.934\n",
      "Ep 1 (Step 037885): Train loss 2.097, Val loss 1.930\n",
      "Ep 1 (Step 037890): Train loss 1.990, Val loss 1.929\n",
      "Ep 1 (Step 037895): Train loss 2.204, Val loss 1.936\n",
      "Ep 1 (Step 037900): Train loss 2.057, Val loss 1.932\n",
      "Ep 1 (Step 037905): Train loss 1.874, Val loss 1.929\n",
      "Ep 1 (Step 037910): Train loss 1.912, Val loss 1.925\n",
      "Ep 1 (Step 037915): Train loss 1.844, Val loss 1.922\n",
      "Ep 1 (Step 037920): Train loss 1.962, Val loss 1.919\n",
      "Ep 1 (Step 037925): Train loss 2.038, Val loss 1.920\n",
      "Ep 1 (Step 037930): Train loss 1.698, Val loss 1.932\n",
      "Ep 1 (Step 037935): Train loss 1.827, Val loss 1.933\n",
      "Ep 1 (Step 037940): Train loss 2.073, Val loss 1.931\n",
      "Ep 1 (Step 037945): Train loss 2.013, Val loss 1.928\n",
      "Ep 1 (Step 037950): Train loss 2.134, Val loss 1.945\n",
      "Ep 1 (Step 037955): Train loss 1.901, Val loss 1.945\n",
      "Ep 1 (Step 037960): Train loss 1.878, Val loss 1.940\n",
      "Ep 1 (Step 037965): Train loss 2.003, Val loss 1.940\n",
      "Ep 1 (Step 037970): Train loss 1.882, Val loss 1.955\n",
      "Ep 1 (Step 037975): Train loss 1.879, Val loss 1.953\n",
      "Ep 1 (Step 037980): Train loss 1.851, Val loss 1.944\n",
      "Ep 1 (Step 037985): Train loss 2.024, Val loss 1.944\n",
      "Ep 1 (Step 037990): Train loss 1.862, Val loss 1.957\n",
      "Ep 1 (Step 037995): Train loss 2.025, Val loss 1.957\n",
      "Ep 1 (Step 038000): Train loss 2.168, Val loss 1.946\n",
      "Ep 1 (Step 038005): Train loss 1.878, Val loss 1.942\n",
      "Ep 1 (Step 038010): Train loss 1.865, Val loss 1.946\n",
      "Ep 1 (Step 038015): Train loss 2.064, Val loss 1.939\n",
      "Ep 1 (Step 038020): Train loss 1.949, Val loss 1.945\n",
      "Ep 1 (Step 038025): Train loss 2.151, Val loss 1.947\n",
      "Ep 1 (Step 038030): Train loss 1.949, Val loss 1.944\n",
      "Ep 1 (Step 038035): Train loss 1.946, Val loss 1.946\n",
      "Ep 1 (Step 038040): Train loss 2.003, Val loss 1.955\n",
      "Ep 1 (Step 038045): Train loss 1.897, Val loss 1.953\n",
      "Ep 1 (Step 038050): Train loss 1.899, Val loss 1.946\n",
      "Ep 1 (Step 038055): Train loss 1.978, Val loss 1.946\n",
      "Ep 1 (Step 038060): Train loss 2.124, Val loss 1.944\n",
      "Ep 1 (Step 038065): Train loss 1.919, Val loss 1.946\n",
      "Ep 1 (Step 038070): Train loss 1.971, Val loss 1.952\n",
      "Ep 1 (Step 038075): Train loss 1.826, Val loss 1.960\n",
      "Ep 1 (Step 038080): Train loss 1.700, Val loss 1.949\n",
      "Ep 1 (Step 038085): Train loss 1.893, Val loss 1.942\n",
      "Ep 1 (Step 038090): Train loss 1.858, Val loss 1.937\n",
      "Ep 1 (Step 038095): Train loss 2.050, Val loss 1.936\n",
      "Ep 1 (Step 038100): Train loss 2.246, Val loss 1.934\n",
      "Ep 1 (Step 038105): Train loss 2.080, Val loss 1.926\n",
      "Ep 1 (Step 038110): Train loss 1.868, Val loss 1.926\n",
      "Ep 1 (Step 038115): Train loss 2.003, Val loss 1.941\n",
      "Ep 1 (Step 038120): Train loss 1.820, Val loss 1.954\n",
      "Ep 1 (Step 038125): Train loss 1.739, Val loss 1.955\n",
      "Ep 1 (Step 038130): Train loss 2.356, Val loss 1.929\n",
      "Ep 1 (Step 038135): Train loss 2.198, Val loss 1.926\n",
      "Ep 1 (Step 038140): Train loss 1.879, Val loss 1.934\n",
      "Ep 1 (Step 038145): Train loss 1.916, Val loss 1.942\n",
      "Ep 1 (Step 038150): Train loss 2.064, Val loss 1.949\n",
      "Ep 1 (Step 038155): Train loss 1.913, Val loss 1.952\n",
      "Ep 1 (Step 038160): Train loss 1.843, Val loss 1.939\n",
      "Ep 1 (Step 038165): Train loss 1.957, Val loss 1.943\n",
      "Ep 1 (Step 038170): Train loss 1.813, Val loss 1.952\n",
      "Ep 1 (Step 038175): Train loss 1.974, Val loss 1.952\n",
      "Ep 1 (Step 038180): Train loss 1.896, Val loss 1.944\n",
      "Ep 1 (Step 038185): Train loss 1.892, Val loss 1.936\n",
      "Ep 1 (Step 038190): Train loss 2.143, Val loss 1.945\n",
      "Ep 1 (Step 038195): Train loss 1.942, Val loss 1.957\n",
      "Ep 1 (Step 038200): Train loss 2.011, Val loss 1.948\n",
      "Ep 1 (Step 038205): Train loss 1.834, Val loss 1.949\n",
      "Ep 1 (Step 038210): Train loss 1.804, Val loss 1.955\n",
      "Ep 1 (Step 038215): Train loss 2.137, Val loss 1.963\n",
      "Ep 1 (Step 038220): Train loss 1.971, Val loss 1.973\n",
      "Ep 1 (Step 038225): Train loss 2.087, Val loss 1.959\n",
      "Ep 1 (Step 038230): Train loss 1.778, Val loss 1.951\n",
      "Ep 1 (Step 038235): Train loss 1.778, Val loss 1.957\n",
      "Ep 1 (Step 038240): Train loss 2.224, Val loss 1.965\n",
      "Ep 1 (Step 038245): Train loss 1.880, Val loss 1.962\n",
      "Ep 1 (Step 038250): Train loss 2.236, Val loss 1.953\n",
      "Ep 1 (Step 038255): Train loss 2.167, Val loss 1.964\n",
      "Ep 1 (Step 038260): Train loss 2.085, Val loss 1.966\n",
      "Ep 1 (Step 038265): Train loss 1.778, Val loss 1.967\n",
      "Ep 1 (Step 038270): Train loss 2.296, Val loss 1.964\n",
      "Ep 1 (Step 038275): Train loss 1.791, Val loss 1.967\n",
      "Ep 1 (Step 038280): Train loss 1.831, Val loss 1.977\n",
      "Ep 1 (Step 038285): Train loss 1.885, Val loss 1.976\n",
      "Ep 1 (Step 038290): Train loss 2.007, Val loss 1.975\n",
      "Ep 1 (Step 038295): Train loss 2.244, Val loss 1.978\n",
      "Ep 1 (Step 038300): Train loss 1.946, Val loss 1.979\n",
      "Ep 1 (Step 038305): Train loss 1.902, Val loss 1.964\n",
      "Ep 1 (Step 038310): Train loss 2.227, Val loss 1.954\n",
      "Ep 1 (Step 038315): Train loss 2.284, Val loss 1.949\n",
      "Ep 1 (Step 038320): Train loss 2.054, Val loss 1.953\n",
      "Ep 1 (Step 038325): Train loss 1.886, Val loss 1.951\n",
      "Ep 1 (Step 038330): Train loss 1.821, Val loss 1.955\n",
      "Ep 1 (Step 038335): Train loss 2.337, Val loss 1.963\n",
      "Ep 1 (Step 038340): Train loss 1.799, Val loss 1.962\n",
      "Ep 1 (Step 038345): Train loss 1.689, Val loss 1.958\n",
      "Ep 1 (Step 038350): Train loss 1.864, Val loss 1.943\n",
      "Ep 1 (Step 038355): Train loss 2.035, Val loss 1.940\n",
      "Ep 1 (Step 038360): Train loss 2.393, Val loss 1.959\n",
      "Ep 1 (Step 038365): Train loss 1.799, Val loss 1.953\n",
      "Ep 1 (Step 038370): Train loss 1.976, Val loss 1.943\n",
      "Ep 1 (Step 038375): Train loss 2.039, Val loss 1.945\n",
      "Ep 1 (Step 038380): Train loss 1.920, Val loss 1.941\n",
      "Ep 1 (Step 038385): Train loss 1.784, Val loss 1.940\n",
      "Ep 1 (Step 038390): Train loss 1.834, Val loss 1.932\n",
      "Ep 1 (Step 038395): Train loss 2.018, Val loss 1.937\n",
      "Ep 1 (Step 038400): Train loss 1.937, Val loss 1.950\n",
      "Ep 1 (Step 038405): Train loss 2.044, Val loss 1.958\n",
      "Ep 1 (Step 038410): Train loss 1.799, Val loss 1.962\n",
      "Ep 1 (Step 038415): Train loss 2.065, Val loss 1.970\n",
      "Ep 1 (Step 038420): Train loss 1.539, Val loss 1.962\n",
      "Ep 1 (Step 038425): Train loss 2.029, Val loss 1.962\n",
      "Ep 1 (Step 038430): Train loss 2.062, Val loss 1.960\n",
      "Ep 1 (Step 038435): Train loss 1.799, Val loss 1.946\n",
      "Ep 1 (Step 038440): Train loss 1.915, Val loss 1.943\n",
      "Ep 1 (Step 038445): Train loss 2.105, Val loss 1.941\n",
      "Ep 1 (Step 038450): Train loss 1.857, Val loss 1.938\n",
      "Ep 1 (Step 038455): Train loss 2.347, Val loss 1.935\n",
      "Ep 1 (Step 038460): Train loss 1.888, Val loss 1.948\n",
      "Ep 1 (Step 038465): Train loss 1.822, Val loss 1.953\n",
      "Ep 1 (Step 038470): Train loss 2.037, Val loss 1.945\n",
      "Ep 1 (Step 038475): Train loss 1.989, Val loss 1.945\n",
      "Ep 1 (Step 038480): Train loss 1.506, Val loss 1.954\n",
      "Ep 1 (Step 038485): Train loss 2.056, Val loss 1.955\n",
      "Ep 1 (Step 038490): Train loss 1.902, Val loss 1.956\n",
      "Ep 1 (Step 038495): Train loss 1.823, Val loss 1.954\n",
      "Ep 1 (Step 038500): Train loss 2.022, Val loss 1.960\n",
      "Ep 1 (Step 038505): Train loss 2.043, Val loss 1.964\n",
      "Ep 1 (Step 038510): Train loss 1.702, Val loss 1.960\n",
      "Ep 1 (Step 038515): Train loss 1.940, Val loss 1.957\n",
      "Ep 1 (Step 038520): Train loss 1.860, Val loss 1.951\n",
      "Ep 1 (Step 038525): Train loss 1.818, Val loss 1.951\n",
      "Ep 1 (Step 038530): Train loss 1.895, Val loss 1.950\n",
      "Ep 1 (Step 038535): Train loss 1.919, Val loss 1.948\n",
      "Ep 1 (Step 038540): Train loss 2.028, Val loss 1.939\n",
      "Ep 1 (Step 038545): Train loss 1.928, Val loss 1.943\n",
      "Ep 1 (Step 038550): Train loss 2.176, Val loss 1.946\n",
      "Ep 1 (Step 038555): Train loss 2.364, Val loss 1.953\n",
      "Ep 1 (Step 038560): Train loss 1.757, Val loss 1.946\n",
      "Ep 1 (Step 038565): Train loss 2.195, Val loss 1.946\n",
      "Ep 1 (Step 038570): Train loss 1.839, Val loss 1.937\n",
      "Ep 1 (Step 038575): Train loss 1.906, Val loss 1.933\n",
      "Ep 1 (Step 038580): Train loss 1.736, Val loss 1.934\n",
      "Ep 1 (Step 038585): Train loss 2.021, Val loss 1.927\n",
      "Ep 1 (Step 038590): Train loss 1.946, Val loss 1.931\n",
      "Ep 1 (Step 038595): Train loss 1.956, Val loss 1.925\n",
      "Ep 1 (Step 038600): Train loss 2.132, Val loss 1.921\n",
      "Ep 1 (Step 038605): Train loss 2.403, Val loss 1.908\n",
      "Ep 1 (Step 038610): Train loss 2.216, Val loss 1.893\n",
      "Ep 1 (Step 038615): Train loss 1.753, Val loss 1.901\n",
      "Ep 1 (Step 038620): Train loss 1.742, Val loss 1.900\n",
      "Ep 1 (Step 038625): Train loss 2.129, Val loss 1.904\n",
      "Ep 1 (Step 038630): Train loss 2.033, Val loss 1.920\n",
      "Ep 1 (Step 038635): Train loss 2.089, Val loss 1.916\n",
      "Ep 1 (Step 038640): Train loss 2.168, Val loss 1.911\n",
      "Ep 1 (Step 038645): Train loss 1.882, Val loss 1.908\n",
      "Ep 1 (Step 038650): Train loss 1.805, Val loss 1.912\n",
      "Ep 1 (Step 038655): Train loss 1.976, Val loss 1.927\n",
      "Ep 1 (Step 038660): Train loss 1.836, Val loss 1.921\n",
      "Ep 1 (Step 038665): Train loss 2.228, Val loss 1.925\n",
      "Ep 1 (Step 038670): Train loss 1.817, Val loss 1.922\n",
      "Ep 1 (Step 038675): Train loss 1.983, Val loss 1.927\n",
      "Ep 1 (Step 038680): Train loss 2.018, Val loss 1.919\n",
      "Ep 1 (Step 038685): Train loss 1.887, Val loss 1.930\n",
      "Ep 1 (Step 038690): Train loss 1.889, Val loss 1.930\n",
      "Ep 1 (Step 038695): Train loss 1.888, Val loss 1.917\n",
      "Ep 1 (Step 038700): Train loss 1.983, Val loss 1.918\n",
      "Ep 1 (Step 038705): Train loss 2.048, Val loss 1.927\n",
      "Ep 1 (Step 038710): Train loss 1.783, Val loss 1.936\n",
      "Ep 1 (Step 038715): Train loss 2.059, Val loss 1.948\n",
      "Ep 1 (Step 038720): Train loss 2.048, Val loss 1.950\n",
      "Ep 1 (Step 038725): Train loss 1.915, Val loss 1.945\n",
      "Ep 1 (Step 038730): Train loss 1.926, Val loss 1.935\n",
      "Ep 1 (Step 038735): Train loss 1.778, Val loss 1.935\n",
      "Ep 1 (Step 038740): Train loss 1.748, Val loss 1.939\n",
      "Ep 1 (Step 038745): Train loss 1.839, Val loss 1.948\n",
      "Ep 1 (Step 038750): Train loss 1.945, Val loss 1.951\n",
      "Ep 1 (Step 038755): Train loss 2.114, Val loss 1.957\n",
      "Ep 1 (Step 038760): Train loss 1.955, Val loss 1.956\n",
      "Ep 1 (Step 038765): Train loss 1.787, Val loss 1.933\n",
      "Ep 1 (Step 038770): Train loss 1.913, Val loss 1.930\n",
      "Ep 1 (Step 038775): Train loss 2.196, Val loss 1.932\n",
      "Ep 1 (Step 038780): Train loss 1.857, Val loss 1.931\n",
      "Ep 1 (Step 038785): Train loss 2.012, Val loss 1.937\n",
      "Ep 1 (Step 038790): Train loss 1.979, Val loss 1.944\n",
      "Ep 1 (Step 038795): Train loss 1.983, Val loss 1.936\n",
      "Ep 1 (Step 038800): Train loss 1.764, Val loss 1.928\n",
      "Ep 1 (Step 038805): Train loss 1.886, Val loss 1.922\n",
      "Ep 1 (Step 038810): Train loss 2.097, Val loss 1.919\n",
      "Ep 1 (Step 038815): Train loss 2.140, Val loss 1.925\n",
      "Ep 1 (Step 038820): Train loss 2.016, Val loss 1.938\n",
      "Ep 1 (Step 038825): Train loss 2.264, Val loss 1.937\n",
      "Ep 1 (Step 038830): Train loss 1.771, Val loss 1.940\n",
      "Ep 1 (Step 038835): Train loss 1.754, Val loss 1.942\n",
      "Ep 1 (Step 038840): Train loss 1.964, Val loss 1.933\n",
      "Ep 1 (Step 038845): Train loss 2.321, Val loss 1.933\n",
      "Ep 1 (Step 038850): Train loss 2.109, Val loss 1.936\n",
      "Ep 1 (Step 038855): Train loss 1.897, Val loss 1.952\n",
      "Ep 1 (Step 038860): Train loss 2.318, Val loss 1.954\n",
      "Ep 1 (Step 038865): Train loss 2.003, Val loss 1.947\n",
      "Ep 1 (Step 038870): Train loss 1.790, Val loss 1.941\n",
      "Ep 1 (Step 038875): Train loss 1.950, Val loss 1.946\n",
      "Ep 1 (Step 038880): Train loss 1.691, Val loss 1.948\n",
      "Ep 1 (Step 038885): Train loss 2.066, Val loss 1.948\n",
      "Ep 1 (Step 038890): Train loss 2.220, Val loss 1.951\n",
      "Ep 1 (Step 038895): Train loss 1.856, Val loss 1.941\n",
      "Ep 1 (Step 038900): Train loss 2.031, Val loss 1.937\n",
      "Ep 1 (Step 038905): Train loss 2.000, Val loss 1.940\n",
      "Ep 1 (Step 038910): Train loss 1.930, Val loss 1.941\n",
      "Ep 1 (Step 038915): Train loss 2.109, Val loss 1.946\n",
      "Ep 1 (Step 038920): Train loss 1.706, Val loss 1.954\n",
      "Ep 1 (Step 038925): Train loss 1.875, Val loss 1.948\n",
      "Ep 1 (Step 038930): Train loss 2.265, Val loss 1.936\n",
      "Ep 1 (Step 038935): Train loss 1.891, Val loss 1.933\n",
      "Ep 1 (Step 038940): Train loss 2.023, Val loss 1.924\n",
      "Ep 1 (Step 038945): Train loss 2.119, Val loss 1.909\n",
      "Ep 1 (Step 038950): Train loss 2.062, Val loss 1.912\n",
      "Ep 1 (Step 038955): Train loss 1.936, Val loss 1.915\n",
      "Ep 1 (Step 038960): Train loss 2.017, Val loss 1.909\n",
      "Ep 1 (Step 038965): Train loss 2.069, Val loss 1.916\n",
      "Ep 1 (Step 038970): Train loss 1.779, Val loss 1.915\n",
      "Ep 1 (Step 038975): Train loss 1.936, Val loss 1.910\n",
      "Ep 1 (Step 038980): Train loss 1.857, Val loss 1.914\n",
      "Ep 1 (Step 038985): Train loss 1.950, Val loss 1.914\n",
      "Ep 1 (Step 038990): Train loss 2.333, Val loss 1.922\n",
      "Ep 1 (Step 038995): Train loss 1.882, Val loss 1.920\n",
      "Ep 1 (Step 039000): Train loss 1.897, Val loss 1.919\n",
      "Ep 1 (Step 039005): Train loss 1.789, Val loss 1.924\n",
      "Ep 1 (Step 039010): Train loss 1.903, Val loss 1.920\n",
      "Ep 1 (Step 039015): Train loss 1.915, Val loss 1.911\n",
      "Ep 1 (Step 039020): Train loss 2.048, Val loss 1.916\n",
      "Ep 1 (Step 039025): Train loss 1.904, Val loss 1.907\n",
      "Ep 1 (Step 039030): Train loss 1.810, Val loss 1.903\n",
      "Ep 1 (Step 039035): Train loss 2.177, Val loss 1.908\n",
      "Ep 1 (Step 039040): Train loss 2.056, Val loss 1.914\n",
      "Ep 1 (Step 039045): Train loss 1.907, Val loss 1.924\n",
      "Ep 1 (Step 039050): Train loss 2.072, Val loss 1.940\n",
      "Ep 1 (Step 039055): Train loss 1.937, Val loss 1.936\n",
      "Ep 1 (Step 039060): Train loss 1.971, Val loss 1.938\n",
      "Ep 1 (Step 039065): Train loss 1.689, Val loss 1.944\n",
      "Ep 1 (Step 039070): Train loss 1.624, Val loss 1.938\n",
      "Ep 1 (Step 039075): Train loss 1.809, Val loss 1.946\n",
      "Ep 1 (Step 039080): Train loss 1.926, Val loss 1.945\n",
      "Ep 1 (Step 039085): Train loss 1.871, Val loss 1.937\n",
      "Ep 1 (Step 039090): Train loss 2.051, Val loss 1.943\n",
      "Ep 1 (Step 039095): Train loss 1.743, Val loss 1.933\n",
      "Ep 1 (Step 039100): Train loss 1.976, Val loss 1.932\n",
      "Ep 1 (Step 039105): Train loss 1.855, Val loss 1.940\n",
      "Ep 1 (Step 039110): Train loss 2.104, Val loss 1.939\n",
      "Ep 1 (Step 039115): Train loss 1.848, Val loss 1.937\n",
      "Ep 1 (Step 039120): Train loss 1.747, Val loss 1.943\n",
      "Ep 1 (Step 039125): Train loss 1.689, Val loss 1.942\n",
      "Ep 1 (Step 039130): Train loss 1.904, Val loss 1.934\n",
      "Ep 1 (Step 039135): Train loss 1.876, Val loss 1.933\n",
      "Ep 1 (Step 039140): Train loss 2.075, Val loss 1.923\n",
      "Ep 1 (Step 039145): Train loss 1.944, Val loss 1.915\n",
      "Ep 1 (Step 039150): Train loss 1.825, Val loss 1.915\n",
      "Ep 1 (Step 039155): Train loss 1.937, Val loss 1.906\n",
      "Ep 1 (Step 039160): Train loss 1.739, Val loss 1.911\n",
      "Ep 1 (Step 039165): Train loss 1.981, Val loss 1.910\n",
      "Ep 1 (Step 039170): Train loss 2.040, Val loss 1.917\n",
      "Ep 1 (Step 039175): Train loss 2.143, Val loss 1.919\n",
      "Ep 1 (Step 039180): Train loss 2.428, Val loss 1.924\n",
      "Ep 1 (Step 039185): Train loss 2.080, Val loss 1.927\n",
      "Ep 1 (Step 039190): Train loss 1.993, Val loss 1.923\n",
      "Ep 1 (Step 039195): Train loss 2.055, Val loss 1.915\n",
      "Ep 1 (Step 039200): Train loss 1.716, Val loss 1.913\n",
      "Ep 1 (Step 039205): Train loss 1.931, Val loss 1.911\n",
      "Ep 1 (Step 039210): Train loss 1.940, Val loss 1.920\n",
      "Ep 1 (Step 039215): Train loss 1.841, Val loss 1.926\n",
      "Ep 1 (Step 039220): Train loss 1.895, Val loss 1.925\n",
      "Ep 1 (Step 039225): Train loss 2.308, Val loss 1.925\n",
      "Ep 1 (Step 039230): Train loss 2.174, Val loss 1.926\n",
      "Ep 1 (Step 039235): Train loss 1.844, Val loss 1.924\n",
      "Ep 1 (Step 039240): Train loss 2.125, Val loss 1.929\n",
      "Ep 1 (Step 039245): Train loss 1.876, Val loss 1.935\n",
      "Ep 1 (Step 039250): Train loss 1.957, Val loss 1.932\n",
      "Ep 1 (Step 039255): Train loss 2.016, Val loss 1.920\n",
      "Ep 1 (Step 039260): Train loss 1.841, Val loss 1.912\n",
      "Ep 1 (Step 039265): Train loss 2.079, Val loss 1.915\n",
      "Ep 1 (Step 039270): Train loss 1.944, Val loss 1.911\n",
      "Ep 1 (Step 039275): Train loss 2.068, Val loss 1.913\n",
      "Ep 1 (Step 039280): Train loss 1.875, Val loss 1.914\n",
      "Ep 1 (Step 039285): Train loss 2.006, Val loss 1.912\n",
      "Ep 1 (Step 039290): Train loss 1.938, Val loss 1.912\n",
      "Ep 1 (Step 039295): Train loss 1.902, Val loss 1.910\n",
      "Ep 1 (Step 039300): Train loss 2.039, Val loss 1.913\n",
      "Ep 1 (Step 039305): Train loss 1.949, Val loss 1.918\n",
      "Ep 1 (Step 039310): Train loss 1.874, Val loss 1.915\n",
      "Ep 1 (Step 039315): Train loss 2.018, Val loss 1.911\n",
      "Ep 1 (Step 039320): Train loss 1.791, Val loss 1.919\n",
      "Ep 1 (Step 039325): Train loss 1.871, Val loss 1.915\n",
      "Ep 1 (Step 039330): Train loss 1.585, Val loss 1.904\n",
      "Ep 1 (Step 039335): Train loss 1.906, Val loss 1.910\n",
      "Ep 1 (Step 039340): Train loss 1.934, Val loss 1.906\n",
      "Ep 1 (Step 039345): Train loss 2.092, Val loss 1.927\n",
      "Ep 1 (Step 039350): Train loss 1.905, Val loss 1.934\n",
      "Ep 1 (Step 039355): Train loss 2.025, Val loss 1.933\n",
      "Ep 1 (Step 039360): Train loss 1.840, Val loss 1.936\n",
      "Ep 1 (Step 039365): Train loss 2.122, Val loss 1.925\n",
      "Ep 1 (Step 039370): Train loss 1.955, Val loss 1.921\n",
      "Ep 1 (Step 039375): Train loss 1.948, Val loss 1.922\n",
      "Ep 1 (Step 039380): Train loss 1.731, Val loss 1.930\n",
      "Ep 1 (Step 039385): Train loss 1.943, Val loss 1.938\n",
      "Ep 1 (Step 039390): Train loss 1.772, Val loss 1.930\n",
      "Ep 1 (Step 039395): Train loss 2.043, Val loss 1.927\n",
      "Ep 1 (Step 039400): Train loss 1.896, Val loss 1.933\n",
      "Ep 1 (Step 039405): Train loss 2.197, Val loss 1.932\n",
      "Ep 1 (Step 039410): Train loss 2.061, Val loss 1.927\n",
      "Ep 1 (Step 039415): Train loss 1.945, Val loss 1.918\n",
      "Ep 1 (Step 039420): Train loss 2.019, Val loss 1.913\n",
      "Ep 1 (Step 039425): Train loss 1.799, Val loss 1.916\n",
      "Ep 1 (Step 039430): Train loss 2.189, Val loss 1.908\n",
      "Ep 1 (Step 039435): Train loss 1.848, Val loss 1.913\n",
      "Ep 1 (Step 039440): Train loss 1.630, Val loss 1.925\n",
      "Ep 1 (Step 039445): Train loss 1.797, Val loss 1.927\n",
      "Ep 1 (Step 039450): Train loss 1.921, Val loss 1.920\n",
      "Ep 1 (Step 039455): Train loss 1.826, Val loss 1.925\n",
      "Ep 1 (Step 039460): Train loss 1.946, Val loss 1.928\n",
      "Ep 1 (Step 039465): Train loss 2.130, Val loss 1.937\n",
      "Ep 1 (Step 039470): Train loss 1.702, Val loss 1.943\n",
      "Ep 1 (Step 039475): Train loss 1.838, Val loss 1.939\n",
      "Ep 1 (Step 039480): Train loss 1.901, Val loss 1.942\n",
      "Ep 1 (Step 039485): Train loss 2.112, Val loss 1.928\n",
      "Ep 1 (Step 039490): Train loss 2.110, Val loss 1.924\n",
      "Ep 1 (Step 039495): Train loss 2.093, Val loss 1.922\n",
      "Ep 1 (Step 039500): Train loss 1.637, Val loss 1.926\n",
      "Ep 1 (Step 039505): Train loss 1.886, Val loss 1.925\n",
      "Ep 1 (Step 039510): Train loss 2.031, Val loss 1.915\n",
      "Ep 1 (Step 039515): Train loss 2.114, Val loss 1.909\n",
      "Ep 1 (Step 039520): Train loss 1.728, Val loss 1.911\n",
      "Ep 1 (Step 039525): Train loss 2.000, Val loss 1.912\n",
      "Ep 1 (Step 039530): Train loss 2.092, Val loss 1.917\n",
      "Ep 1 (Step 039535): Train loss 2.026, Val loss 1.917\n",
      "Ep 1 (Step 039540): Train loss 1.990, Val loss 1.920\n",
      "Ep 1 (Step 039545): Train loss 2.143, Val loss 1.922\n",
      "Ep 1 (Step 039550): Train loss 1.919, Val loss 1.928\n",
      "Ep 1 (Step 039555): Train loss 1.998, Val loss 1.931\n",
      "Ep 1 (Step 039560): Train loss 1.925, Val loss 1.927\n",
      "Ep 1 (Step 039565): Train loss 1.935, Val loss 1.929\n",
      "Ep 1 (Step 039570): Train loss 1.962, Val loss 1.919\n",
      "Ep 1 (Step 039575): Train loss 1.914, Val loss 1.913\n",
      "Ep 1 (Step 039580): Train loss 2.158, Val loss 1.903\n",
      "Ep 1 (Step 039585): Train loss 2.474, Val loss 1.906\n",
      "Ep 1 (Step 039590): Train loss 1.925, Val loss 1.913\n",
      "Ep 1 (Step 039595): Train loss 2.057, Val loss 1.912\n",
      "Ep 1 (Step 039600): Train loss 1.908, Val loss 1.915\n",
      "Ep 1 (Step 039605): Train loss 1.944, Val loss 1.897\n",
      "Ep 1 (Step 039610): Train loss 1.858, Val loss 1.892\n",
      "Ep 1 (Step 039615): Train loss 1.876, Val loss 1.899\n",
      "Ep 1 (Step 039620): Train loss 1.823, Val loss 1.900\n",
      "Ep 1 (Step 039625): Train loss 1.959, Val loss 1.890\n",
      "Ep 1 (Step 039630): Train loss 2.043, Val loss 1.886\n",
      "Ep 1 (Step 039635): Train loss 1.729, Val loss 1.890\n",
      "Ep 1 (Step 039640): Train loss 1.926, Val loss 1.893\n",
      "Ep 1 (Step 039645): Train loss 1.985, Val loss 1.892\n",
      "Ep 1 (Step 039650): Train loss 1.920, Val loss 1.900\n",
      "Ep 1 (Step 039655): Train loss 1.826, Val loss 1.907\n",
      "Ep 1 (Step 039660): Train loss 1.796, Val loss 1.899\n",
      "Ep 1 (Step 039665): Train loss 1.869, Val loss 1.900\n",
      "Ep 1 (Step 039670): Train loss 2.298, Val loss 1.900\n",
      "Ep 1 (Step 039675): Train loss 1.866, Val loss 1.896\n",
      "Ep 1 (Step 039680): Train loss 1.927, Val loss 1.903\n",
      "Ep 1 (Step 039685): Train loss 1.904, Val loss 1.909\n",
      "Ep 1 (Step 039690): Train loss 2.181, Val loss 1.903\n",
      "Ep 1 (Step 039695): Train loss 2.132, Val loss 1.911\n",
      "Ep 1 (Step 039700): Train loss 1.998, Val loss 1.923\n",
      "Ep 1 (Step 039705): Train loss 2.117, Val loss 1.941\n",
      "Ep 1 (Step 039710): Train loss 1.828, Val loss 1.927\n",
      "Ep 1 (Step 039715): Train loss 1.951, Val loss 1.917\n",
      "Ep 1 (Step 039720): Train loss 2.242, Val loss 1.907\n",
      "Ep 1 (Step 039725): Train loss 1.846, Val loss 1.912\n",
      "Ep 1 (Step 039730): Train loss 1.803, Val loss 1.916\n",
      "Ep 1 (Step 039735): Train loss 2.094, Val loss 1.914\n",
      "Ep 1 (Step 039740): Train loss 1.978, Val loss 1.916\n",
      "Ep 1 (Step 039745): Train loss 2.037, Val loss 1.912\n",
      "Ep 1 (Step 039750): Train loss 1.946, Val loss 1.909\n",
      "Ep 1 (Step 039755): Train loss 1.894, Val loss 1.913\n",
      "Ep 1 (Step 039760): Train loss 2.053, Val loss 1.919\n",
      "Ep 1 (Step 039765): Train loss 1.711, Val loss 1.920\n",
      "Ep 1 (Step 039770): Train loss 1.874, Val loss 1.926\n",
      "Ep 1 (Step 039775): Train loss 2.089, Val loss 1.915\n",
      "Ep 1 (Step 039780): Train loss 1.917, Val loss 1.915\n",
      "Ep 1 (Step 039785): Train loss 2.013, Val loss 1.902\n",
      "Ep 1 (Step 039790): Train loss 1.965, Val loss 1.902\n",
      "Ep 1 (Step 039795): Train loss 1.878, Val loss 1.910\n",
      "Ep 1 (Step 039800): Train loss 1.907, Val loss 1.919\n",
      "Ep 1 (Step 039805): Train loss 1.724, Val loss 1.914\n",
      "Ep 1 (Step 039810): Train loss 2.222, Val loss 1.906\n",
      "Ep 1 (Step 039815): Train loss 1.942, Val loss 1.906\n",
      "Ep 1 (Step 039820): Train loss 1.914, Val loss 1.917\n",
      "Ep 1 (Step 039825): Train loss 1.882, Val loss 1.914\n",
      "Ep 1 (Step 039830): Train loss 1.765, Val loss 1.923\n",
      "Ep 1 (Step 039835): Train loss 1.936, Val loss 1.915\n",
      "Ep 1 (Step 039840): Train loss 2.052, Val loss 1.922\n",
      "Ep 1 (Step 039845): Train loss 2.269, Val loss 1.907\n",
      "Ep 1 (Step 039850): Train loss 1.775, Val loss 1.897\n",
      "Ep 1 (Step 039855): Train loss 1.874, Val loss 1.899\n",
      "Ep 1 (Step 039860): Train loss 1.870, Val loss 1.908\n",
      "Ep 1 (Step 039865): Train loss 2.191, Val loss 1.912\n",
      "Ep 1 (Step 039870): Train loss 2.076, Val loss 1.914\n",
      "Ep 1 (Step 039875): Train loss 1.806, Val loss 1.912\n",
      "Ep 1 (Step 039880): Train loss 2.110, Val loss 1.899\n",
      "Ep 1 (Step 039885): Train loss 1.768, Val loss 1.905\n",
      "Ep 1 (Step 039890): Train loss 1.898, Val loss 1.917\n",
      "Ep 1 (Step 039895): Train loss 1.796, Val loss 1.902\n",
      "Ep 1 (Step 039900): Train loss 2.057, Val loss 1.912\n",
      "Ep 1 (Step 039905): Train loss 1.668, Val loss 1.920\n",
      "Ep 1 (Step 039910): Train loss 1.988, Val loss 1.926\n",
      "Ep 1 (Step 039915): Train loss 1.924, Val loss 1.915\n",
      "Ep 1 (Step 039920): Train loss 1.737, Val loss 1.906\n",
      "Ep 1 (Step 039925): Train loss 2.015, Val loss 1.900\n",
      "Ep 1 (Step 039930): Train loss 1.937, Val loss 1.912\n",
      "Ep 1 (Step 039935): Train loss 1.806, Val loss 1.904\n",
      "Ep 1 (Step 039940): Train loss 2.059, Val loss 1.898\n",
      "Ep 1 (Step 039945): Train loss 1.863, Val loss 1.899\n",
      "Ep 1 (Step 039950): Train loss 1.936, Val loss 1.903\n",
      "Ep 1 (Step 039955): Train loss 2.303, Val loss 1.906\n",
      "Ep 1 (Step 039960): Train loss 1.902, Val loss 1.900\n",
      "Ep 1 (Step 039965): Train loss 2.068, Val loss 1.902\n",
      "Ep 1 (Step 039970): Train loss 2.116, Val loss 1.902\n",
      "Ep 1 (Step 039975): Train loss 1.723, Val loss 1.898\n",
      "Ep 1 (Step 039980): Train loss 1.823, Val loss 1.891\n",
      "Ep 1 (Step 039985): Train loss 2.301, Val loss 1.897\n",
      "Ep 1 (Step 039990): Train loss 1.961, Val loss 1.901\n",
      "Ep 1 (Step 039995): Train loss 2.153, Val loss 1.903\n",
      "Ep 1 (Step 040000): Train loss 2.065, Val loss 1.887\n",
      "Ep 1 (Step 040005): Train loss 1.995, Val loss 1.880\n",
      "Ep 1 (Step 040010): Train loss 1.790, Val loss 1.881\n",
      "Ep 1 (Step 040015): Train loss 1.929, Val loss 1.878\n",
      "Ep 1 (Step 040020): Train loss 2.077, Val loss 1.881\n",
      "Ep 1 (Step 040025): Train loss 1.830, Val loss 1.888\n",
      "Ep 1 (Step 040030): Train loss 1.944, Val loss 1.888\n",
      "Ep 1 (Step 040035): Train loss 1.861, Val loss 1.891\n",
      "Ep 1 (Step 040040): Train loss 1.674, Val loss 1.897\n",
      "Ep 1 (Step 040045): Train loss 1.855, Val loss 1.889\n",
      "Ep 1 (Step 040050): Train loss 1.778, Val loss 1.891\n",
      "Ep 1 (Step 040055): Train loss 1.777, Val loss 1.903\n",
      "Ep 1 (Step 040060): Train loss 1.686, Val loss 1.912\n",
      "Ep 1 (Step 040065): Train loss 1.735, Val loss 1.910\n",
      "Ep 1 (Step 040070): Train loss 1.894, Val loss 1.898\n",
      "Ep 1 (Step 040075): Train loss 1.970, Val loss 1.904\n",
      "Ep 1 (Step 040080): Train loss 1.771, Val loss 1.909\n",
      "Ep 1 (Step 040085): Train loss 2.017, Val loss 1.906\n",
      "Ep 1 (Step 040090): Train loss 1.982, Val loss 1.910\n",
      "Ep 1 (Step 040095): Train loss 1.902, Val loss 1.913\n",
      "Ep 1 (Step 040100): Train loss 1.985, Val loss 1.906\n",
      "Ep 1 (Step 040105): Train loss 2.007, Val loss 1.894\n",
      "Ep 1 (Step 040110): Train loss 1.907, Val loss 1.887\n",
      "Ep 1 (Step 040115): Train loss 2.032, Val loss 1.886\n",
      "Ep 1 (Step 040120): Train loss 1.884, Val loss 1.894\n",
      "Ep 1 (Step 040125): Train loss 2.245, Val loss 1.907\n",
      "Ep 1 (Step 040130): Train loss 1.834, Val loss 1.910\n",
      "Ep 1 (Step 040135): Train loss 2.106, Val loss 1.904\n",
      "Ep 1 (Step 040140): Train loss 1.810, Val loss 1.903\n",
      "Ep 1 (Step 040145): Train loss 1.741, Val loss 1.905\n",
      "Ep 1 (Step 040150): Train loss 1.775, Val loss 1.900\n",
      "Ep 1 (Step 040155): Train loss 1.886, Val loss 1.892\n",
      "Ep 1 (Step 040160): Train loss 1.812, Val loss 1.888\n",
      "Ep 1 (Step 040165): Train loss 2.039, Val loss 1.882\n",
      "Ep 1 (Step 040170): Train loss 1.794, Val loss 1.879\n",
      "Ep 1 (Step 040175): Train loss 2.092, Val loss 1.884\n",
      "Ep 1 (Step 040180): Train loss 1.905, Val loss 1.893\n",
      "Ep 1 (Step 040185): Train loss 1.873, Val loss 1.908\n",
      "Ep 1 (Step 040190): Train loss 2.143, Val loss 1.895\n",
      "Ep 1 (Step 040195): Train loss 2.227, Val loss 1.891\n",
      "Ep 1 (Step 040200): Train loss 2.055, Val loss 1.897\n",
      "Ep 1 (Step 040205): Train loss 1.698, Val loss 1.902\n",
      "Ep 1 (Step 040210): Train loss 2.223, Val loss 1.911\n",
      "Ep 1 (Step 040215): Train loss 1.942, Val loss 1.908\n",
      "Ep 1 (Step 040220): Train loss 2.058, Val loss 1.911\n",
      "Ep 1 (Step 040225): Train loss 2.118, Val loss 1.907\n",
      "Ep 1 (Step 040230): Train loss 2.124, Val loss 1.905\n",
      "Ep 1 (Step 040235): Train loss 2.211, Val loss 1.909\n",
      "Ep 1 (Step 040240): Train loss 1.946, Val loss 1.909\n",
      "Ep 1 (Step 040245): Train loss 2.035, Val loss 1.895\n",
      "Ep 1 (Step 040250): Train loss 1.629, Val loss 1.886\n",
      "Ep 1 (Step 040255): Train loss 1.885, Val loss 1.886\n",
      "Ep 1 (Step 040260): Train loss 1.806, Val loss 1.894\n",
      "Ep 1 (Step 040265): Train loss 2.093, Val loss 1.903\n",
      "Ep 1 (Step 040270): Train loss 1.844, Val loss 1.901\n",
      "Ep 1 (Step 040275): Train loss 1.771, Val loss 1.898\n",
      "Ep 1 (Step 040280): Train loss 2.220, Val loss 1.894\n",
      "Ep 1 (Step 040285): Train loss 1.856, Val loss 1.898\n",
      "Ep 1 (Step 040290): Train loss 2.049, Val loss 1.901\n",
      "Ep 1 (Step 040295): Train loss 1.919, Val loss 1.896\n",
      "Ep 1 (Step 040300): Train loss 2.152, Val loss 1.886\n",
      "Ep 1 (Step 040305): Train loss 1.743, Val loss 1.884\n",
      "Ep 1 (Step 040310): Train loss 1.863, Val loss 1.895\n",
      "Ep 1 (Step 040315): Train loss 1.895, Val loss 1.901\n",
      "Ep 1 (Step 040320): Train loss 2.029, Val loss 1.906\n",
      "Ep 1 (Step 040325): Train loss 1.913, Val loss 1.916\n",
      "Ep 1 (Step 040330): Train loss 1.895, Val loss 1.919\n",
      "Ep 1 (Step 040335): Train loss 1.876, Val loss 1.923\n",
      "Ep 1 (Step 040340): Train loss 1.741, Val loss 1.921\n",
      "Ep 1 (Step 040345): Train loss 1.981, Val loss 1.910\n",
      "Ep 1 (Step 040350): Train loss 1.820, Val loss 1.902\n",
      "Ep 1 (Step 040355): Train loss 1.927, Val loss 1.890\n",
      "Ep 1 (Step 040360): Train loss 2.102, Val loss 1.888\n",
      "Ep 1 (Step 040365): Train loss 2.235, Val loss 1.891\n",
      "Ep 1 (Step 040370): Train loss 1.912, Val loss 1.895\n",
      "Ep 1 (Step 040375): Train loss 1.853, Val loss 1.894\n",
      "Ep 1 (Step 040380): Train loss 2.082, Val loss 1.890\n",
      "Ep 1 (Step 040385): Train loss 1.906, Val loss 1.896\n",
      "Ep 1 (Step 040390): Train loss 2.064, Val loss 1.910\n",
      "Ep 1 (Step 040395): Train loss 1.908, Val loss 1.919\n",
      "Ep 1 (Step 040400): Train loss 2.031, Val loss 1.912\n",
      "Ep 1 (Step 040405): Train loss 1.822, Val loss 1.913\n",
      "Ep 1 (Step 040410): Train loss 1.910, Val loss 1.911\n",
      "Ep 1 (Step 040415): Train loss 1.880, Val loss 1.899\n",
      "Ep 1 (Step 040420): Train loss 2.104, Val loss 1.894\n",
      "Ep 1 (Step 040425): Train loss 2.066, Val loss 1.902\n",
      "Ep 1 (Step 040430): Train loss 1.786, Val loss 1.904\n",
      "Ep 1 (Step 040435): Train loss 1.796, Val loss 1.901\n",
      "Ep 1 (Step 040440): Train loss 1.818, Val loss 1.903\n",
      "Ep 1 (Step 040445): Train loss 1.983, Val loss 1.906\n",
      "Ep 1 (Step 040450): Train loss 2.111, Val loss 1.909\n",
      "Ep 1 (Step 040455): Train loss 1.949, Val loss 1.910\n",
      "Ep 1 (Step 040460): Train loss 1.779, Val loss 1.918\n",
      "Ep 1 (Step 040465): Train loss 2.364, Val loss 1.933\n",
      "Ep 1 (Step 040470): Train loss 1.926, Val loss 1.933\n",
      "Ep 1 (Step 040475): Train loss 2.108, Val loss 1.916\n",
      "Ep 1 (Step 040480): Train loss 2.024, Val loss 1.909\n",
      "Ep 1 (Step 040485): Train loss 2.220, Val loss 1.912\n",
      "Ep 1 (Step 040490): Train loss 1.899, Val loss 1.910\n",
      "Ep 1 (Step 040495): Train loss 1.889, Val loss 1.900\n",
      "Ep 1 (Step 040500): Train loss 1.902, Val loss 1.897\n",
      "Ep 1 (Step 040505): Train loss 1.697, Val loss 1.896\n",
      "Ep 1 (Step 040510): Train loss 2.065, Val loss 1.902\n",
      "Ep 1 (Step 040515): Train loss 1.985, Val loss 1.902\n",
      "Ep 1 (Step 040520): Train loss 1.851, Val loss 1.913\n",
      "Ep 1 (Step 040525): Train loss 1.960, Val loss 1.918\n",
      "Ep 1 (Step 040530): Train loss 1.968, Val loss 1.912\n",
      "Ep 1 (Step 040535): Train loss 2.124, Val loss 1.909\n",
      "Ep 1 (Step 040540): Train loss 1.927, Val loss 1.908\n",
      "Ep 1 (Step 040545): Train loss 1.683, Val loss 1.918\n",
      "Ep 1 (Step 040550): Train loss 1.891, Val loss 1.919\n",
      "Ep 1 (Step 040555): Train loss 1.960, Val loss 1.913\n",
      "Ep 1 (Step 040560): Train loss 1.745, Val loss 1.904\n",
      "Ep 1 (Step 040565): Train loss 2.125, Val loss 1.898\n",
      "Ep 1 (Step 040570): Train loss 1.742, Val loss 1.903\n",
      "Ep 1 (Step 040575): Train loss 1.836, Val loss 1.912\n",
      "Ep 1 (Step 040580): Train loss 2.242, Val loss 1.918\n",
      "Ep 1 (Step 040585): Train loss 1.875, Val loss 1.917\n",
      "Ep 1 (Step 040590): Train loss 1.907, Val loss 1.913\n",
      "Ep 1 (Step 040595): Train loss 2.071, Val loss 1.907\n",
      "Ep 1 (Step 040600): Train loss 1.877, Val loss 1.924\n",
      "Ep 1 (Step 040605): Train loss 1.976, Val loss 1.919\n",
      "Ep 1 (Step 040610): Train loss 1.762, Val loss 1.904\n",
      "Ep 1 (Step 040615): Train loss 1.832, Val loss 1.902\n",
      "Ep 1 (Step 040620): Train loss 2.022, Val loss 1.911\n",
      "Ep 1 (Step 040625): Train loss 1.687, Val loss 1.919\n",
      "Ep 1 (Step 040630): Train loss 1.711, Val loss 1.919\n",
      "Ep 1 (Step 040635): Train loss 2.096, Val loss 1.915\n",
      "Ep 1 (Step 040640): Train loss 1.819, Val loss 1.906\n",
      "Ep 1 (Step 040645): Train loss 1.858, Val loss 1.907\n",
      "Ep 1 (Step 040650): Train loss 1.812, Val loss 1.912\n",
      "Ep 1 (Step 040655): Train loss 1.882, Val loss 1.915\n",
      "Ep 1 (Step 040660): Train loss 1.862, Val loss 1.904\n",
      "Ep 1 (Step 040665): Train loss 2.021, Val loss 1.897\n",
      "Ep 1 (Step 040670): Train loss 2.094, Val loss 1.902\n",
      "Ep 1 (Step 040675): Train loss 1.785, Val loss 1.914\n",
      "Ep 1 (Step 040680): Train loss 1.839, Val loss 1.910\n",
      "Ep 1 (Step 040685): Train loss 1.908, Val loss 1.912\n",
      "Ep 1 (Step 040690): Train loss 1.747, Val loss 1.909\n",
      "Ep 1 (Step 040695): Train loss 2.088, Val loss 1.912\n",
      "Ep 1 (Step 040700): Train loss 2.086, Val loss 1.917\n",
      "Ep 1 (Step 040705): Train loss 1.613, Val loss 1.918\n",
      "Ep 1 (Step 040710): Train loss 1.865, Val loss 1.917\n",
      "Ep 1 (Step 040715): Train loss 1.997, Val loss 1.909\n",
      "Ep 1 (Step 040720): Train loss 1.729, Val loss 1.915\n",
      "Ep 1 (Step 040725): Train loss 1.781, Val loss 1.916\n",
      "Ep 1 (Step 040730): Train loss 2.088, Val loss 1.924\n",
      "Ep 1 (Step 040735): Train loss 1.962, Val loss 1.926\n",
      "Ep 1 (Step 040740): Train loss 1.875, Val loss 1.918\n",
      "Ep 1 (Step 040745): Train loss 1.921, Val loss 1.922\n",
      "Ep 1 (Step 040750): Train loss 1.854, Val loss 1.929\n",
      "Ep 1 (Step 040755): Train loss 1.743, Val loss 1.934\n",
      "Ep 1 (Step 040760): Train loss 1.842, Val loss 1.926\n",
      "Ep 1 (Step 040765): Train loss 1.841, Val loss 1.920\n",
      "Ep 1 (Step 040770): Train loss 2.063, Val loss 1.920\n",
      "Ep 1 (Step 040775): Train loss 2.001, Val loss 1.928\n",
      "Ep 1 (Step 040780): Train loss 2.314, Val loss 1.927\n",
      "Ep 1 (Step 040785): Train loss 2.327, Val loss 1.916\n",
      "Ep 1 (Step 040790): Train loss 1.737, Val loss 1.918\n",
      "Ep 1 (Step 040795): Train loss 2.002, Val loss 1.931\n",
      "Ep 1 (Step 040800): Train loss 1.947, Val loss 1.926\n",
      "Ep 1 (Step 040805): Train loss 1.773, Val loss 1.922\n",
      "Ep 1 (Step 040810): Train loss 1.939, Val loss 1.930\n",
      "Ep 1 (Step 040815): Train loss 1.877, Val loss 1.933\n",
      "Ep 1 (Step 040820): Train loss 1.781, Val loss 1.925\n",
      "Ep 1 (Step 040825): Train loss 1.849, Val loss 1.934\n",
      "Ep 1 (Step 040830): Train loss 1.870, Val loss 1.940\n",
      "Ep 1 (Step 040835): Train loss 1.904, Val loss 1.933\n",
      "Ep 1 (Step 040840): Train loss 2.055, Val loss 1.920\n",
      "Ep 1 (Step 040845): Train loss 1.773, Val loss 1.911\n",
      "Ep 1 (Step 040850): Train loss 1.787, Val loss 1.911\n",
      "Ep 1 (Step 040855): Train loss 1.859, Val loss 1.909\n",
      "Ep 1 (Step 040860): Train loss 1.970, Val loss 1.902\n",
      "Ep 1 (Step 040865): Train loss 1.707, Val loss 1.894\n",
      "Ep 1 (Step 040870): Train loss 1.662, Val loss 1.887\n",
      "Ep 1 (Step 040875): Train loss 1.922, Val loss 1.889\n",
      "Ep 1 (Step 040880): Train loss 2.095, Val loss 1.889\n",
      "Ep 1 (Step 040885): Train loss 1.671, Val loss 1.891\n",
      "Ep 1 (Step 040890): Train loss 1.938, Val loss 1.898\n",
      "Ep 1 (Step 040895): Train loss 1.976, Val loss 1.904\n",
      "Ep 1 (Step 040900): Train loss 1.743, Val loss 1.903\n",
      "Ep 1 (Step 040905): Train loss 1.925, Val loss 1.900\n",
      "Ep 1 (Step 040910): Train loss 2.088, Val loss 1.902\n",
      "Ep 1 (Step 040915): Train loss 1.770, Val loss 1.906\n",
      "Ep 1 (Step 040920): Train loss 2.031, Val loss 1.899\n",
      "Ep 1 (Step 040925): Train loss 1.839, Val loss 1.897\n",
      "Ep 1 (Step 040930): Train loss 2.230, Val loss 1.902\n",
      "Ep 1 (Step 040935): Train loss 1.669, Val loss 1.910\n",
      "Ep 1 (Step 040940): Train loss 1.930, Val loss 1.906\n",
      "Ep 1 (Step 040945): Train loss 1.828, Val loss 1.903\n",
      "Ep 1 (Step 040950): Train loss 2.003, Val loss 1.906\n",
      "Ep 1 (Step 040955): Train loss 1.784, Val loss 1.910\n",
      "Ep 1 (Step 040960): Train loss 1.884, Val loss 1.906\n",
      "Ep 1 (Step 040965): Train loss 1.979, Val loss 1.911\n",
      "Ep 1 (Step 040970): Train loss 2.004, Val loss 1.917\n",
      "Ep 1 (Step 040975): Train loss 1.833, Val loss 1.907\n",
      "Ep 1 (Step 040980): Train loss 1.884, Val loss 1.909\n",
      "Ep 1 (Step 040985): Train loss 1.956, Val loss 1.909\n",
      "Ep 1 (Step 040990): Train loss 1.921, Val loss 1.908\n",
      "Ep 1 (Step 040995): Train loss 2.048, Val loss 1.914\n",
      "Ep 1 (Step 041000): Train loss 1.815, Val loss 1.911\n",
      "Ep 1 (Step 041005): Train loss 1.802, Val loss 1.914\n",
      "Ep 1 (Step 041010): Train loss 2.054, Val loss 1.915\n",
      "Ep 1 (Step 041015): Train loss 1.641, Val loss 1.931\n",
      "Ep 1 (Step 041020): Train loss 2.104, Val loss 1.926\n",
      "Ep 1 (Step 041025): Train loss 2.090, Val loss 1.917\n",
      "Ep 1 (Step 041030): Train loss 2.053, Val loss 1.918\n",
      "Ep 1 (Step 041035): Train loss 2.215, Val loss 1.915\n",
      "Ep 1 (Step 041040): Train loss 1.744, Val loss 1.918\n",
      "Ep 1 (Step 041045): Train loss 1.913, Val loss 1.926\n",
      "Ep 1 (Step 041050): Train loss 2.077, Val loss 1.912\n",
      "Ep 1 (Step 041055): Train loss 1.753, Val loss 1.913\n",
      "Ep 1 (Step 041060): Train loss 1.817, Val loss 1.910\n",
      "Ep 1 (Step 041065): Train loss 2.225, Val loss 1.921\n",
      "Ep 1 (Step 041070): Train loss 1.890, Val loss 1.922\n",
      "Ep 1 (Step 041075): Train loss 1.966, Val loss 1.911\n",
      "Ep 1 (Step 041080): Train loss 2.094, Val loss 1.903\n",
      "Ep 1 (Step 041085): Train loss 2.285, Val loss 1.894\n",
      "Ep 1 (Step 041090): Train loss 1.762, Val loss 1.895\n",
      "Ep 1 (Step 041095): Train loss 1.983, Val loss 1.909\n",
      "Ep 1 (Step 041100): Train loss 1.720, Val loss 1.909\n",
      "Ep 1 (Step 041105): Train loss 2.005, Val loss 1.903\n",
      "Ep 1 (Step 041110): Train loss 1.884, Val loss 1.900\n",
      "Ep 1 (Step 041115): Train loss 2.180, Val loss 1.910\n",
      "Ep 1 (Step 041120): Train loss 2.129, Val loss 1.906\n",
      "Ep 1 (Step 041125): Train loss 1.966, Val loss 1.902\n",
      "Ep 1 (Step 041130): Train loss 1.631, Val loss 1.900\n",
      "Ep 1 (Step 041135): Train loss 1.875, Val loss 1.901\n",
      "Ep 1 (Step 041140): Train loss 1.532, Val loss 1.899\n",
      "Ep 1 (Step 041145): Train loss 2.078, Val loss 1.912\n",
      "Ep 1 (Step 041150): Train loss 1.899, Val loss 1.924\n",
      "Ep 1 (Step 041155): Train loss 1.518, Val loss 1.931\n",
      "Ep 1 (Step 041160): Train loss 1.787, Val loss 1.929\n",
      "Ep 1 (Step 041165): Train loss 1.938, Val loss 1.921\n",
      "Ep 1 (Step 041170): Train loss 1.752, Val loss 1.908\n",
      "Ep 1 (Step 041175): Train loss 1.925, Val loss 1.912\n",
      "Ep 1 (Step 041180): Train loss 2.047, Val loss 1.920\n",
      "Ep 1 (Step 041185): Train loss 1.896, Val loss 1.917\n",
      "Ep 1 (Step 041190): Train loss 1.862, Val loss 1.916\n",
      "Ep 1 (Step 041195): Train loss 1.807, Val loss 1.918\n",
      "Ep 1 (Step 041200): Train loss 1.990, Val loss 1.915\n",
      "Ep 1 (Step 041205): Train loss 1.973, Val loss 1.903\n",
      "Ep 1 (Step 041210): Train loss 1.794, Val loss 1.909\n",
      "Ep 1 (Step 041215): Train loss 1.875, Val loss 1.908\n",
      "Ep 1 (Step 041220): Train loss 2.021, Val loss 1.896\n",
      "Ep 1 (Step 041225): Train loss 1.983, Val loss 1.893\n",
      "Ep 1 (Step 041230): Train loss 2.027, Val loss 1.897\n",
      "Ep 1 (Step 041235): Train loss 1.878, Val loss 1.895\n",
      "Ep 1 (Step 041240): Train loss 2.006, Val loss 1.900\n",
      "Ep 1 (Step 041245): Train loss 2.013, Val loss 1.912\n",
      "Ep 1 (Step 041250): Train loss 1.894, Val loss 1.919\n",
      "Ep 1 (Step 041255): Train loss 1.917, Val loss 1.924\n",
      "Ep 1 (Step 041260): Train loss 1.978, Val loss 1.916\n",
      "Ep 1 (Step 041265): Train loss 1.826, Val loss 1.913\n",
      "Ep 1 (Step 041270): Train loss 2.056, Val loss 1.910\n",
      "Ep 1 (Step 041275): Train loss 1.869, Val loss 1.911\n",
      "Ep 1 (Step 041280): Train loss 2.027, Val loss 1.919\n",
      "Ep 1 (Step 041285): Train loss 2.021, Val loss 1.921\n",
      "Ep 1 (Step 041290): Train loss 2.044, Val loss 1.917\n",
      "Ep 1 (Step 041295): Train loss 1.885, Val loss 1.911\n",
      "Ep 1 (Step 041300): Train loss 1.700, Val loss 1.908\n",
      "Ep 1 (Step 041305): Train loss 1.773, Val loss 1.910\n",
      "Ep 1 (Step 041310): Train loss 1.935, Val loss 1.907\n",
      "Ep 1 (Step 041315): Train loss 1.858, Val loss 1.901\n",
      "Ep 1 (Step 041320): Train loss 1.954, Val loss 1.896\n",
      "Ep 1 (Step 041325): Train loss 2.042, Val loss 1.894\n",
      "Ep 1 (Step 041330): Train loss 1.899, Val loss 1.896\n",
      "Ep 1 (Step 041335): Train loss 1.801, Val loss 1.903\n",
      "Ep 1 (Step 041340): Train loss 1.760, Val loss 1.905\n",
      "Ep 1 (Step 041345): Train loss 1.816, Val loss 1.908\n",
      "Ep 1 (Step 041350): Train loss 2.110, Val loss 1.913\n",
      "Ep 1 (Step 041355): Train loss 2.173, Val loss 1.920\n",
      "Ep 1 (Step 041360): Train loss 1.956, Val loss 1.920\n",
      "Ep 1 (Step 041365): Train loss 1.662, Val loss 1.910\n",
      "Ep 1 (Step 041370): Train loss 1.814, Val loss 1.909\n",
      "Ep 1 (Step 041375): Train loss 1.962, Val loss 1.907\n",
      "Ep 1 (Step 041380): Train loss 1.811, Val loss 1.905\n",
      "Ep 1 (Step 041385): Train loss 2.008, Val loss 1.912\n",
      "Ep 1 (Step 041390): Train loss 1.777, Val loss 1.907\n",
      "Ep 1 (Step 041395): Train loss 2.017, Val loss 1.902\n",
      "Ep 1 (Step 041400): Train loss 1.918, Val loss 1.897\n",
      "Ep 1 (Step 041405): Train loss 1.955, Val loss 1.903\n",
      "Ep 1 (Step 041410): Train loss 2.213, Val loss 1.901\n",
      "Ep 1 (Step 041415): Train loss 2.131, Val loss 1.896\n",
      "Ep 1 (Step 041420): Train loss 1.704, Val loss 1.896\n",
      "Ep 1 (Step 041425): Train loss 2.135, Val loss 1.892\n",
      "Ep 1 (Step 041430): Train loss 2.084, Val loss 1.879\n",
      "Ep 1 (Step 041435): Train loss 1.865, Val loss 1.883\n",
      "Ep 1 (Step 041440): Train loss 1.820, Val loss 1.890\n",
      "Ep 1 (Step 041445): Train loss 2.096, Val loss 1.890\n",
      "Ep 1 (Step 041450): Train loss 1.916, Val loss 1.898\n",
      "Ep 1 (Step 041455): Train loss 1.891, Val loss 1.905\n",
      "Ep 1 (Step 041460): Train loss 2.048, Val loss 1.903\n",
      "Ep 1 (Step 041465): Train loss 2.054, Val loss 1.899\n",
      "Ep 1 (Step 041470): Train loss 2.055, Val loss 1.894\n",
      "Ep 1 (Step 041475): Train loss 1.800, Val loss 1.895\n",
      "Ep 1 (Step 041480): Train loss 2.103, Val loss 1.894\n",
      "Ep 1 (Step 041485): Train loss 1.877, Val loss 1.889\n",
      "Ep 1 (Step 041490): Train loss 1.816, Val loss 1.892\n",
      "Ep 1 (Step 041495): Train loss 1.956, Val loss 1.896\n",
      "Ep 1 (Step 041500): Train loss 1.784, Val loss 1.902\n",
      "Ep 1 (Step 041505): Train loss 2.021, Val loss 1.904\n",
      "Ep 1 (Step 041510): Train loss 1.877, Val loss 1.908\n",
      "Ep 1 (Step 041515): Train loss 1.652, Val loss 1.906\n",
      "Ep 1 (Step 041520): Train loss 1.856, Val loss 1.913\n",
      "Ep 1 (Step 041525): Train loss 1.803, Val loss 1.907\n",
      "Ep 1 (Step 041530): Train loss 1.890, Val loss 1.906\n",
      "Ep 1 (Step 041535): Train loss 1.711, Val loss 1.898\n",
      "Ep 1 (Step 041540): Train loss 1.736, Val loss 1.894\n",
      "Ep 1 (Step 041545): Train loss 1.836, Val loss 1.895\n",
      "Ep 1 (Step 041550): Train loss 1.738, Val loss 1.901\n",
      "Ep 1 (Step 041555): Train loss 1.715, Val loss 1.904\n",
      "Ep 1 (Step 041560): Train loss 1.963, Val loss 1.894\n",
      "Ep 1 (Step 041565): Train loss 1.884, Val loss 1.906\n",
      "Ep 1 (Step 041570): Train loss 1.787, Val loss 1.914\n",
      "Ep 1 (Step 041575): Train loss 1.863, Val loss 1.920\n",
      "Ep 1 (Step 041580): Train loss 1.745, Val loss 1.910\n",
      "Ep 1 (Step 041585): Train loss 1.927, Val loss 1.912\n",
      "Ep 1 (Step 041590): Train loss 1.613, Val loss 1.920\n",
      "Ep 1 (Step 041595): Train loss 1.943, Val loss 1.921\n",
      "Ep 1 (Step 041600): Train loss 1.663, Val loss 1.922\n",
      "Ep 1 (Step 041605): Train loss 1.603, Val loss 1.920\n",
      "Ep 1 (Step 041610): Train loss 1.899, Val loss 1.917\n",
      "Ep 1 (Step 041615): Train loss 1.821, Val loss 1.915\n",
      "Ep 1 (Step 041620): Train loss 1.999, Val loss 1.919\n",
      "Ep 1 (Step 041625): Train loss 1.834, Val loss 1.915\n",
      "Ep 1 (Step 041630): Train loss 1.800, Val loss 1.924\n",
      "Ep 1 (Step 041635): Train loss 2.045, Val loss 1.928\n",
      "Ep 1 (Step 041640): Train loss 1.821, Val loss 1.932\n",
      "Ep 1 (Step 041645): Train loss 1.859, Val loss 1.923\n",
      "Ep 1 (Step 041650): Train loss 2.113, Val loss 1.918\n",
      "Ep 1 (Step 041655): Train loss 1.830, Val loss 1.919\n",
      "Ep 1 (Step 041660): Train loss 1.828, Val loss 1.923\n",
      "Ep 1 (Step 041665): Train loss 2.023, Val loss 1.913\n",
      "Ep 1 (Step 041670): Train loss 1.713, Val loss 1.916\n",
      "Ep 1 (Step 041675): Train loss 1.967, Val loss 1.930\n",
      "Ep 1 (Step 041680): Train loss 1.859, Val loss 1.934\n",
      "Ep 1 (Step 041685): Train loss 1.986, Val loss 1.924\n",
      "Ep 1 (Step 041690): Train loss 1.866, Val loss 1.917\n",
      "Ep 1 (Step 041695): Train loss 1.948, Val loss 1.903\n",
      "Ep 1 (Step 041700): Train loss 1.916, Val loss 1.888\n",
      "Ep 1 (Step 041705): Train loss 1.766, Val loss 1.887\n",
      "Ep 1 (Step 041710): Train loss 1.980, Val loss 1.895\n",
      "Ep 1 (Step 041715): Train loss 1.736, Val loss 1.922\n",
      "Ep 1 (Step 041720): Train loss 1.749, Val loss 1.918\n",
      "Ep 1 (Step 041725): Train loss 2.002, Val loss 1.914\n",
      "Ep 1 (Step 041730): Train loss 1.939, Val loss 1.916\n",
      "Ep 1 (Step 041735): Train loss 1.758, Val loss 1.919\n",
      "Ep 1 (Step 041740): Train loss 1.749, Val loss 1.925\n",
      "Ep 1 (Step 041745): Train loss 1.840, Val loss 1.918\n",
      "Ep 1 (Step 041750): Train loss 2.123, Val loss 1.916\n",
      "Ep 1 (Step 041755): Train loss 1.805, Val loss 1.908\n",
      "Ep 1 (Step 041760): Train loss 1.802, Val loss 1.911\n",
      "Ep 1 (Step 041765): Train loss 2.181, Val loss 1.921\n",
      "Ep 1 (Step 041770): Train loss 1.986, Val loss 1.925\n",
      "Ep 1 (Step 041775): Train loss 1.757, Val loss 1.924\n",
      "Ep 1 (Step 041780): Train loss 1.771, Val loss 1.914\n",
      "Ep 1 (Step 041785): Train loss 1.957, Val loss 1.911\n",
      "Ep 1 (Step 041790): Train loss 1.923, Val loss 1.916\n",
      "Ep 1 (Step 041795): Train loss 1.969, Val loss 1.914\n",
      "Ep 1 (Step 041800): Train loss 2.046, Val loss 1.904\n",
      "Ep 1 (Step 041805): Train loss 1.768, Val loss 1.896\n",
      "Ep 1 (Step 041810): Train loss 2.164, Val loss 1.893\n",
      "Ep 1 (Step 041815): Train loss 2.016, Val loss 1.892\n",
      "Ep 1 (Step 041820): Train loss 1.656, Val loss 1.889\n",
      "Ep 1 (Step 041825): Train loss 1.752, Val loss 1.895\n",
      "Ep 1 (Step 041830): Train loss 1.810, Val loss 1.899\n",
      "Ep 1 (Step 041835): Train loss 1.885, Val loss 1.907\n",
      "Ep 1 (Step 041840): Train loss 1.879, Val loss 1.909\n",
      "Ep 1 (Step 041845): Train loss 1.582, Val loss 1.907\n",
      "Ep 1 (Step 041850): Train loss 2.117, Val loss 1.901\n",
      "Ep 1 (Step 041855): Train loss 2.096, Val loss 1.901\n",
      "Ep 1 (Step 041860): Train loss 2.015, Val loss 1.912\n",
      "Ep 1 (Step 041865): Train loss 2.292, Val loss 1.913\n",
      "Ep 1 (Step 041870): Train loss 1.967, Val loss 1.917\n",
      "Ep 1 (Step 041875): Train loss 2.039, Val loss 1.922\n",
      "Ep 1 (Step 041880): Train loss 1.995, Val loss 1.927\n",
      "Ep 1 (Step 041885): Train loss 2.113, Val loss 1.925\n",
      "Ep 1 (Step 041890): Train loss 1.735, Val loss 1.925\n",
      "Ep 1 (Step 041895): Train loss 1.762, Val loss 1.919\n",
      "Ep 1 (Step 041900): Train loss 1.897, Val loss 1.914\n",
      "Ep 1 (Step 041905): Train loss 1.802, Val loss 1.915\n",
      "Ep 1 (Step 041910): Train loss 1.755, Val loss 1.918\n",
      "Ep 1 (Step 041915): Train loss 2.533, Val loss 1.913\n",
      "Ep 1 (Step 041920): Train loss 1.926, Val loss 1.900\n",
      "Ep 1 (Step 041925): Train loss 1.825, Val loss 1.901\n",
      "Ep 1 (Step 041930): Train loss 1.569, Val loss 1.905\n",
      "Ep 1 (Step 041935): Train loss 1.690, Val loss 1.915\n",
      "Ep 1 (Step 041940): Train loss 1.888, Val loss 1.909\n",
      "Ep 1 (Step 041945): Train loss 1.850, Val loss 1.910\n",
      "Ep 1 (Step 041950): Train loss 2.031, Val loss 1.912\n",
      "Ep 1 (Step 041955): Train loss 1.755, Val loss 1.918\n",
      "Ep 1 (Step 041960): Train loss 2.042, Val loss 1.932\n",
      "Ep 1 (Step 041965): Train loss 2.295, Val loss 1.919\n",
      "Ep 1 (Step 041970): Train loss 1.815, Val loss 1.904\n",
      "Ep 1 (Step 041975): Train loss 1.716, Val loss 1.897\n",
      "Ep 1 (Step 041980): Train loss 1.605, Val loss 1.898\n",
      "Ep 1 (Step 041985): Train loss 1.792, Val loss 1.895\n",
      "Ep 1 (Step 041990): Train loss 1.756, Val loss 1.894\n",
      "Ep 1 (Step 041995): Train loss 1.899, Val loss 1.904\n",
      "Ep 1 (Step 042000): Train loss 2.109, Val loss 1.907\n",
      "Ep 1 (Step 042005): Train loss 1.801, Val loss 1.903\n",
      "Ep 1 (Step 042010): Train loss 1.933, Val loss 1.913\n",
      "Ep 1 (Step 042015): Train loss 1.901, Val loss 1.917\n",
      "Ep 1 (Step 042020): Train loss 1.970, Val loss 1.915\n",
      "Ep 1 (Step 042025): Train loss 1.936, Val loss 1.902\n",
      "Ep 1 (Step 042030): Train loss 2.236, Val loss 1.893\n",
      "Ep 1 (Step 042035): Train loss 1.905, Val loss 1.892\n",
      "Ep 1 (Step 042040): Train loss 2.091, Val loss 1.893\n",
      "Ep 1 (Step 042045): Train loss 1.826, Val loss 1.898\n",
      "Ep 1 (Step 042050): Train loss 2.156, Val loss 1.904\n",
      "Ep 1 (Step 042055): Train loss 1.916, Val loss 1.908\n",
      "Ep 1 (Step 042060): Train loss 2.066, Val loss 1.895\n",
      "Ep 1 (Step 042065): Train loss 1.979, Val loss 1.886\n",
      "Ep 1 (Step 042070): Train loss 1.730, Val loss 1.892\n",
      "Ep 1 (Step 042075): Train loss 2.215, Val loss 1.881\n",
      "Ep 1 (Step 042080): Train loss 1.764, Val loss 1.875\n",
      "Ep 1 (Step 042085): Train loss 1.858, Val loss 1.881\n",
      "Ep 1 (Step 042090): Train loss 1.823, Val loss 1.878\n",
      "Ep 1 (Step 042095): Train loss 2.014, Val loss 1.874\n",
      "Ep 1 (Step 042100): Train loss 1.955, Val loss 1.876\n",
      "Ep 1 (Step 042105): Train loss 1.897, Val loss 1.883\n",
      "Ep 1 (Step 042110): Train loss 1.953, Val loss 1.883\n",
      "Ep 1 (Step 042115): Train loss 1.824, Val loss 1.884\n",
      "Ep 1 (Step 042120): Train loss 1.862, Val loss 1.883\n",
      "Ep 1 (Step 042125): Train loss 1.967, Val loss 1.893\n",
      "Ep 1 (Step 042130): Train loss 2.094, Val loss 1.892\n",
      "Ep 1 (Step 042135): Train loss 2.288, Val loss 1.887\n",
      "Ep 1 (Step 042140): Train loss 1.722, Val loss 1.886\n",
      "Ep 1 (Step 042145): Train loss 1.821, Val loss 1.894\n",
      "Ep 1 (Step 042150): Train loss 2.134, Val loss 1.896\n",
      "Ep 1 (Step 042155): Train loss 1.784, Val loss 1.894\n",
      "Ep 1 (Step 042160): Train loss 1.890, Val loss 1.900\n",
      "Ep 1 (Step 042165): Train loss 2.013, Val loss 1.904\n",
      "Ep 1 (Step 042170): Train loss 1.976, Val loss 1.902\n",
      "Ep 1 (Step 042175): Train loss 1.641, Val loss 1.900\n",
      "Ep 1 (Step 042180): Train loss 1.913, Val loss 1.883\n",
      "Ep 1 (Step 042185): Train loss 1.959, Val loss 1.879\n",
      "Ep 1 (Step 042190): Train loss 2.193, Val loss 1.883\n",
      "Ep 1 (Step 042195): Train loss 1.912, Val loss 1.888\n",
      "Ep 1 (Step 042200): Train loss 1.749, Val loss 1.898\n",
      "Ep 1 (Step 042205): Train loss 1.830, Val loss 1.905\n",
      "Ep 1 (Step 042210): Train loss 2.117, Val loss 1.900\n",
      "Ep 1 (Step 042215): Train loss 1.897, Val loss 1.899\n",
      "Ep 1 (Step 042220): Train loss 1.984, Val loss 1.897\n",
      "Ep 1 (Step 042225): Train loss 1.918, Val loss 1.895\n",
      "Ep 1 (Step 042230): Train loss 1.975, Val loss 1.890\n",
      "Ep 1 (Step 042235): Train loss 1.883, Val loss 1.883\n",
      "Ep 1 (Step 042240): Train loss 2.033, Val loss 1.876\n",
      "Ep 1 (Step 042245): Train loss 1.992, Val loss 1.872\n",
      "Ep 1 (Step 042250): Train loss 2.025, Val loss 1.876\n",
      "Ep 1 (Step 042255): Train loss 1.981, Val loss 1.880\n",
      "Ep 1 (Step 042260): Train loss 1.844, Val loss 1.878\n",
      "Ep 1 (Step 042265): Train loss 1.747, Val loss 1.879\n",
      "Ep 1 (Step 042270): Train loss 2.181, Val loss 1.880\n",
      "Ep 1 (Step 042275): Train loss 1.961, Val loss 1.882\n",
      "Ep 1 (Step 042280): Train loss 1.947, Val loss 1.876\n",
      "Ep 1 (Step 042285): Train loss 1.930, Val loss 1.876\n",
      "Ep 1 (Step 042290): Train loss 2.175, Val loss 1.878\n",
      "Ep 1 (Step 042295): Train loss 1.961, Val loss 1.882\n",
      "Ep 1 (Step 042300): Train loss 1.934, Val loss 1.882\n",
      "Ep 1 (Step 042305): Train loss 1.638, Val loss 1.881\n",
      "Ep 1 (Step 042310): Train loss 1.928, Val loss 1.884\n",
      "Ep 1 (Step 042315): Train loss 2.098, Val loss 1.897\n",
      "Ep 1 (Step 042320): Train loss 1.672, Val loss 1.894\n",
      "Ep 1 (Step 042325): Train loss 1.951, Val loss 1.886\n",
      "Ep 1 (Step 042330): Train loss 1.702, Val loss 1.880\n",
      "Ep 1 (Step 042335): Train loss 1.959, Val loss 1.872\n",
      "Ep 1 (Step 042340): Train loss 1.913, Val loss 1.874\n",
      "Ep 1 (Step 042345): Train loss 1.941, Val loss 1.870\n",
      "Ep 1 (Step 042350): Train loss 1.981, Val loss 1.867\n",
      "Ep 1 (Step 042355): Train loss 2.106, Val loss 1.871\n",
      "Ep 1 (Step 042360): Train loss 1.760, Val loss 1.871\n",
      "Ep 1 (Step 042365): Train loss 1.971, Val loss 1.874\n",
      "Ep 1 (Step 042370): Train loss 1.745, Val loss 1.886\n",
      "Ep 1 (Step 042375): Train loss 2.055, Val loss 1.901\n",
      "Ep 1 (Step 042380): Train loss 1.866, Val loss 1.912\n",
      "Ep 1 (Step 042385): Train loss 1.736, Val loss 1.906\n",
      "Ep 1 (Step 042390): Train loss 1.799, Val loss 1.897\n",
      "Ep 1 (Step 042395): Train loss 1.894, Val loss 1.884\n",
      "Ep 1 (Step 042400): Train loss 1.971, Val loss 1.880\n",
      "Ep 1 (Step 042405): Train loss 1.957, Val loss 1.883\n",
      "Ep 1 (Step 042410): Train loss 1.817, Val loss 1.891\n",
      "Ep 1 (Step 042415): Train loss 1.919, Val loss 1.890\n",
      "Ep 1 (Step 042420): Train loss 2.077, Val loss 1.878\n",
      "Ep 1 (Step 042425): Train loss 1.993, Val loss 1.872\n",
      "Ep 1 (Step 042430): Train loss 2.075, Val loss 1.877\n",
      "Ep 1 (Step 042435): Train loss 1.984, Val loss 1.890\n",
      "Ep 1 (Step 042440): Train loss 1.942, Val loss 1.892\n",
      "Ep 1 (Step 042445): Train loss 1.762, Val loss 1.888\n",
      "Ep 1 (Step 042450): Train loss 2.047, Val loss 1.891\n",
      "Ep 1 (Step 042455): Train loss 1.936, Val loss 1.909\n",
      "Ep 1 (Step 042460): Train loss 2.097, Val loss 1.912\n",
      "Ep 1 (Step 042465): Train loss 2.092, Val loss 1.892\n",
      "Ep 1 (Step 042470): Train loss 2.223, Val loss 1.882\n",
      "Ep 1 (Step 042475): Train loss 2.263, Val loss 1.890\n",
      "Ep 1 (Step 042480): Train loss 1.919, Val loss 1.902\n",
      "Ep 1 (Step 042485): Train loss 1.914, Val loss 1.900\n",
      "Ep 1 (Step 042490): Train loss 2.089, Val loss 1.890\n",
      "Ep 1 (Step 042495): Train loss 1.930, Val loss 1.887\n",
      "Ep 1 (Step 042500): Train loss 1.894, Val loss 1.899\n",
      "Ep 1 (Step 042505): Train loss 1.933, Val loss 1.910\n",
      "Ep 1 (Step 042510): Train loss 1.747, Val loss 1.898\n",
      "Ep 1 (Step 042515): Train loss 1.967, Val loss 1.891\n",
      "Ep 1 (Step 042520): Train loss 1.817, Val loss 1.891\n",
      "Ep 1 (Step 042525): Train loss 1.582, Val loss 1.900\n",
      "Ep 1 (Step 042530): Train loss 1.909, Val loss 1.914\n",
      "Ep 1 (Step 042535): Train loss 1.803, Val loss 1.915\n",
      "Ep 1 (Step 042540): Train loss 1.612, Val loss 1.908\n",
      "Ep 1 (Step 042545): Train loss 1.907, Val loss 1.899\n",
      "Ep 1 (Step 042550): Train loss 1.858, Val loss 1.895\n",
      "Ep 1 (Step 042555): Train loss 1.939, Val loss 1.885\n",
      "Ep 1 (Step 042560): Train loss 1.882, Val loss 1.884\n",
      "Ep 1 (Step 042565): Train loss 2.482, Val loss 1.892\n",
      "Ep 1 (Step 042570): Train loss 1.887, Val loss 1.896\n",
      "Ep 1 (Step 042575): Train loss 1.828, Val loss 1.901\n",
      "Ep 1 (Step 042580): Train loss 2.019, Val loss 1.902\n",
      "Ep 1 (Step 042585): Train loss 1.761, Val loss 1.898\n",
      "Ep 1 (Step 042590): Train loss 2.234, Val loss 1.896\n",
      "Ep 1 (Step 042595): Train loss 1.968, Val loss 1.894\n",
      "Ep 1 (Step 042600): Train loss 1.915, Val loss 1.895\n",
      "Ep 1 (Step 042605): Train loss 1.797, Val loss 1.895\n",
      "Ep 1 (Step 042610): Train loss 1.957, Val loss 1.896\n",
      "Ep 1 (Step 042615): Train loss 1.781, Val loss 1.886\n",
      "Ep 1 (Step 042620): Train loss 1.839, Val loss 1.881\n",
      "Ep 1 (Step 042625): Train loss 2.143, Val loss 1.884\n",
      "Ep 1 (Step 042630): Train loss 1.845, Val loss 1.907\n",
      "Ep 1 (Step 042635): Train loss 1.901, Val loss 1.904\n",
      "Ep 1 (Step 042640): Train loss 1.781, Val loss 1.895\n",
      "Ep 1 (Step 042645): Train loss 1.840, Val loss 1.890\n",
      "Ep 1 (Step 042650): Train loss 2.041, Val loss 1.896\n",
      "Ep 1 (Step 042655): Train loss 1.989, Val loss 1.891\n",
      "Ep 1 (Step 042660): Train loss 2.045, Val loss 1.882\n",
      "Ep 1 (Step 042665): Train loss 1.791, Val loss 1.884\n",
      "Ep 1 (Step 042670): Train loss 1.812, Val loss 1.882\n",
      "Ep 1 (Step 042675): Train loss 1.950, Val loss 1.880\n",
      "Ep 1 (Step 042680): Train loss 2.092, Val loss 1.880\n",
      "Ep 1 (Step 042685): Train loss 1.813, Val loss 1.887\n",
      "Ep 1 (Step 042690): Train loss 1.930, Val loss 1.893\n",
      "Ep 1 (Step 042695): Train loss 1.898, Val loss 1.895\n",
      "Ep 1 (Step 042700): Train loss 2.005, Val loss 1.894\n",
      "Ep 1 (Step 042705): Train loss 1.866, Val loss 1.885\n",
      "Ep 1 (Step 042710): Train loss 2.066, Val loss 1.893\n",
      "Ep 1 (Step 042715): Train loss 1.857, Val loss 1.897\n",
      "Ep 1 (Step 042720): Train loss 2.187, Val loss 1.888\n",
      "Ep 1 (Step 042725): Train loss 1.984, Val loss 1.887\n",
      "Ep 1 (Step 042730): Train loss 1.918, Val loss 1.886\n",
      "Ep 1 (Step 042735): Train loss 1.927, Val loss 1.876\n",
      "Ep 1 (Step 042740): Train loss 1.822, Val loss 1.879\n",
      "Ep 1 (Step 042745): Train loss 1.960, Val loss 1.888\n",
      "Ep 1 (Step 042750): Train loss 1.812, Val loss 1.895\n",
      "Ep 1 (Step 042755): Train loss 1.896, Val loss 1.891\n",
      "Ep 1 (Step 042760): Train loss 1.869, Val loss 1.900\n",
      "Ep 1 (Step 042765): Train loss 1.959, Val loss 1.904\n",
      "Ep 1 (Step 042770): Train loss 1.814, Val loss 1.890\n",
      "Ep 1 (Step 042775): Train loss 1.944, Val loss 1.886\n",
      "Ep 1 (Step 042780): Train loss 2.035, Val loss 1.875\n",
      "Ep 1 (Step 042785): Train loss 2.061, Val loss 1.875\n",
      "Ep 1 (Step 042790): Train loss 1.781, Val loss 1.876\n",
      "Ep 1 (Step 042795): Train loss 1.917, Val loss 1.875\n",
      "Ep 1 (Step 042800): Train loss 2.019, Val loss 1.890\n",
      "Ep 1 (Step 042805): Train loss 1.937, Val loss 1.891\n",
      "Ep 1 (Step 042810): Train loss 1.980, Val loss 1.901\n",
      "Ep 1 (Step 042815): Train loss 1.879, Val loss 1.905\n",
      "Ep 1 (Step 042820): Train loss 2.137, Val loss 1.905\n",
      "Ep 1 (Step 042825): Train loss 1.953, Val loss 1.892\n",
      "Ep 1 (Step 042830): Train loss 1.839, Val loss 1.880\n",
      "Ep 1 (Step 042835): Train loss 1.939, Val loss 1.871\n",
      "Ep 1 (Step 042840): Train loss 1.590, Val loss 1.869\n",
      "Ep 1 (Step 042845): Train loss 1.875, Val loss 1.878\n",
      "Ep 1 (Step 042850): Train loss 1.720, Val loss 1.888\n",
      "Ep 1 (Step 042855): Train loss 1.829, Val loss 1.881\n",
      "Ep 1 (Step 042860): Train loss 1.953, Val loss 1.885\n",
      "Ep 1 (Step 042865): Train loss 1.754, Val loss 1.892\n",
      "Ep 1 (Step 042870): Train loss 1.792, Val loss 1.892\n",
      "Ep 1 (Step 042875): Train loss 2.048, Val loss 1.884\n",
      "Ep 1 (Step 042880): Train loss 1.749, Val loss 1.882\n",
      "Ep 1 (Step 042885): Train loss 1.740, Val loss 1.878\n",
      "Ep 1 (Step 042890): Train loss 1.693, Val loss 1.890\n",
      "Ep 1 (Step 042895): Train loss 1.964, Val loss 1.889\n",
      "Ep 1 (Step 042900): Train loss 1.680, Val loss 1.884\n",
      "Ep 1 (Step 042905): Train loss 1.584, Val loss 1.882\n",
      "Ep 1 (Step 042910): Train loss 1.839, Val loss 1.889\n",
      "Ep 1 (Step 042915): Train loss 1.749, Val loss 1.902\n",
      "Ep 1 (Step 042920): Train loss 1.748, Val loss 1.915\n",
      "Ep 1 (Step 042925): Train loss 1.879, Val loss 1.910\n",
      "Ep 1 (Step 042930): Train loss 1.878, Val loss 1.898\n",
      "Ep 1 (Step 042935): Train loss 1.782, Val loss 1.892\n",
      "Ep 1 (Step 042940): Train loss 1.814, Val loss 1.902\n",
      "Ep 1 (Step 042945): Train loss 1.811, Val loss 1.895\n",
      "Ep 1 (Step 042950): Train loss 2.052, Val loss 1.895\n",
      "Ep 1 (Step 042955): Train loss 1.712, Val loss 1.902\n",
      "Ep 1 (Step 042960): Train loss 2.111, Val loss 1.902\n",
      "Ep 1 (Step 042965): Train loss 2.006, Val loss 1.904\n",
      "Ep 1 (Step 042970): Train loss 1.835, Val loss 1.912\n",
      "Ep 1 (Step 042975): Train loss 1.924, Val loss 1.902\n",
      "Ep 1 (Step 042980): Train loss 1.853, Val loss 1.884\n",
      "Ep 1 (Step 042985): Train loss 2.076, Val loss 1.884\n",
      "Ep 1 (Step 042990): Train loss 1.870, Val loss 1.885\n",
      "Ep 1 (Step 042995): Train loss 2.022, Val loss 1.893\n",
      "Ep 1 (Step 043000): Train loss 1.910, Val loss 1.902\n",
      "Ep 1 (Step 043005): Train loss 2.064, Val loss 1.906\n",
      "Ep 1 (Step 043010): Train loss 1.839, Val loss 1.901\n",
      "Ep 1 (Step 043015): Train loss 1.747, Val loss 1.888\n",
      "Ep 1 (Step 043020): Train loss 2.194, Val loss 1.893\n",
      "Ep 1 (Step 043025): Train loss 2.059, Val loss 1.885\n",
      "Ep 1 (Step 043030): Train loss 1.980, Val loss 1.880\n",
      "Ep 1 (Step 043035): Train loss 1.742, Val loss 1.884\n",
      "Ep 1 (Step 043040): Train loss 1.845, Val loss 1.881\n",
      "Ep 1 (Step 043045): Train loss 1.659, Val loss 1.876\n",
      "Ep 1 (Step 043050): Train loss 1.645, Val loss 1.876\n",
      "Ep 1 (Step 043055): Train loss 1.903, Val loss 1.875\n",
      "Ep 1 (Step 043060): Train loss 2.238, Val loss 1.881\n",
      "Ep 1 (Step 043065): Train loss 1.935, Val loss 1.881\n",
      "Ep 1 (Step 043070): Train loss 1.795, Val loss 1.874\n",
      "Ep 1 (Step 043075): Train loss 1.739, Val loss 1.876\n",
      "Ep 1 (Step 043080): Train loss 2.035, Val loss 1.885\n",
      "Ep 1 (Step 043085): Train loss 2.188, Val loss 1.894\n",
      "Ep 1 (Step 043090): Train loss 2.031, Val loss 1.895\n",
      "Ep 1 (Step 043095): Train loss 2.242, Val loss 1.888\n",
      "Ep 1 (Step 043100): Train loss 2.052, Val loss 1.888\n",
      "Ep 1 (Step 043105): Train loss 1.680, Val loss 1.881\n",
      "Ep 1 (Step 043110): Train loss 2.127, Val loss 1.885\n",
      "Ep 1 (Step 043115): Train loss 2.117, Val loss 1.886\n",
      "Ep 1 (Step 043120): Train loss 1.814, Val loss 1.888\n",
      "Ep 1 (Step 043125): Train loss 2.162, Val loss 1.874\n",
      "Ep 1 (Step 043130): Train loss 1.924, Val loss 1.872\n",
      "Ep 1 (Step 043135): Train loss 1.834, Val loss 1.878\n",
      "Ep 1 (Step 043140): Train loss 2.194, Val loss 1.875\n",
      "Ep 1 (Step 043145): Train loss 1.831, Val loss 1.881\n",
      "Ep 1 (Step 043150): Train loss 1.901, Val loss 1.883\n",
      "Ep 1 (Step 043155): Train loss 1.796, Val loss 1.885\n",
      "Ep 1 (Step 043160): Train loss 1.969, Val loss 1.877\n",
      "Ep 1 (Step 043165): Train loss 1.985, Val loss 1.866\n",
      "Ep 1 (Step 043170): Train loss 1.918, Val loss 1.857\n",
      "Ep 1 (Step 043175): Train loss 1.914, Val loss 1.856\n",
      "Ep 1 (Step 043180): Train loss 2.437, Val loss 1.869\n",
      "Ep 1 (Step 043185): Train loss 1.933, Val loss 1.875\n",
      "Ep 1 (Step 043190): Train loss 1.955, Val loss 1.871\n",
      "Ep 1 (Step 043195): Train loss 2.168, Val loss 1.877\n",
      "Ep 1 (Step 043200): Train loss 1.988, Val loss 1.882\n",
      "Ep 1 (Step 043205): Train loss 1.679, Val loss 1.880\n",
      "Ep 1 (Step 043210): Train loss 1.999, Val loss 1.881\n",
      "Ep 1 (Step 043215): Train loss 1.550, Val loss 1.876\n",
      "Ep 1 (Step 043220): Train loss 2.017, Val loss 1.867\n",
      "Ep 1 (Step 043225): Train loss 2.037, Val loss 1.873\n",
      "Ep 1 (Step 043230): Train loss 1.938, Val loss 1.879\n",
      "Ep 1 (Step 043235): Train loss 1.777, Val loss 1.871\n",
      "Ep 1 (Step 043240): Train loss 2.145, Val loss 1.872\n",
      "Ep 1 (Step 043245): Train loss 1.782, Val loss 1.875\n",
      "Ep 1 (Step 043250): Train loss 1.693, Val loss 1.878\n",
      "Ep 1 (Step 043255): Train loss 1.895, Val loss 1.887\n",
      "Ep 1 (Step 043260): Train loss 1.786, Val loss 1.879\n",
      "Ep 1 (Step 043265): Train loss 1.639, Val loss 1.876\n",
      "Ep 1 (Step 043270): Train loss 1.864, Val loss 1.886\n",
      "Ep 1 (Step 043275): Train loss 1.986, Val loss 1.890\n",
      "Ep 1 (Step 043280): Train loss 2.009, Val loss 1.886\n",
      "Ep 1 (Step 043285): Train loss 2.070, Val loss 1.881\n",
      "Ep 1 (Step 043290): Train loss 1.873, Val loss 1.879\n",
      "Ep 1 (Step 043295): Train loss 1.884, Val loss 1.874\n",
      "Ep 1 (Step 043300): Train loss 2.068, Val loss 1.876\n",
      "Ep 1 (Step 043305): Train loss 1.890, Val loss 1.885\n",
      "Ep 1 (Step 043310): Train loss 1.685, Val loss 1.888\n",
      "Ep 1 (Step 043315): Train loss 1.971, Val loss 1.883\n",
      "Ep 1 (Step 043320): Train loss 1.867, Val loss 1.884\n",
      "Ep 1 (Step 043325): Train loss 2.096, Val loss 1.889\n",
      "Ep 1 (Step 043330): Train loss 1.962, Val loss 1.887\n",
      "Ep 1 (Step 043335): Train loss 2.226, Val loss 1.885\n",
      "Ep 1 (Step 043340): Train loss 1.726, Val loss 1.885\n",
      "Ep 1 (Step 043345): Train loss 1.813, Val loss 1.894\n",
      "Ep 1 (Step 043350): Train loss 2.013, Val loss 1.901\n",
      "Ep 1 (Step 043355): Train loss 1.796, Val loss 1.895\n",
      "Ep 1 (Step 043360): Train loss 1.925, Val loss 1.891\n",
      "Ep 1 (Step 043365): Train loss 1.721, Val loss 1.891\n",
      "Ep 1 (Step 043370): Train loss 1.720, Val loss 1.898\n",
      "Ep 1 (Step 043375): Train loss 2.061, Val loss 1.895\n",
      "Ep 1 (Step 043380): Train loss 1.934, Val loss 1.889\n",
      "Ep 1 (Step 043385): Train loss 1.982, Val loss 1.890\n",
      "Ep 1 (Step 043390): Train loss 1.989, Val loss 1.899\n",
      "Ep 1 (Step 043395): Train loss 1.898, Val loss 1.911\n",
      "Ep 1 (Step 043400): Train loss 1.805, Val loss 1.906\n",
      "Ep 1 (Step 043405): Train loss 2.007, Val loss 1.905\n",
      "Ep 1 (Step 043410): Train loss 1.757, Val loss 1.908\n",
      "Ep 1 (Step 043415): Train loss 1.936, Val loss 1.899\n",
      "Ep 1 (Step 043420): Train loss 2.170, Val loss 1.895\n",
      "Ep 1 (Step 043425): Train loss 2.000, Val loss 1.902\n",
      "Ep 1 (Step 043430): Train loss 1.746, Val loss 1.904\n",
      "Ep 1 (Step 043435): Train loss 1.821, Val loss 1.908\n",
      "Ep 1 (Step 043440): Train loss 1.988, Val loss 1.909\n",
      "Ep 1 (Step 043445): Train loss 1.885, Val loss 1.916\n",
      "Ep 1 (Step 043450): Train loss 2.301, Val loss 1.929\n",
      "Ep 1 (Step 043455): Train loss 1.844, Val loss 1.919\n",
      "Ep 1 (Step 043460): Train loss 2.040, Val loss 1.903\n",
      "Ep 1 (Step 043465): Train loss 1.621, Val loss 1.952\n",
      "Ep 1 (Step 043470): Train loss 1.871, Val loss 1.928\n",
      "Ep 1 (Step 043475): Train loss 2.018, Val loss 1.931\n",
      "Ep 1 (Step 043480): Train loss 1.646, Val loss 1.915\n",
      "Ep 1 (Step 043485): Train loss 1.628, Val loss 1.911\n",
      "Ep 1 (Step 043490): Train loss 1.929, Val loss 1.911\n",
      "Ep 1 (Step 043495): Train loss 1.808, Val loss 1.921\n",
      "Ep 1 (Step 043500): Train loss 1.905, Val loss 1.923\n",
      "Ep 1 (Step 043505): Train loss 1.833, Val loss 1.918\n",
      "Ep 1 (Step 043510): Train loss 1.889, Val loss 1.908\n",
      "Ep 1 (Step 043515): Train loss 1.935, Val loss 1.904\n",
      "Ep 1 (Step 043520): Train loss 1.666, Val loss 1.916\n",
      "Ep 1 (Step 043525): Train loss 1.925, Val loss 1.921\n",
      "Ep 1 (Step 043530): Train loss 1.636, Val loss 1.903\n",
      "Ep 1 (Step 043535): Train loss 2.005, Val loss 1.898\n",
      "Ep 1 (Step 043540): Train loss 1.959, Val loss 1.902\n",
      "Ep 1 (Step 043545): Train loss 2.076, Val loss 1.902\n",
      "Ep 1 (Step 043550): Train loss 2.055, Val loss 1.913\n",
      "Ep 1 (Step 043555): Train loss 1.748, Val loss 1.914\n",
      "Ep 1 (Step 043560): Train loss 1.700, Val loss 1.908\n",
      "Ep 1 (Step 043565): Train loss 1.881, Val loss 1.904\n",
      "Ep 1 (Step 043570): Train loss 1.742, Val loss 1.902\n",
      "Ep 1 (Step 043575): Train loss 1.944, Val loss 1.893\n",
      "Ep 1 (Step 043580): Train loss 2.171, Val loss 1.893\n",
      "Ep 1 (Step 043585): Train loss 2.361, Val loss 1.893\n",
      "Ep 1 (Step 043590): Train loss 1.850, Val loss 1.888\n",
      "Ep 1 (Step 043595): Train loss 1.709, Val loss 1.888\n",
      "Ep 1 (Step 043600): Train loss 1.988, Val loss 1.891\n",
      "Ep 1 (Step 043605): Train loss 1.698, Val loss 1.902\n",
      "Ep 1 (Step 043610): Train loss 1.796, Val loss 1.897\n",
      "Ep 1 (Step 043615): Train loss 1.739, Val loss 1.892\n",
      "Ep 1 (Step 043620): Train loss 2.016, Val loss 1.893\n",
      "Ep 1 (Step 043625): Train loss 1.570, Val loss 1.898\n",
      "Ep 1 (Step 043630): Train loss 1.997, Val loss 1.905\n",
      "Ep 1 (Step 043635): Train loss 1.783, Val loss 1.907\n",
      "Ep 1 (Step 043640): Train loss 1.926, Val loss 1.905\n",
      "Ep 1 (Step 043645): Train loss 1.804, Val loss 1.897\n",
      "Ep 1 (Step 043650): Train loss 1.768, Val loss 1.891\n",
      "Ep 1 (Step 043655): Train loss 1.713, Val loss 1.892\n",
      "Ep 1 (Step 043660): Train loss 1.646, Val loss 1.896\n",
      "Ep 1 (Step 043665): Train loss 1.866, Val loss 1.900\n",
      "Ep 1 (Step 043670): Train loss 2.139, Val loss 1.906\n",
      "Ep 1 (Step 043675): Train loss 1.771, Val loss 1.915\n",
      "Ep 1 (Step 043680): Train loss 2.057, Val loss 1.913\n",
      "Ep 1 (Step 043685): Train loss 1.948, Val loss 1.912\n",
      "Ep 1 (Step 043690): Train loss 1.971, Val loss 1.907\n",
      "Ep 1 (Step 043695): Train loss 1.990, Val loss 1.904\n",
      "Ep 1 (Step 043700): Train loss 2.290, Val loss 1.898\n",
      "Ep 1 (Step 043705): Train loss 1.828, Val loss 1.892\n",
      "Ep 1 (Step 043710): Train loss 1.876, Val loss 1.894\n",
      "Ep 1 (Step 043715): Train loss 1.826, Val loss 1.889\n",
      "Ep 1 (Step 043720): Train loss 1.831, Val loss 1.883\n",
      "Ep 1 (Step 043725): Train loss 1.993, Val loss 1.878\n",
      "Ep 1 (Step 043730): Train loss 1.844, Val loss 1.889\n",
      "Ep 1 (Step 043735): Train loss 1.765, Val loss 1.892\n",
      "Ep 1 (Step 043740): Train loss 2.145, Val loss 1.889\n",
      "Ep 1 (Step 043745): Train loss 2.053, Val loss 1.891\n",
      "Ep 1 (Step 043750): Train loss 2.031, Val loss 1.889\n",
      "Ep 1 (Step 043755): Train loss 1.644, Val loss 1.888\n",
      "Ep 1 (Step 043760): Train loss 1.746, Val loss 1.889\n",
      "Ep 1 (Step 043765): Train loss 1.893, Val loss 1.889\n",
      "Ep 1 (Step 043770): Train loss 1.813, Val loss 1.894\n",
      "Ep 1 (Step 043775): Train loss 1.880, Val loss 1.881\n",
      "Ep 1 (Step 043780): Train loss 2.050, Val loss 1.876\n",
      "Ep 1 (Step 043785): Train loss 1.655, Val loss 1.876\n",
      "Ep 1 (Step 043790): Train loss 1.922, Val loss 1.878\n",
      "Ep 1 (Step 043795): Train loss 1.891, Val loss 1.880\n",
      "Ep 1 (Step 043800): Train loss 2.017, Val loss 1.883\n",
      "Ep 1 (Step 043805): Train loss 1.714, Val loss 1.887\n",
      "Ep 1 (Step 043810): Train loss 1.705, Val loss 1.896\n",
      "Ep 1 (Step 043815): Train loss 1.728, Val loss 1.910\n",
      "Ep 1 (Step 043820): Train loss 1.913, Val loss 1.916\n",
      "Ep 1 (Step 043825): Train loss 1.709, Val loss 1.916\n",
      "Ep 1 (Step 043830): Train loss 1.894, Val loss 1.906\n",
      "Ep 1 (Step 043835): Train loss 1.847, Val loss 1.897\n",
      "Ep 1 (Step 043840): Train loss 1.711, Val loss 1.899\n",
      "Ep 1 (Step 043845): Train loss 1.781, Val loss 1.899\n",
      "Ep 1 (Step 043850): Train loss 1.666, Val loss 1.904\n",
      "Ep 1 (Step 043855): Train loss 1.946, Val loss 1.902\n",
      "Ep 1 (Step 043860): Train loss 2.174, Val loss 1.900\n",
      "Ep 1 (Step 043865): Train loss 2.029, Val loss 1.899\n",
      "Ep 1 (Step 043870): Train loss 1.779, Val loss 1.902\n",
      "Ep 1 (Step 043875): Train loss 1.936, Val loss 1.896\n",
      "Ep 1 (Step 043880): Train loss 1.816, Val loss 1.899\n",
      "Ep 1 (Step 043885): Train loss 1.933, Val loss 1.907\n",
      "Ep 1 (Step 043890): Train loss 1.848, Val loss 1.909\n",
      "Ep 1 (Step 043895): Train loss 1.797, Val loss 1.914\n",
      "Ep 1 (Step 043900): Train loss 1.957, Val loss 1.914\n",
      "Ep 1 (Step 043905): Train loss 1.830, Val loss 1.912\n",
      "Ep 1 (Step 043910): Train loss 2.123, Val loss 1.909\n",
      "Ep 1 (Step 043915): Train loss 1.925, Val loss 1.905\n",
      "Ep 1 (Step 043920): Train loss 1.873, Val loss 1.898\n",
      "Ep 1 (Step 043925): Train loss 2.200, Val loss 1.888\n",
      "Ep 1 (Step 043930): Train loss 1.791, Val loss 1.881\n",
      "Ep 1 (Step 043935): Train loss 1.818, Val loss 1.874\n",
      "Ep 1 (Step 043940): Train loss 1.938, Val loss 1.880\n",
      "Ep 1 (Step 043945): Train loss 1.936, Val loss 1.881\n",
      "Ep 1 (Step 043950): Train loss 2.050, Val loss 1.880\n",
      "Ep 1 (Step 043955): Train loss 2.075, Val loss 1.877\n",
      "Ep 1 (Step 043960): Train loss 1.669, Val loss 1.879\n",
      "Ep 1 (Step 043965): Train loss 1.638, Val loss 1.890\n",
      "Ep 1 (Step 043970): Train loss 1.907, Val loss 1.881\n",
      "Ep 1 (Step 043975): Train loss 1.956, Val loss 1.865\n",
      "Ep 1 (Step 043980): Train loss 1.874, Val loss 1.867\n",
      "Ep 1 (Step 043985): Train loss 1.893, Val loss 1.881\n",
      "Ep 1 (Step 043990): Train loss 2.127, Val loss 1.889\n",
      "Ep 1 (Step 043995): Train loss 1.901, Val loss 1.888\n",
      "Ep 1 (Step 044000): Train loss 1.728, Val loss 1.895\n",
      "Ep 1 (Step 044005): Train loss 1.811, Val loss 1.903\n",
      "Ep 1 (Step 044010): Train loss 2.085, Val loss 1.904\n",
      "Ep 1 (Step 044015): Train loss 2.109, Val loss 1.901\n",
      "Ep 1 (Step 044020): Train loss 1.817, Val loss 1.886\n",
      "Ep 1 (Step 044025): Train loss 1.833, Val loss 1.878\n",
      "Ep 1 (Step 044030): Train loss 1.601, Val loss 1.882\n",
      "Ep 1 (Step 044035): Train loss 1.887, Val loss 1.885\n",
      "Ep 1 (Step 044040): Train loss 1.819, Val loss 1.885\n",
      "Ep 1 (Step 044045): Train loss 1.879, Val loss 1.886\n",
      "Ep 1 (Step 044050): Train loss 1.850, Val loss 1.899\n",
      "Ep 1 (Step 044055): Train loss 1.794, Val loss 1.910\n",
      "Ep 1 (Step 044060): Train loss 1.809, Val loss 1.907\n",
      "Ep 1 (Step 044065): Train loss 1.910, Val loss 1.906\n",
      "Ep 1 (Step 044070): Train loss 2.199, Val loss 1.896\n",
      "Ep 1 (Step 044075): Train loss 1.782, Val loss 1.893\n",
      "Ep 1 (Step 044080): Train loss 1.858, Val loss 1.890\n",
      "Ep 1 (Step 044085): Train loss 1.933, Val loss 1.886\n",
      "Ep 1 (Step 044090): Train loss 1.789, Val loss 1.880\n",
      "Ep 1 (Step 044095): Train loss 1.908, Val loss 1.887\n",
      "Ep 1 (Step 044100): Train loss 2.087, Val loss 1.894\n",
      "Ep 1 (Step 044105): Train loss 2.120, Val loss 1.897\n",
      "Ep 1 (Step 044110): Train loss 1.905, Val loss 1.893\n",
      "Ep 1 (Step 044115): Train loss 1.827, Val loss 1.889\n",
      "Ep 1 (Step 044120): Train loss 1.822, Val loss 1.876\n",
      "Ep 1 (Step 044125): Train loss 1.933, Val loss 1.872\n",
      "Ep 1 (Step 044130): Train loss 2.156, Val loss 1.883\n",
      "Ep 1 (Step 044135): Train loss 1.804, Val loss 1.892\n",
      "Ep 1 (Step 044140): Train loss 2.314, Val loss 1.890\n",
      "Ep 1 (Step 044145): Train loss 1.719, Val loss 1.889\n",
      "Ep 1 (Step 044150): Train loss 1.909, Val loss 1.900\n",
      "Ep 1 (Step 044155): Train loss 1.757, Val loss 1.906\n",
      "Ep 1 (Step 044160): Train loss 2.167, Val loss 1.897\n",
      "Ep 1 (Step 044165): Train loss 1.676, Val loss 1.893\n",
      "Ep 1 (Step 044170): Train loss 1.919, Val loss 1.901\n",
      "Ep 1 (Step 044175): Train loss 1.951, Val loss 1.897\n",
      "Ep 1 (Step 044180): Train loss 1.717, Val loss 1.892\n",
      "Ep 1 (Step 044185): Train loss 1.877, Val loss 1.887\n",
      "Ep 1 (Step 044190): Train loss 1.828, Val loss 1.887\n",
      "Ep 1 (Step 044195): Train loss 1.909, Val loss 1.887\n",
      "Ep 1 (Step 044200): Train loss 1.893, Val loss 1.883\n",
      "Ep 1 (Step 044205): Train loss 1.966, Val loss 1.876\n",
      "Ep 1 (Step 044210): Train loss 2.076, Val loss 1.875\n",
      "Ep 1 (Step 044215): Train loss 2.125, Val loss 1.888\n",
      "Ep 1 (Step 044220): Train loss 1.989, Val loss 1.891\n",
      "Ep 1 (Step 044225): Train loss 1.889, Val loss 1.871\n",
      "Ep 1 (Step 044230): Train loss 1.931, Val loss 1.868\n",
      "Ep 1 (Step 044235): Train loss 2.123, Val loss 1.867\n",
      "Ep 1 (Step 044240): Train loss 1.708, Val loss 1.868\n",
      "Ep 1 (Step 044245): Train loss 1.762, Val loss 1.875\n",
      "Ep 1 (Step 044250): Train loss 1.951, Val loss 1.888\n",
      "Ep 1 (Step 044255): Train loss 1.801, Val loss 1.881\n",
      "Ep 1 (Step 044260): Train loss 1.902, Val loss 1.868\n",
      "Ep 1 (Step 044265): Train loss 1.831, Val loss 1.870\n",
      "Ep 1 (Step 044270): Train loss 1.764, Val loss 1.876\n",
      "Ep 1 (Step 044275): Train loss 1.840, Val loss 1.876\n",
      "Ep 1 (Step 044280): Train loss 1.749, Val loss 1.872\n",
      "Ep 1 (Step 044285): Train loss 1.986, Val loss 1.877\n",
      "Ep 1 (Step 044290): Train loss 2.060, Val loss 1.890\n",
      "Ep 1 (Step 044295): Train loss 1.974, Val loss 1.881\n",
      "Ep 1 (Step 044300): Train loss 1.946, Val loss 1.884\n",
      "Ep 1 (Step 044305): Train loss 1.733, Val loss 1.896\n",
      "Ep 1 (Step 044310): Train loss 1.898, Val loss 1.902\n",
      "Ep 1 (Step 044315): Train loss 1.931, Val loss 1.901\n",
      "Ep 1 (Step 044320): Train loss 1.804, Val loss 1.902\n",
      "Ep 1 (Step 044325): Train loss 1.944, Val loss 1.892\n",
      "Ep 1 (Step 044330): Train loss 1.968, Val loss 1.883\n",
      "Ep 1 (Step 044335): Train loss 1.904, Val loss 1.878\n",
      "Ep 1 (Step 044340): Train loss 1.863, Val loss 1.880\n",
      "Ep 1 (Step 044345): Train loss 1.816, Val loss 1.885\n",
      "Ep 1 (Step 044350): Train loss 1.843, Val loss 1.879\n",
      "Ep 1 (Step 044355): Train loss 1.687, Val loss 1.883\n",
      "Ep 1 (Step 044360): Train loss 1.823, Val loss 1.878\n",
      "Ep 1 (Step 044365): Train loss 1.861, Val loss 1.877\n",
      "Ep 1 (Step 044370): Train loss 1.785, Val loss 1.878\n",
      "Ep 1 (Step 044375): Train loss 1.946, Val loss 1.880\n",
      "Ep 1 (Step 044380): Train loss 1.697, Val loss 1.874\n",
      "Ep 1 (Step 044385): Train loss 1.951, Val loss 1.879\n",
      "Ep 1 (Step 044390): Train loss 1.764, Val loss 1.881\n",
      "Ep 1 (Step 044395): Train loss 1.991, Val loss 1.887\n",
      "Ep 1 (Step 044400): Train loss 1.873, Val loss 1.901\n",
      "Ep 1 (Step 044405): Train loss 2.037, Val loss 1.906\n",
      "Ep 1 (Step 044410): Train loss 2.121, Val loss 1.901\n",
      "Ep 1 (Step 044415): Train loss 2.170, Val loss 1.912\n",
      "Ep 1 (Step 044420): Train loss 1.817, Val loss 1.906\n",
      "Ep 1 (Step 044425): Train loss 1.864, Val loss 1.903\n",
      "Ep 1 (Step 044430): Train loss 2.114, Val loss 1.913\n",
      "Ep 1 (Step 044435): Train loss 1.861, Val loss 1.913\n",
      "Ep 1 (Step 044440): Train loss 2.096, Val loss 1.897\n",
      "Ep 1 (Step 044445): Train loss 2.008, Val loss 1.902\n",
      "Ep 1 (Step 044450): Train loss 1.768, Val loss 1.905\n",
      "Ep 1 (Step 044455): Train loss 1.899, Val loss 1.909\n",
      "Ep 1 (Step 044460): Train loss 1.909, Val loss 1.903\n",
      "Ep 1 (Step 044465): Train loss 2.068, Val loss 1.901\n",
      "Ep 1 (Step 044470): Train loss 2.029, Val loss 1.891\n",
      "Ep 1 (Step 044475): Train loss 2.103, Val loss 1.892\n",
      "Ep 1 (Step 044480): Train loss 2.035, Val loss 1.885\n",
      "Ep 1 (Step 044485): Train loss 2.023, Val loss 1.886\n",
      "Ep 1 (Step 044490): Train loss 2.084, Val loss 1.887\n",
      "Ep 1 (Step 044495): Train loss 1.862, Val loss 1.879\n",
      "Ep 1 (Step 044500): Train loss 1.937, Val loss 1.878\n",
      "Ep 1 (Step 044505): Train loss 1.753, Val loss 1.870\n",
      "Ep 1 (Step 044510): Train loss 1.873, Val loss 1.876\n",
      "Ep 1 (Step 044515): Train loss 1.915, Val loss 1.879\n",
      "Ep 1 (Step 044520): Train loss 2.033, Val loss 1.875\n",
      "Ep 1 (Step 044525): Train loss 1.935, Val loss 1.878\n",
      "Ep 1 (Step 044530): Train loss 2.038, Val loss 1.890\n",
      "Ep 1 (Step 044535): Train loss 1.899, Val loss 1.884\n",
      "Ep 1 (Step 044540): Train loss 2.072, Val loss 1.882\n",
      "Ep 1 (Step 044545): Train loss 1.800, Val loss 1.871\n",
      "Ep 1 (Step 044550): Train loss 2.076, Val loss 1.874\n",
      "Ep 1 (Step 044555): Train loss 1.973, Val loss 1.883\n",
      "Ep 1 (Step 044560): Train loss 1.806, Val loss 1.881\n",
      "Ep 1 (Step 044565): Train loss 2.069, Val loss 1.874\n",
      "Ep 1 (Step 044570): Train loss 2.115, Val loss 1.870\n",
      "Ep 1 (Step 044575): Train loss 1.679, Val loss 1.872\n",
      "Ep 1 (Step 044580): Train loss 1.662, Val loss 1.874\n",
      "Ep 1 (Step 044585): Train loss 1.976, Val loss 1.862\n",
      "Ep 1 (Step 044590): Train loss 1.846, Val loss 1.856\n",
      "Ep 1 (Step 044595): Train loss 1.917, Val loss 1.864\n",
      "Ep 1 (Step 044600): Train loss 1.791, Val loss 1.869\n",
      "Ep 1 (Step 044605): Train loss 1.674, Val loss 1.864\n",
      "Ep 1 (Step 044610): Train loss 2.111, Val loss 1.866\n",
      "Ep 1 (Step 044615): Train loss 1.579, Val loss 1.865\n",
      "Ep 1 (Step 044620): Train loss 2.128, Val loss 1.858\n",
      "Ep 1 (Step 044625): Train loss 1.746, Val loss 1.860\n",
      "Ep 1 (Step 044630): Train loss 1.884, Val loss 1.868\n",
      "Ep 1 (Step 044635): Train loss 1.768, Val loss 1.868\n",
      "Ep 1 (Step 044640): Train loss 1.627, Val loss 1.866\n",
      "Ep 1 (Step 044645): Train loss 1.893, Val loss 1.859\n",
      "Ep 1 (Step 044650): Train loss 1.837, Val loss 1.857\n",
      "Ep 1 (Step 044655): Train loss 1.875, Val loss 1.859\n",
      "Ep 1 (Step 044660): Train loss 1.806, Val loss 1.859\n",
      "Ep 1 (Step 044665): Train loss 2.148, Val loss 1.866\n",
      "Ep 1 (Step 044670): Train loss 2.295, Val loss 1.873\n",
      "Ep 1 (Step 044675): Train loss 1.752, Val loss 1.872\n",
      "Ep 1 (Step 044680): Train loss 1.932, Val loss 1.870\n",
      "Ep 1 (Step 044685): Train loss 1.868, Val loss 1.863\n",
      "Ep 1 (Step 044690): Train loss 1.737, Val loss 1.867\n",
      "Ep 1 (Step 044695): Train loss 1.898, Val loss 1.874\n",
      "Ep 1 (Step 044700): Train loss 1.816, Val loss 1.881\n",
      "Ep 1 (Step 044705): Train loss 1.765, Val loss 1.883\n",
      "Ep 1 (Step 044710): Train loss 1.783, Val loss 1.882\n",
      "Ep 1 (Step 044715): Train loss 1.954, Val loss 1.894\n",
      "Ep 1 (Step 044720): Train loss 1.664, Val loss 1.889\n",
      "Ep 1 (Step 044725): Train loss 1.591, Val loss 1.881\n",
      "Ep 1 (Step 044730): Train loss 2.136, Val loss 1.869\n",
      "Ep 1 (Step 044735): Train loss 2.189, Val loss 1.867\n",
      "Ep 1 (Step 044740): Train loss 1.936, Val loss 1.864\n",
      "Ep 1 (Step 044745): Train loss 1.721, Val loss 1.866\n",
      "Ep 1 (Step 044750): Train loss 2.260, Val loss 1.879\n",
      "Ep 1 (Step 044755): Train loss 1.993, Val loss 1.875\n",
      "Ep 1 (Step 044760): Train loss 1.850, Val loss 1.873\n",
      "Ep 1 (Step 044765): Train loss 1.615, Val loss 1.874\n",
      "Ep 1 (Step 044770): Train loss 1.805, Val loss 1.877\n",
      "Ep 1 (Step 044775): Train loss 1.730, Val loss 1.880\n",
      "Ep 1 (Step 044780): Train loss 2.090, Val loss 1.881\n",
      "Ep 1 (Step 044785): Train loss 1.659, Val loss 1.881\n",
      "Ep 1 (Step 044790): Train loss 1.756, Val loss 1.867\n",
      "Ep 1 (Step 044795): Train loss 1.911, Val loss 1.863\n",
      "Ep 1 (Step 044800): Train loss 1.872, Val loss 1.868\n",
      "Ep 1 (Step 044805): Train loss 1.696, Val loss 1.882\n",
      "Ep 1 (Step 044810): Train loss 1.956, Val loss 1.899\n",
      "Ep 1 (Step 044815): Train loss 1.910, Val loss 1.904\n",
      "Ep 1 (Step 044820): Train loss 1.932, Val loss 1.896\n",
      "Ep 1 (Step 044825): Train loss 1.989, Val loss 1.896\n",
      "Ep 1 (Step 044830): Train loss 2.086, Val loss 1.883\n",
      "Ep 1 (Step 044835): Train loss 1.907, Val loss 1.886\n",
      "Ep 1 (Step 044840): Train loss 1.855, Val loss 1.888\n",
      "Ep 1 (Step 044845): Train loss 1.775, Val loss 1.881\n",
      "Ep 1 (Step 044850): Train loss 2.062, Val loss 1.883\n",
      "Ep 1 (Step 044855): Train loss 2.116, Val loss 1.890\n",
      "Ep 1 (Step 044860): Train loss 1.745, Val loss 1.890\n",
      "Ep 1 (Step 044865): Train loss 2.019, Val loss 1.893\n",
      "Ep 1 (Step 044870): Train loss 1.917, Val loss 1.891\n",
      "Ep 1 (Step 044875): Train loss 1.881, Val loss 1.889\n",
      "Ep 1 (Step 044880): Train loss 1.777, Val loss 1.878\n",
      "Ep 1 (Step 044885): Train loss 1.985, Val loss 1.880\n",
      "Ep 1 (Step 044890): Train loss 1.892, Val loss 1.881\n",
      "Ep 1 (Step 044895): Train loss 2.114, Val loss 1.880\n",
      "Ep 1 (Step 044900): Train loss 1.860, Val loss 1.877\n",
      "Ep 1 (Step 044905): Train loss 1.850, Val loss 1.876\n",
      "Ep 1 (Step 044910): Train loss 1.740, Val loss 1.878\n",
      "Ep 1 (Step 044915): Train loss 2.156, Val loss 1.881\n",
      "Ep 1 (Step 044920): Train loss 1.880, Val loss 1.882\n",
      "Ep 1 (Step 044925): Train loss 2.049, Val loss 1.887\n",
      "Ep 1 (Step 044930): Train loss 1.978, Val loss 1.893\n",
      "Ep 1 (Step 044935): Train loss 2.092, Val loss 1.886\n",
      "Ep 1 (Step 044940): Train loss 1.874, Val loss 1.885\n",
      "Ep 1 (Step 044945): Train loss 1.903, Val loss 1.885\n",
      "Ep 1 (Step 044950): Train loss 2.022, Val loss 1.881\n",
      "Ep 1 (Step 044955): Train loss 2.026, Val loss 1.872\n",
      "Ep 1 (Step 044960): Train loss 1.703, Val loss 1.869\n",
      "Ep 1 (Step 044965): Train loss 2.104, Val loss 1.870\n",
      "Ep 1 (Step 044970): Train loss 1.690, Val loss 1.881\n",
      "Ep 1 (Step 044975): Train loss 1.827, Val loss 1.894\n",
      "Ep 1 (Step 044980): Train loss 2.039, Val loss 1.892\n",
      "Ep 1 (Step 044985): Train loss 1.720, Val loss 1.890\n",
      "Ep 1 (Step 044990): Train loss 1.875, Val loss 1.912\n",
      "Ep 1 (Step 044995): Train loss 2.261, Val loss 1.922\n",
      "Ep 1 (Step 045000): Train loss 1.951, Val loss 1.911\n",
      "Ep 1 (Step 045005): Train loss 1.745, Val loss 1.907\n",
      "Ep 1 (Step 045010): Train loss 2.004, Val loss 1.915\n",
      "Ep 1 (Step 045015): Train loss 1.900, Val loss 1.919\n",
      "Ep 1 (Step 045020): Train loss 1.858, Val loss 1.907\n",
      "Ep 1 (Step 045025): Train loss 1.863, Val loss 1.897\n",
      "Ep 1 (Step 045030): Train loss 1.932, Val loss 1.886\n",
      "Ep 1 (Step 045035): Train loss 1.712, Val loss 1.893\n",
      "Ep 1 (Step 045040): Train loss 1.985, Val loss 1.906\n",
      "Ep 1 (Step 045045): Train loss 2.292, Val loss 1.894\n",
      "Ep 1 (Step 045050): Train loss 1.876, Val loss 1.890\n",
      "Ep 1 (Step 045055): Train loss 1.694, Val loss 1.888\n",
      "Ep 1 (Step 045060): Train loss 1.996, Val loss 1.889\n",
      "Ep 1 (Step 045065): Train loss 1.843, Val loss 1.895\n",
      "Ep 1 (Step 045070): Train loss 1.738, Val loss 1.895\n",
      "Ep 1 (Step 045075): Train loss 1.706, Val loss 1.888\n",
      "Ep 1 (Step 045080): Train loss 1.764, Val loss 1.890\n",
      "Ep 1 (Step 045085): Train loss 1.815, Val loss 1.890\n",
      "Ep 1 (Step 045090): Train loss 1.937, Val loss 1.883\n",
      "Ep 1 (Step 045095): Train loss 2.194, Val loss 1.886\n",
      "Ep 1 (Step 045100): Train loss 1.816, Val loss 1.881\n",
      "Ep 1 (Step 045105): Train loss 1.983, Val loss 1.884\n",
      "Ep 1 (Step 045110): Train loss 2.171, Val loss 1.890\n",
      "Ep 1 (Step 045115): Train loss 2.130, Val loss 1.889\n",
      "Ep 1 (Step 045120): Train loss 1.778, Val loss 1.891\n",
      "Ep 1 (Step 045125): Train loss 1.828, Val loss 1.907\n",
      "Ep 1 (Step 045130): Train loss 1.918, Val loss 1.909\n",
      "Ep 1 (Step 045135): Train loss 1.688, Val loss 1.899\n",
      "Ep 1 (Step 045140): Train loss 1.793, Val loss 1.888\n",
      "Ep 1 (Step 045145): Train loss 1.880, Val loss 1.897\n",
      "Ep 1 (Step 045150): Train loss 1.845, Val loss 1.901\n",
      "Ep 1 (Step 045155): Train loss 1.899, Val loss 1.897\n",
      "Ep 1 (Step 045160): Train loss 1.833, Val loss 1.900\n",
      "Ep 1 (Step 045165): Train loss 1.893, Val loss 1.896\n",
      "Ep 1 (Step 045170): Train loss 2.260, Val loss 1.904\n",
      "Ep 1 (Step 045175): Train loss 1.798, Val loss 1.906\n",
      "Ep 1 (Step 045180): Train loss 2.043, Val loss 1.895\n",
      "Ep 1 (Step 045185): Train loss 2.016, Val loss 1.887\n",
      "Ep 1 (Step 045190): Train loss 2.056, Val loss 1.886\n",
      "Ep 1 (Step 045195): Train loss 1.995, Val loss 1.891\n",
      "Ep 1 (Step 045200): Train loss 1.763, Val loss 1.894\n",
      "Ep 1 (Step 045205): Train loss 1.866, Val loss 1.901\n",
      "Ep 1 (Step 045210): Train loss 1.710, Val loss 1.900\n",
      "Ep 1 (Step 045215): Train loss 1.906, Val loss 1.901\n",
      "Ep 1 (Step 045220): Train loss 1.693, Val loss 1.901\n",
      "Ep 1 (Step 045225): Train loss 2.221, Val loss 1.896\n",
      "Ep 1 (Step 045230): Train loss 1.768, Val loss 1.900\n",
      "Ep 1 (Step 045235): Train loss 1.927, Val loss 1.894\n",
      "Ep 1 (Step 045240): Train loss 1.954, Val loss 1.886\n",
      "Ep 1 (Step 045245): Train loss 2.009, Val loss 1.884\n",
      "Ep 1 (Step 045250): Train loss 2.048, Val loss 1.875\n",
      "Ep 1 (Step 045255): Train loss 2.003, Val loss 1.881\n",
      "Ep 1 (Step 045260): Train loss 2.279, Val loss 1.877\n",
      "Ep 1 (Step 045265): Train loss 1.849, Val loss 1.868\n",
      "Ep 1 (Step 045270): Train loss 1.879, Val loss 1.864\n",
      "Ep 1 (Step 045275): Train loss 1.935, Val loss 1.864\n",
      "Ep 1 (Step 045280): Train loss 1.855, Val loss 1.866\n",
      "Ep 1 (Step 045285): Train loss 1.897, Val loss 1.860\n",
      "Ep 1 (Step 045290): Train loss 1.939, Val loss 1.860\n",
      "Ep 1 (Step 045295): Train loss 1.754, Val loss 1.855\n",
      "Ep 1 (Step 045300): Train loss 2.021, Val loss 1.857\n",
      "Ep 1 (Step 045305): Train loss 1.995, Val loss 1.861\n",
      "Ep 1 (Step 045310): Train loss 1.760, Val loss 1.862\n",
      "Ep 1 (Step 045315): Train loss 1.682, Val loss 1.870\n",
      "Ep 1 (Step 045320): Train loss 1.990, Val loss 1.871\n",
      "Ep 1 (Step 045325): Train loss 1.546, Val loss 1.873\n",
      "Ep 1 (Step 045330): Train loss 1.772, Val loss 1.886\n",
      "Ep 1 (Step 045335): Train loss 1.748, Val loss 1.885\n",
      "Ep 1 (Step 045340): Train loss 1.736, Val loss 1.876\n",
      "Ep 1 (Step 045345): Train loss 2.010, Val loss 1.881\n",
      "Ep 1 (Step 045350): Train loss 1.897, Val loss 1.884\n",
      "Ep 1 (Step 045355): Train loss 1.757, Val loss 1.890\n",
      "Ep 1 (Step 045360): Train loss 1.940, Val loss 1.877\n",
      "Ep 1 (Step 045365): Train loss 2.014, Val loss 1.876\n",
      "Ep 1 (Step 045370): Train loss 1.705, Val loss 1.877\n",
      "Ep 1 (Step 045375): Train loss 1.801, Val loss 1.873\n",
      "Ep 1 (Step 045380): Train loss 2.073, Val loss 1.859\n",
      "Ep 1 (Step 045385): Train loss 1.873, Val loss 1.860\n",
      "Ep 1 (Step 045390): Train loss 1.726, Val loss 1.869\n",
      "Ep 1 (Step 045395): Train loss 1.833, Val loss 1.866\n",
      "Ep 1 (Step 045400): Train loss 1.804, Val loss 1.856\n",
      "Ep 1 (Step 045405): Train loss 1.906, Val loss 1.845\n",
      "Ep 1 (Step 045410): Train loss 2.073, Val loss 1.842\n",
      "Ep 1 (Step 045415): Train loss 1.700, Val loss 1.849\n",
      "Ep 1 (Step 045420): Train loss 1.892, Val loss 1.854\n",
      "Ep 1 (Step 045425): Train loss 1.869, Val loss 1.858\n",
      "Ep 1 (Step 045430): Train loss 1.845, Val loss 1.857\n",
      "Ep 1 (Step 045435): Train loss 1.801, Val loss 1.850\n",
      "Ep 1 (Step 045440): Train loss 1.753, Val loss 1.858\n",
      "Ep 1 (Step 045445): Train loss 2.236, Val loss 1.863\n",
      "Ep 1 (Step 045450): Train loss 1.757, Val loss 1.864\n",
      "Ep 1 (Step 045455): Train loss 1.679, Val loss 1.871\n",
      "Ep 1 (Step 045460): Train loss 2.033, Val loss 1.878\n",
      "Ep 1 (Step 045465): Train loss 1.856, Val loss 1.875\n",
      "Ep 1 (Step 045470): Train loss 2.108, Val loss 1.872\n",
      "Ep 1 (Step 045475): Train loss 1.840, Val loss 1.877\n",
      "Ep 1 (Step 045480): Train loss 2.133, Val loss 1.874\n",
      "Ep 1 (Step 045485): Train loss 1.842, Val loss 1.871\n",
      "Ep 1 (Step 045490): Train loss 1.926, Val loss 1.877\n",
      "Ep 1 (Step 045495): Train loss 2.199, Val loss 1.882\n",
      "Ep 1 (Step 045500): Train loss 1.772, Val loss 1.893\n",
      "Ep 1 (Step 045505): Train loss 1.714, Val loss 1.893\n",
      "Ep 1 (Step 045510): Train loss 1.751, Val loss 1.892\n",
      "Ep 1 (Step 045515): Train loss 2.154, Val loss 1.888\n",
      "Ep 1 (Step 045520): Train loss 1.753, Val loss 1.876\n",
      "Ep 1 (Step 045525): Train loss 1.784, Val loss 1.867\n",
      "Ep 1 (Step 045530): Train loss 2.030, Val loss 1.876\n",
      "Ep 1 (Step 045535): Train loss 1.914, Val loss 1.876\n",
      "Ep 1 (Step 045540): Train loss 1.922, Val loss 1.873\n",
      "Ep 1 (Step 045545): Train loss 2.208, Val loss 1.872\n",
      "Ep 1 (Step 045550): Train loss 1.923, Val loss 1.877\n",
      "Ep 1 (Step 045555): Train loss 1.796, Val loss 1.885\n",
      "Ep 1 (Step 045560): Train loss 1.845, Val loss 1.881\n",
      "Ep 1 (Step 045565): Train loss 2.586, Val loss 1.876\n",
      "Ep 1 (Step 045570): Train loss 1.989, Val loss 1.876\n",
      "Ep 1 (Step 045575): Train loss 1.994, Val loss 1.883\n",
      "Ep 1 (Step 045580): Train loss 1.907, Val loss 1.885\n",
      "Ep 1 (Step 045585): Train loss 1.925, Val loss 1.878\n",
      "Ep 1 (Step 045590): Train loss 2.019, Val loss 1.869\n",
      "Ep 1 (Step 045595): Train loss 2.080, Val loss 1.866\n",
      "Ep 1 (Step 045600): Train loss 1.883, Val loss 1.870\n",
      "Ep 1 (Step 045605): Train loss 1.883, Val loss 1.872\n",
      "Ep 1 (Step 045610): Train loss 1.849, Val loss 1.868\n",
      "Ep 1 (Step 045615): Train loss 1.883, Val loss 1.866\n",
      "Ep 1 (Step 045620): Train loss 1.630, Val loss 1.865\n",
      "Ep 1 (Step 045625): Train loss 1.761, Val loss 1.872\n",
      "Ep 1 (Step 045630): Train loss 1.683, Val loss 1.873\n",
      "Ep 1 (Step 045635): Train loss 1.720, Val loss 1.874\n",
      "Ep 1 (Step 045640): Train loss 2.010, Val loss 1.874\n",
      "Ep 1 (Step 045645): Train loss 1.849, Val loss 1.878\n",
      "Ep 1 (Step 045650): Train loss 1.718, Val loss 1.875\n",
      "Ep 1 (Step 045655): Train loss 1.899, Val loss 1.866\n",
      "Ep 1 (Step 045660): Train loss 1.827, Val loss 1.875\n",
      "Ep 1 (Step 045665): Train loss 1.712, Val loss 1.877\n",
      "Ep 1 (Step 045670): Train loss 1.640, Val loss 1.872\n",
      "Ep 1 (Step 045675): Train loss 1.906, Val loss 1.870\n",
      "Ep 1 (Step 045680): Train loss 1.935, Val loss 1.883\n",
      "Ep 1 (Step 045685): Train loss 1.914, Val loss 1.895\n",
      "Ep 1 (Step 045690): Train loss 1.795, Val loss 1.889\n",
      "Ep 1 (Step 045695): Train loss 1.850, Val loss 1.882\n",
      "Ep 1 (Step 045700): Train loss 1.932, Val loss 1.881\n",
      "Ep 1 (Step 045705): Train loss 1.973, Val loss 1.884\n",
      "Ep 1 (Step 045710): Train loss 2.233, Val loss 1.882\n",
      "Ep 1 (Step 045715): Train loss 1.748, Val loss 1.882\n",
      "Ep 1 (Step 045720): Train loss 1.803, Val loss 1.884\n",
      "Ep 1 (Step 045725): Train loss 1.830, Val loss 1.885\n",
      "Ep 1 (Step 045730): Train loss 1.645, Val loss 1.880\n",
      "Ep 1 (Step 045735): Train loss 2.254, Val loss 1.876\n",
      "Ep 1 (Step 045740): Train loss 2.291, Val loss 1.873\n",
      "Ep 1 (Step 045745): Train loss 1.743, Val loss 1.876\n",
      "Ep 1 (Step 045750): Train loss 2.184, Val loss 1.873\n",
      "Ep 1 (Step 045755): Train loss 1.861, Val loss 1.871\n",
      "Ep 1 (Step 045760): Train loss 2.058, Val loss 1.864\n",
      "Ep 1 (Step 045765): Train loss 1.951, Val loss 1.862\n",
      "Ep 1 (Step 045770): Train loss 2.322, Val loss 1.864\n",
      "Ep 1 (Step 045775): Train loss 1.933, Val loss 1.863\n",
      "Ep 1 (Step 045780): Train loss 1.986, Val loss 1.871\n",
      "Ep 1 (Step 045785): Train loss 1.722, Val loss 1.870\n",
      "Ep 1 (Step 045790): Train loss 1.679, Val loss 1.861\n",
      "Ep 1 (Step 045795): Train loss 1.969, Val loss 1.858\n",
      "Ep 1 (Step 045800): Train loss 2.009, Val loss 1.859\n",
      "Ep 1 (Step 045805): Train loss 2.008, Val loss 1.867\n",
      "Ep 1 (Step 045810): Train loss 1.979, Val loss 1.874\n",
      "Ep 1 (Step 045815): Train loss 2.289, Val loss 1.876\n",
      "Ep 1 (Step 045820): Train loss 1.637, Val loss 1.877\n",
      "Ep 1 (Step 045825): Train loss 1.916, Val loss 1.875\n",
      "Ep 1 (Step 045830): Train loss 2.240, Val loss 1.874\n",
      "Ep 1 (Step 045835): Train loss 2.029, Val loss 1.886\n",
      "Ep 1 (Step 045840): Train loss 1.688, Val loss 1.890\n",
      "Ep 1 (Step 045845): Train loss 1.772, Val loss 1.893\n",
      "Ep 1 (Step 045850): Train loss 1.720, Val loss 1.893\n",
      "Ep 1 (Step 045855): Train loss 1.762, Val loss 1.885\n",
      "Ep 1 (Step 045860): Train loss 1.930, Val loss 1.877\n",
      "Ep 1 (Step 045865): Train loss 1.972, Val loss 1.879\n",
      "Ep 1 (Step 045870): Train loss 1.942, Val loss 1.884\n",
      "Ep 1 (Step 045875): Train loss 1.892, Val loss 1.887\n",
      "Ep 1 (Step 045880): Train loss 1.925, Val loss 1.886\n",
      "Ep 1 (Step 045885): Train loss 1.798, Val loss 1.885\n",
      "Ep 1 (Step 045890): Train loss 2.087, Val loss 1.889\n",
      "Ep 1 (Step 045895): Train loss 1.981, Val loss 1.886\n",
      "Ep 1 (Step 045900): Train loss 1.548, Val loss 1.884\n",
      "Ep 1 (Step 045905): Train loss 1.997, Val loss 1.880\n",
      "Ep 1 (Step 045910): Train loss 1.702, Val loss 1.888\n",
      "Ep 1 (Step 045915): Train loss 2.004, Val loss 1.888\n",
      "Ep 1 (Step 045920): Train loss 1.792, Val loss 1.885\n",
      "Ep 1 (Step 045925): Train loss 1.914, Val loss 1.878\n",
      "Ep 1 (Step 045930): Train loss 1.703, Val loss 1.872\n",
      "Ep 1 (Step 045935): Train loss 1.907, Val loss 1.871\n",
      "Ep 1 (Step 045940): Train loss 2.039, Val loss 1.876\n",
      "Ep 1 (Step 045945): Train loss 1.817, Val loss 1.871\n",
      "Ep 1 (Step 045950): Train loss 1.745, Val loss 1.873\n",
      "Ep 1 (Step 045955): Train loss 1.983, Val loss 1.882\n",
      "Ep 1 (Step 045960): Train loss 1.816, Val loss 1.889\n",
      "Ep 1 (Step 045965): Train loss 1.987, Val loss 1.895\n",
      "Ep 1 (Step 045970): Train loss 1.672, Val loss 1.890\n",
      "Ep 1 (Step 045975): Train loss 1.723, Val loss 1.876\n",
      "Ep 1 (Step 045980): Train loss 1.895, Val loss 1.870\n",
      "Ep 1 (Step 045985): Train loss 2.087, Val loss 1.876\n",
      "Ep 1 (Step 045990): Train loss 1.797, Val loss 1.884\n",
      "Ep 1 (Step 045995): Train loss 2.053, Val loss 1.886\n",
      "Ep 1 (Step 046000): Train loss 1.718, Val loss 1.884\n",
      "Ep 1 (Step 046005): Train loss 1.926, Val loss 1.886\n",
      "Ep 1 (Step 046010): Train loss 1.926, Val loss 1.900\n",
      "Ep 1 (Step 046015): Train loss 1.645, Val loss 1.881\n",
      "Ep 1 (Step 046020): Train loss 1.983, Val loss 1.878\n",
      "Ep 1 (Step 046025): Train loss 1.854, Val loss 1.871\n",
      "Ep 1 (Step 046030): Train loss 1.897, Val loss 1.868\n",
      "Ep 1 (Step 046035): Train loss 2.111, Val loss 1.863\n",
      "Ep 1 (Step 046040): Train loss 1.746, Val loss 1.864\n",
      "Ep 1 (Step 046045): Train loss 2.006, Val loss 1.875\n",
      "Ep 1 (Step 046050): Train loss 1.829, Val loss 1.885\n",
      "Ep 1 (Step 046055): Train loss 2.040, Val loss 1.886\n",
      "Ep 1 (Step 046060): Train loss 1.907, Val loss 1.876\n",
      "Ep 1 (Step 046065): Train loss 2.058, Val loss 1.878\n",
      "Ep 1 (Step 046070): Train loss 1.807, Val loss 1.889\n",
      "Ep 1 (Step 046075): Train loss 1.958, Val loss 1.891\n",
      "Ep 1 (Step 046080): Train loss 1.898, Val loss 1.899\n",
      "Ep 1 (Step 046085): Train loss 2.033, Val loss 1.909\n",
      "Ep 1 (Step 046090): Train loss 1.589, Val loss 1.897\n",
      "Ep 1 (Step 046095): Train loss 2.049, Val loss 1.888\n",
      "Ep 1 (Step 046100): Train loss 1.862, Val loss 1.890\n",
      "Ep 1 (Step 046105): Train loss 1.923, Val loss 1.888\n",
      "Ep 1 (Step 046110): Train loss 1.759, Val loss 1.891\n",
      "Ep 1 (Step 046115): Train loss 1.814, Val loss 1.889\n",
      "Ep 1 (Step 046120): Train loss 2.032, Val loss 1.888\n",
      "Ep 1 (Step 046125): Train loss 2.211, Val loss 1.883\n",
      "Ep 1 (Step 046130): Train loss 1.829, Val loss 1.881\n",
      "Ep 1 (Step 046135): Train loss 1.794, Val loss 1.872\n",
      "Ep 1 (Step 046140): Train loss 1.916, Val loss 1.867\n",
      "Ep 1 (Step 046145): Train loss 1.800, Val loss 1.867\n",
      "Ep 1 (Step 046150): Train loss 1.630, Val loss 1.870\n",
      "Ep 1 (Step 046155): Train loss 1.804, Val loss 1.872\n",
      "Ep 1 (Step 046160): Train loss 1.868, Val loss 1.876\n",
      "Ep 1 (Step 046165): Train loss 1.868, Val loss 1.884\n",
      "Ep 1 (Step 046170): Train loss 1.927, Val loss 1.883\n",
      "Ep 1 (Step 046175): Train loss 1.797, Val loss 1.891\n",
      "Ep 1 (Step 046180): Train loss 1.959, Val loss 1.894\n",
      "Ep 1 (Step 046185): Train loss 2.037, Val loss 1.888\n",
      "Ep 1 (Step 046190): Train loss 1.990, Val loss 1.879\n",
      "Ep 1 (Step 046195): Train loss 1.783, Val loss 1.878\n",
      "Ep 1 (Step 046200): Train loss 1.802, Val loss 1.875\n",
      "Ep 1 (Step 046205): Train loss 2.146, Val loss 1.865\n",
      "Ep 1 (Step 046210): Train loss 1.911, Val loss 1.876\n",
      "Ep 1 (Step 046215): Train loss 1.880, Val loss 1.866\n",
      "Ep 1 (Step 046220): Train loss 1.959, Val loss 1.863\n",
      "Ep 1 (Step 046225): Train loss 2.268, Val loss 1.870\n",
      "Ep 1 (Step 046230): Train loss 1.807, Val loss 1.882\n",
      "Ep 1 (Step 046235): Train loss 1.762, Val loss 1.878\n",
      "Ep 1 (Step 046240): Train loss 1.889, Val loss 1.876\n",
      "Ep 1 (Step 046245): Train loss 1.729, Val loss 1.877\n",
      "Ep 1 (Step 046250): Train loss 1.686, Val loss 1.878\n",
      "Ep 1 (Step 046255): Train loss 1.866, Val loss 1.872\n",
      "Ep 1 (Step 046260): Train loss 1.895, Val loss 1.881\n",
      "Ep 1 (Step 046265): Train loss 1.596, Val loss 1.894\n",
      "Ep 1 (Step 046270): Train loss 1.705, Val loss 1.891\n",
      "Ep 1 (Step 046275): Train loss 2.090, Val loss 1.875\n",
      "Ep 1 (Step 046280): Train loss 2.051, Val loss 1.867\n",
      "Ep 1 (Step 046285): Train loss 1.947, Val loss 1.868\n",
      "Ep 1 (Step 046290): Train loss 1.844, Val loss 1.871\n",
      "Ep 1 (Step 046295): Train loss 1.775, Val loss 1.877\n",
      "Ep 1 (Step 046300): Train loss 1.807, Val loss 1.872\n",
      "Ep 1 (Step 046305): Train loss 1.880, Val loss 1.871\n",
      "Ep 1 (Step 046310): Train loss 1.890, Val loss 1.867\n",
      "Ep 1 (Step 046315): Train loss 1.846, Val loss 1.871\n",
      "Ep 1 (Step 046320): Train loss 2.067, Val loss 1.865\n",
      "Ep 1 (Step 046325): Train loss 1.930, Val loss 1.855\n",
      "Ep 1 (Step 046330): Train loss 1.822, Val loss 1.852\n",
      "Ep 1 (Step 046335): Train loss 1.954, Val loss 1.855\n",
      "Ep 1 (Step 046340): Train loss 1.837, Val loss 1.852\n",
      "Ep 1 (Step 046345): Train loss 1.991, Val loss 1.861\n",
      "Ep 1 (Step 046350): Train loss 1.830, Val loss 1.866\n",
      "Ep 1 (Step 046355): Train loss 2.100, Val loss 1.870\n",
      "Ep 1 (Step 046360): Train loss 1.767, Val loss 1.868\n",
      "Ep 1 (Step 046365): Train loss 1.959, Val loss 1.859\n",
      "Ep 1 (Step 046370): Train loss 2.072, Val loss 1.853\n",
      "Ep 1 (Step 046375): Train loss 1.768, Val loss 1.849\n",
      "Ep 1 (Step 046380): Train loss 1.767, Val loss 1.860\n",
      "Ep 1 (Step 046385): Train loss 1.926, Val loss 1.862\n",
      "Ep 1 (Step 046390): Train loss 2.030, Val loss 1.867\n",
      "Ep 1 (Step 046395): Train loss 1.782, Val loss 1.867\n",
      "Ep 1 (Step 046400): Train loss 1.734, Val loss 1.873\n",
      "Ep 1 (Step 046405): Train loss 1.546, Val loss 1.869\n",
      "Ep 1 (Step 046410): Train loss 1.881, Val loss 1.869\n",
      "Ep 1 (Step 046415): Train loss 1.934, Val loss 1.866\n",
      "Ep 1 (Step 046420): Train loss 1.950, Val loss 1.864\n",
      "Ep 1 (Step 046425): Train loss 1.908, Val loss 1.863\n",
      "Ep 1 (Step 046430): Train loss 1.880, Val loss 1.861\n",
      "Ep 1 (Step 046435): Train loss 1.869, Val loss 1.877\n",
      "Ep 1 (Step 046440): Train loss 1.700, Val loss 1.883\n",
      "Ep 1 (Step 046445): Train loss 1.731, Val loss 1.897\n",
      "Ep 1 (Step 046450): Train loss 1.987, Val loss 1.888\n",
      "Ep 1 (Step 046455): Train loss 1.977, Val loss 1.872\n",
      "Ep 1 (Step 046460): Train loss 2.111, Val loss 1.865\n",
      "Ep 1 (Step 046465): Train loss 1.880, Val loss 1.869\n",
      "Ep 1 (Step 046470): Train loss 1.971, Val loss 1.888\n",
      "Ep 1 (Step 046475): Train loss 1.774, Val loss 1.892\n",
      "Ep 1 (Step 046480): Train loss 1.716, Val loss 1.892\n",
      "Ep 1 (Step 046485): Train loss 1.793, Val loss 1.889\n",
      "Ep 1 (Step 046490): Train loss 1.813, Val loss 1.889\n",
      "Ep 1 (Step 046495): Train loss 1.899, Val loss 1.898\n",
      "Ep 1 (Step 046500): Train loss 2.003, Val loss 1.899\n",
      "Ep 1 (Step 046505): Train loss 2.019, Val loss 1.894\n",
      "Ep 1 (Step 046510): Train loss 1.924, Val loss 1.887\n",
      "Ep 1 (Step 046515): Train loss 1.917, Val loss 1.883\n",
      "Ep 1 (Step 046520): Train loss 1.885, Val loss 1.889\n",
      "Ep 1 (Step 046525): Train loss 1.791, Val loss 1.877\n",
      "Ep 1 (Step 046530): Train loss 1.809, Val loss 1.874\n",
      "Ep 1 (Step 046535): Train loss 1.679, Val loss 1.875\n",
      "Ep 1 (Step 046540): Train loss 1.874, Val loss 1.888\n",
      "Ep 1 (Step 046545): Train loss 1.912, Val loss 1.886\n",
      "Ep 1 (Step 046550): Train loss 2.155, Val loss 1.879\n",
      "Ep 1 (Step 046555): Train loss 1.783, Val loss 1.881\n",
      "Ep 1 (Step 046560): Train loss 1.761, Val loss 1.894\n",
      "Ep 1 (Step 046565): Train loss 1.654, Val loss 1.887\n",
      "Ep 1 (Step 046570): Train loss 1.711, Val loss 1.882\n",
      "Ep 1 (Step 046575): Train loss 2.114, Val loss 1.876\n",
      "Ep 1 (Step 046580): Train loss 1.666, Val loss 1.866\n",
      "Ep 1 (Step 046585): Train loss 1.877, Val loss 1.867\n",
      "Ep 1 (Step 046590): Train loss 1.725, Val loss 1.863\n",
      "Ep 1 (Step 046595): Train loss 1.736, Val loss 1.861\n",
      "Ep 1 (Step 046600): Train loss 2.018, Val loss 1.870\n",
      "Ep 1 (Step 046605): Train loss 1.808, Val loss 1.870\n",
      "Ep 1 (Step 046610): Train loss 2.112, Val loss 1.869\n",
      "Ep 1 (Step 046615): Train loss 1.806, Val loss 1.874\n",
      "Ep 1 (Step 046620): Train loss 1.818, Val loss 1.874\n",
      "Ep 1 (Step 046625): Train loss 2.051, Val loss 1.870\n",
      "Ep 1 (Step 046630): Train loss 1.984, Val loss 1.869\n",
      "Ep 1 (Step 046635): Train loss 2.095, Val loss 1.873\n",
      "Ep 1 (Step 046640): Train loss 2.279, Val loss 1.872\n",
      "Ep 1 (Step 046645): Train loss 1.937, Val loss 1.881\n",
      "Ep 1 (Step 046650): Train loss 1.979, Val loss 1.885\n",
      "Ep 1 (Step 046655): Train loss 1.766, Val loss 1.881\n",
      "Ep 1 (Step 046660): Train loss 2.082, Val loss 1.873\n",
      "Ep 1 (Step 046665): Train loss 1.764, Val loss 1.874\n",
      "Ep 1 (Step 046670): Train loss 1.749, Val loss 1.872\n",
      "Ep 1 (Step 046675): Train loss 2.023, Val loss 1.884\n",
      "Ep 1 (Step 046680): Train loss 2.024, Val loss 1.885\n",
      "Ep 1 (Step 046685): Train loss 2.023, Val loss 1.875\n",
      "Ep 1 (Step 046690): Train loss 1.708, Val loss 1.868\n",
      "Ep 1 (Step 046695): Train loss 1.780, Val loss 1.869\n",
      "Ep 1 (Step 046700): Train loss 1.609, Val loss 1.876\n",
      "Ep 1 (Step 046705): Train loss 1.800, Val loss 1.890\n",
      "Ep 1 (Step 046710): Train loss 1.907, Val loss 1.891\n",
      "Ep 1 (Step 046715): Train loss 2.001, Val loss 1.890\n",
      "Ep 1 (Step 046720): Train loss 1.637, Val loss 1.892\n",
      "Ep 1 (Step 046725): Train loss 1.947, Val loss 1.893\n",
      "Ep 1 (Step 046730): Train loss 1.676, Val loss 1.886\n",
      "Ep 1 (Step 046735): Train loss 1.665, Val loss 1.876\n",
      "Ep 1 (Step 046740): Train loss 2.393, Val loss 1.872\n",
      "Ep 1 (Step 046745): Train loss 1.738, Val loss 1.871\n",
      "Ep 1 (Step 046750): Train loss 2.172, Val loss 1.870\n",
      "Ep 1 (Step 046755): Train loss 1.863, Val loss 1.861\n",
      "Ep 1 (Step 046760): Train loss 1.830, Val loss 1.861\n",
      "Ep 1 (Step 046765): Train loss 1.639, Val loss 1.876\n",
      "Ep 1 (Step 046770): Train loss 2.011, Val loss 1.871\n",
      "Ep 1 (Step 046775): Train loss 1.520, Val loss 1.864\n",
      "Ep 1 (Step 046780): Train loss 1.821, Val loss 1.859\n",
      "Ep 1 (Step 046785): Train loss 1.738, Val loss 1.857\n",
      "Ep 1 (Step 046790): Train loss 1.948, Val loss 1.851\n",
      "Ep 1 (Step 046795): Train loss 1.924, Val loss 1.861\n",
      "Ep 1 (Step 046800): Train loss 1.893, Val loss 1.872\n",
      "Ep 1 (Step 046805): Train loss 2.004, Val loss 1.885\n",
      "Ep 1 (Step 046810): Train loss 1.718, Val loss 1.884\n",
      "Ep 1 (Step 046815): Train loss 1.975, Val loss 1.873\n",
      "Ep 1 (Step 046820): Train loss 2.002, Val loss 1.869\n",
      "Ep 1 (Step 046825): Train loss 1.760, Val loss 1.865\n",
      "Ep 1 (Step 046830): Train loss 2.023, Val loss 1.867\n",
      "Ep 1 (Step 046835): Train loss 1.855, Val loss 1.875\n",
      "Ep 1 (Step 046840): Train loss 1.691, Val loss 1.874\n",
      "Ep 1 (Step 046845): Train loss 1.998, Val loss 1.866\n",
      "Ep 1 (Step 046850): Train loss 1.707, Val loss 1.861\n",
      "Ep 1 (Step 046855): Train loss 1.826, Val loss 1.866\n",
      "Ep 1 (Step 046860): Train loss 1.878, Val loss 1.870\n",
      "Ep 1 (Step 046865): Train loss 1.666, Val loss 1.875\n",
      "Ep 1 (Step 046870): Train loss 1.795, Val loss 1.878\n",
      "Ep 1 (Step 046875): Train loss 1.827, Val loss 1.867\n",
      "Ep 1 (Step 046880): Train loss 1.759, Val loss 1.864\n",
      "Ep 1 (Step 046885): Train loss 1.822, Val loss 1.858\n",
      "Ep 1 (Step 046890): Train loss 1.902, Val loss 1.858\n",
      "Ep 1 (Step 046895): Train loss 1.678, Val loss 1.851\n",
      "Ep 1 (Step 046900): Train loss 2.056, Val loss 1.846\n",
      "Ep 1 (Step 046905): Train loss 1.870, Val loss 1.854\n",
      "Ep 1 (Step 046910): Train loss 1.708, Val loss 1.861\n",
      "Ep 1 (Step 046915): Train loss 1.705, Val loss 1.864\n",
      "Ep 1 (Step 046920): Train loss 1.980, Val loss 1.869\n",
      "Ep 1 (Step 046925): Train loss 2.032, Val loss 1.870\n",
      "Ep 1 (Step 046930): Train loss 2.005, Val loss 1.872\n",
      "Ep 1 (Step 046935): Train loss 1.943, Val loss 1.856\n",
      "Ep 1 (Step 046940): Train loss 1.902, Val loss 1.851\n",
      "Ep 1 (Step 046945): Train loss 1.915, Val loss 1.849\n",
      "Ep 1 (Step 046950): Train loss 1.816, Val loss 1.850\n",
      "Ep 1 (Step 046955): Train loss 1.582, Val loss 1.858\n",
      "Ep 1 (Step 046960): Train loss 2.077, Val loss 1.854\n",
      "Ep 1 (Step 046965): Train loss 1.734, Val loss 1.850\n",
      "Ep 1 (Step 046970): Train loss 1.884, Val loss 1.853\n",
      "Ep 1 (Step 046975): Train loss 1.601, Val loss 1.858\n",
      "Ep 1 (Step 046980): Train loss 1.634, Val loss 1.867\n",
      "Ep 1 (Step 046985): Train loss 1.722, Val loss 1.858\n",
      "Ep 1 (Step 046990): Train loss 1.668, Val loss 1.855\n",
      "Ep 1 (Step 046995): Train loss 2.078, Val loss 1.854\n",
      "Ep 1 (Step 047000): Train loss 2.060, Val loss 1.869\n",
      "Ep 1 (Step 047005): Train loss 2.138, Val loss 1.868\n",
      "Ep 1 (Step 047010): Train loss 1.784, Val loss 1.863\n",
      "Ep 1 (Step 047015): Train loss 1.904, Val loss 1.865\n",
      "Ep 1 (Step 047020): Train loss 1.953, Val loss 1.864\n",
      "Ep 1 (Step 047025): Train loss 1.601, Val loss 1.867\n",
      "Ep 1 (Step 047030): Train loss 1.938, Val loss 1.864\n",
      "Ep 1 (Step 047035): Train loss 1.920, Val loss 1.875\n",
      "Ep 1 (Step 047040): Train loss 2.077, Val loss 1.875\n",
      "Ep 1 (Step 047045): Train loss 2.077, Val loss 1.861\n",
      "Ep 1 (Step 047050): Train loss 1.912, Val loss 1.855\n",
      "Ep 1 (Step 047055): Train loss 1.862, Val loss 1.843\n",
      "Ep 1 (Step 047060): Train loss 1.797, Val loss 1.836\n",
      "Ep 1 (Step 047065): Train loss 1.768, Val loss 1.844\n",
      "Ep 1 (Step 047070): Train loss 1.820, Val loss 1.852\n",
      "Ep 1 (Step 047075): Train loss 1.981, Val loss 1.848\n",
      "Ep 1 (Step 047080): Train loss 1.953, Val loss 1.850\n",
      "Ep 1 (Step 047085): Train loss 1.761, Val loss 1.851\n",
      "Ep 1 (Step 047090): Train loss 2.013, Val loss 1.853\n",
      "Ep 1 (Step 047095): Train loss 1.680, Val loss 1.853\n",
      "Ep 1 (Step 047100): Train loss 1.908, Val loss 1.860\n",
      "Ep 1 (Step 047105): Train loss 2.132, Val loss 1.862\n",
      "Ep 1 (Step 047110): Train loss 1.855, Val loss 1.860\n",
      "Ep 1 (Step 047115): Train loss 1.934, Val loss 1.853\n",
      "Ep 1 (Step 047120): Train loss 1.943, Val loss 1.853\n",
      "Ep 1 (Step 047125): Train loss 2.019, Val loss 1.859\n",
      "Ep 1 (Step 047130): Train loss 1.849, Val loss 1.865\n",
      "Ep 1 (Step 047135): Train loss 1.738, Val loss 1.865\n",
      "Ep 1 (Step 047140): Train loss 1.786, Val loss 1.863\n",
      "Ep 1 (Step 047145): Train loss 1.652, Val loss 1.866\n",
      "Ep 1 (Step 047150): Train loss 1.928, Val loss 1.870\n",
      "Ep 1 (Step 047155): Train loss 1.823, Val loss 1.866\n",
      "Ep 1 (Step 047160): Train loss 2.035, Val loss 1.857\n",
      "Ep 1 (Step 047165): Train loss 2.086, Val loss 1.857\n",
      "Ep 1 (Step 047170): Train loss 1.539, Val loss 1.860\n",
      "Ep 1 (Step 047175): Train loss 1.771, Val loss 1.867\n",
      "Ep 1 (Step 047180): Train loss 1.830, Val loss 1.880\n",
      "Ep 1 (Step 047185): Train loss 1.794, Val loss 1.885\n",
      "Ep 1 (Step 047190): Train loss 2.085, Val loss 1.896\n",
      "Ep 1 (Step 047195): Train loss 1.894, Val loss 1.886\n",
      "Ep 1 (Step 047200): Train loss 1.956, Val loss 1.879\n",
      "Ep 1 (Step 047205): Train loss 1.682, Val loss 1.870\n",
      "Ep 1 (Step 047210): Train loss 1.762, Val loss 1.869\n",
      "Ep 1 (Step 047215): Train loss 1.971, Val loss 1.872\n",
      "Ep 1 (Step 047220): Train loss 2.055, Val loss 1.875\n",
      "Ep 1 (Step 047225): Train loss 1.827, Val loss 1.863\n",
      "Ep 1 (Step 047230): Train loss 2.255, Val loss 1.859\n",
      "Ep 1 (Step 047235): Train loss 1.854, Val loss 1.860\n",
      "Ep 1 (Step 047240): Train loss 2.190, Val loss 1.862\n",
      "Ep 1 (Step 047245): Train loss 1.970, Val loss 1.870\n",
      "Ep 1 (Step 047250): Train loss 1.788, Val loss 1.875\n",
      "Ep 1 (Step 047255): Train loss 1.931, Val loss 1.878\n",
      "Ep 1 (Step 047260): Train loss 1.712, Val loss 1.882\n",
      "Ep 1 (Step 047265): Train loss 1.808, Val loss 1.885\n",
      "Ep 1 (Step 047270): Train loss 2.272, Val loss 1.885\n",
      "Ep 1 (Step 047275): Train loss 1.807, Val loss 1.884\n",
      "Ep 1 (Step 047280): Train loss 1.859, Val loss 1.874\n",
      "Ep 1 (Step 047285): Train loss 1.836, Val loss 1.862\n",
      "Ep 1 (Step 047290): Train loss 1.724, Val loss 1.858\n",
      "Ep 1 (Step 047295): Train loss 1.747, Val loss 1.854\n",
      "Ep 1 (Step 047300): Train loss 1.887, Val loss 1.850\n",
      "Ep 1 (Step 047305): Train loss 1.700, Val loss 1.854\n",
      "Ep 1 (Step 047310): Train loss 1.880, Val loss 1.865\n",
      "Ep 1 (Step 047315): Train loss 1.802, Val loss 1.860\n",
      "Ep 1 (Step 047320): Train loss 1.861, Val loss 1.852\n",
      "Ep 1 (Step 047325): Train loss 1.645, Val loss 1.854\n",
      "Ep 1 (Step 047330): Train loss 1.877, Val loss 1.858\n",
      "Ep 1 (Step 047335): Train loss 2.164, Val loss 1.860\n",
      "Ep 1 (Step 047340): Train loss 1.742, Val loss 1.849\n",
      "Ep 1 (Step 047345): Train loss 1.973, Val loss 1.847\n",
      "Ep 1 (Step 047350): Train loss 1.764, Val loss 1.849\n",
      "Ep 1 (Step 047355): Train loss 2.036, Val loss 1.855\n",
      "Ep 1 (Step 047360): Train loss 1.570, Val loss 1.859\n",
      "Ep 1 (Step 047365): Train loss 1.661, Val loss 1.862\n",
      "Ep 1 (Step 047370): Train loss 1.975, Val loss 1.863\n",
      "Ep 1 (Step 047375): Train loss 1.723, Val loss 1.858\n",
      "Ep 1 (Step 047380): Train loss 2.034, Val loss 1.846\n",
      "Ep 1 (Step 047385): Train loss 1.844, Val loss 1.854\n",
      "Ep 1 (Step 047390): Train loss 1.775, Val loss 1.854\n",
      "Ep 1 (Step 047395): Train loss 2.061, Val loss 1.852\n",
      "Ep 1 (Step 047400): Train loss 1.698, Val loss 1.857\n",
      "Ep 1 (Step 047405): Train loss 1.729, Val loss 1.871\n",
      "Ep 1 (Step 047410): Train loss 1.761, Val loss 1.871\n",
      "Ep 1 (Step 047415): Train loss 1.814, Val loss 1.872\n",
      "Ep 1 (Step 047420): Train loss 1.885, Val loss 1.872\n",
      "Ep 1 (Step 047425): Train loss 1.729, Val loss 1.874\n",
      "Ep 1 (Step 047430): Train loss 1.860, Val loss 1.873\n",
      "Ep 1 (Step 047435): Train loss 1.710, Val loss 1.871\n",
      "Ep 1 (Step 047440): Train loss 1.897, Val loss 1.879\n",
      "Ep 1 (Step 047445): Train loss 1.969, Val loss 1.886\n",
      "Ep 1 (Step 047450): Train loss 2.071, Val loss 1.885\n",
      "Ep 1 (Step 047455): Train loss 1.838, Val loss 1.876\n",
      "Ep 1 (Step 047460): Train loss 1.781, Val loss 1.869\n",
      "Ep 1 (Step 047465): Train loss 2.016, Val loss 1.863\n",
      "Ep 1 (Step 047470): Train loss 2.049, Val loss 1.870\n",
      "Ep 1 (Step 047475): Train loss 1.993, Val loss 1.867\n",
      "Ep 1 (Step 047480): Train loss 1.626, Val loss 1.867\n",
      "Ep 1 (Step 047485): Train loss 1.835, Val loss 1.868\n",
      "Ep 1 (Step 047490): Train loss 2.279, Val loss 1.860\n",
      "Ep 1 (Step 047495): Train loss 2.089, Val loss 1.853\n",
      "Ep 1 (Step 047500): Train loss 1.781, Val loss 1.858\n",
      "Ep 1 (Step 047505): Train loss 2.268, Val loss 1.861\n",
      "Ep 1 (Step 047510): Train loss 2.012, Val loss 1.857\n",
      "Ep 1 (Step 047515): Train loss 2.296, Val loss 1.853\n",
      "Ep 1 (Step 047520): Train loss 1.628, Val loss 1.853\n",
      "Ep 1 (Step 047525): Train loss 1.727, Val loss 1.860\n",
      "Ep 1 (Step 047530): Train loss 1.723, Val loss 1.854\n",
      "Ep 1 (Step 047535): Train loss 1.894, Val loss 1.846\n",
      "Ep 1 (Step 047540): Train loss 1.775, Val loss 1.843\n",
      "Ep 1 (Step 047545): Train loss 1.980, Val loss 1.846\n",
      "Ep 1 (Step 047550): Train loss 1.919, Val loss 1.849\n",
      "Ep 1 (Step 047555): Train loss 1.685, Val loss 1.851\n",
      "Ep 1 (Step 047560): Train loss 1.945, Val loss 1.858\n",
      "Ep 1 (Step 047565): Train loss 1.883, Val loss 1.850\n",
      "Ep 1 (Step 047570): Train loss 2.041, Val loss 1.846\n",
      "Ep 1 (Step 047575): Train loss 1.854, Val loss 1.847\n",
      "Ep 1 (Step 047580): Train loss 1.945, Val loss 1.852\n",
      "Ep 1 (Step 047585): Train loss 2.045, Val loss 1.855\n",
      "Ep 1 (Step 047590): Train loss 1.665, Val loss 1.855\n",
      "Ep 1 (Step 047595): Train loss 1.861, Val loss 1.859\n",
      "Ep 1 (Step 047600): Train loss 2.116, Val loss 1.855\n",
      "Ep 1 (Step 047605): Train loss 1.847, Val loss 1.852\n",
      "Ep 1 (Step 047610): Train loss 2.122, Val loss 1.851\n",
      "Ep 1 (Step 047615): Train loss 1.791, Val loss 1.860\n",
      "Ep 1 (Step 047620): Train loss 1.925, Val loss 1.867\n",
      "Ep 1 (Step 047625): Train loss 1.774, Val loss 1.855\n",
      "Ep 1 (Step 047630): Train loss 1.968, Val loss 1.854\n",
      "Ep 1 (Step 047635): Train loss 1.809, Val loss 1.854\n",
      "Ep 1 (Step 047640): Train loss 1.881, Val loss 1.847\n",
      "Ep 1 (Step 047645): Train loss 1.814, Val loss 1.835\n",
      "Ep 1 (Step 047650): Train loss 1.987, Val loss 1.831\n",
      "Ep 1 (Step 047655): Train loss 1.953, Val loss 1.839\n",
      "Ep 1 (Step 047660): Train loss 1.527, Val loss 1.843\n",
      "Ep 1 (Step 047665): Train loss 1.701, Val loss 1.848\n",
      "Ep 1 (Step 047670): Train loss 1.745, Val loss 1.853\n",
      "Ep 1 (Step 047675): Train loss 1.927, Val loss 1.852\n",
      "Ep 1 (Step 047680): Train loss 1.828, Val loss 1.861\n",
      "Ep 1 (Step 047685): Train loss 1.938, Val loss 1.860\n",
      "Ep 1 (Step 047690): Train loss 1.900, Val loss 1.861\n",
      "Ep 1 (Step 047695): Train loss 1.800, Val loss 1.863\n",
      "Ep 1 (Step 047700): Train loss 2.026, Val loss 1.864\n",
      "Ep 1 (Step 047705): Train loss 1.671, Val loss 1.859\n",
      "Ep 1 (Step 047710): Train loss 1.960, Val loss 1.855\n",
      "Ep 1 (Step 047715): Train loss 1.619, Val loss 1.864\n",
      "Ep 1 (Step 047720): Train loss 1.620, Val loss 1.871\n",
      "Ep 1 (Step 047725): Train loss 1.758, Val loss 1.872\n",
      "Ep 1 (Step 047730): Train loss 1.843, Val loss 1.872\n",
      "Ep 1 (Step 047735): Train loss 1.639, Val loss 1.872\n",
      "Ep 1 (Step 047740): Train loss 1.942, Val loss 1.879\n",
      "Ep 1 (Step 047745): Train loss 2.144, Val loss 1.881\n",
      "Ep 1 (Step 047750): Train loss 1.842, Val loss 1.885\n",
      "Ep 1 (Step 047755): Train loss 2.105, Val loss 1.880\n",
      "Ep 1 (Step 047760): Train loss 1.762, Val loss 1.877\n",
      "Ep 1 (Step 047765): Train loss 1.724, Val loss 1.878\n",
      "Ep 1 (Step 047770): Train loss 1.734, Val loss 1.873\n",
      "Ep 1 (Step 047775): Train loss 1.700, Val loss 1.862\n",
      "Ep 1 (Step 047780): Train loss 1.956, Val loss 1.868\n",
      "Ep 1 (Step 047785): Train loss 1.898, Val loss 1.871\n",
      "Ep 1 (Step 047790): Train loss 1.934, Val loss 1.871\n",
      "Ep 1 (Step 047795): Train loss 1.776, Val loss 1.877\n",
      "Ep 1 (Step 047800): Train loss 1.936, Val loss 1.885\n",
      "Ep 1 (Step 047805): Train loss 1.953, Val loss 1.879\n",
      "Ep 1 (Step 047810): Train loss 1.706, Val loss 1.888\n",
      "Ep 1 (Step 047815): Train loss 1.896, Val loss 1.884\n",
      "Ep 1 (Step 047820): Train loss 1.879, Val loss 1.880\n",
      "Ep 1 (Step 047825): Train loss 1.868, Val loss 1.873\n",
      "Ep 1 (Step 047830): Train loss 1.729, Val loss 1.870\n",
      "Ep 1 (Step 047835): Train loss 1.961, Val loss 1.875\n",
      "Ep 1 (Step 047840): Train loss 1.744, Val loss 1.884\n",
      "Ep 1 (Step 047845): Train loss 1.745, Val loss 1.878\n",
      "Ep 1 (Step 047850): Train loss 1.935, Val loss 1.877\n",
      "Ep 1 (Step 047855): Train loss 1.898, Val loss 1.877\n",
      "Ep 1 (Step 047860): Train loss 1.837, Val loss 1.867\n",
      "Ep 1 (Step 047865): Train loss 1.675, Val loss 1.854\n",
      "Ep 1 (Step 047870): Train loss 1.961, Val loss 1.857\n",
      "Ep 1 (Step 047875): Train loss 1.884, Val loss 1.860\n",
      "Ep 1 (Step 047880): Train loss 1.720, Val loss 1.860\n",
      "Ep 1 (Step 047885): Train loss 1.914, Val loss 1.869\n",
      "Ep 1 (Step 047890): Train loss 1.958, Val loss 1.859\n",
      "Ep 1 (Step 047895): Train loss 1.658, Val loss 1.860\n",
      "Ep 1 (Step 047900): Train loss 1.679, Val loss 1.862\n",
      "Ep 1 (Step 047905): Train loss 1.911, Val loss 1.873\n",
      "Ep 1 (Step 047910): Train loss 1.832, Val loss 1.871\n",
      "Ep 1 (Step 047915): Train loss 1.923, Val loss 1.863\n",
      "Ep 1 (Step 047920): Train loss 1.623, Val loss 1.862\n",
      "Ep 1 (Step 047925): Train loss 1.826, Val loss 1.868\n",
      "Ep 1 (Step 047930): Train loss 2.187, Val loss 1.866\n",
      "Ep 1 (Step 047935): Train loss 1.712, Val loss 1.864\n",
      "Ep 1 (Step 047940): Train loss 2.140, Val loss 1.861\n",
      "Ep 1 (Step 047945): Train loss 1.707, Val loss 1.867\n",
      "Ep 1 (Step 047950): Train loss 2.068, Val loss 1.876\n",
      "Ep 1 (Step 047955): Train loss 1.738, Val loss 1.877\n",
      "Ep 1 (Step 047960): Train loss 1.935, Val loss 1.874\n",
      "Ep 1 (Step 047965): Train loss 1.787, Val loss 1.866\n",
      "Ep 1 (Step 047970): Train loss 1.967, Val loss 1.863\n",
      "Ep 1 (Step 047975): Train loss 1.648, Val loss 1.865\n",
      "Ep 1 (Step 047980): Train loss 1.938, Val loss 1.872\n",
      "Ep 1 (Step 047985): Train loss 1.721, Val loss 1.870\n",
      "Ep 1 (Step 047990): Train loss 1.946, Val loss 1.862\n",
      "Ep 1 (Step 047995): Train loss 1.637, Val loss 1.861\n",
      "Ep 1 (Step 048000): Train loss 2.011, Val loss 1.861\n",
      "Ep 1 (Step 048005): Train loss 1.848, Val loss 1.864\n",
      "Ep 1 (Step 048010): Train loss 1.765, Val loss 1.875\n",
      "Ep 1 (Step 048015): Train loss 2.155, Val loss 1.873\n",
      "Ep 1 (Step 048020): Train loss 2.049, Val loss 1.864\n",
      "Ep 1 (Step 048025): Train loss 1.883, Val loss 1.875\n",
      "Ep 1 (Step 048030): Train loss 1.866, Val loss 1.876\n",
      "Ep 1 (Step 048035): Train loss 2.048, Val loss 1.867\n",
      "Ep 1 (Step 048040): Train loss 1.701, Val loss 1.854\n",
      "Ep 1 (Step 048045): Train loss 1.977, Val loss 1.854\n",
      "Ep 1 (Step 048050): Train loss 1.629, Val loss 1.860\n",
      "Ep 1 (Step 048055): Train loss 1.782, Val loss 1.853\n",
      "Ep 1 (Step 048060): Train loss 2.002, Val loss 1.839\n",
      "Ep 1 (Step 048065): Train loss 1.704, Val loss 1.840\n",
      "Ep 1 (Step 048070): Train loss 1.824, Val loss 1.852\n",
      "Ep 1 (Step 048075): Train loss 1.906, Val loss 1.858\n",
      "Ep 1 (Step 048080): Train loss 1.702, Val loss 1.855\n",
      "Ep 1 (Step 048085): Train loss 1.906, Val loss 1.851\n",
      "Ep 1 (Step 048090): Train loss 2.094, Val loss 1.855\n",
      "Ep 1 (Step 048095): Train loss 2.083, Val loss 1.852\n",
      "Ep 1 (Step 048100): Train loss 1.923, Val loss 1.844\n",
      "Ep 1 (Step 048105): Train loss 1.784, Val loss 1.844\n",
      "Ep 1 (Step 048110): Train loss 2.093, Val loss 1.847\n",
      "Ep 1 (Step 048115): Train loss 2.121, Val loss 1.844\n",
      "Ep 1 (Step 048120): Train loss 1.815, Val loss 1.838\n",
      "Ep 1 (Step 048125): Train loss 1.896, Val loss 1.838\n",
      "Ep 1 (Step 048130): Train loss 1.956, Val loss 1.852\n",
      "Ep 1 (Step 048135): Train loss 1.994, Val loss 1.862\n",
      "Ep 1 (Step 048140): Train loss 1.826, Val loss 1.849\n",
      "Ep 1 (Step 048145): Train loss 1.920, Val loss 1.837\n",
      "Ep 1 (Step 048150): Train loss 1.729, Val loss 1.830\n",
      "Ep 1 (Step 048155): Train loss 2.011, Val loss 1.834\n",
      "Ep 1 (Step 048160): Train loss 2.040, Val loss 1.828\n",
      "Ep 1 (Step 048165): Train loss 1.896, Val loss 1.822\n",
      "Ep 1 (Step 048170): Train loss 2.058, Val loss 1.824\n",
      "Ep 1 (Step 048175): Train loss 1.887, Val loss 1.828\n",
      "Ep 1 (Step 048180): Train loss 1.759, Val loss 1.833\n",
      "Ep 1 (Step 048185): Train loss 1.837, Val loss 1.830\n",
      "Ep 1 (Step 048190): Train loss 1.936, Val loss 1.827\n",
      "Ep 1 (Step 048195): Train loss 1.708, Val loss 1.837\n",
      "Ep 1 (Step 048200): Train loss 1.786, Val loss 1.851\n",
      "Ep 1 (Step 048205): Train loss 1.659, Val loss 1.853\n",
      "Ep 1 (Step 048210): Train loss 1.722, Val loss 1.853\n",
      "Ep 1 (Step 048215): Train loss 1.891, Val loss 1.850\n",
      "Ep 1 (Step 048220): Train loss 1.881, Val loss 1.849\n",
      "Ep 1 (Step 048225): Train loss 2.106, Val loss 1.839\n",
      "Ep 1 (Step 048230): Train loss 1.759, Val loss 1.839\n",
      "Ep 1 (Step 048235): Train loss 1.787, Val loss 1.846\n",
      "Ep 1 (Step 048240): Train loss 1.720, Val loss 1.849\n",
      "Ep 1 (Step 048245): Train loss 1.657, Val loss 1.842\n",
      "Ep 1 (Step 048250): Train loss 1.984, Val loss 1.841\n",
      "Ep 1 (Step 048255): Train loss 1.893, Val loss 1.845\n",
      "Ep 1 (Step 048260): Train loss 1.758, Val loss 1.839\n",
      "Ep 1 (Step 048265): Train loss 1.781, Val loss 1.827\n",
      "Ep 1 (Step 048270): Train loss 2.176, Val loss 1.826\n",
      "Ep 1 (Step 048275): Train loss 2.433, Val loss 1.824\n",
      "Ep 1 (Step 048280): Train loss 1.876, Val loss 1.823\n",
      "Ep 1 (Step 048285): Train loss 1.754, Val loss 1.834\n",
      "Ep 1 (Step 048290): Train loss 1.910, Val loss 1.851\n",
      "Ep 1 (Step 048295): Train loss 1.731, Val loss 1.859\n",
      "Ep 1 (Step 048300): Train loss 1.937, Val loss 1.862\n",
      "Ep 1 (Step 048305): Train loss 1.710, Val loss 1.857\n",
      "Ep 1 (Step 048310): Train loss 1.900, Val loss 1.860\n",
      "Ep 1 (Step 048315): Train loss 1.739, Val loss 1.857\n",
      "Ep 1 (Step 048320): Train loss 1.900, Val loss 1.849\n",
      "Ep 1 (Step 048325): Train loss 2.031, Val loss 1.846\n",
      "Ep 1 (Step 048330): Train loss 1.824, Val loss 1.851\n",
      "Ep 1 (Step 048335): Train loss 1.969, Val loss 1.848\n",
      "Ep 1 (Step 048340): Train loss 1.882, Val loss 1.851\n",
      "Ep 1 (Step 048345): Train loss 1.774, Val loss 1.858\n",
      "Ep 1 (Step 048350): Train loss 2.041, Val loss 1.860\n",
      "Ep 1 (Step 048355): Train loss 2.212, Val loss 1.850\n",
      "Ep 1 (Step 048360): Train loss 1.846, Val loss 1.854\n",
      "Ep 1 (Step 048365): Train loss 1.642, Val loss 1.857\n",
      "Ep 1 (Step 048370): Train loss 1.943, Val loss 1.849\n",
      "Ep 1 (Step 048375): Train loss 2.118, Val loss 1.845\n",
      "Ep 1 (Step 048380): Train loss 2.253, Val loss 1.845\n",
      "Ep 1 (Step 048385): Train loss 1.812, Val loss 1.843\n",
      "Ep 1 (Step 048390): Train loss 1.843, Val loss 1.842\n",
      "Ep 1 (Step 048395): Train loss 1.840, Val loss 1.845\n",
      "Ep 1 (Step 048400): Train loss 2.007, Val loss 1.843\n",
      "Ep 1 (Step 048405): Train loss 2.010, Val loss 1.846\n",
      "Ep 1 (Step 048410): Train loss 1.764, Val loss 1.843\n",
      "Ep 1 (Step 048415): Train loss 1.733, Val loss 1.841\n",
      "Ep 1 (Step 048420): Train loss 1.712, Val loss 1.841\n",
      "Ep 1 (Step 048425): Train loss 1.783, Val loss 1.848\n",
      "Ep 1 (Step 048430): Train loss 1.762, Val loss 1.852\n",
      "Ep 1 (Step 048435): Train loss 1.816, Val loss 1.854\n",
      "Ep 1 (Step 048440): Train loss 1.905, Val loss 1.859\n",
      "Ep 1 (Step 048445): Train loss 1.807, Val loss 1.860\n",
      "Ep 1 (Step 048450): Train loss 1.991, Val loss 1.863\n",
      "Ep 1 (Step 048455): Train loss 1.863, Val loss 1.890\n",
      "Ep 1 (Step 048460): Train loss 2.016, Val loss 1.888\n",
      "Ep 1 (Step 048465): Train loss 1.762, Val loss 1.880\n",
      "Ep 1 (Step 048470): Train loss 1.737, Val loss 1.875\n",
      "Ep 1 (Step 048475): Train loss 1.734, Val loss 1.870\n",
      "Ep 1 (Step 048480): Train loss 1.934, Val loss 1.869\n",
      "Ep 1 (Step 048485): Train loss 1.999, Val loss 1.863\n",
      "Ep 1 (Step 048490): Train loss 1.750, Val loss 1.859\n",
      "Ep 1 (Step 048495): Train loss 1.770, Val loss 1.854\n",
      "Ep 1 (Step 048500): Train loss 1.693, Val loss 1.845\n",
      "Ep 1 (Step 048505): Train loss 1.691, Val loss 1.848\n",
      "Ep 1 (Step 048510): Train loss 2.079, Val loss 1.856\n",
      "Ep 1 (Step 048515): Train loss 1.894, Val loss 1.863\n",
      "Ep 1 (Step 048520): Train loss 1.982, Val loss 1.863\n",
      "Ep 1 (Step 048525): Train loss 1.809, Val loss 1.852\n",
      "Ep 1 (Step 048530): Train loss 1.796, Val loss 1.844\n",
      "Ep 1 (Step 048535): Train loss 1.795, Val loss 1.841\n",
      "Ep 1 (Step 048540): Train loss 1.672, Val loss 1.846\n",
      "Ep 1 (Step 048545): Train loss 1.879, Val loss 1.853\n",
      "Ep 1 (Step 048550): Train loss 1.740, Val loss 1.862\n",
      "Ep 1 (Step 048555): Train loss 1.946, Val loss 1.849\n",
      "Ep 1 (Step 048560): Train loss 1.996, Val loss 1.847\n",
      "Ep 1 (Step 048565): Train loss 1.850, Val loss 1.847\n",
      "Ep 1 (Step 048570): Train loss 1.772, Val loss 1.853\n",
      "Ep 1 (Step 048575): Train loss 1.864, Val loss 1.871\n",
      "Ep 1 (Step 048580): Train loss 1.850, Val loss 1.854\n",
      "Ep 1 (Step 048585): Train loss 1.791, Val loss 1.846\n",
      "Ep 1 (Step 048590): Train loss 1.965, Val loss 1.842\n",
      "Ep 1 (Step 048595): Train loss 1.791, Val loss 1.837\n",
      "Ep 1 (Step 048600): Train loss 1.732, Val loss 1.837\n",
      "Ep 1 (Step 048605): Train loss 1.895, Val loss 1.843\n",
      "Ep 1 (Step 048610): Train loss 1.707, Val loss 1.844\n",
      "Ep 1 (Step 048615): Train loss 1.798, Val loss 1.852\n",
      "Ep 1 (Step 048620): Train loss 1.685, Val loss 1.863\n",
      "Ep 1 (Step 048625): Train loss 1.991, Val loss 1.861\n",
      "Ep 1 (Step 048630): Train loss 2.034, Val loss 1.864\n",
      "Ep 1 (Step 048635): Train loss 1.928, Val loss 1.868\n",
      "Ep 1 (Step 048640): Train loss 2.015, Val loss 1.871\n",
      "Ep 1 (Step 048645): Train loss 2.200, Val loss 1.875\n",
      "Ep 1 (Step 048650): Train loss 1.643, Val loss 1.880\n",
      "Ep 1 (Step 048655): Train loss 2.272, Val loss 1.871\n",
      "Ep 1 (Step 048660): Train loss 1.698, Val loss 1.864\n",
      "Ep 1 (Step 048665): Train loss 1.682, Val loss 1.868\n",
      "Ep 1 (Step 048670): Train loss 1.963, Val loss 1.858\n",
      "Ep 1 (Step 048675): Train loss 1.666, Val loss 1.864\n",
      "Ep 1 (Step 048680): Train loss 1.810, Val loss 1.861\n",
      "Ep 1 (Step 048685): Train loss 1.778, Val loss 1.860\n",
      "Ep 1 (Step 048690): Train loss 1.935, Val loss 1.856\n",
      "Ep 1 (Step 048695): Train loss 2.385, Val loss 1.861\n",
      "Ep 1 (Step 048700): Train loss 1.798, Val loss 1.864\n",
      "Ep 1 (Step 048705): Train loss 1.720, Val loss 1.859\n",
      "Ep 1 (Step 048710): Train loss 1.738, Val loss 1.864\n",
      "Ep 1 (Step 048715): Train loss 2.113, Val loss 1.869\n",
      "Ep 1 (Step 048720): Train loss 1.858, Val loss 1.873\n",
      "Ep 1 (Step 048725): Train loss 2.040, Val loss 1.870\n",
      "Ep 1 (Step 048730): Train loss 1.820, Val loss 1.865\n",
      "Ep 1 (Step 048735): Train loss 1.655, Val loss 1.861\n",
      "Ep 1 (Step 048740): Train loss 1.930, Val loss 1.857\n",
      "Ep 1 (Step 048745): Train loss 1.831, Val loss 1.856\n",
      "Ep 1 (Step 048750): Train loss 1.665, Val loss 1.872\n",
      "Ep 1 (Step 048755): Train loss 1.974, Val loss 1.875\n",
      "Ep 1 (Step 048760): Train loss 1.772, Val loss 1.863\n",
      "Ep 1 (Step 048765): Train loss 1.967, Val loss 1.852\n",
      "Ep 1 (Step 048770): Train loss 1.774, Val loss 1.850\n",
      "Ep 1 (Step 048775): Train loss 1.945, Val loss 1.853\n",
      "Ep 1 (Step 048780): Train loss 1.702, Val loss 1.849\n",
      "Ep 1 (Step 048785): Train loss 1.789, Val loss 1.852\n",
      "Ep 1 (Step 048790): Train loss 1.990, Val loss 1.849\n",
      "Ep 1 (Step 048795): Train loss 1.823, Val loss 1.855\n",
      "Ep 1 (Step 048800): Train loss 1.755, Val loss 1.858\n",
      "Ep 1 (Step 048805): Train loss 1.897, Val loss 1.862\n",
      "Ep 1 (Step 048810): Train loss 1.880, Val loss 1.865\n",
      "Ep 1 (Step 048815): Train loss 1.813, Val loss 1.863\n",
      "Ep 1 (Step 048820): Train loss 1.586, Val loss 1.861\n",
      "Ep 1 (Step 048825): Train loss 1.941, Val loss 1.857\n",
      "Ep 1 (Step 048830): Train loss 1.836, Val loss 1.854\n",
      "Ep 1 (Step 048835): Train loss 2.085, Val loss 1.848\n",
      "Ep 1 (Step 048840): Train loss 1.814, Val loss 1.838\n",
      "Ep 1 (Step 048845): Train loss 1.701, Val loss 1.832\n",
      "Ep 1 (Step 048850): Train loss 1.899, Val loss 1.836\n",
      "Ep 1 (Step 048855): Train loss 1.820, Val loss 1.835\n",
      "Ep 1 (Step 048860): Train loss 2.068, Val loss 1.848\n",
      "Ep 1 (Step 048865): Train loss 1.834, Val loss 1.857\n",
      "Ep 1 (Step 048870): Train loss 1.707, Val loss 1.847\n",
      "Ep 1 (Step 048875): Train loss 2.028, Val loss 1.853\n",
      "Ep 1 (Step 048880): Train loss 1.962, Val loss 1.855\n",
      "Ep 1 (Step 048885): Train loss 1.944, Val loss 1.846\n",
      "Ep 1 (Step 048890): Train loss 2.184, Val loss 1.835\n",
      "Ep 1 (Step 048895): Train loss 1.876, Val loss 1.829\n",
      "Ep 1 (Step 048900): Train loss 1.850, Val loss 1.828\n",
      "Ep 1 (Step 048905): Train loss 1.933, Val loss 1.839\n",
      "Ep 1 (Step 048910): Train loss 1.796, Val loss 1.850\n",
      "Ep 1 (Step 048915): Train loss 1.690, Val loss 1.855\n",
      "Ep 1 (Step 048920): Train loss 1.638, Val loss 1.853\n",
      "Ep 1 (Step 048925): Train loss 1.933, Val loss 1.853\n",
      "Ep 1 (Step 048930): Train loss 1.804, Val loss 1.845\n",
      "Ep 1 (Step 048935): Train loss 1.721, Val loss 1.845\n",
      "Ep 1 (Step 048940): Train loss 1.857, Val loss 1.839\n",
      "Ep 1 (Step 048945): Train loss 1.873, Val loss 1.846\n",
      "Ep 1 (Step 048950): Train loss 1.901, Val loss 1.861\n",
      "Ep 1 (Step 048955): Train loss 1.629, Val loss 1.872\n",
      "Ep 1 (Step 048960): Train loss 1.763, Val loss 1.876\n",
      "Ep 1 (Step 048965): Train loss 2.157, Val loss 1.868\n",
      "Ep 1 (Step 048970): Train loss 1.975, Val loss 1.857\n",
      "Ep 1 (Step 048975): Train loss 1.948, Val loss 1.847\n",
      "Ep 1 (Step 048980): Train loss 1.745, Val loss 1.839\n",
      "Ep 1 (Step 048985): Train loss 2.044, Val loss 1.833\n",
      "Ep 1 (Step 048990): Train loss 1.868, Val loss 1.831\n",
      "Ep 1 (Step 048995): Train loss 1.732, Val loss 1.837\n",
      "Ep 1 (Step 049000): Train loss 1.869, Val loss 1.831\n",
      "Ep 1 (Step 049005): Train loss 2.027, Val loss 1.828\n",
      "Ep 1 (Step 049010): Train loss 2.127, Val loss 1.830\n",
      "Ep 1 (Step 049015): Train loss 1.822, Val loss 1.840\n",
      "Ep 1 (Step 049020): Train loss 1.942, Val loss 1.840\n",
      "Ep 1 (Step 049025): Train loss 1.728, Val loss 1.835\n",
      "Ep 1 (Step 049030): Train loss 1.584, Val loss 1.836\n",
      "Ep 1 (Step 049035): Train loss 1.871, Val loss 1.842\n",
      "Ep 1 (Step 049040): Train loss 1.943, Val loss 1.854\n",
      "Ep 1 (Step 049045): Train loss 1.749, Val loss 1.863\n",
      "Ep 1 (Step 049050): Train loss 2.066, Val loss 1.867\n",
      "Ep 1 (Step 049055): Train loss 1.829, Val loss 1.862\n",
      "Ep 1 (Step 049060): Train loss 1.612, Val loss 1.862\n",
      "Ep 1 (Step 049065): Train loss 1.807, Val loss 1.858\n",
      "Ep 1 (Step 049070): Train loss 1.787, Val loss 1.843\n",
      "Ep 1 (Step 049075): Train loss 1.885, Val loss 1.836\n",
      "Ep 1 (Step 049080): Train loss 1.777, Val loss 1.837\n",
      "Ep 1 (Step 049085): Train loss 2.056, Val loss 1.836\n",
      "Ep 1 (Step 049090): Train loss 2.322, Val loss 1.838\n",
      "Ep 1 (Step 049095): Train loss 1.989, Val loss 1.835\n",
      "Ep 1 (Step 049100): Train loss 2.168, Val loss 1.840\n",
      "Ep 1 (Step 049105): Train loss 2.015, Val loss 1.844\n",
      "Ep 1 (Step 049110): Train loss 1.855, Val loss 1.846\n",
      "Ep 1 (Step 049115): Train loss 2.000, Val loss 1.852\n",
      "Ep 1 (Step 049120): Train loss 1.761, Val loss 1.847\n",
      "Ep 1 (Step 049125): Train loss 1.548, Val loss 1.858\n",
      "Ep 1 (Step 049130): Train loss 1.808, Val loss 1.854\n",
      "Ep 1 (Step 049135): Train loss 1.614, Val loss 1.849\n",
      "Ep 1 (Step 049140): Train loss 1.905, Val loss 1.844\n",
      "Ep 1 (Step 049145): Train loss 1.775, Val loss 1.837\n",
      "Ep 1 (Step 049150): Train loss 2.410, Val loss 1.827\n",
      "Ep 1 (Step 049155): Train loss 1.865, Val loss 1.831\n",
      "Ep 1 (Step 049160): Train loss 1.850, Val loss 1.839\n",
      "Ep 1 (Step 049165): Train loss 1.854, Val loss 1.837\n",
      "Ep 1 (Step 049170): Train loss 1.528, Val loss 1.841\n",
      "Ep 1 (Step 049175): Train loss 1.927, Val loss 1.843\n",
      "Ep 1 (Step 049180): Train loss 1.634, Val loss 1.842\n",
      "Ep 1 (Step 049185): Train loss 2.042, Val loss 1.842\n",
      "Ep 1 (Step 049190): Train loss 1.871, Val loss 1.843\n",
      "Ep 1 (Step 049195): Train loss 2.190, Val loss 1.846\n",
      "Ep 1 (Step 049200): Train loss 1.792, Val loss 1.852\n",
      "Ep 1 (Step 049205): Train loss 1.739, Val loss 1.856\n",
      "Ep 1 (Step 049210): Train loss 2.093, Val loss 1.849\n",
      "Ep 1 (Step 049215): Train loss 1.711, Val loss 1.854\n",
      "Ep 1 (Step 049220): Train loss 1.749, Val loss 1.858\n",
      "Ep 1 (Step 049225): Train loss 1.971, Val loss 1.853\n",
      "Ep 1 (Step 049230): Train loss 1.608, Val loss 1.852\n",
      "Ep 1 (Step 049235): Train loss 1.746, Val loss 1.856\n",
      "Ep 1 (Step 049240): Train loss 1.528, Val loss 1.848\n",
      "Ep 1 (Step 049245): Train loss 2.049, Val loss 1.859\n",
      "Ep 1 (Step 049250): Train loss 1.770, Val loss 1.855\n",
      "Ep 1 (Step 049255): Train loss 1.779, Val loss 1.852\n",
      "Ep 1 (Step 049260): Train loss 1.920, Val loss 1.856\n",
      "Ep 1 (Step 049265): Train loss 1.881, Val loss 1.855\n",
      "Ep 1 (Step 049270): Train loss 2.003, Val loss 1.853\n",
      "Ep 1 (Step 049275): Train loss 1.952, Val loss 1.849\n",
      "Ep 1 (Step 049280): Train loss 1.866, Val loss 1.850\n",
      "Ep 1 (Step 049285): Train loss 2.030, Val loss 1.851\n",
      "Ep 1 (Step 049290): Train loss 1.841, Val loss 1.857\n",
      "Ep 1 (Step 049295): Train loss 1.870, Val loss 1.860\n",
      "Ep 1 (Step 049300): Train loss 1.675, Val loss 1.862\n",
      "Ep 1 (Step 049305): Train loss 1.937, Val loss 1.855\n",
      "Ep 1 (Step 049310): Train loss 1.860, Val loss 1.845\n",
      "Ep 1 (Step 049315): Train loss 1.878, Val loss 1.843\n",
      "Ep 1 (Step 049320): Train loss 1.991, Val loss 1.847\n",
      "Ep 1 (Step 049325): Train loss 2.079, Val loss 1.858\n",
      "Ep 1 (Step 049330): Train loss 1.817, Val loss 1.860\n",
      "Ep 1 (Step 049335): Train loss 2.081, Val loss 1.863\n",
      "Ep 1 (Step 049340): Train loss 1.874, Val loss 1.855\n",
      "Ep 1 (Step 049345): Train loss 1.939, Val loss 1.868\n",
      "Ep 1 (Step 049350): Train loss 1.641, Val loss 1.866\n",
      "Ep 1 (Step 049355): Train loss 1.681, Val loss 1.862\n",
      "Ep 1 (Step 049360): Train loss 1.848, Val loss 1.861\n",
      "Ep 1 (Step 049365): Train loss 1.827, Val loss 1.858\n",
      "Ep 1 (Step 049370): Train loss 1.808, Val loss 1.845\n",
      "Ep 1 (Step 049375): Train loss 2.088, Val loss 1.838\n",
      "Ep 1 (Step 049380): Train loss 1.721, Val loss 1.842\n",
      "Ep 1 (Step 049385): Train loss 1.690, Val loss 1.848\n",
      "Ep 1 (Step 049390): Train loss 1.874, Val loss 1.844\n",
      "Ep 1 (Step 049395): Train loss 1.970, Val loss 1.842\n",
      "Ep 1 (Step 049400): Train loss 1.796, Val loss 1.852\n",
      "Ep 1 (Step 049405): Train loss 2.111, Val loss 1.857\n",
      "Ep 1 (Step 049410): Train loss 1.828, Val loss 1.854\n",
      "Ep 1 (Step 049415): Train loss 1.833, Val loss 1.860\n",
      "Ep 1 (Step 049420): Train loss 1.976, Val loss 1.856\n",
      "Ep 1 (Step 049425): Train loss 1.909, Val loss 1.851\n",
      "Ep 1 (Step 049430): Train loss 1.855, Val loss 1.849\n",
      "Ep 1 (Step 049435): Train loss 1.808, Val loss 1.854\n",
      "Ep 1 (Step 049440): Train loss 1.865, Val loss 1.855\n",
      "Ep 1 (Step 049445): Train loss 1.819, Val loss 1.866\n",
      "Ep 1 (Step 049450): Train loss 1.809, Val loss 1.869\n",
      "Ep 1 (Step 049455): Train loss 1.873, Val loss 1.861\n",
      "Ep 1 (Step 049460): Train loss 1.882, Val loss 1.856\n",
      "Ep 1 (Step 049465): Train loss 1.829, Val loss 1.857\n",
      "Ep 1 (Step 049470): Train loss 1.832, Val loss 1.853\n",
      "Ep 1 (Step 049475): Train loss 2.204, Val loss 1.860\n",
      "Ep 1 (Step 049480): Train loss 2.093, Val loss 1.865\n",
      "Ep 1 (Step 049485): Train loss 2.004, Val loss 1.880\n",
      "Ep 1 (Step 049490): Train loss 2.005, Val loss 1.884\n",
      "Ep 1 (Step 049495): Train loss 1.536, Val loss 1.889\n",
      "Ep 1 (Step 049500): Train loss 1.843, Val loss 1.897\n",
      "Ep 1 (Step 049505): Train loss 1.661, Val loss 1.890\n",
      "Ep 1 (Step 049510): Train loss 1.813, Val loss 1.888\n",
      "Ep 1 (Step 049515): Train loss 2.063, Val loss 1.886\n",
      "Ep 1 (Step 049520): Train loss 1.710, Val loss 1.876\n",
      "Ep 1 (Step 049525): Train loss 1.649, Val loss 1.879\n",
      "Ep 1 (Step 049530): Train loss 1.698, Val loss 1.880\n",
      "Ep 1 (Step 049535): Train loss 2.129, Val loss 1.883\n",
      "Ep 1 (Step 049540): Train loss 2.015, Val loss 1.893\n",
      "Ep 1 (Step 049545): Train loss 2.058, Val loss 1.881\n",
      "Ep 1 (Step 049550): Train loss 1.899, Val loss 1.878\n",
      "Ep 1 (Step 049555): Train loss 1.856, Val loss 1.872\n",
      "Ep 1 (Step 049560): Train loss 2.032, Val loss 1.866\n",
      "Ep 1 (Step 049565): Train loss 1.734, Val loss 1.861\n",
      "Ep 1 (Step 049570): Train loss 1.748, Val loss 1.858\n",
      "Ep 1 (Step 049575): Train loss 1.534, Val loss 1.852\n",
      "Ep 1 (Step 049580): Train loss 1.794, Val loss 1.857\n",
      "Ep 1 (Step 049585): Train loss 2.034, Val loss 1.862\n",
      "Ep 1 (Step 049590): Train loss 1.765, Val loss 1.864\n",
      "Ep 1 (Step 049595): Train loss 1.754, Val loss 1.859\n",
      "Ep 1 (Step 049600): Train loss 1.813, Val loss 1.856\n",
      "Ep 1 (Step 049605): Train loss 1.772, Val loss 1.848\n",
      "Ep 1 (Step 049610): Train loss 2.122, Val loss 1.854\n",
      "Ep 1 (Step 049615): Train loss 2.025, Val loss 1.854\n",
      "Ep 1 (Step 049620): Train loss 1.924, Val loss 1.854\n",
      "Ep 1 (Step 049625): Train loss 1.654, Val loss 1.867\n",
      "Ep 1 (Step 049630): Train loss 1.580, Val loss 1.859\n",
      "Ep 1 (Step 049635): Train loss 2.066, Val loss 1.851\n",
      "Ep 1 (Step 049640): Train loss 1.914, Val loss 1.846\n",
      "Ep 1 (Step 049645): Train loss 1.800, Val loss 1.831\n",
      "Ep 1 (Step 049650): Train loss 1.766, Val loss 1.833\n",
      "Ep 1 (Step 049655): Train loss 1.963, Val loss 1.838\n",
      "Ep 1 (Step 049660): Train loss 1.780, Val loss 1.841\n",
      "Ep 1 (Step 049665): Train loss 1.724, Val loss 1.818\n",
      "Ep 1 (Step 049670): Train loss 1.787, Val loss 1.824\n",
      "Ep 1 (Step 049675): Train loss 2.056, Val loss 1.833\n",
      "Ep 1 (Step 049680): Train loss 1.791, Val loss 1.836\n",
      "Ep 1 (Step 049685): Train loss 1.887, Val loss 1.835\n",
      "Ep 1 (Step 049690): Train loss 1.709, Val loss 1.833\n",
      "Ep 1 (Step 049695): Train loss 2.114, Val loss 1.839\n",
      "Ep 1 (Step 049700): Train loss 1.836, Val loss 1.840\n",
      "Ep 1 (Step 049705): Train loss 1.752, Val loss 1.837\n",
      "Ep 1 (Step 049710): Train loss 1.741, Val loss 1.841\n",
      "Ep 1 (Step 049715): Train loss 1.620, Val loss 1.843\n",
      "Ep 1 (Step 049720): Train loss 2.101, Val loss 1.846\n",
      "Ep 1 (Step 049725): Train loss 1.969, Val loss 1.849\n",
      "Ep 1 (Step 049730): Train loss 1.911, Val loss 1.850\n",
      "Ep 1 (Step 049735): Train loss 1.771, Val loss 1.847\n",
      "Ep 1 (Step 049740): Train loss 1.978, Val loss 1.855\n",
      "Ep 1 (Step 049745): Train loss 1.910, Val loss 1.860\n",
      "Ep 1 (Step 049750): Train loss 1.827, Val loss 1.861\n",
      "Ep 1 (Step 049755): Train loss 1.747, Val loss 1.864\n",
      "Ep 1 (Step 049760): Train loss 1.950, Val loss 1.867\n",
      "Ep 1 (Step 049765): Train loss 1.849, Val loss 1.876\n",
      "Ep 1 (Step 049770): Train loss 1.794, Val loss 1.880\n",
      "Ep 1 (Step 049775): Train loss 1.943, Val loss 1.884\n",
      "Ep 1 (Step 049780): Train loss 1.914, Val loss 1.868\n",
      "Ep 1 (Step 049785): Train loss 1.804, Val loss 1.858\n",
      "Ep 1 (Step 049790): Train loss 1.998, Val loss 1.845\n",
      "Ep 1 (Step 049795): Train loss 1.692, Val loss 1.843\n",
      "Ep 1 (Step 049800): Train loss 1.896, Val loss 1.849\n",
      "Ep 1 (Step 049805): Train loss 1.814, Val loss 1.856\n",
      "Ep 1 (Step 049810): Train loss 1.752, Val loss 1.850\n",
      "Ep 1 (Step 049815): Train loss 1.685, Val loss 1.841\n",
      "Ep 1 (Step 049820): Train loss 1.888, Val loss 1.840\n",
      "Ep 1 (Step 049825): Train loss 1.944, Val loss 1.855\n",
      "Ep 1 (Step 049830): Train loss 1.874, Val loss 1.864\n",
      "Ep 1 (Step 049835): Train loss 1.837, Val loss 1.865\n",
      "Ep 1 (Step 049840): Train loss 1.942, Val loss 1.866\n",
      "Ep 1 (Step 049845): Train loss 1.720, Val loss 1.852\n",
      "Ep 1 (Step 049850): Train loss 1.976, Val loss 1.839\n",
      "Ep 1 (Step 049855): Train loss 1.960, Val loss 1.843\n",
      "Ep 1 (Step 049860): Train loss 2.076, Val loss 1.837\n",
      "Ep 1 (Step 049865): Train loss 1.779, Val loss 1.836\n",
      "Ep 1 (Step 049870): Train loss 1.982, Val loss 1.830\n",
      "Ep 1 (Step 049875): Train loss 1.756, Val loss 1.827\n",
      "Ep 1 (Step 049880): Train loss 2.001, Val loss 1.826\n",
      "Ep 1 (Step 049885): Train loss 1.846, Val loss 1.823\n",
      "Ep 1 (Step 049890): Train loss 1.729, Val loss 1.820\n",
      "Ep 1 (Step 049895): Train loss 1.910, Val loss 1.819\n",
      "Ep 1 (Step 049900): Train loss 1.463, Val loss 1.828\n",
      "Ep 1 (Step 049905): Train loss 1.777, Val loss 1.835\n",
      "Ep 1 (Step 049910): Train loss 2.104, Val loss 1.826\n",
      "Ep 1 (Step 049915): Train loss 1.622, Val loss 1.820\n",
      "Ep 1 (Step 049920): Train loss 1.814, Val loss 1.816\n",
      "Ep 1 (Step 049925): Train loss 1.736, Val loss 1.806\n",
      "Ep 1 (Step 049930): Train loss 2.037, Val loss 1.801\n",
      "Ep 1 (Step 049935): Train loss 1.735, Val loss 1.812\n",
      "Ep 1 (Step 049940): Train loss 1.646, Val loss 1.821\n",
      "Ep 1 (Step 049945): Train loss 2.080, Val loss 1.824\n",
      "Ep 1 (Step 049950): Train loss 1.886, Val loss 1.824\n",
      "Ep 1 (Step 049955): Train loss 1.847, Val loss 1.823\n",
      "Ep 1 (Step 049960): Train loss 2.044, Val loss 1.828\n",
      "Ep 1 (Step 049965): Train loss 1.757, Val loss 1.829\n",
      "Ep 1 (Step 049970): Train loss 1.800, Val loss 1.831\n",
      "Ep 1 (Step 049975): Train loss 1.794, Val loss 1.836\n",
      "Ep 1 (Step 049980): Train loss 1.796, Val loss 1.851\n",
      "Ep 1 (Step 049985): Train loss 1.837, Val loss 1.854\n",
      "Ep 1 (Step 049990): Train loss 1.848, Val loss 1.846\n",
      "Ep 1 (Step 049995): Train loss 2.101, Val loss 1.859\n",
      "Ep 1 (Step 050000): Train loss 1.923, Val loss 1.867\n",
      "Ep 1 (Step 050005): Train loss 1.967, Val loss 1.860\n",
      "Ep 1 (Step 050010): Train loss 1.708, Val loss 1.848\n",
      "Ep 1 (Step 050015): Train loss 2.091, Val loss 1.844\n",
      "Ep 1 (Step 050020): Train loss 1.699, Val loss 1.845\n",
      "Ep 1 (Step 050025): Train loss 1.767, Val loss 1.844\n",
      "Ep 1 (Step 050030): Train loss 1.663, Val loss 1.842\n",
      "Ep 1 (Step 050035): Train loss 1.852, Val loss 1.833\n",
      "Ep 1 (Step 050040): Train loss 1.971, Val loss 1.823\n",
      "Ep 1 (Step 050045): Train loss 1.742, Val loss 1.824\n",
      "Ep 1 (Step 050050): Train loss 2.028, Val loss 1.828\n",
      "Ep 1 (Step 050055): Train loss 1.670, Val loss 1.826\n",
      "Ep 1 (Step 050060): Train loss 1.935, Val loss 1.826\n",
      "Ep 1 (Step 050065): Train loss 2.019, Val loss 1.820\n",
      "Ep 1 (Step 050070): Train loss 1.989, Val loss 1.823\n",
      "Ep 1 (Step 050075): Train loss 1.817, Val loss 1.836\n",
      "Ep 1 (Step 050080): Train loss 1.849, Val loss 1.835\n",
      "Ep 1 (Step 050085): Train loss 1.863, Val loss 1.836\n",
      "Ep 1 (Step 050090): Train loss 2.150, Val loss 1.840\n",
      "Ep 1 (Step 050095): Train loss 1.885, Val loss 1.836\n",
      "Ep 1 (Step 050100): Train loss 1.683, Val loss 1.831\n",
      "Ep 1 (Step 050105): Train loss 1.749, Val loss 1.836\n",
      "Ep 1 (Step 050110): Train loss 2.127, Val loss 1.845\n",
      "Ep 1 (Step 050115): Train loss 1.892, Val loss 1.838\n",
      "Ep 1 (Step 050120): Train loss 1.890, Val loss 1.836\n",
      "Ep 1 (Step 050125): Train loss 1.679, Val loss 1.816\n",
      "Ep 1 (Step 050130): Train loss 2.202, Val loss 1.820\n",
      "Ep 1 (Step 050135): Train loss 2.257, Val loss 1.833\n",
      "Ep 1 (Step 050140): Train loss 1.825, Val loss 1.838\n",
      "Ep 1 (Step 050145): Train loss 1.734, Val loss 1.837\n",
      "Ep 1 (Step 050150): Train loss 1.879, Val loss 1.832\n",
      "Ep 1 (Step 050155): Train loss 1.567, Val loss 1.830\n",
      "Ep 1 (Step 050160): Train loss 1.477, Val loss 1.840\n",
      "Ep 1 (Step 050165): Train loss 2.082, Val loss 1.842\n",
      "Ep 1 (Step 050170): Train loss 1.652, Val loss 1.833\n",
      "Ep 1 (Step 050175): Train loss 1.721, Val loss 1.832\n",
      "Ep 1 (Step 050180): Train loss 1.889, Val loss 1.837\n",
      "Ep 1 (Step 050185): Train loss 1.606, Val loss 1.854\n",
      "Ep 1 (Step 050190): Train loss 1.846, Val loss 1.853\n",
      "Ep 1 (Step 050195): Train loss 1.926, Val loss 1.845\n",
      "Ep 1 (Step 050200): Train loss 1.716, Val loss 1.839\n",
      "Ep 1 (Step 050205): Train loss 1.966, Val loss 1.836\n",
      "Ep 1 (Step 050210): Train loss 1.960, Val loss 1.832\n",
      "Ep 1 (Step 050215): Train loss 1.674, Val loss 1.831\n",
      "Ep 1 (Step 050220): Train loss 1.999, Val loss 1.836\n",
      "Ep 1 (Step 050225): Train loss 2.071, Val loss 1.840\n",
      "Ep 1 (Step 050230): Train loss 1.802, Val loss 1.842\n",
      "Ep 1 (Step 050235): Train loss 1.969, Val loss 1.844\n",
      "Ep 1 (Step 050240): Train loss 2.018, Val loss 1.839\n",
      "Ep 1 (Step 050245): Train loss 1.848, Val loss 1.838\n",
      "Ep 1 (Step 050250): Train loss 1.867, Val loss 1.834\n",
      "Ep 1 (Step 050255): Train loss 1.868, Val loss 1.849\n",
      "Ep 1 (Step 050260): Train loss 1.827, Val loss 1.854\n",
      "Ep 1 (Step 050265): Train loss 1.835, Val loss 1.848\n",
      "Ep 1 (Step 050270): Train loss 1.980, Val loss 1.847\n",
      "Ep 1 (Step 050275): Train loss 1.632, Val loss 1.847\n",
      "Ep 1 (Step 050280): Train loss 2.015, Val loss 1.841\n",
      "Ep 1 (Step 050285): Train loss 2.223, Val loss 1.841\n",
      "Ep 1 (Step 050290): Train loss 1.795, Val loss 1.846\n",
      "Ep 1 (Step 050295): Train loss 1.814, Val loss 1.843\n",
      "Ep 1 (Step 050300): Train loss 1.829, Val loss 1.843\n",
      "Ep 1 (Step 050305): Train loss 1.482, Val loss 1.851\n",
      "Ep 1 (Step 050310): Train loss 1.799, Val loss 1.842\n",
      "Ep 1 (Step 050315): Train loss 2.063, Val loss 1.846\n",
      "Ep 1 (Step 050320): Train loss 1.987, Val loss 1.843\n",
      "Ep 1 (Step 050325): Train loss 1.830, Val loss 1.839\n",
      "Ep 1 (Step 050330): Train loss 1.958, Val loss 1.837\n",
      "Ep 1 (Step 050335): Train loss 1.897, Val loss 1.836\n",
      "Ep 1 (Step 050340): Train loss 1.845, Val loss 1.830\n",
      "Ep 1 (Step 050345): Train loss 2.074, Val loss 1.833\n",
      "Ep 1 (Step 050350): Train loss 1.822, Val loss 1.837\n",
      "Ep 1 (Step 050355): Train loss 1.666, Val loss 1.840\n",
      "Ep 1 (Step 050360): Train loss 1.998, Val loss 1.832\n",
      "Ep 1 (Step 050365): Train loss 1.793, Val loss 1.818\n",
      "Ep 1 (Step 050370): Train loss 1.681, Val loss 1.824\n",
      "Ep 1 (Step 050375): Train loss 2.101, Val loss 1.837\n",
      "Ep 1 (Step 050380): Train loss 1.985, Val loss 1.843\n",
      "Ep 1 (Step 050385): Train loss 1.944, Val loss 1.840\n",
      "Ep 1 (Step 050390): Train loss 1.796, Val loss 1.832\n",
      "Ep 1 (Step 050395): Train loss 1.873, Val loss 1.825\n",
      "Ep 1 (Step 050400): Train loss 2.177, Val loss 1.835\n",
      "Ep 1 (Step 050405): Train loss 1.997, Val loss 1.839\n",
      "Ep 1 (Step 050410): Train loss 2.018, Val loss 1.854\n",
      "Ep 1 (Step 050415): Train loss 2.046, Val loss 1.862\n",
      "Ep 1 (Step 050420): Train loss 2.209, Val loss 1.852\n",
      "Ep 1 (Step 050425): Train loss 1.940, Val loss 1.846\n",
      "Ep 1 (Step 050430): Train loss 1.784, Val loss 1.844\n",
      "Ep 1 (Step 050435): Train loss 1.754, Val loss 1.834\n",
      "Ep 1 (Step 050440): Train loss 1.835, Val loss 1.830\n",
      "Ep 1 (Step 050445): Train loss 2.021, Val loss 1.836\n",
      "Ep 1 (Step 050450): Train loss 1.988, Val loss 1.837\n",
      "Ep 1 (Step 050455): Train loss 2.066, Val loss 1.845\n",
      "Ep 1 (Step 050460): Train loss 1.871, Val loss 1.840\n",
      "Ep 1 (Step 050465): Train loss 2.200, Val loss 1.829\n",
      "Ep 1 (Step 050470): Train loss 1.807, Val loss 1.830\n",
      "Ep 1 (Step 050475): Train loss 1.879, Val loss 1.835\n",
      "Ep 1 (Step 050480): Train loss 1.951, Val loss 1.845\n",
      "Ep 1 (Step 050485): Train loss 1.966, Val loss 1.839\n",
      "Ep 1 (Step 050490): Train loss 1.971, Val loss 1.828\n",
      "Ep 1 (Step 050495): Train loss 1.628, Val loss 1.827\n",
      "Ep 1 (Step 050500): Train loss 2.014, Val loss 1.836\n",
      "Ep 1 (Step 050505): Train loss 1.670, Val loss 1.830\n",
      "Ep 1 (Step 050510): Train loss 1.816, Val loss 1.818\n",
      "Ep 1 (Step 050515): Train loss 1.816, Val loss 1.815\n",
      "Ep 1 (Step 050520): Train loss 1.718, Val loss 1.812\n",
      "Ep 1 (Step 050525): Train loss 1.926, Val loss 1.805\n",
      "Ep 1 (Step 050530): Train loss 1.668, Val loss 1.808\n",
      "Ep 1 (Step 050535): Train loss 2.055, Val loss 1.806\n",
      "Ep 1 (Step 050540): Train loss 1.832, Val loss 1.810\n",
      "Ep 1 (Step 050545): Train loss 1.853, Val loss 1.820\n",
      "Ep 1 (Step 050550): Train loss 1.906, Val loss 1.817\n",
      "Ep 1 (Step 050555): Train loss 1.882, Val loss 1.821\n",
      "Ep 1 (Step 050560): Train loss 1.760, Val loss 1.815\n",
      "Ep 1 (Step 050565): Train loss 2.034, Val loss 1.811\n",
      "Ep 1 (Step 050570): Train loss 1.916, Val loss 1.813\n",
      "Ep 1 (Step 050575): Train loss 1.845, Val loss 1.832\n",
      "Ep 1 (Step 050580): Train loss 2.028, Val loss 1.817\n",
      "Ep 1 (Step 050585): Train loss 1.793, Val loss 1.814\n",
      "Ep 1 (Step 050590): Train loss 1.747, Val loss 1.817\n",
      "Ep 1 (Step 050595): Train loss 1.790, Val loss 1.827\n",
      "Ep 1 (Step 050600): Train loss 1.919, Val loss 1.823\n",
      "Ep 1 (Step 050605): Train loss 1.764, Val loss 1.810\n",
      "Ep 1 (Step 050610): Train loss 2.228, Val loss 1.810\n",
      "Ep 1 (Step 050615): Train loss 1.940, Val loss 1.816\n",
      "Ep 1 (Step 050620): Train loss 1.864, Val loss 1.828\n",
      "Ep 1 (Step 050625): Train loss 1.768, Val loss 1.842\n",
      "Ep 1 (Step 050630): Train loss 2.195, Val loss 1.824\n",
      "Ep 1 (Step 050635): Train loss 1.706, Val loss 1.819\n",
      "Ep 1 (Step 050640): Train loss 1.889, Val loss 1.821\n",
      "Ep 1 (Step 050645): Train loss 1.752, Val loss 1.823\n",
      "Ep 1 (Step 050650): Train loss 1.824, Val loss 1.827\n",
      "Ep 1 (Step 050655): Train loss 2.161, Val loss 1.828\n",
      "Ep 1 (Step 050660): Train loss 1.726, Val loss 1.828\n",
      "Ep 1 (Step 050665): Train loss 1.737, Val loss 1.829\n",
      "Ep 1 (Step 050670): Train loss 2.141, Val loss 1.835\n",
      "Ep 1 (Step 050675): Train loss 2.012, Val loss 1.832\n",
      "Ep 1 (Step 050680): Train loss 2.143, Val loss 1.833\n",
      "Ep 1 (Step 050685): Train loss 1.919, Val loss 1.833\n",
      "Ep 1 (Step 050690): Train loss 1.764, Val loss 1.841\n",
      "Ep 1 (Step 050695): Train loss 2.029, Val loss 1.836\n",
      "Ep 1 (Step 050700): Train loss 1.737, Val loss 1.829\n",
      "Ep 1 (Step 050705): Train loss 1.959, Val loss 1.830\n",
      "Ep 1 (Step 050710): Train loss 1.693, Val loss 1.830\n",
      "Ep 1 (Step 050715): Train loss 1.973, Val loss 1.832\n",
      "Ep 1 (Step 050720): Train loss 2.122, Val loss 1.833\n",
      "Ep 1 (Step 050725): Train loss 1.938, Val loss 1.828\n",
      "Ep 1 (Step 050730): Train loss 1.777, Val loss 1.827\n",
      "Ep 1 (Step 050735): Train loss 1.793, Val loss 1.821\n",
      "Ep 1 (Step 050740): Train loss 1.799, Val loss 1.810\n",
      "Ep 1 (Step 050745): Train loss 2.056, Val loss 1.810\n",
      "Ep 1 (Step 050750): Train loss 1.931, Val loss 1.815\n",
      "Ep 1 (Step 050755): Train loss 1.831, Val loss 1.813\n",
      "Ep 1 (Step 050760): Train loss 2.125, Val loss 1.806\n",
      "Ep 1 (Step 050765): Train loss 1.837, Val loss 1.797\n",
      "Ep 1 (Step 050770): Train loss 1.972, Val loss 1.806\n",
      "Ep 1 (Step 050775): Train loss 2.156, Val loss 1.815\n",
      "Ep 1 (Step 050780): Train loss 1.798, Val loss 1.811\n",
      "Ep 1 (Step 050785): Train loss 1.864, Val loss 1.811\n",
      "Ep 1 (Step 050790): Train loss 1.563, Val loss 1.806\n",
      "Ep 1 (Step 050795): Train loss 1.754, Val loss 1.807\n",
      "Ep 1 (Step 050800): Train loss 1.907, Val loss 1.806\n",
      "Ep 1 (Step 050805): Train loss 1.785, Val loss 1.808\n",
      "Ep 1 (Step 050810): Train loss 1.713, Val loss 1.812\n",
      "Ep 1 (Step 050815): Train loss 1.877, Val loss 1.814\n",
      "Ep 1 (Step 050820): Train loss 2.158, Val loss 1.819\n",
      "Ep 1 (Step 050825): Train loss 1.869, Val loss 1.826\n",
      "Ep 1 (Step 050830): Train loss 1.721, Val loss 1.825\n",
      "Ep 1 (Step 050835): Train loss 1.849, Val loss 1.818\n",
      "Ep 1 (Step 050840): Train loss 1.925, Val loss 1.816\n",
      "Ep 1 (Step 050845): Train loss 2.163, Val loss 1.824\n",
      "Ep 1 (Step 050850): Train loss 1.852, Val loss 1.836\n",
      "Ep 1 (Step 050855): Train loss 1.880, Val loss 1.838\n",
      "Ep 1 (Step 050860): Train loss 1.938, Val loss 1.843\n",
      "Ep 1 (Step 050865): Train loss 1.945, Val loss 1.850\n",
      "Ep 1 (Step 050870): Train loss 1.765, Val loss 1.845\n",
      "Ep 1 (Step 050875): Train loss 2.004, Val loss 1.853\n",
      "Ep 1 (Step 050880): Train loss 2.183, Val loss 1.851\n",
      "Ep 1 (Step 050885): Train loss 1.887, Val loss 1.849\n",
      "Ep 1 (Step 050890): Train loss 1.977, Val loss 1.837\n",
      "Ep 1 (Step 050895): Train loss 1.825, Val loss 1.826\n",
      "Ep 1 (Step 050900): Train loss 1.651, Val loss 1.823\n",
      "Ep 1 (Step 050905): Train loss 1.780, Val loss 1.826\n",
      "Ep 1 (Step 050910): Train loss 1.811, Val loss 1.829\n",
      "Ep 1 (Step 050915): Train loss 2.199, Val loss 1.836\n",
      "Ep 1 (Step 050920): Train loss 1.649, Val loss 1.825\n",
      "Ep 1 (Step 050925): Train loss 2.024, Val loss 1.801\n",
      "Ep 1 (Step 050930): Train loss 1.894, Val loss 1.797\n",
      "Ep 1 (Step 050935): Train loss 1.901, Val loss 1.799\n",
      "Ep 1 (Step 050940): Train loss 2.083, Val loss 1.811\n",
      "Ep 1 (Step 050945): Train loss 1.877, Val loss 1.806\n",
      "Ep 1 (Step 050950): Train loss 1.870, Val loss 1.783\n",
      "Ep 1 (Step 050955): Train loss 1.783, Val loss 1.779\n",
      "Ep 1 (Step 050960): Train loss 1.985, Val loss 1.777\n",
      "Ep 1 (Step 050965): Train loss 2.060, Val loss 1.773\n",
      "Ep 1 (Step 050970): Train loss 1.848, Val loss 1.771\n",
      "Ep 1 (Step 050975): Train loss 1.740, Val loss 1.767\n",
      "Ep 1 (Step 050980): Train loss 1.917, Val loss 1.780\n",
      "Ep 1 (Step 050985): Train loss 1.747, Val loss 1.782\n",
      "Ep 1 (Step 050990): Train loss 1.887, Val loss 1.782\n",
      "Ep 1 (Step 050995): Train loss 1.962, Val loss 1.768\n",
      "Ep 1 (Step 051000): Train loss 1.674, Val loss 1.771\n",
      "Ep 1 (Step 051005): Train loss 1.965, Val loss 1.779\n",
      "Ep 1 (Step 051010): Train loss 1.778, Val loss 1.778\n",
      "Ep 1 (Step 051015): Train loss 1.924, Val loss 1.777\n",
      "Ep 1 (Step 051020): Train loss 1.990, Val loss 1.780\n",
      "Ep 1 (Step 051025): Train loss 1.764, Val loss 1.785\n",
      "Ep 1 (Step 051030): Train loss 1.847, Val loss 1.793\n",
      "Ep 1 (Step 051035): Train loss 1.909, Val loss 1.791\n",
      "Ep 1 (Step 051040): Train loss 1.772, Val loss 1.794\n",
      "Ep 1 (Step 051045): Train loss 1.924, Val loss 1.789\n",
      "Ep 1 (Step 051050): Train loss 1.882, Val loss 1.787\n",
      "Ep 1 (Step 051055): Train loss 1.993, Val loss 1.782\n",
      "Ep 1 (Step 051060): Train loss 1.799, Val loss 1.779\n",
      "Ep 1 (Step 051065): Train loss 1.714, Val loss 1.784\n",
      "Ep 1 (Step 051070): Train loss 1.553, Val loss 1.798\n",
      "Ep 1 (Step 051075): Train loss 2.106, Val loss 1.807\n",
      "Ep 1 (Step 051080): Train loss 1.763, Val loss 1.797\n",
      "Ep 1 (Step 051085): Train loss 1.923, Val loss 1.797\n",
      "Ep 1 (Step 051090): Train loss 2.028, Val loss 1.813\n",
      "Ep 1 (Step 051095): Train loss 1.849, Val loss 1.817\n",
      "Ep 1 (Step 051100): Train loss 1.824, Val loss 1.815\n",
      "Ep 1 (Step 051105): Train loss 1.694, Val loss 1.806\n",
      "Ep 1 (Step 051110): Train loss 1.786, Val loss 1.801\n",
      "Ep 1 (Step 051115): Train loss 1.949, Val loss 1.798\n",
      "Ep 1 (Step 051120): Train loss 1.848, Val loss 1.798\n",
      "Ep 1 (Step 051125): Train loss 1.773, Val loss 1.793\n",
      "Ep 1 (Step 051130): Train loss 1.971, Val loss 1.796\n",
      "Ep 1 (Step 051135): Train loss 1.785, Val loss 1.799\n",
      "Ep 1 (Step 051140): Train loss 1.677, Val loss 1.805\n",
      "Ep 1 (Step 051145): Train loss 1.880, Val loss 1.802\n",
      "Ep 1 (Step 051150): Train loss 1.872, Val loss 1.798\n",
      "Ep 1 (Step 051155): Train loss 1.878, Val loss 1.801\n",
      "Ep 1 (Step 051160): Train loss 1.675, Val loss 1.810\n",
      "Ep 1 (Step 051165): Train loss 1.814, Val loss 1.809\n",
      "Ep 1 (Step 051170): Train loss 1.706, Val loss 1.805\n",
      "Ep 1 (Step 051175): Train loss 1.605, Val loss 1.804\n",
      "Ep 1 (Step 051180): Train loss 1.836, Val loss 1.805\n",
      "Ep 1 (Step 051185): Train loss 1.969, Val loss 1.793\n",
      "Ep 1 (Step 051190): Train loss 2.081, Val loss 1.791\n",
      "Ep 1 (Step 051195): Train loss 1.711, Val loss 1.793\n",
      "Ep 1 (Step 051200): Train loss 1.968, Val loss 1.797\n",
      "Ep 1 (Step 051205): Train loss 1.635, Val loss 1.790\n",
      "Ep 1 (Step 051210): Train loss 1.560, Val loss 1.790\n",
      "Ep 1 (Step 051215): Train loss 1.891, Val loss 1.791\n",
      "Ep 1 (Step 051220): Train loss 1.995, Val loss 1.795\n",
      "Ep 1 (Step 051225): Train loss 1.855, Val loss 1.796\n",
      "Ep 1 (Step 051230): Train loss 1.960, Val loss 1.797\n",
      "Ep 1 (Step 051235): Train loss 1.785, Val loss 1.794\n",
      "Ep 1 (Step 051240): Train loss 1.644, Val loss 1.806\n",
      "Ep 1 (Step 051245): Train loss 2.249, Val loss 1.815\n",
      "Ep 1 (Step 051250): Train loss 1.751, Val loss 1.817\n",
      "Ep 1 (Step 051255): Train loss 1.637, Val loss 1.813\n",
      "Ep 1 (Step 051260): Train loss 2.109, Val loss 1.805\n",
      "Ep 1 (Step 051265): Train loss 1.900, Val loss 1.798\n",
      "Ep 1 (Step 051270): Train loss 1.900, Val loss 1.797\n",
      "Ep 1 (Step 051275): Train loss 1.855, Val loss 1.805\n",
      "Ep 1 (Step 051280): Train loss 1.703, Val loss 1.821\n",
      "Ep 1 (Step 051285): Train loss 1.931, Val loss 1.820\n",
      "Ep 1 (Step 051290): Train loss 1.703, Val loss 1.818\n",
      "Ep 1 (Step 051295): Train loss 1.640, Val loss 1.813\n",
      "Ep 1 (Step 051300): Train loss 1.735, Val loss 1.821\n",
      "Ep 1 (Step 051305): Train loss 1.586, Val loss 1.828\n",
      "Ep 1 (Step 051310): Train loss 1.910, Val loss 1.813\n",
      "Ep 1 (Step 051315): Train loss 1.520, Val loss 1.806\n",
      "Ep 1 (Step 051320): Train loss 1.696, Val loss 1.801\n",
      "Ep 1 (Step 051325): Train loss 1.889, Val loss 1.802\n",
      "Ep 1 (Step 051330): Train loss 1.788, Val loss 1.808\n",
      "Ep 1 (Step 051335): Train loss 2.111, Val loss 1.818\n",
      "Ep 1 (Step 051340): Train loss 1.738, Val loss 1.811\n",
      "Ep 1 (Step 051345): Train loss 1.724, Val loss 1.799\n",
      "Ep 1 (Step 051350): Train loss 1.968, Val loss 1.796\n",
      "Ep 1 (Step 051355): Train loss 1.692, Val loss 1.794\n",
      "Ep 1 (Step 051360): Train loss 1.948, Val loss 1.786\n",
      "Ep 1 (Step 051365): Train loss 1.897, Val loss 1.783\n",
      "Ep 1 (Step 051370): Train loss 2.123, Val loss 1.782\n",
      "Ep 1 (Step 051375): Train loss 1.890, Val loss 1.785\n",
      "Ep 1 (Step 051380): Train loss 1.855, Val loss 1.776\n",
      "Ep 1 (Step 051385): Train loss 1.931, Val loss 1.779\n",
      "Ep 1 (Step 051390): Train loss 1.849, Val loss 1.796\n",
      "Ep 1 (Step 051395): Train loss 2.066, Val loss 1.795\n",
      "Ep 1 (Step 051400): Train loss 1.825, Val loss 1.782\n",
      "Ep 1 (Step 051405): Train loss 1.839, Val loss 1.782\n",
      "Ep 1 (Step 051410): Train loss 1.942, Val loss 1.779\n",
      "Ep 1 (Step 051415): Train loss 1.713, Val loss 1.775\n",
      "Ep 1 (Step 051420): Train loss 1.702, Val loss 1.780\n",
      "Ep 1 (Step 051425): Train loss 1.716, Val loss 1.775\n",
      "Ep 1 (Step 051430): Train loss 1.758, Val loss 1.775\n",
      "Ep 1 (Step 051435): Train loss 1.790, Val loss 1.775\n",
      "Ep 1 (Step 051440): Train loss 1.681, Val loss 1.776\n",
      "Ep 1 (Step 051445): Train loss 1.647, Val loss 1.773\n",
      "Ep 1 (Step 051450): Train loss 1.942, Val loss 1.768\n",
      "Ep 1 (Step 051455): Train loss 1.845, Val loss 1.771\n",
      "Ep 1 (Step 051460): Train loss 2.013, Val loss 1.773\n",
      "Ep 1 (Step 051465): Train loss 1.716, Val loss 1.774\n",
      "Ep 1 (Step 051470): Train loss 1.644, Val loss 1.781\n",
      "Ep 1 (Step 051475): Train loss 1.739, Val loss 1.790\n",
      "Ep 1 (Step 051480): Train loss 1.804, Val loss 1.796\n",
      "Ep 1 (Step 051485): Train loss 1.558, Val loss 1.789\n",
      "Ep 1 (Step 051490): Train loss 1.756, Val loss 1.794\n",
      "Ep 1 (Step 051495): Train loss 1.872, Val loss 1.797\n",
      "Ep 1 (Step 051500): Train loss 1.754, Val loss 1.806\n",
      "Ep 1 (Step 051505): Train loss 1.868, Val loss 1.804\n",
      "Ep 1 (Step 051510): Train loss 1.598, Val loss 1.797\n",
      "Ep 1 (Step 051515): Train loss 1.824, Val loss 1.799\n",
      "Ep 1 (Step 051520): Train loss 1.648, Val loss 1.793\n",
      "Ep 1 (Step 051525): Train loss 1.845, Val loss 1.794\n",
      "Ep 1 (Step 051530): Train loss 1.881, Val loss 1.795\n",
      "Ep 1 (Step 051535): Train loss 2.018, Val loss 1.798\n",
      "Ep 1 (Step 051540): Train loss 1.715, Val loss 1.804\n",
      "Ep 1 (Step 051545): Train loss 1.780, Val loss 1.808\n",
      "Ep 1 (Step 051550): Train loss 1.943, Val loss 1.807\n",
      "Ep 1 (Step 051555): Train loss 2.025, Val loss 1.815\n",
      "Ep 1 (Step 051560): Train loss 1.906, Val loss 1.817\n",
      "Ep 1 (Step 051565): Train loss 1.861, Val loss 1.810\n",
      "Ep 1 (Step 051570): Train loss 2.039, Val loss 1.811\n",
      "Ep 1 (Step 051575): Train loss 1.921, Val loss 1.815\n",
      "Ep 1 (Step 051580): Train loss 1.855, Val loss 1.807\n",
      "Ep 1 (Step 051585): Train loss 1.745, Val loss 1.809\n",
      "Ep 1 (Step 051590): Train loss 1.895, Val loss 1.814\n",
      "Ep 1 (Step 051595): Train loss 1.821, Val loss 1.813\n",
      "Ep 1 (Step 051600): Train loss 1.683, Val loss 1.812\n",
      "Ep 1 (Step 051605): Train loss 1.807, Val loss 1.803\n",
      "Ep 1 (Step 051610): Train loss 1.714, Val loss 1.806\n",
      "Ep 1 (Step 051615): Train loss 1.772, Val loss 1.812\n",
      "Ep 1 (Step 051620): Train loss 1.931, Val loss 1.814\n",
      "Ep 1 (Step 051625): Train loss 1.880, Val loss 1.818\n",
      "Ep 1 (Step 051630): Train loss 1.849, Val loss 1.815\n",
      "Ep 1 (Step 051635): Train loss 1.920, Val loss 1.818\n",
      "Ep 1 (Step 051640): Train loss 2.011, Val loss 1.820\n",
      "Ep 1 (Step 051645): Train loss 1.828, Val loss 1.821\n",
      "Ep 1 (Step 051650): Train loss 1.885, Val loss 1.822\n",
      "Ep 1 (Step 051655): Train loss 1.831, Val loss 1.811\n",
      "Ep 1 (Step 051660): Train loss 1.907, Val loss 1.810\n",
      "Ep 1 (Step 051665): Train loss 1.676, Val loss 1.810\n",
      "Ep 1 (Step 051670): Train loss 1.829, Val loss 1.813\n",
      "Ep 1 (Step 051675): Train loss 1.715, Val loss 1.806\n",
      "Ep 1 (Step 051680): Train loss 1.984, Val loss 1.801\n",
      "Ep 1 (Step 051685): Train loss 1.726, Val loss 1.802\n",
      "Ep 1 (Step 051690): Train loss 2.068, Val loss 1.806\n",
      "Ep 1 (Step 051695): Train loss 1.744, Val loss 1.809\n",
      "Ep 1 (Step 051700): Train loss 1.798, Val loss 1.809\n",
      "Ep 1 (Step 051705): Train loss 1.907, Val loss 1.821\n",
      "Ep 1 (Step 051710): Train loss 1.717, Val loss 1.838\n",
      "Ep 1 (Step 051715): Train loss 1.783, Val loss 1.832\n",
      "Ep 1 (Step 051720): Train loss 2.006, Val loss 1.828\n",
      "Ep 1 (Step 051725): Train loss 1.847, Val loss 1.823\n",
      "Ep 1 (Step 051730): Train loss 1.700, Val loss 1.827\n",
      "Ep 1 (Step 051735): Train loss 1.917, Val loss 1.830\n",
      "Ep 1 (Step 051740): Train loss 2.064, Val loss 1.830\n",
      "Ep 1 (Step 051745): Train loss 1.649, Val loss 1.824\n",
      "Ep 1 (Step 051750): Train loss 1.879, Val loss 1.816\n",
      "Ep 1 (Step 051755): Train loss 1.954, Val loss 1.813\n",
      "Ep 1 (Step 051760): Train loss 1.807, Val loss 1.811\n",
      "Ep 1 (Step 051765): Train loss 1.599, Val loss 1.812\n",
      "Ep 1 (Step 051770): Train loss 1.639, Val loss 1.810\n",
      "Ep 1 (Step 051775): Train loss 1.773, Val loss 1.804\n",
      "Ep 1 (Step 051780): Train loss 1.630, Val loss 1.810\n",
      "Ep 1 (Step 051785): Train loss 1.848, Val loss 1.808\n",
      "Ep 1 (Step 051790): Train loss 1.814, Val loss 1.819\n",
      "Ep 1 (Step 051795): Train loss 1.955, Val loss 1.833\n",
      "Ep 1 (Step 051800): Train loss 1.875, Val loss 1.825\n",
      "Ep 1 (Step 051805): Train loss 2.153, Val loss 1.817\n",
      "Ep 1 (Step 051810): Train loss 1.797, Val loss 1.812\n",
      "Ep 1 (Step 051815): Train loss 2.194, Val loss 1.817\n",
      "Ep 1 (Step 051820): Train loss 1.794, Val loss 1.821\n",
      "Ep 1 (Step 051825): Train loss 1.837, Val loss 1.824\n",
      "Ep 1 (Step 051830): Train loss 1.960, Val loss 1.822\n",
      "Ep 1 (Step 051835): Train loss 2.084, Val loss 1.824\n",
      "Ep 1 (Step 051840): Train loss 1.662, Val loss 1.831\n",
      "Ep 1 (Step 051845): Train loss 1.751, Val loss 1.819\n",
      "Ep 1 (Step 051850): Train loss 1.908, Val loss 1.815\n",
      "Ep 1 (Step 051855): Train loss 2.006, Val loss 1.816\n",
      "Ep 1 (Step 051860): Train loss 1.827, Val loss 1.822\n",
      "Ep 1 (Step 051865): Train loss 1.897, Val loss 1.828\n",
      "Ep 1 (Step 051870): Train loss 1.765, Val loss 1.825\n",
      "Ep 1 (Step 051875): Train loss 1.960, Val loss 1.825\n",
      "Ep 1 (Step 051880): Train loss 2.065, Val loss 1.824\n",
      "Ep 1 (Step 051885): Train loss 1.803, Val loss 1.823\n",
      "Ep 1 (Step 051890): Train loss 1.851, Val loss 1.810\n",
      "Ep 1 (Step 051895): Train loss 1.970, Val loss 1.800\n",
      "Ep 1 (Step 051900): Train loss 1.667, Val loss 1.800\n",
      "Ep 1 (Step 051905): Train loss 1.925, Val loss 1.804\n",
      "Ep 1 (Step 051910): Train loss 1.546, Val loss 1.801\n",
      "Ep 1 (Step 051915): Train loss 1.884, Val loss 1.799\n",
      "Ep 1 (Step 051920): Train loss 1.839, Val loss 1.795\n",
      "Ep 1 (Step 051925): Train loss 1.821, Val loss 1.800\n",
      "Ep 1 (Step 051930): Train loss 1.840, Val loss 1.793\n",
      "Ep 1 (Step 051935): Train loss 2.125, Val loss 1.785\n",
      "Ep 1 (Step 051940): Train loss 1.762, Val loss 1.775\n",
      "Ep 1 (Step 051945): Train loss 1.640, Val loss 1.788\n",
      "Ep 1 (Step 051950): Train loss 1.974, Val loss 1.788\n",
      "Ep 1 (Step 051955): Train loss 1.851, Val loss 1.794\n",
      "Ep 1 (Step 051960): Train loss 1.793, Val loss 1.807\n",
      "Ep 1 (Step 051965): Train loss 1.905, Val loss 1.802\n",
      "Ep 1 (Step 051970): Train loss 1.756, Val loss 1.807\n",
      "Ep 1 (Step 051975): Train loss 1.982, Val loss 1.802\n",
      "Ep 1 (Step 051980): Train loss 1.727, Val loss 1.799\n",
      "Ep 1 (Step 051985): Train loss 1.710, Val loss 1.803\n",
      "Ep 1 (Step 051990): Train loss 1.671, Val loss 1.802\n",
      "Ep 1 (Step 051995): Train loss 2.020, Val loss 1.797\n",
      "Ep 1 (Step 052000): Train loss 1.832, Val loss 1.799\n",
      "Ep 1 (Step 052005): Train loss 2.166, Val loss 1.802\n",
      "Ep 1 (Step 052010): Train loss 1.823, Val loss 1.803\n",
      "Ep 1 (Step 052015): Train loss 1.859, Val loss 1.796\n",
      "Ep 1 (Step 052020): Train loss 1.699, Val loss 1.800\n",
      "Ep 1 (Step 052025): Train loss 2.117, Val loss 1.793\n",
      "Ep 1 (Step 052030): Train loss 1.688, Val loss 1.799\n",
      "Ep 1 (Step 052035): Train loss 1.779, Val loss 1.805\n",
      "Ep 1 (Step 052040): Train loss 1.708, Val loss 1.796\n",
      "Ep 1 (Step 052045): Train loss 1.689, Val loss 1.799\n",
      "Ep 1 (Step 052050): Train loss 1.605, Val loss 1.801\n",
      "Ep 1 (Step 052055): Train loss 1.789, Val loss 1.803\n",
      "Ep 1 (Step 052060): Train loss 1.718, Val loss 1.800\n",
      "Ep 1 (Step 052065): Train loss 1.686, Val loss 1.810\n",
      "Ep 1 (Step 052070): Train loss 1.771, Val loss 1.819\n",
      "Ep 1 (Step 052075): Train loss 1.866, Val loss 1.823\n",
      "Ep 1 (Step 052080): Train loss 1.869, Val loss 1.812\n",
      "Ep 1 (Step 052085): Train loss 2.191, Val loss 1.799\n",
      "Ep 1 (Step 052090): Train loss 1.884, Val loss 1.790\n",
      "Ep 1 (Step 052095): Train loss 1.946, Val loss 1.780\n",
      "Ep 1 (Step 052100): Train loss 1.698, Val loss 1.774\n",
      "Ep 1 (Step 052105): Train loss 1.785, Val loss 1.770\n",
      "Ep 1 (Step 052110): Train loss 2.095, Val loss 1.772\n",
      "Ep 1 (Step 052115): Train loss 1.864, Val loss 1.777\n",
      "Ep 1 (Step 052120): Train loss 1.893, Val loss 1.773\n",
      "Ep 1 (Step 052125): Train loss 1.780, Val loss 1.782\n",
      "Ep 1 (Step 052130): Train loss 1.643, Val loss 1.789\n",
      "Ep 1 (Step 052135): Train loss 1.690, Val loss 1.791\n",
      "Ep 1 (Step 052140): Train loss 2.077, Val loss 1.794\n",
      "Ep 1 (Step 052145): Train loss 1.918, Val loss 1.809\n",
      "Ep 1 (Step 052150): Train loss 1.893, Val loss 1.818\n",
      "Ep 1 (Step 052155): Train loss 1.773, Val loss 1.829\n",
      "Ep 1 (Step 052160): Train loss 1.645, Val loss 1.821\n",
      "Ep 1 (Step 052165): Train loss 1.866, Val loss 1.813\n",
      "Ep 1 (Step 052170): Train loss 1.804, Val loss 1.804\n",
      "Ep 1 (Step 052175): Train loss 1.907, Val loss 1.797\n",
      "Ep 1 (Step 052180): Train loss 1.710, Val loss 1.798\n",
      "Ep 1 (Step 052185): Train loss 1.659, Val loss 1.802\n",
      "Ep 1 (Step 052190): Train loss 1.681, Val loss 1.813\n",
      "Ep 1 (Step 052195): Train loss 1.791, Val loss 1.809\n",
      "Ep 1 (Step 052200): Train loss 1.786, Val loss 1.805\n",
      "Ep 1 (Step 052205): Train loss 1.940, Val loss 1.805\n",
      "Ep 1 (Step 052210): Train loss 1.849, Val loss 1.805\n",
      "Ep 1 (Step 052215): Train loss 2.080, Val loss 1.805\n",
      "Ep 1 (Step 052220): Train loss 1.987, Val loss 1.800\n",
      "Ep 1 (Step 052225): Train loss 1.772, Val loss 1.804\n",
      "Ep 1 (Step 052230): Train loss 1.646, Val loss 1.814\n",
      "Ep 1 (Step 052235): Train loss 1.874, Val loss 1.806\n",
      "Ep 1 (Step 052240): Train loss 1.559, Val loss 1.799\n",
      "Ep 1 (Step 052245): Train loss 1.848, Val loss 1.796\n",
      "Ep 1 (Step 052250): Train loss 2.052, Val loss 1.796\n",
      "Ep 1 (Step 052255): Train loss 1.595, Val loss 1.803\n",
      "Ep 1 (Step 052260): Train loss 1.740, Val loss 1.800\n",
      "Ep 1 (Step 052265): Train loss 1.812, Val loss 1.795\n",
      "Ep 1 (Step 052270): Train loss 1.893, Val loss 1.805\n",
      "Ep 1 (Step 052275): Train loss 1.958, Val loss 1.800\n",
      "Ep 1 (Step 052280): Train loss 2.104, Val loss 1.799\n",
      "Ep 1 (Step 052285): Train loss 2.045, Val loss 1.805\n",
      "Ep 1 (Step 052290): Train loss 1.941, Val loss 1.809\n",
      "Ep 1 (Step 052295): Train loss 1.981, Val loss 1.807\n",
      "Ep 1 (Step 052300): Train loss 2.067, Val loss 1.809\n",
      "Ep 1 (Step 052305): Train loss 1.752, Val loss 1.808\n",
      "Ep 1 (Step 052310): Train loss 1.916, Val loss 1.804\n",
      "Ep 1 (Step 052315): Train loss 1.716, Val loss 1.801\n",
      "Ep 1 (Step 052320): Train loss 1.688, Val loss 1.801\n",
      "Ep 1 (Step 052325): Train loss 1.698, Val loss 1.802\n",
      "Ep 1 (Step 052330): Train loss 1.773, Val loss 1.804\n",
      "Ep 1 (Step 052335): Train loss 1.783, Val loss 1.809\n",
      "Ep 1 (Step 052340): Train loss 1.709, Val loss 1.805\n",
      "Ep 1 (Step 052345): Train loss 1.570, Val loss 1.793\n",
      "Ep 1 (Step 052350): Train loss 2.033, Val loss 1.783\n",
      "Ep 1 (Step 052355): Train loss 1.899, Val loss 1.784\n",
      "Ep 1 (Step 052360): Train loss 1.688, Val loss 1.791\n",
      "Ep 1 (Step 052365): Train loss 1.753, Val loss 1.798\n",
      "Ep 1 (Step 052370): Train loss 1.895, Val loss 1.799\n",
      "Ep 1 (Step 052375): Train loss 1.727, Val loss 1.801\n",
      "Ep 1 (Step 052380): Train loss 1.565, Val loss 1.798\n",
      "Ep 1 (Step 052385): Train loss 1.896, Val loss 1.810\n",
      "Ep 1 (Step 052390): Train loss 1.735, Val loss 1.823\n",
      "Ep 1 (Step 052395): Train loss 1.784, Val loss 1.808\n",
      "Ep 1 (Step 052400): Train loss 1.748, Val loss 1.795\n",
      "Ep 1 (Step 052405): Train loss 2.136, Val loss 1.792\n",
      "Ep 1 (Step 052410): Train loss 2.061, Val loss 1.799\n",
      "Ep 1 (Step 052415): Train loss 1.763, Val loss 1.808\n",
      "Ep 1 (Step 052420): Train loss 1.753, Val loss 1.804\n",
      "Ep 1 (Step 052425): Train loss 1.733, Val loss 1.806\n",
      "Ep 1 (Step 052430): Train loss 1.808, Val loss 1.812\n",
      "Ep 1 (Step 052435): Train loss 1.866, Val loss 1.810\n",
      "Ep 1 (Step 052440): Train loss 1.724, Val loss 1.816\n",
      "Ep 1 (Step 052445): Train loss 2.001, Val loss 1.815\n",
      "Ep 1 (Step 052450): Train loss 1.883, Val loss 1.798\n",
      "Ep 1 (Step 052455): Train loss 1.665, Val loss 1.785\n",
      "Ep 1 (Step 052460): Train loss 1.986, Val loss 1.793\n",
      "Ep 1 (Step 052465): Train loss 1.985, Val loss 1.805\n",
      "Ep 1 (Step 052470): Train loss 2.093, Val loss 1.807\n",
      "Ep 1 (Step 052475): Train loss 1.771, Val loss 1.801\n",
      "Ep 1 (Step 052480): Train loss 1.997, Val loss 1.807\n",
      "Ep 1 (Step 052485): Train loss 2.272, Val loss 1.813\n",
      "Ep 1 (Step 052490): Train loss 1.837, Val loss 1.806\n",
      "Ep 1 (Step 052495): Train loss 1.849, Val loss 1.802\n",
      "Ep 1 (Step 052500): Train loss 1.802, Val loss 1.810\n",
      "Ep 1 (Step 052505): Train loss 1.943, Val loss 1.809\n",
      "Ep 1 (Step 052510): Train loss 1.834, Val loss 1.807\n",
      "Ep 1 (Step 052515): Train loss 1.904, Val loss 1.803\n",
      "Ep 1 (Step 052520): Train loss 1.724, Val loss 1.805\n",
      "Ep 1 (Step 052525): Train loss 1.640, Val loss 1.797\n",
      "Ep 1 (Step 052530): Train loss 1.734, Val loss 1.807\n",
      "Ep 1 (Step 052535): Train loss 2.020, Val loss 1.807\n",
      "Ep 1 (Step 052540): Train loss 1.850, Val loss 1.803\n",
      "Ep 1 (Step 052545): Train loss 1.906, Val loss 1.796\n",
      "Ep 1 (Step 052550): Train loss 1.801, Val loss 1.798\n",
      "Ep 1 (Step 052555): Train loss 1.807, Val loss 1.798\n",
      "Ep 1 (Step 052560): Train loss 1.974, Val loss 1.787\n",
      "Ep 1 (Step 052565): Train loss 1.769, Val loss 1.784\n",
      "Ep 1 (Step 052570): Train loss 1.881, Val loss 1.787\n",
      "Ep 1 (Step 052575): Train loss 1.721, Val loss 1.789\n",
      "Ep 1 (Step 052580): Train loss 1.882, Val loss 1.789\n",
      "Ep 1 (Step 052585): Train loss 1.415, Val loss 1.795\n",
      "Ep 1 (Step 052590): Train loss 1.744, Val loss 1.798\n",
      "Ep 1 (Step 052595): Train loss 1.876, Val loss 1.801\n",
      "Ep 1 (Step 052600): Train loss 2.091, Val loss 1.808\n",
      "Ep 1 (Step 052605): Train loss 1.808, Val loss 1.814\n",
      "Ep 1 (Step 052610): Train loss 1.790, Val loss 1.824\n",
      "Ep 1 (Step 052615): Train loss 2.001, Val loss 1.809\n",
      "Ep 1 (Step 052620): Train loss 1.591, Val loss 1.806\n",
      "Ep 1 (Step 052625): Train loss 1.771, Val loss 1.807\n",
      "Ep 1 (Step 052630): Train loss 1.868, Val loss 1.817\n",
      "Ep 1 (Step 052635): Train loss 1.831, Val loss 1.820\n",
      "Ep 1 (Step 052640): Train loss 1.976, Val loss 1.810\n",
      "Ep 1 (Step 052645): Train loss 1.678, Val loss 1.808\n",
      "Ep 1 (Step 052650): Train loss 1.617, Val loss 1.813\n",
      "Ep 1 (Step 052655): Train loss 1.733, Val loss 1.818\n",
      "Ep 1 (Step 052660): Train loss 1.838, Val loss 1.809\n",
      "Ep 1 (Step 052665): Train loss 1.827, Val loss 1.798\n",
      "Ep 1 (Step 052670): Train loss 1.822, Val loss 1.801\n",
      "Ep 1 (Step 052675): Train loss 1.572, Val loss 1.804\n",
      "Ep 1 (Step 052680): Train loss 1.794, Val loss 1.797\n",
      "Ep 1 (Step 052685): Train loss 1.895, Val loss 1.802\n",
      "Ep 1 (Step 052690): Train loss 1.852, Val loss 1.815\n",
      "Ep 1 (Step 052695): Train loss 1.709, Val loss 1.822\n",
      "Ep 1 (Step 052700): Train loss 1.939, Val loss 1.823\n",
      "Ep 1 (Step 052705): Train loss 1.923, Val loss 1.816\n",
      "Ep 1 (Step 052710): Train loss 2.045, Val loss 1.811\n",
      "Ep 1 (Step 052715): Train loss 1.884, Val loss 1.814\n",
      "Ep 1 (Step 052720): Train loss 1.769, Val loss 1.807\n",
      "Ep 1 (Step 052725): Train loss 2.078, Val loss 1.805\n",
      "Ep 1 (Step 052730): Train loss 1.971, Val loss 1.813\n",
      "Ep 1 (Step 052735): Train loss 1.749, Val loss 1.821\n",
      "Ep 1 (Step 052740): Train loss 1.945, Val loss 1.815\n",
      "Ep 1 (Step 052745): Train loss 1.714, Val loss 1.814\n",
      "Ep 1 (Step 052750): Train loss 2.038, Val loss 1.810\n",
      "Ep 1 (Step 052755): Train loss 1.775, Val loss 1.815\n",
      "Ep 1 (Step 052760): Train loss 1.626, Val loss 1.818\n",
      "Ep 1 (Step 052765): Train loss 1.911, Val loss 1.828\n",
      "Ep 1 (Step 052770): Train loss 1.776, Val loss 1.842\n",
      "Ep 1 (Step 052775): Train loss 2.194, Val loss 1.852\n",
      "Ep 1 (Step 052780): Train loss 1.844, Val loss 1.841\n",
      "Ep 1 (Step 052785): Train loss 1.739, Val loss 1.831\n",
      "Ep 1 (Step 052790): Train loss 1.900, Val loss 1.832\n",
      "Ep 1 (Step 052795): Train loss 1.772, Val loss 1.827\n",
      "Ep 1 (Step 052800): Train loss 1.843, Val loss 1.818\n",
      "Ep 1 (Step 052805): Train loss 1.854, Val loss 1.813\n",
      "Ep 1 (Step 052810): Train loss 2.064, Val loss 1.807\n",
      "Ep 1 (Step 052815): Train loss 1.744, Val loss 1.797\n",
      "Ep 1 (Step 052820): Train loss 1.866, Val loss 1.784\n",
      "Ep 1 (Step 052825): Train loss 1.571, Val loss 1.783\n",
      "Ep 1 (Step 052830): Train loss 2.003, Val loss 1.783\n",
      "Ep 1 (Step 052835): Train loss 1.642, Val loss 1.786\n",
      "Ep 1 (Step 052840): Train loss 1.575, Val loss 1.800\n",
      "Ep 1 (Step 052845): Train loss 1.902, Val loss 1.800\n",
      "Ep 1 (Step 052850): Train loss 1.937, Val loss 1.809\n",
      "Ep 1 (Step 052855): Train loss 1.987, Val loss 1.808\n",
      "Ep 1 (Step 052860): Train loss 1.642, Val loss 1.812\n",
      "Ep 1 (Step 052865): Train loss 1.452, Val loss 1.812\n",
      "Ep 1 (Step 052870): Train loss 1.695, Val loss 1.816\n",
      "Ep 1 (Step 052875): Train loss 1.984, Val loss 1.814\n",
      "Ep 1 (Step 052880): Train loss 1.739, Val loss 1.809\n",
      "Ep 1 (Step 052885): Train loss 1.930, Val loss 1.806\n",
      "Ep 1 (Step 052890): Train loss 1.653, Val loss 1.815\n",
      "Ep 1 (Step 052895): Train loss 1.798, Val loss 1.825\n",
      "Ep 1 (Step 052900): Train loss 1.851, Val loss 1.822\n",
      "Ep 1 (Step 052905): Train loss 1.975, Val loss 1.818\n",
      "Ep 1 (Step 052910): Train loss 1.735, Val loss 1.820\n",
      "Ep 1 (Step 052915): Train loss 1.623, Val loss 1.817\n",
      "Ep 1 (Step 052920): Train loss 1.972, Val loss 1.810\n",
      "Ep 1 (Step 052925): Train loss 1.738, Val loss 1.814\n",
      "Ep 1 (Step 052930): Train loss 1.879, Val loss 1.809\n",
      "Ep 1 (Step 052935): Train loss 1.825, Val loss 1.800\n",
      "Ep 1 (Step 052940): Train loss 1.851, Val loss 1.801\n",
      "Ep 1 (Step 052945): Train loss 1.824, Val loss 1.813\n",
      "Ep 1 (Step 052950): Train loss 1.682, Val loss 1.818\n",
      "Ep 1 (Step 052955): Train loss 1.979, Val loss 1.816\n",
      "Ep 1 (Step 052960): Train loss 2.158, Val loss 1.823\n",
      "Ep 1 (Step 052965): Train loss 1.877, Val loss 1.817\n",
      "Ep 1 (Step 052970): Train loss 2.055, Val loss 1.812\n",
      "Ep 1 (Step 052975): Train loss 2.121, Val loss 1.815\n",
      "Ep 1 (Step 052980): Train loss 1.703, Val loss 1.821\n",
      "Ep 1 (Step 052985): Train loss 1.595, Val loss 1.829\n",
      "Ep 1 (Step 052990): Train loss 1.962, Val loss 1.828\n",
      "Ep 1 (Step 052995): Train loss 1.952, Val loss 1.820\n",
      "Ep 1 (Step 053000): Train loss 2.169, Val loss 1.820\n",
      "Ep 1 (Step 053005): Train loss 2.168, Val loss 1.822\n",
      "Ep 1 (Step 053010): Train loss 1.957, Val loss 1.821\n",
      "Ep 1 (Step 053015): Train loss 1.841, Val loss 1.820\n",
      "Ep 1 (Step 053020): Train loss 1.954, Val loss 1.817\n",
      "Ep 1 (Step 053025): Train loss 1.740, Val loss 1.827\n",
      "Ep 1 (Step 053030): Train loss 1.876, Val loss 1.837\n",
      "Ep 1 (Step 053035): Train loss 1.731, Val loss 1.833\n",
      "Ep 1 (Step 053040): Train loss 1.766, Val loss 1.819\n",
      "Ep 1 (Step 053045): Train loss 1.674, Val loss 1.812\n",
      "Ep 1 (Step 053050): Train loss 1.854, Val loss 1.817\n",
      "Ep 1 (Step 053055): Train loss 2.000, Val loss 1.825\n",
      "Ep 1 (Step 053060): Train loss 1.793, Val loss 1.834\n",
      "Ep 1 (Step 053065): Train loss 1.738, Val loss 1.835\n",
      "Ep 1 (Step 053070): Train loss 2.041, Val loss 1.826\n",
      "Ep 1 (Step 053075): Train loss 2.001, Val loss 1.814\n",
      "Ep 1 (Step 053080): Train loss 2.115, Val loss 1.819\n",
      "Ep 1 (Step 053085): Train loss 1.883, Val loss 1.817\n",
      "Ep 1 (Step 053090): Train loss 1.728, Val loss 1.809\n",
      "Ep 1 (Step 053095): Train loss 2.000, Val loss 1.807\n",
      "Ep 1 (Step 053100): Train loss 1.925, Val loss 1.807\n",
      "Ep 1 (Step 053105): Train loss 1.864, Val loss 1.804\n",
      "Ep 1 (Step 053110): Train loss 1.723, Val loss 1.811\n",
      "Ep 1 (Step 053115): Train loss 1.746, Val loss 1.816\n",
      "Ep 1 (Step 053120): Train loss 1.843, Val loss 1.834\n",
      "Ep 1 (Step 053125): Train loss 1.746, Val loss 1.839\n",
      "Ep 1 (Step 053130): Train loss 1.667, Val loss 1.837\n",
      "Ep 1 (Step 053135): Train loss 1.774, Val loss 1.831\n",
      "Ep 1 (Step 053140): Train loss 2.117, Val loss 1.835\n",
      "Ep 1 (Step 053145): Train loss 1.862, Val loss 1.831\n",
      "Ep 1 (Step 053150): Train loss 1.658, Val loss 1.828\n",
      "Ep 1 (Step 053155): Train loss 1.954, Val loss 1.818\n",
      "Ep 1 (Step 053160): Train loss 1.901, Val loss 1.816\n",
      "Ep 1 (Step 053165): Train loss 2.119, Val loss 1.808\n",
      "Ep 1 (Step 053170): Train loss 1.733, Val loss 1.808\n",
      "Ep 1 (Step 053175): Train loss 1.668, Val loss 1.810\n",
      "Ep 1 (Step 053180): Train loss 1.753, Val loss 1.808\n",
      "Ep 1 (Step 053185): Train loss 1.634, Val loss 1.814\n",
      "Ep 1 (Step 053190): Train loss 1.889, Val loss 1.812\n",
      "Ep 1 (Step 053195): Train loss 1.789, Val loss 1.802\n",
      "Ep 1 (Step 053200): Train loss 1.884, Val loss 1.807\n",
      "Ep 1 (Step 053205): Train loss 1.535, Val loss 1.816\n",
      "Ep 1 (Step 053210): Train loss 1.858, Val loss 1.803\n",
      "Ep 1 (Step 053215): Train loss 1.827, Val loss 1.800\n",
      "Ep 1 (Step 053220): Train loss 1.823, Val loss 1.807\n",
      "Ep 1 (Step 053225): Train loss 1.850, Val loss 1.813\n",
      "Ep 1 (Step 053230): Train loss 1.913, Val loss 1.818\n",
      "Ep 1 (Step 053235): Train loss 1.553, Val loss 1.826\n",
      "Ep 1 (Step 053240): Train loss 2.064, Val loss 1.824\n",
      "Ep 1 (Step 053245): Train loss 1.714, Val loss 1.807\n",
      "Ep 1 (Step 053250): Train loss 1.703, Val loss 1.808\n",
      "Ep 1 (Step 053255): Train loss 1.667, Val loss 1.812\n",
      "Ep 1 (Step 053260): Train loss 1.948, Val loss 1.807\n",
      "Ep 1 (Step 053265): Train loss 2.059, Val loss 1.797\n",
      "Ep 1 (Step 053270): Train loss 1.502, Val loss 1.793\n",
      "Ep 1 (Step 053275): Train loss 2.073, Val loss 1.804\n",
      "Ep 1 (Step 053280): Train loss 1.655, Val loss 1.808\n",
      "Ep 1 (Step 053285): Train loss 1.731, Val loss 1.809\n",
      "Ep 1 (Step 053290): Train loss 1.768, Val loss 1.813\n",
      "Ep 1 (Step 053295): Train loss 1.823, Val loss 1.818\n",
      "Ep 1 (Step 053300): Train loss 1.566, Val loss 1.814\n",
      "Ep 1 (Step 053305): Train loss 2.043, Val loss 1.815\n",
      "Ep 1 (Step 053310): Train loss 1.925, Val loss 1.821\n",
      "Ep 1 (Step 053315): Train loss 1.638, Val loss 1.820\n",
      "Ep 1 (Step 053320): Train loss 2.117, Val loss 1.817\n",
      "Ep 1 (Step 053325): Train loss 2.217, Val loss 1.823\n",
      "Ep 1 (Step 053330): Train loss 2.064, Val loss 1.819\n",
      "Ep 1 (Step 053335): Train loss 1.883, Val loss 1.812\n",
      "Ep 1 (Step 053340): Train loss 2.038, Val loss 1.798\n",
      "Ep 1 (Step 053345): Train loss 1.895, Val loss 1.808\n",
      "Ep 1 (Step 053350): Train loss 1.681, Val loss 1.806\n",
      "Ep 1 (Step 053355): Train loss 1.671, Val loss 1.803\n",
      "Ep 1 (Step 053360): Train loss 1.841, Val loss 1.811\n",
      "Ep 1 (Step 053365): Train loss 2.035, Val loss 1.817\n",
      "Ep 1 (Step 053370): Train loss 1.653, Val loss 1.809\n",
      "Ep 1 (Step 053375): Train loss 1.823, Val loss 1.804\n",
      "Ep 1 (Step 053380): Train loss 1.943, Val loss 1.808\n",
      "Ep 1 (Step 053385): Train loss 2.140, Val loss 1.813\n",
      "Ep 1 (Step 053390): Train loss 1.907, Val loss 1.806\n",
      "Ep 1 (Step 053395): Train loss 1.867, Val loss 1.798\n",
      "Ep 1 (Step 053400): Train loss 1.717, Val loss 1.798\n",
      "Ep 1 (Step 053405): Train loss 1.669, Val loss 1.801\n",
      "Ep 1 (Step 053410): Train loss 1.763, Val loss 1.804\n",
      "Ep 1 (Step 053415): Train loss 1.814, Val loss 1.806\n",
      "Ep 1 (Step 053420): Train loss 1.685, Val loss 1.804\n",
      "Ep 1 (Step 053425): Train loss 1.929, Val loss 1.805\n",
      "Ep 1 (Step 053430): Train loss 1.645, Val loss 1.808\n",
      "Ep 1 (Step 053435): Train loss 1.741, Val loss 1.802\n",
      "Ep 1 (Step 053440): Train loss 1.983, Val loss 1.803\n",
      "Ep 1 (Step 053445): Train loss 1.757, Val loss 1.805\n",
      "Ep 1 (Step 053450): Train loss 1.671, Val loss 1.811\n",
      "Ep 1 (Step 053455): Train loss 1.834, Val loss 1.814\n",
      "Ep 1 (Step 053460): Train loss 1.799, Val loss 1.815\n",
      "Ep 1 (Step 053465): Train loss 1.779, Val loss 1.815\n",
      "Ep 1 (Step 053470): Train loss 1.719, Val loss 1.813\n",
      "Ep 1 (Step 053475): Train loss 1.842, Val loss 1.803\n",
      "Ep 1 (Step 053480): Train loss 1.646, Val loss 1.799\n",
      "Ep 1 (Step 053485): Train loss 1.874, Val loss 1.806\n",
      "Ep 1 (Step 053490): Train loss 2.035, Val loss 1.809\n",
      "Ep 1 (Step 053495): Train loss 1.816, Val loss 1.818\n",
      "Ep 1 (Step 053500): Train loss 1.640, Val loss 1.819\n",
      "Ep 1 (Step 053505): Train loss 1.843, Val loss 1.819\n",
      "Ep 1 (Step 053510): Train loss 1.871, Val loss 1.820\n",
      "Ep 1 (Step 053515): Train loss 1.842, Val loss 1.824\n",
      "Ep 1 (Step 053520): Train loss 1.835, Val loss 1.828\n",
      "Ep 1 (Step 053525): Train loss 1.671, Val loss 1.833\n",
      "Ep 1 (Step 053530): Train loss 1.703, Val loss 1.832\n",
      "Ep 1 (Step 053535): Train loss 1.769, Val loss 1.819\n",
      "Ep 1 (Step 053540): Train loss 1.759, Val loss 1.820\n",
      "Ep 1 (Step 053545): Train loss 1.686, Val loss 1.828\n",
      "Ep 1 (Step 053550): Train loss 1.981, Val loss 1.832\n",
      "Ep 1 (Step 053555): Train loss 1.756, Val loss 1.820\n",
      "Ep 1 (Step 053560): Train loss 1.664, Val loss 1.829\n",
      "Ep 1 (Step 053565): Train loss 1.904, Val loss 1.843\n",
      "Ep 1 (Step 053570): Train loss 1.741, Val loss 1.859\n",
      "Ep 1 (Step 053575): Train loss 2.034, Val loss 1.848\n",
      "Ep 1 (Step 053580): Train loss 2.102, Val loss 1.831\n",
      "Ep 1 (Step 053585): Train loss 1.719, Val loss 1.833\n",
      "Ep 1 (Step 053590): Train loss 1.963, Val loss 1.839\n",
      "Ep 1 (Step 053595): Train loss 1.844, Val loss 1.842\n",
      "Ep 1 (Step 053600): Train loss 1.588, Val loss 1.841\n",
      "Ep 1 (Step 053605): Train loss 2.057, Val loss 1.838\n",
      "Ep 1 (Step 053610): Train loss 1.829, Val loss 1.837\n",
      "Ep 1 (Step 053615): Train loss 1.960, Val loss 1.834\n",
      "Ep 1 (Step 053620): Train loss 1.397, Val loss 1.829\n",
      "Ep 1 (Step 053625): Train loss 2.151, Val loss 1.819\n",
      "Ep 1 (Step 053630): Train loss 1.768, Val loss 1.813\n",
      "Ep 1 (Step 053635): Train loss 1.986, Val loss 1.807\n",
      "Ep 1 (Step 053640): Train loss 1.758, Val loss 1.808\n",
      "Ep 1 (Step 053645): Train loss 1.679, Val loss 1.824\n",
      "Ep 1 (Step 053650): Train loss 1.810, Val loss 1.813\n",
      "Ep 1 (Step 053655): Train loss 1.867, Val loss 1.809\n",
      "Ep 1 (Step 053660): Train loss 1.936, Val loss 1.803\n",
      "Ep 1 (Step 053665): Train loss 1.950, Val loss 1.821\n",
      "Ep 1 (Step 053670): Train loss 1.936, Val loss 1.829\n",
      "Ep 1 (Step 053675): Train loss 1.625, Val loss 1.837\n",
      "Ep 1 (Step 053680): Train loss 2.121, Val loss 1.839\n",
      "Ep 1 (Step 053685): Train loss 1.868, Val loss 1.854\n",
      "Ep 1 (Step 053690): Train loss 1.741, Val loss 1.850\n",
      "Ep 1 (Step 053695): Train loss 1.809, Val loss 1.838\n",
      "Ep 1 (Step 053700): Train loss 1.568, Val loss 1.824\n",
      "Ep 1 (Step 053705): Train loss 1.907, Val loss 1.830\n",
      "Ep 1 (Step 053710): Train loss 1.789, Val loss 1.845\n",
      "Ep 1 (Step 053715): Train loss 1.842, Val loss 1.837\n",
      "Ep 1 (Step 053720): Train loss 1.730, Val loss 1.827\n",
      "Ep 1 (Step 053725): Train loss 1.700, Val loss 1.828\n",
      "Ep 1 (Step 053730): Train loss 1.899, Val loss 1.822\n",
      "Ep 1 (Step 053735): Train loss 2.024, Val loss 1.808\n",
      "Ep 1 (Step 053740): Train loss 1.831, Val loss 1.801\n",
      "Ep 1 (Step 053745): Train loss 1.824, Val loss 1.815\n",
      "Ep 1 (Step 053750): Train loss 1.873, Val loss 1.812\n",
      "Ep 1 (Step 053755): Train loss 1.831, Val loss 1.809\n",
      "Ep 1 (Step 053760): Train loss 1.957, Val loss 1.811\n",
      "Ep 1 (Step 053765): Train loss 1.537, Val loss 1.817\n",
      "Ep 1 (Step 053770): Train loss 1.784, Val loss 1.809\n",
      "Ep 1 (Step 053775): Train loss 1.791, Val loss 1.821\n",
      "Ep 1 (Step 053780): Train loss 1.626, Val loss 1.826\n",
      "Ep 1 (Step 053785): Train loss 1.903, Val loss 1.823\n",
      "Ep 1 (Step 053790): Train loss 1.978, Val loss 1.827\n",
      "Ep 1 (Step 053795): Train loss 1.846, Val loss 1.828\n",
      "Ep 1 (Step 053800): Train loss 1.932, Val loss 1.816\n",
      "Ep 1 (Step 053805): Train loss 2.023, Val loss 1.814\n",
      "Ep 1 (Step 053810): Train loss 1.676, Val loss 1.812\n",
      "Ep 1 (Step 053815): Train loss 1.807, Val loss 1.804\n",
      "Ep 1 (Step 053820): Train loss 1.842, Val loss 1.801\n",
      "Ep 1 (Step 053825): Train loss 1.608, Val loss 1.807\n",
      "Ep 1 (Step 053830): Train loss 1.825, Val loss 1.813\n",
      "Ep 1 (Step 053835): Train loss 1.966, Val loss 1.808\n",
      "Ep 1 (Step 053840): Train loss 1.907, Val loss 1.812\n",
      "Ep 1 (Step 053845): Train loss 2.092, Val loss 1.808\n",
      "Ep 1 (Step 053850): Train loss 2.018, Val loss 1.809\n",
      "Ep 1 (Step 053855): Train loss 1.940, Val loss 1.809\n",
      "Ep 1 (Step 053860): Train loss 1.797, Val loss 1.804\n",
      "Ep 1 (Step 053865): Train loss 1.751, Val loss 1.801\n",
      "Ep 1 (Step 053870): Train loss 1.971, Val loss 1.799\n",
      "Ep 1 (Step 053875): Train loss 1.665, Val loss 1.794\n",
      "Ep 1 (Step 053880): Train loss 2.016, Val loss 1.792\n",
      "Ep 1 (Step 053885): Train loss 1.761, Val loss 1.799\n",
      "Ep 1 (Step 053890): Train loss 1.629, Val loss 1.798\n",
      "Ep 1 (Step 053895): Train loss 1.499, Val loss 1.810\n",
      "Ep 1 (Step 053900): Train loss 2.137, Val loss 1.811\n",
      "Ep 1 (Step 053905): Train loss 1.548, Val loss 1.803\n",
      "Ep 1 (Step 053910): Train loss 1.746, Val loss 1.807\n",
      "Ep 1 (Step 053915): Train loss 2.082, Val loss 1.814\n",
      "Ep 1 (Step 053920): Train loss 1.947, Val loss 1.812\n",
      "Ep 1 (Step 053925): Train loss 1.575, Val loss 1.821\n",
      "Ep 1 (Step 053930): Train loss 1.716, Val loss 1.827\n",
      "Ep 1 (Step 053935): Train loss 1.738, Val loss 1.819\n",
      "Ep 1 (Step 053940): Train loss 1.747, Val loss 1.818\n",
      "Ep 1 (Step 053945): Train loss 2.049, Val loss 1.820\n",
      "Ep 1 (Step 053950): Train loss 1.940, Val loss 1.828\n",
      "Ep 1 (Step 053955): Train loss 1.762, Val loss 1.821\n",
      "Ep 1 (Step 053960): Train loss 1.965, Val loss 1.813\n",
      "Ep 1 (Step 053965): Train loss 1.946, Val loss 1.814\n",
      "Ep 1 (Step 053970): Train loss 1.955, Val loss 1.814\n",
      "Ep 1 (Step 053975): Train loss 1.863, Val loss 1.823\n",
      "Ep 1 (Step 053980): Train loss 1.680, Val loss 1.833\n",
      "Ep 1 (Step 053985): Train loss 1.875, Val loss 1.828\n",
      "Ep 1 (Step 053990): Train loss 1.733, Val loss 1.825\n",
      "Ep 1 (Step 053995): Train loss 1.837, Val loss 1.821\n",
      "Ep 1 (Step 054000): Train loss 1.688, Val loss 1.816\n",
      "Ep 1 (Step 054005): Train loss 1.833, Val loss 1.810\n",
      "Ep 1 (Step 054010): Train loss 1.825, Val loss 1.811\n",
      "Ep 1 (Step 054015): Train loss 1.880, Val loss 1.803\n",
      "Ep 1 (Step 054020): Train loss 1.755, Val loss 1.808\n",
      "Ep 1 (Step 054025): Train loss 1.562, Val loss 1.813\n",
      "Ep 1 (Step 054030): Train loss 1.505, Val loss 1.826\n",
      "Ep 1 (Step 054035): Train loss 1.769, Val loss 1.825\n",
      "Ep 1 (Step 054040): Train loss 1.697, Val loss 1.805\n",
      "Ep 1 (Step 054045): Train loss 1.802, Val loss 1.798\n",
      "Ep 1 (Step 054050): Train loss 1.801, Val loss 1.806\n",
      "Ep 1 (Step 054055): Train loss 1.677, Val loss 1.803\n",
      "Ep 1 (Step 054060): Train loss 1.753, Val loss 1.791\n",
      "Ep 1 (Step 054065): Train loss 2.078, Val loss 1.786\n",
      "Ep 1 (Step 054070): Train loss 1.752, Val loss 1.785\n",
      "Ep 1 (Step 054075): Train loss 1.793, Val loss 1.792\n",
      "Ep 1 (Step 054080): Train loss 1.850, Val loss 1.800\n",
      "Ep 1 (Step 054085): Train loss 1.671, Val loss 1.803\n",
      "Ep 1 (Step 054090): Train loss 1.756, Val loss 1.799\n",
      "Ep 1 (Step 054095): Train loss 1.909, Val loss 1.796\n",
      "Ep 1 (Step 054100): Train loss 1.949, Val loss 1.806\n",
      "Ep 1 (Step 054105): Train loss 1.713, Val loss 1.798\n",
      "Ep 1 (Step 054110): Train loss 1.680, Val loss 1.792\n",
      "Ep 1 (Step 054115): Train loss 1.813, Val loss 1.795\n",
      "Ep 1 (Step 054120): Train loss 1.707, Val loss 1.807\n",
      "Ep 1 (Step 054125): Train loss 2.092, Val loss 1.808\n",
      "Ep 1 (Step 054130): Train loss 1.935, Val loss 1.807\n",
      "Ep 1 (Step 054135): Train loss 2.001, Val loss 1.813\n",
      "Ep 1 (Step 054140): Train loss 1.623, Val loss 1.805\n",
      "Ep 1 (Step 054145): Train loss 2.251, Val loss 1.800\n",
      "Ep 1 (Step 054150): Train loss 1.615, Val loss 1.815\n",
      "Ep 1 (Step 054155): Train loss 1.603, Val loss 1.823\n",
      "Ep 1 (Step 054160): Train loss 1.909, Val loss 1.828\n",
      "Ep 1 (Step 054165): Train loss 1.728, Val loss 1.818\n",
      "Ep 1 (Step 054170): Train loss 1.871, Val loss 1.807\n",
      "Ep 1 (Step 054175): Train loss 2.019, Val loss 1.805\n",
      "Ep 1 (Step 054180): Train loss 1.838, Val loss 1.813\n",
      "Ep 1 (Step 054185): Train loss 1.923, Val loss 1.819\n",
      "Ep 1 (Step 054190): Train loss 2.048, Val loss 1.824\n",
      "Ep 1 (Step 054195): Train loss 1.644, Val loss 1.820\n",
      "Ep 1 (Step 054200): Train loss 1.728, Val loss 1.810\n",
      "Ep 1 (Step 054205): Train loss 1.787, Val loss 1.809\n",
      "Ep 1 (Step 054210): Train loss 2.107, Val loss 1.805\n",
      "Ep 1 (Step 054215): Train loss 1.830, Val loss 1.806\n",
      "Ep 1 (Step 054220): Train loss 2.132, Val loss 1.813\n",
      "Ep 1 (Step 054225): Train loss 1.636, Val loss 1.824\n",
      "Ep 1 (Step 054230): Train loss 2.023, Val loss 1.813\n",
      "Ep 1 (Step 054235): Train loss 1.660, Val loss 1.805\n",
      "Ep 1 (Step 054240): Train loss 1.896, Val loss 1.806\n",
      "Ep 1 (Step 054245): Train loss 1.930, Val loss 1.807\n",
      "Ep 1 (Step 054250): Train loss 1.748, Val loss 1.811\n",
      "Ep 1 (Step 054255): Train loss 1.967, Val loss 1.805\n",
      "Ep 1 (Step 054260): Train loss 1.770, Val loss 1.804\n",
      "Ep 1 (Step 054265): Train loss 1.865, Val loss 1.809\n",
      "Ep 1 (Step 054270): Train loss 1.923, Val loss 1.822\n",
      "Ep 1 (Step 054275): Train loss 1.841, Val loss 1.827\n",
      "Ep 1 (Step 054280): Train loss 1.554, Val loss 1.809\n",
      "Ep 1 (Step 054285): Train loss 1.851, Val loss 1.792\n",
      "Ep 1 (Step 054290): Train loss 1.878, Val loss 1.788\n",
      "Ep 1 (Step 054295): Train loss 1.803, Val loss 1.801\n",
      "Ep 1 (Step 054300): Train loss 1.765, Val loss 1.804\n",
      "Ep 1 (Step 054305): Train loss 1.615, Val loss 1.807\n",
      "Ep 1 (Step 054310): Train loss 1.720, Val loss 1.811\n",
      "Ep 1 (Step 054315): Train loss 1.714, Val loss 1.813\n",
      "Ep 1 (Step 054320): Train loss 1.832, Val loss 1.810\n",
      "Ep 1 (Step 054325): Train loss 1.725, Val loss 1.809\n",
      "Ep 1 (Step 054330): Train loss 1.996, Val loss 1.804\n",
      "Ep 1 (Step 054335): Train loss 1.749, Val loss 1.814\n",
      "Ep 1 (Step 054340): Train loss 1.957, Val loss 1.821\n",
      "Ep 1 (Step 054345): Train loss 2.005, Val loss 1.819\n",
      "Ep 1 (Step 054350): Train loss 1.868, Val loss 1.816\n",
      "Ep 1 (Step 054355): Train loss 1.771, Val loss 1.817\n",
      "Ep 1 (Step 054360): Train loss 1.947, Val loss 1.826\n",
      "Ep 1 (Step 054365): Train loss 2.070, Val loss 1.814\n",
      "Ep 1 (Step 054370): Train loss 1.856, Val loss 1.812\n",
      "Ep 1 (Step 054375): Train loss 1.829, Val loss 1.806\n",
      "Ep 1 (Step 054380): Train loss 1.790, Val loss 1.799\n",
      "Ep 1 (Step 054385): Train loss 1.898, Val loss 1.795\n",
      "Ep 1 (Step 054390): Train loss 1.885, Val loss 1.806\n",
      "Ep 1 (Step 054395): Train loss 1.809, Val loss 1.812\n",
      "Ep 1 (Step 054400): Train loss 1.881, Val loss 1.817\n",
      "Ep 1 (Step 054405): Train loss 1.662, Val loss 1.817\n",
      "Ep 1 (Step 054410): Train loss 1.789, Val loss 1.809\n",
      "Ep 1 (Step 054415): Train loss 1.514, Val loss 1.809\n",
      "Ep 1 (Step 054420): Train loss 1.949, Val loss 1.810\n",
      "Ep 1 (Step 054425): Train loss 1.858, Val loss 1.819\n",
      "Ep 1 (Step 054430): Train loss 1.721, Val loss 1.815\n",
      "Ep 1 (Step 054435): Train loss 1.737, Val loss 1.812\n",
      "Ep 1 (Step 054440): Train loss 1.709, Val loss 1.822\n",
      "Ep 1 (Step 054445): Train loss 1.763, Val loss 1.827\n",
      "Ep 1 (Step 054450): Train loss 1.722, Val loss 1.823\n",
      "Ep 1 (Step 054455): Train loss 1.871, Val loss 1.828\n",
      "Ep 1 (Step 054460): Train loss 1.853, Val loss 1.836\n",
      "Ep 1 (Step 054465): Train loss 1.744, Val loss 1.838\n",
      "Ep 1 (Step 054470): Train loss 1.894, Val loss 1.815\n",
      "Ep 1 (Step 054475): Train loss 1.724, Val loss 1.806\n",
      "Ep 1 (Step 054480): Train loss 1.760, Val loss 1.814\n",
      "Ep 1 (Step 054485): Train loss 1.807, Val loss 1.817\n",
      "Ep 1 (Step 054490): Train loss 1.918, Val loss 1.806\n",
      "Ep 1 (Step 054495): Train loss 1.655, Val loss 1.795\n",
      "Ep 1 (Step 054500): Train loss 1.977, Val loss 1.806\n",
      "Ep 1 (Step 054505): Train loss 1.576, Val loss 1.810\n",
      "Ep 1 (Step 054510): Train loss 1.804, Val loss 1.801\n",
      "Ep 1 (Step 054515): Train loss 1.901, Val loss 1.805\n",
      "Ep 1 (Step 054520): Train loss 1.905, Val loss 1.808\n",
      "Ep 1 (Step 054525): Train loss 1.720, Val loss 1.804\n",
      "Ep 1 (Step 054530): Train loss 1.760, Val loss 1.811\n",
      "Ep 1 (Step 054535): Train loss 1.657, Val loss 1.805\n",
      "Ep 1 (Step 054540): Train loss 1.688, Val loss 1.793\n",
      "Ep 1 (Step 054545): Train loss 1.843, Val loss 1.800\n",
      "Ep 1 (Step 054550): Train loss 1.935, Val loss 1.816\n",
      "Ep 1 (Step 054555): Train loss 1.848, Val loss 1.832\n",
      "Ep 1 (Step 054560): Train loss 2.035, Val loss 1.830\n",
      "Ep 1 (Step 054565): Train loss 2.002, Val loss 1.822\n",
      "Ep 1 (Step 054570): Train loss 1.926, Val loss 1.817\n",
      "Ep 1 (Step 054575): Train loss 1.547, Val loss 1.820\n",
      "Ep 1 (Step 054580): Train loss 1.897, Val loss 1.829\n",
      "Ep 1 (Step 054585): Train loss 1.756, Val loss 1.820\n",
      "Ep 1 (Step 054590): Train loss 1.715, Val loss 1.812\n",
      "Ep 1 (Step 054595): Train loss 1.953, Val loss 1.812\n",
      "Ep 1 (Step 054600): Train loss 1.806, Val loss 1.824\n",
      "Ep 1 (Step 054605): Train loss 1.648, Val loss 1.828\n",
      "Ep 1 (Step 054610): Train loss 1.797, Val loss 1.821\n",
      "Ep 1 (Step 054615): Train loss 1.710, Val loss 1.817\n",
      "Ep 1 (Step 054620): Train loss 1.785, Val loss 1.825\n",
      "Ep 1 (Step 054625): Train loss 1.763, Val loss 1.821\n",
      "Ep 1 (Step 054630): Train loss 1.785, Val loss 1.810\n",
      "Ep 1 (Step 054635): Train loss 1.875, Val loss 1.820\n",
      "Ep 1 (Step 054640): Train loss 2.163, Val loss 1.827\n",
      "Ep 1 (Step 054645): Train loss 2.037, Val loss 1.824\n",
      "Ep 1 (Step 054650): Train loss 1.916, Val loss 1.821\n",
      "Ep 1 (Step 054655): Train loss 1.849, Val loss 1.824\n",
      "Ep 1 (Step 054660): Train loss 1.887, Val loss 1.823\n",
      "Ep 1 (Step 054665): Train loss 1.900, Val loss 1.822\n",
      "Ep 1 (Step 054670): Train loss 1.740, Val loss 1.814\n",
      "Ep 1 (Step 054675): Train loss 1.904, Val loss 1.809\n",
      "Ep 1 (Step 054680): Train loss 1.728, Val loss 1.811\n",
      "Ep 1 (Step 054685): Train loss 1.784, Val loss 1.807\n",
      "Ep 1 (Step 054690): Train loss 1.676, Val loss 1.803\n",
      "Ep 1 (Step 054695): Train loss 1.834, Val loss 1.804\n",
      "Ep 1 (Step 054700): Train loss 1.709, Val loss 1.824\n",
      "Ep 1 (Step 054705): Train loss 1.850, Val loss 1.842\n",
      "Ep 1 (Step 054710): Train loss 1.715, Val loss 1.832\n",
      "Ep 1 (Step 054715): Train loss 1.996, Val loss 1.831\n",
      "Ep 1 (Step 054720): Train loss 1.949, Val loss 1.832\n",
      "Ep 1 (Step 054725): Train loss 1.769, Val loss 1.826\n",
      "Ep 1 (Step 054730): Train loss 1.638, Val loss 1.807\n",
      "Ep 1 (Step 054735): Train loss 1.829, Val loss 1.804\n",
      "Ep 1 (Step 054740): Train loss 1.738, Val loss 1.812\n",
      "Ep 1 (Step 054745): Train loss 1.761, Val loss 1.805\n",
      "Ep 1 (Step 054750): Train loss 2.089, Val loss 1.800\n",
      "Ep 1 (Step 054755): Train loss 2.002, Val loss 1.797\n",
      "Ep 1 (Step 054760): Train loss 1.846, Val loss 1.794\n",
      "Ep 1 (Step 054765): Train loss 2.245, Val loss 1.785\n",
      "Ep 1 (Step 054770): Train loss 1.928, Val loss 1.785\n",
      "Ep 1 (Step 054775): Train loss 1.732, Val loss 1.788\n",
      "Ep 1 (Step 054780): Train loss 1.912, Val loss 1.782\n",
      "Ep 1 (Step 054785): Train loss 1.629, Val loss 1.790\n",
      "Ep 1 (Step 054790): Train loss 1.869, Val loss 1.794\n",
      "Ep 1 (Step 054795): Train loss 2.025, Val loss 1.788\n",
      "Ep 1 (Step 054800): Train loss 1.798, Val loss 1.784\n",
      "Ep 1 (Step 054805): Train loss 1.707, Val loss 1.778\n",
      "Ep 1 (Step 054810): Train loss 1.912, Val loss 1.779\n",
      "Ep 1 (Step 054815): Train loss 1.763, Val loss 1.782\n",
      "Ep 1 (Step 054820): Train loss 1.889, Val loss 1.790\n",
      "Ep 1 (Step 054825): Train loss 1.634, Val loss 1.793\n",
      "Ep 1 (Step 054830): Train loss 1.628, Val loss 1.802\n",
      "Ep 1 (Step 054835): Train loss 1.871, Val loss 1.801\n",
      "Ep 1 (Step 054840): Train loss 2.003, Val loss 1.800\n",
      "Ep 1 (Step 054845): Train loss 1.964, Val loss 1.799\n",
      "Ep 1 (Step 054850): Train loss 1.710, Val loss 1.796\n",
      "Ep 1 (Step 054855): Train loss 1.737, Val loss 1.800\n",
      "Ep 1 (Step 054860): Train loss 2.080, Val loss 1.804\n",
      "Ep 1 (Step 054865): Train loss 1.745, Val loss 1.797\n",
      "Ep 1 (Step 054870): Train loss 1.798, Val loss 1.800\n",
      "Ep 1 (Step 054875): Train loss 1.951, Val loss 1.804\n",
      "Ep 1 (Step 054880): Train loss 1.839, Val loss 1.804\n",
      "Ep 1 (Step 054885): Train loss 2.101, Val loss 1.804\n",
      "Ep 1 (Step 054890): Train loss 2.079, Val loss 1.801\n",
      "Ep 1 (Step 054895): Train loss 2.173, Val loss 1.793\n",
      "Ep 1 (Step 054900): Train loss 1.806, Val loss 1.787\n",
      "Ep 1 (Step 054905): Train loss 1.924, Val loss 1.795\n",
      "Ep 1 (Step 054910): Train loss 1.905, Val loss 1.803\n",
      "Ep 1 (Step 054915): Train loss 1.790, Val loss 1.800\n",
      "Ep 1 (Step 054920): Train loss 1.576, Val loss 1.803\n",
      "Ep 1 (Step 054925): Train loss 1.859, Val loss 1.800\n",
      "Ep 1 (Step 054930): Train loss 1.759, Val loss 1.800\n",
      "Ep 1 (Step 054935): Train loss 1.853, Val loss 1.799\n",
      "Ep 1 (Step 054940): Train loss 1.809, Val loss 1.805\n",
      "Ep 1 (Step 054945): Train loss 1.654, Val loss 1.810\n",
      "Ep 1 (Step 054950): Train loss 1.954, Val loss 1.813\n",
      "Ep 1 (Step 054955): Train loss 1.724, Val loss 1.815\n",
      "Ep 1 (Step 054960): Train loss 2.339, Val loss 1.813\n",
      "Ep 1 (Step 054965): Train loss 1.728, Val loss 1.814\n",
      "Ep 1 (Step 054970): Train loss 2.085, Val loss 1.813\n",
      "Ep 1 (Step 054975): Train loss 1.788, Val loss 1.799\n",
      "Ep 1 (Step 054980): Train loss 1.812, Val loss 1.793\n",
      "Ep 1 (Step 054985): Train loss 1.818, Val loss 1.796\n",
      "Ep 1 (Step 054990): Train loss 1.665, Val loss 1.801\n",
      "Ep 1 (Step 054995): Train loss 1.796, Val loss 1.802\n",
      "Ep 1 (Step 055000): Train loss 1.950, Val loss 1.800\n",
      "Ep 1 (Step 055005): Train loss 1.734, Val loss 1.795\n",
      "Ep 1 (Step 055010): Train loss 1.938, Val loss 1.782\n",
      "Ep 1 (Step 055015): Train loss 1.905, Val loss 1.773\n",
      "Ep 1 (Step 055020): Train loss 1.814, Val loss 1.776\n",
      "Ep 1 (Step 055025): Train loss 1.849, Val loss 1.792\n",
      "Ep 1 (Step 055030): Train loss 1.799, Val loss 1.788\n",
      "Ep 1 (Step 055035): Train loss 1.777, Val loss 1.779\n",
      "Ep 1 (Step 055040): Train loss 1.910, Val loss 1.782\n",
      "Ep 1 (Step 055045): Train loss 1.896, Val loss 1.771\n",
      "Ep 1 (Step 055050): Train loss 1.588, Val loss 1.771\n",
      "Ep 1 (Step 055055): Train loss 1.652, Val loss 1.772\n",
      "Ep 1 (Step 055060): Train loss 1.702, Val loss 1.774\n",
      "Ep 1 (Step 055065): Train loss 1.511, Val loss 1.769\n",
      "Ep 1 (Step 055070): Train loss 1.658, Val loss 1.760\n",
      "Ep 1 (Step 055075): Train loss 1.693, Val loss 1.759\n",
      "Ep 1 (Step 055080): Train loss 1.832, Val loss 1.767\n",
      "Ep 1 (Step 055085): Train loss 1.659, Val loss 1.775\n",
      "Ep 1 (Step 055090): Train loss 1.761, Val loss 1.777\n",
      "Ep 1 (Step 055095): Train loss 1.664, Val loss 1.775\n",
      "Ep 1 (Step 055100): Train loss 1.822, Val loss 1.776\n",
      "Ep 1 (Step 055105): Train loss 1.753, Val loss 1.771\n",
      "Ep 1 (Step 055110): Train loss 1.513, Val loss 1.764\n",
      "Ep 1 (Step 055115): Train loss 1.867, Val loss 1.764\n",
      "Ep 1 (Step 055120): Train loss 1.863, Val loss 1.760\n",
      "Ep 1 (Step 055125): Train loss 1.963, Val loss 1.756\n",
      "Ep 1 (Step 055130): Train loss 1.703, Val loss 1.759\n",
      "Ep 1 (Step 055135): Train loss 1.951, Val loss 1.764\n",
      "Ep 1 (Step 055140): Train loss 1.803, Val loss 1.771\n",
      "Ep 1 (Step 055145): Train loss 2.001, Val loss 1.767\n",
      "Ep 1 (Step 055150): Train loss 1.920, Val loss 1.761\n",
      "Ep 1 (Step 055155): Train loss 1.779, Val loss 1.757\n",
      "Ep 1 (Step 055160): Train loss 1.814, Val loss 1.758\n",
      "Ep 1 (Step 055165): Train loss 1.791, Val loss 1.760\n",
      "Ep 1 (Step 055170): Train loss 1.610, Val loss 1.754\n",
      "Ep 1 (Step 055175): Train loss 1.770, Val loss 1.751\n",
      "Ep 1 (Step 055180): Train loss 1.855, Val loss 1.757\n",
      "Ep 1 (Step 055185): Train loss 1.888, Val loss 1.757\n",
      "Ep 1 (Step 055190): Train loss 1.629, Val loss 1.759\n",
      "Ep 1 (Step 055195): Train loss 2.148, Val loss 1.751\n",
      "Ep 1 (Step 055200): Train loss 1.769, Val loss 1.738\n",
      "Ep 1 (Step 055205): Train loss 1.923, Val loss 1.741\n",
      "Ep 1 (Step 055210): Train loss 1.818, Val loss 1.741\n",
      "Ep 1 (Step 055215): Train loss 1.905, Val loss 1.748\n",
      "Ep 1 (Step 055220): Train loss 1.731, Val loss 1.760\n",
      "Ep 1 (Step 055225): Train loss 2.007, Val loss 1.757\n",
      "Ep 1 (Step 055230): Train loss 1.703, Val loss 1.759\n",
      "Ep 1 (Step 055235): Train loss 1.957, Val loss 1.760\n",
      "Ep 1 (Step 055240): Train loss 1.554, Val loss 1.765\n",
      "Ep 1 (Step 055245): Train loss 2.282, Val loss 1.764\n",
      "Ep 1 (Step 055250): Train loss 1.793, Val loss 1.763\n",
      "Ep 1 (Step 055255): Train loss 1.577, Val loss 1.766\n",
      "Ep 1 (Step 055260): Train loss 1.634, Val loss 1.770\n",
      "Ep 1 (Step 055265): Train loss 1.643, Val loss 1.776\n",
      "Ep 1 (Step 055270): Train loss 2.083, Val loss 1.776\n",
      "Ep 1 (Step 055275): Train loss 1.976, Val loss 1.779\n",
      "Ep 1 (Step 055280): Train loss 1.650, Val loss 1.775\n",
      "Ep 1 (Step 055285): Train loss 2.012, Val loss 1.779\n",
      "Ep 1 (Step 055290): Train loss 1.667, Val loss 1.778\n",
      "Ep 1 (Step 055295): Train loss 1.762, Val loss 1.776\n",
      "Ep 1 (Step 055300): Train loss 1.661, Val loss 1.780\n",
      "Ep 1 (Step 055305): Train loss 1.769, Val loss 1.780\n",
      "Ep 1 (Step 055310): Train loss 1.830, Val loss 1.777\n",
      "Ep 1 (Step 055315): Train loss 1.930, Val loss 1.784\n",
      "Ep 1 (Step 055320): Train loss 1.770, Val loss 1.781\n",
      "Ep 1 (Step 055325): Train loss 2.096, Val loss 1.788\n",
      "Ep 1 (Step 055330): Train loss 1.482, Val loss 1.788\n",
      "Ep 1 (Step 055335): Train loss 1.757, Val loss 1.789\n",
      "Ep 1 (Step 055340): Train loss 1.896, Val loss 1.778\n",
      "Ep 1 (Step 055345): Train loss 1.892, Val loss 1.771\n",
      "Ep 1 (Step 055350): Train loss 1.822, Val loss 1.771\n",
      "Ep 1 (Step 055355): Train loss 2.016, Val loss 1.785\n",
      "Ep 1 (Step 055360): Train loss 1.730, Val loss 1.795\n",
      "Ep 1 (Step 055365): Train loss 1.860, Val loss 1.785\n",
      "Ep 1 (Step 055370): Train loss 1.613, Val loss 1.782\n",
      "Ep 1 (Step 055375): Train loss 1.757, Val loss 1.789\n",
      "Ep 1 (Step 055380): Train loss 1.933, Val loss 1.787\n",
      "Ep 1 (Step 055385): Train loss 1.882, Val loss 1.774\n",
      "Ep 1 (Step 055390): Train loss 1.757, Val loss 1.768\n",
      "Ep 1 (Step 055395): Train loss 1.800, Val loss 1.765\n",
      "Ep 1 (Step 055400): Train loss 1.923, Val loss 1.760\n",
      "Ep 1 (Step 055405): Train loss 1.811, Val loss 1.755\n",
      "Ep 1 (Step 055410): Train loss 1.709, Val loss 1.750\n",
      "Ep 1 (Step 055415): Train loss 1.729, Val loss 1.749\n",
      "Ep 1 (Step 055420): Train loss 1.931, Val loss 1.753\n",
      "Ep 1 (Step 055425): Train loss 1.888, Val loss 1.761\n",
      "Ep 1 (Step 055430): Train loss 1.782, Val loss 1.770\n",
      "Ep 1 (Step 055435): Train loss 1.755, Val loss 1.782\n",
      "Ep 1 (Step 055440): Train loss 1.840, Val loss 1.788\n",
      "Ep 1 (Step 055445): Train loss 1.953, Val loss 1.783\n",
      "Ep 1 (Step 055450): Train loss 1.965, Val loss 1.785\n",
      "Ep 1 (Step 055455): Train loss 1.767, Val loss 1.784\n",
      "Ep 1 (Step 055460): Train loss 1.761, Val loss 1.782\n",
      "Ep 1 (Step 055465): Train loss 2.074, Val loss 1.790\n",
      "Ep 1 (Step 055470): Train loss 1.726, Val loss 1.795\n",
      "Ep 1 (Step 055475): Train loss 1.784, Val loss 1.798\n",
      "Ep 1 (Step 055480): Train loss 1.748, Val loss 1.788\n",
      "Ep 1 (Step 055485): Train loss 2.006, Val loss 1.783\n",
      "Ep 1 (Step 055490): Train loss 1.888, Val loss 1.780\n",
      "Ep 1 (Step 055495): Train loss 1.886, Val loss 1.784\n",
      "Ep 1 (Step 055500): Train loss 2.127, Val loss 1.782\n",
      "Ep 1 (Step 055505): Train loss 1.858, Val loss 1.782\n",
      "Ep 1 (Step 055510): Train loss 1.923, Val loss 1.786\n",
      "Ep 1 (Step 055515): Train loss 2.065, Val loss 1.796\n",
      "Ep 1 (Step 055520): Train loss 1.853, Val loss 1.798\n",
      "Ep 1 (Step 055525): Train loss 1.744, Val loss 1.794\n",
      "Ep 1 (Step 055530): Train loss 1.666, Val loss 1.788\n",
      "Ep 1 (Step 055535): Train loss 1.648, Val loss 1.785\n",
      "Ep 1 (Step 055540): Train loss 1.788, Val loss 1.782\n",
      "Ep 1 (Step 055545): Train loss 1.922, Val loss 1.787\n",
      "Ep 1 (Step 055550): Train loss 1.975, Val loss 1.791\n",
      "Ep 1 (Step 055555): Train loss 1.588, Val loss 1.793\n",
      "Ep 1 (Step 055560): Train loss 1.697, Val loss 1.785\n",
      "Ep 1 (Step 055565): Train loss 2.091, Val loss 1.777\n",
      "Ep 1 (Step 055570): Train loss 1.695, Val loss 1.785\n",
      "Ep 1 (Step 055575): Train loss 1.750, Val loss 1.796\n",
      "Ep 1 (Step 055580): Train loss 1.784, Val loss 1.795\n",
      "Ep 1 (Step 055585): Train loss 1.742, Val loss 1.790\n",
      "Ep 1 (Step 055590): Train loss 1.722, Val loss 1.786\n",
      "Ep 1 (Step 055595): Train loss 1.783, Val loss 1.788\n",
      "Ep 1 (Step 055600): Train loss 1.805, Val loss 1.794\n",
      "Ep 1 (Step 055605): Train loss 1.647, Val loss 1.796\n",
      "Ep 1 (Step 055610): Train loss 1.917, Val loss 1.799\n",
      "Ep 1 (Step 055615): Train loss 1.807, Val loss 1.810\n",
      "Ep 1 (Step 055620): Train loss 1.859, Val loss 1.804\n",
      "Ep 1 (Step 055625): Train loss 2.292, Val loss 1.801\n",
      "Ep 1 (Step 055630): Train loss 1.758, Val loss 1.803\n",
      "Ep 1 (Step 055635): Train loss 1.881, Val loss 1.799\n",
      "Ep 1 (Step 055640): Train loss 1.782, Val loss 1.796\n",
      "Ep 1 (Step 055645): Train loss 1.788, Val loss 1.794\n",
      "Ep 1 (Step 055650): Train loss 1.627, Val loss 1.793\n",
      "Ep 1 (Step 055655): Train loss 1.636, Val loss 1.784\n",
      "Ep 1 (Step 055660): Train loss 1.795, Val loss 1.783\n",
      "Ep 1 (Step 055665): Train loss 1.591, Val loss 1.796\n",
      "Ep 1 (Step 055670): Train loss 1.864, Val loss 1.798\n",
      "Ep 1 (Step 055675): Train loss 2.113, Val loss 1.792\n",
      "Ep 1 (Step 055680): Train loss 1.843, Val loss 1.792\n",
      "Ep 1 (Step 055685): Train loss 1.709, Val loss 1.792\n",
      "Ep 1 (Step 055690): Train loss 2.048, Val loss 1.776\n",
      "Ep 1 (Step 055695): Train loss 1.613, Val loss 1.761\n",
      "Ep 1 (Step 055700): Train loss 1.941, Val loss 1.761\n",
      "Ep 1 (Step 055705): Train loss 1.904, Val loss 1.768\n",
      "Ep 1 (Step 055710): Train loss 1.849, Val loss 1.764\n",
      "Ep 1 (Step 055715): Train loss 1.858, Val loss 1.756\n",
      "Ep 1 (Step 055720): Train loss 2.013, Val loss 1.752\n",
      "Ep 1 (Step 055725): Train loss 1.953, Val loss 1.758\n",
      "Ep 1 (Step 055730): Train loss 1.677, Val loss 1.768\n",
      "Ep 1 (Step 055735): Train loss 1.635, Val loss 1.765\n",
      "Ep 1 (Step 055740): Train loss 1.908, Val loss 1.762\n",
      "Ep 1 (Step 055745): Train loss 1.655, Val loss 1.759\n",
      "Ep 1 (Step 055750): Train loss 1.779, Val loss 1.760\n",
      "Ep 1 (Step 055755): Train loss 1.733, Val loss 1.770\n",
      "Ep 1 (Step 055760): Train loss 1.758, Val loss 1.772\n",
      "Ep 1 (Step 055765): Train loss 1.817, Val loss 1.778\n",
      "Ep 1 (Step 055770): Train loss 1.568, Val loss 1.778\n",
      "Ep 1 (Step 055775): Train loss 1.887, Val loss 1.774\n",
      "Ep 1 (Step 055780): Train loss 1.775, Val loss 1.772\n",
      "Ep 1 (Step 055785): Train loss 1.761, Val loss 1.778\n",
      "Ep 1 (Step 055790): Train loss 1.986, Val loss 1.782\n",
      "Ep 1 (Step 055795): Train loss 1.761, Val loss 1.780\n",
      "Ep 1 (Step 055800): Train loss 1.810, Val loss 1.768\n",
      "Ep 1 (Step 055805): Train loss 1.618, Val loss 1.766\n",
      "Ep 1 (Step 055810): Train loss 1.807, Val loss 1.784\n",
      "Ep 1 (Step 055815): Train loss 2.055, Val loss 1.789\n",
      "Ep 1 (Step 055820): Train loss 1.636, Val loss 1.795\n",
      "Ep 1 (Step 055825): Train loss 1.800, Val loss 1.800\n",
      "Ep 1 (Step 055830): Train loss 1.899, Val loss 1.800\n",
      "Ep 1 (Step 055835): Train loss 1.466, Val loss 1.795\n",
      "Ep 1 (Step 055840): Train loss 1.889, Val loss 1.787\n",
      "Ep 1 (Step 055845): Train loss 1.765, Val loss 1.785\n",
      "Ep 1 (Step 055850): Train loss 1.731, Val loss 1.787\n",
      "Ep 1 (Step 055855): Train loss 1.855, Val loss 1.786\n",
      "Ep 1 (Step 055860): Train loss 1.797, Val loss 1.786\n",
      "Ep 1 (Step 055865): Train loss 1.913, Val loss 1.782\n",
      "Ep 1 (Step 055870): Train loss 1.658, Val loss 1.783\n",
      "Ep 1 (Step 055875): Train loss 1.592, Val loss 1.782\n",
      "Ep 1 (Step 055880): Train loss 1.730, Val loss 1.788\n",
      "Ep 1 (Step 055885): Train loss 1.918, Val loss 1.785\n",
      "Ep 1 (Step 055890): Train loss 1.517, Val loss 1.786\n",
      "Ep 1 (Step 055895): Train loss 1.895, Val loss 1.786\n",
      "Ep 1 (Step 055900): Train loss 1.987, Val loss 1.784\n",
      "Ep 1 (Step 055905): Train loss 2.124, Val loss 1.777\n",
      "Ep 1 (Step 055910): Train loss 1.874, Val loss 1.780\n",
      "Ep 1 (Step 055915): Train loss 1.907, Val loss 1.782\n",
      "Ep 1 (Step 055920): Train loss 1.709, Val loss 1.791\n",
      "Ep 1 (Step 055925): Train loss 1.665, Val loss 1.789\n",
      "Ep 1 (Step 055930): Train loss 1.873, Val loss 1.787\n",
      "Ep 1 (Step 055935): Train loss 1.945, Val loss 1.790\n",
      "Ep 1 (Step 055940): Train loss 1.837, Val loss 1.788\n",
      "Ep 1 (Step 055945): Train loss 2.081, Val loss 1.779\n",
      "Ep 1 (Step 055950): Train loss 1.692, Val loss 1.777\n",
      "Ep 1 (Step 055955): Train loss 1.593, Val loss 1.775\n",
      "Ep 1 (Step 055960): Train loss 1.760, Val loss 1.777\n",
      "Ep 1 (Step 055965): Train loss 1.703, Val loss 1.783\n",
      "Ep 1 (Step 055970): Train loss 1.571, Val loss 1.789\n",
      "Ep 1 (Step 055975): Train loss 1.659, Val loss 1.784\n",
      "Ep 1 (Step 055980): Train loss 1.687, Val loss 1.792\n",
      "Ep 1 (Step 055985): Train loss 1.764, Val loss 1.798\n",
      "Ep 1 (Step 055990): Train loss 1.857, Val loss 1.799\n",
      "Ep 1 (Step 055995): Train loss 1.677, Val loss 1.802\n",
      "Ep 1 (Step 056000): Train loss 1.524, Val loss 1.796\n",
      "Ep 1 (Step 056005): Train loss 1.826, Val loss 1.826\n",
      "Ep 1 (Step 056010): Train loss 1.673, Val loss 1.823\n",
      "Ep 1 (Step 056015): Train loss 1.772, Val loss 1.827\n",
      "Ep 1 (Step 056020): Train loss 1.661, Val loss 1.821\n",
      "Ep 1 (Step 056025): Train loss 2.228, Val loss 1.806\n",
      "Ep 1 (Step 056030): Train loss 1.797, Val loss 1.805\n",
      "Ep 1 (Step 056035): Train loss 1.626, Val loss 1.789\n",
      "Ep 1 (Step 056040): Train loss 1.982, Val loss 1.790\n",
      "Ep 1 (Step 056045): Train loss 1.788, Val loss 1.789\n",
      "Ep 1 (Step 056050): Train loss 1.698, Val loss 1.781\n",
      "Ep 1 (Step 056055): Train loss 1.691, Val loss 1.781\n",
      "Ep 1 (Step 056060): Train loss 1.695, Val loss 1.782\n",
      "Ep 1 (Step 056065): Train loss 1.685, Val loss 1.773\n",
      "Ep 1 (Step 056070): Train loss 1.834, Val loss 1.774\n",
      "Ep 1 (Step 056075): Train loss 1.894, Val loss 1.772\n",
      "Ep 1 (Step 056080): Train loss 1.843, Val loss 1.770\n",
      "Ep 1 (Step 056085): Train loss 1.770, Val loss 1.779\n",
      "Ep 1 (Step 056090): Train loss 1.802, Val loss 1.785\n",
      "Ep 1 (Step 056095): Train loss 1.855, Val loss 1.780\n",
      "Ep 1 (Step 056100): Train loss 1.686, Val loss 1.776\n",
      "Ep 1 (Step 056105): Train loss 1.951, Val loss 1.782\n",
      "Ep 1 (Step 056110): Train loss 1.928, Val loss 1.776\n",
      "Ep 1 (Step 056115): Train loss 1.601, Val loss 1.769\n",
      "Ep 1 (Step 056120): Train loss 1.836, Val loss 1.767\n",
      "Ep 1 (Step 056125): Train loss 1.889, Val loss 1.766\n",
      "Ep 1 (Step 056130): Train loss 1.839, Val loss 1.763\n",
      "Ep 1 (Step 056135): Train loss 1.855, Val loss 1.757\n",
      "Ep 1 (Step 056140): Train loss 1.864, Val loss 1.756\n",
      "Ep 1 (Step 056145): Train loss 1.734, Val loss 1.759\n",
      "Ep 1 (Step 056150): Train loss 1.776, Val loss 1.767\n",
      "Ep 1 (Step 056155): Train loss 1.665, Val loss 1.759\n",
      "Ep 1 (Step 056160): Train loss 1.961, Val loss 1.759\n",
      "Ep 1 (Step 056165): Train loss 1.533, Val loss 1.766\n",
      "Ep 1 (Step 056170): Train loss 1.642, Val loss 1.771\n",
      "Ep 1 (Step 056175): Train loss 1.813, Val loss 1.767\n",
      "Ep 1 (Step 056180): Train loss 1.665, Val loss 1.761\n",
      "Ep 1 (Step 056185): Train loss 1.927, Val loss 1.763\n",
      "Ep 1 (Step 056190): Train loss 2.033, Val loss 1.768\n",
      "Ep 1 (Step 056195): Train loss 1.447, Val loss 1.768\n",
      "Ep 1 (Step 056200): Train loss 1.669, Val loss 1.765\n",
      "Ep 1 (Step 056205): Train loss 1.802, Val loss 1.774\n",
      "Ep 1 (Step 056210): Train loss 1.838, Val loss 1.773\n",
      "Ep 1 (Step 056215): Train loss 1.936, Val loss 1.770\n",
      "Ep 1 (Step 056220): Train loss 1.837, Val loss 1.763\n",
      "Ep 1 (Step 056225): Train loss 2.092, Val loss 1.765\n",
      "Ep 1 (Step 056230): Train loss 1.826, Val loss 1.767\n",
      "Ep 1 (Step 056235): Train loss 1.986, Val loss 1.768\n",
      "Ep 1 (Step 056240): Train loss 1.967, Val loss 1.759\n",
      "Ep 1 (Step 056245): Train loss 2.280, Val loss 1.754\n",
      "Ep 1 (Step 056250): Train loss 1.510, Val loss 1.752\n",
      "Ep 1 (Step 056255): Train loss 1.554, Val loss 1.761\n",
      "Ep 1 (Step 056260): Train loss 1.668, Val loss 1.774\n",
      "Ep 1 (Step 056265): Train loss 1.719, Val loss 1.767\n",
      "Ep 1 (Step 056270): Train loss 2.055, Val loss 1.768\n",
      "Ep 1 (Step 056275): Train loss 1.810, Val loss 1.771\n",
      "Ep 1 (Step 056280): Train loss 2.119, Val loss 1.763\n",
      "Ep 1 (Step 056285): Train loss 1.700, Val loss 1.764\n",
      "Ep 1 (Step 056290): Train loss 1.933, Val loss 1.768\n",
      "Ep 1 (Step 056295): Train loss 1.703, Val loss 1.762\n",
      "Ep 1 (Step 056300): Train loss 2.016, Val loss 1.768\n",
      "Ep 1 (Step 056305): Train loss 2.227, Val loss 1.773\n",
      "Ep 1 (Step 056310): Train loss 1.823, Val loss 1.774\n",
      "Ep 1 (Step 056315): Train loss 1.871, Val loss 1.774\n",
      "Ep 1 (Step 056320): Train loss 1.830, Val loss 1.768\n",
      "Ep 1 (Step 056325): Train loss 1.966, Val loss 1.766\n",
      "Ep 1 (Step 056330): Train loss 1.645, Val loss 1.768\n",
      "Ep 1 (Step 056335): Train loss 1.719, Val loss 1.773\n",
      "Ep 1 (Step 056340): Train loss 1.910, Val loss 1.765\n",
      "Ep 1 (Step 056345): Train loss 1.709, Val loss 1.762\n",
      "Ep 1 (Step 056350): Train loss 1.935, Val loss 1.767\n",
      "Ep 1 (Step 056355): Train loss 1.943, Val loss 1.769\n",
      "Ep 1 (Step 056360): Train loss 2.127, Val loss 1.778\n",
      "Ep 1 (Step 056365): Train loss 1.646, Val loss 1.775\n",
      "Ep 1 (Step 056370): Train loss 1.945, Val loss 1.772\n",
      "Ep 1 (Step 056375): Train loss 2.083, Val loss 1.775\n",
      "Ep 1 (Step 056380): Train loss 1.897, Val loss 1.772\n",
      "Ep 1 (Step 056385): Train loss 1.946, Val loss 1.772\n",
      "Ep 1 (Step 056390): Train loss 1.998, Val loss 1.773\n",
      "Ep 1 (Step 056395): Train loss 1.926, Val loss 1.772\n",
      "Ep 1 (Step 056400): Train loss 1.887, Val loss 1.768\n",
      "Ep 1 (Step 056405): Train loss 1.724, Val loss 1.763\n",
      "Ep 1 (Step 056410): Train loss 2.088, Val loss 1.766\n",
      "Ep 1 (Step 056415): Train loss 1.681, Val loss 1.766\n",
      "Ep 1 (Step 056420): Train loss 1.799, Val loss 1.765\n",
      "Ep 1 (Step 056425): Train loss 1.909, Val loss 1.767\n",
      "Ep 1 (Step 056430): Train loss 1.516, Val loss 1.764\n",
      "Ep 1 (Step 056435): Train loss 1.775, Val loss 1.766\n",
      "Ep 1 (Step 056440): Train loss 1.819, Val loss 1.780\n",
      "Ep 1 (Step 056445): Train loss 2.004, Val loss 1.786\n",
      "Ep 1 (Step 056450): Train loss 1.840, Val loss 1.782\n",
      "Ep 1 (Step 056455): Train loss 1.894, Val loss 1.781\n",
      "Ep 1 (Step 056460): Train loss 1.600, Val loss 1.778\n",
      "Ep 1 (Step 056465): Train loss 1.827, Val loss 1.776\n",
      "Ep 1 (Step 056470): Train loss 1.593, Val loss 1.770\n",
      "Ep 1 (Step 056475): Train loss 1.852, Val loss 1.764\n",
      "Ep 1 (Step 056480): Train loss 1.970, Val loss 1.768\n",
      "Ep 1 (Step 056485): Train loss 1.894, Val loss 1.770\n",
      "Ep 1 (Step 056490): Train loss 1.827, Val loss 1.773\n",
      "Ep 1 (Step 056495): Train loss 2.042, Val loss 1.772\n",
      "Ep 1 (Step 056500): Train loss 1.744, Val loss 1.783\n",
      "Ep 1 (Step 056505): Train loss 1.954, Val loss 1.792\n",
      "Ep 1 (Step 056510): Train loss 1.767, Val loss 1.789\n",
      "Ep 1 (Step 056515): Train loss 1.787, Val loss 1.778\n",
      "Ep 1 (Step 056520): Train loss 1.903, Val loss 1.777\n",
      "Ep 1 (Step 056525): Train loss 1.990, Val loss 1.782\n",
      "Ep 1 (Step 056530): Train loss 1.692, Val loss 1.786\n",
      "Ep 1 (Step 056535): Train loss 2.125, Val loss 1.784\n",
      "Ep 1 (Step 056540): Train loss 1.814, Val loss 1.777\n",
      "Ep 1 (Step 056545): Train loss 1.922, Val loss 1.779\n",
      "Ep 1 (Step 056550): Train loss 1.681, Val loss 1.784\n",
      "Ep 1 (Step 056555): Train loss 1.836, Val loss 1.787\n",
      "Ep 1 (Step 056560): Train loss 1.546, Val loss 1.785\n",
      "Ep 1 (Step 056565): Train loss 1.861, Val loss 1.775\n",
      "Ep 1 (Step 056570): Train loss 1.838, Val loss 1.775\n",
      "Ep 1 (Step 056575): Train loss 1.610, Val loss 1.780\n",
      "Ep 1 (Step 056580): Train loss 1.746, Val loss 1.783\n",
      "Ep 1 (Step 056585): Train loss 1.541, Val loss 1.785\n",
      "Ep 1 (Step 056590): Train loss 1.647, Val loss 1.790\n",
      "Ep 1 (Step 056595): Train loss 1.661, Val loss 1.788\n",
      "Ep 1 (Step 056600): Train loss 1.725, Val loss 1.764\n",
      "Ep 1 (Step 056605): Train loss 1.823, Val loss 1.760\n",
      "Ep 1 (Step 056610): Train loss 1.767, Val loss 1.763\n",
      "Ep 1 (Step 056615): Train loss 1.782, Val loss 1.762\n",
      "Ep 1 (Step 056620): Train loss 1.674, Val loss 1.765\n",
      "Ep 1 (Step 056625): Train loss 1.666, Val loss 1.768\n",
      "Ep 1 (Step 056630): Train loss 1.807, Val loss 1.774\n",
      "Ep 1 (Step 056635): Train loss 1.938, Val loss 1.777\n",
      "Ep 1 (Step 056640): Train loss 1.708, Val loss 1.779\n",
      "Ep 1 (Step 056645): Train loss 1.751, Val loss 1.772\n",
      "Ep 1 (Step 056650): Train loss 1.815, Val loss 1.759\n",
      "Ep 1 (Step 056655): Train loss 2.068, Val loss 1.754\n",
      "Ep 1 (Step 056660): Train loss 1.860, Val loss 1.761\n",
      "Ep 1 (Step 056665): Train loss 1.994, Val loss 1.761\n",
      "Ep 1 (Step 056670): Train loss 1.642, Val loss 1.764\n",
      "Ep 1 (Step 056675): Train loss 1.524, Val loss 1.767\n",
      "Ep 1 (Step 056680): Train loss 1.778, Val loss 1.775\n",
      "Ep 1 (Step 056685): Train loss 1.757, Val loss 1.774\n",
      "Ep 1 (Step 056690): Train loss 1.862, Val loss 1.780\n",
      "Ep 1 (Step 056695): Train loss 1.925, Val loss 1.780\n",
      "Ep 1 (Step 056700): Train loss 1.585, Val loss 1.781\n",
      "Ep 1 (Step 056705): Train loss 1.749, Val loss 1.785\n",
      "Ep 1 (Step 056710): Train loss 1.542, Val loss 1.781\n",
      "Ep 1 (Step 056715): Train loss 1.707, Val loss 1.776\n",
      "Ep 1 (Step 056720): Train loss 1.874, Val loss 1.780\n",
      "Ep 1 (Step 056725): Train loss 1.771, Val loss 1.783\n",
      "Ep 1 (Step 056730): Train loss 1.807, Val loss 1.792\n",
      "Ep 1 (Step 056735): Train loss 1.774, Val loss 1.793\n",
      "Ep 1 (Step 056740): Train loss 1.867, Val loss 1.787\n",
      "Ep 1 (Step 056745): Train loss 1.809, Val loss 1.783\n",
      "Ep 1 (Step 056750): Train loss 1.827, Val loss 1.774\n",
      "Ep 1 (Step 056755): Train loss 1.708, Val loss 1.772\n",
      "Ep 1 (Step 056760): Train loss 1.621, Val loss 1.778\n",
      "Ep 1 (Step 056765): Train loss 1.828, Val loss 1.784\n",
      "Ep 1 (Step 056770): Train loss 1.669, Val loss 1.777\n",
      "Ep 1 (Step 056775): Train loss 1.840, Val loss 1.778\n",
      "Ep 1 (Step 056780): Train loss 1.885, Val loss 1.775\n",
      "Ep 1 (Step 056785): Train loss 1.490, Val loss 1.779\n",
      "Ep 1 (Step 056790): Train loss 1.982, Val loss 1.781\n",
      "Ep 1 (Step 056795): Train loss 1.986, Val loss 1.774\n",
      "Ep 1 (Step 056800): Train loss 1.979, Val loss 1.776\n",
      "Ep 1 (Step 056805): Train loss 1.729, Val loss 1.783\n",
      "Ep 1 (Step 056810): Train loss 1.753, Val loss 1.780\n",
      "Ep 1 (Step 056815): Train loss 2.076, Val loss 1.780\n",
      "Ep 1 (Step 056820): Train loss 1.699, Val loss 1.786\n",
      "Ep 1 (Step 056825): Train loss 1.896, Val loss 1.773\n",
      "Ep 1 (Step 056830): Train loss 1.542, Val loss 1.769\n",
      "Ep 1 (Step 056835): Train loss 1.757, Val loss 1.770\n",
      "Ep 1 (Step 056840): Train loss 1.643, Val loss 1.772\n",
      "Ep 1 (Step 056845): Train loss 1.638, Val loss 1.780\n",
      "Ep 1 (Step 056850): Train loss 1.716, Val loss 1.784\n",
      "Ep 1 (Step 056855): Train loss 1.833, Val loss 1.788\n",
      "Ep 1 (Step 056860): Train loss 1.852, Val loss 1.781\n",
      "Ep 1 (Step 056865): Train loss 1.992, Val loss 1.774\n",
      "Ep 1 (Step 056870): Train loss 1.876, Val loss 1.771\n",
      "Ep 1 (Step 056875): Train loss 1.743, Val loss 1.772\n",
      "Ep 1 (Step 056880): Train loss 1.763, Val loss 1.777\n",
      "Ep 1 (Step 056885): Train loss 1.901, Val loss 1.775\n",
      "Ep 1 (Step 056890): Train loss 1.798, Val loss 1.777\n",
      "Ep 1 (Step 056895): Train loss 1.750, Val loss 1.786\n",
      "Ep 1 (Step 056900): Train loss 1.475, Val loss 1.793\n",
      "Ep 1 (Step 056905): Train loss 1.806, Val loss 1.794\n",
      "Ep 1 (Step 056910): Train loss 2.079, Val loss 1.793\n",
      "Ep 1 (Step 056915): Train loss 1.921, Val loss 1.790\n",
      "Ep 1 (Step 056920): Train loss 1.770, Val loss 1.792\n",
      "Ep 1 (Step 056925): Train loss 1.810, Val loss 1.798\n",
      "Ep 1 (Step 056930): Train loss 1.909, Val loss 1.802\n",
      "Ep 1 (Step 056935): Train loss 1.743, Val loss 1.797\n",
      "Ep 1 (Step 056940): Train loss 2.072, Val loss 1.793\n",
      "Ep 1 (Step 056945): Train loss 1.707, Val loss 1.785\n",
      "Ep 1 (Step 056950): Train loss 1.868, Val loss 1.791\n",
      "Ep 1 (Step 056955): Train loss 2.137, Val loss 1.796\n",
      "Ep 1 (Step 056960): Train loss 1.928, Val loss 1.801\n",
      "Ep 1 (Step 056965): Train loss 1.770, Val loss 1.807\n",
      "Ep 1 (Step 056970): Train loss 1.926, Val loss 1.806\n",
      "Ep 1 (Step 056975): Train loss 1.471, Val loss 1.803\n",
      "Ep 1 (Step 056980): Train loss 1.485, Val loss 1.798\n",
      "Ep 1 (Step 056985): Train loss 1.978, Val loss 1.797\n",
      "Ep 1 (Step 056990): Train loss 1.876, Val loss 1.785\n",
      "Ep 1 (Step 056995): Train loss 1.884, Val loss 1.774\n",
      "Ep 1 (Step 057000): Train loss 1.784, Val loss 1.775\n",
      "Ep 1 (Step 057005): Train loss 1.753, Val loss 1.783\n",
      "Ep 1 (Step 057010): Train loss 2.067, Val loss 1.792\n",
      "Ep 1 (Step 057015): Train loss 1.594, Val loss 1.785\n",
      "Ep 1 (Step 057020): Train loss 1.849, Val loss 1.784\n",
      "Ep 1 (Step 057025): Train loss 1.843, Val loss 1.778\n",
      "Ep 1 (Step 057030): Train loss 1.732, Val loss 1.777\n",
      "Ep 1 (Step 057035): Train loss 1.826, Val loss 1.782\n",
      "Ep 1 (Step 057040): Train loss 1.857, Val loss 1.784\n",
      "Ep 1 (Step 057045): Train loss 1.824, Val loss 1.788\n",
      "Ep 1 (Step 057050): Train loss 2.013, Val loss 1.785\n",
      "Ep 1 (Step 057055): Train loss 2.102, Val loss 1.789\n",
      "Ep 1 (Step 057060): Train loss 1.972, Val loss 1.789\n",
      "Ep 1 (Step 057065): Train loss 1.833, Val loss 1.784\n",
      "Ep 1 (Step 057070): Train loss 2.022, Val loss 1.787\n",
      "Ep 1 (Step 057075): Train loss 1.832, Val loss 1.775\n",
      "Ep 1 (Step 057080): Train loss 1.797, Val loss 1.770\n",
      "Ep 1 (Step 057085): Train loss 1.971, Val loss 1.771\n",
      "Ep 1 (Step 057090): Train loss 1.992, Val loss 1.773\n",
      "Ep 1 (Step 057095): Train loss 1.945, Val loss 1.774\n",
      "Ep 1 (Step 057100): Train loss 1.841, Val loss 1.776\n",
      "Ep 1 (Step 057105): Train loss 1.855, Val loss 1.777\n",
      "Ep 1 (Step 057110): Train loss 1.945, Val loss 1.778\n",
      "Ep 1 (Step 057115): Train loss 1.743, Val loss 1.776\n",
      "Ep 1 (Step 057120): Train loss 1.640, Val loss 1.778\n",
      "Ep 1 (Step 057125): Train loss 1.665, Val loss 1.790\n",
      "Ep 1 (Step 057130): Train loss 1.490, Val loss 1.797\n",
      "Ep 1 (Step 057135): Train loss 1.657, Val loss 1.786\n",
      "Ep 1 (Step 057140): Train loss 1.872, Val loss 1.780\n",
      "Ep 1 (Step 057145): Train loss 1.623, Val loss 1.783\n",
      "Ep 1 (Step 057150): Train loss 1.749, Val loss 1.775\n",
      "Ep 1 (Step 057155): Train loss 1.648, Val loss 1.777\n",
      "Ep 1 (Step 057160): Train loss 1.841, Val loss 1.768\n",
      "Ep 1 (Step 057165): Train loss 1.752, Val loss 1.765\n",
      "Ep 1 (Step 057170): Train loss 1.783, Val loss 1.769\n",
      "Ep 1 (Step 057175): Train loss 2.143, Val loss 1.768\n",
      "Ep 1 (Step 057180): Train loss 1.842, Val loss 1.767\n",
      "Ep 1 (Step 057185): Train loss 1.905, Val loss 1.768\n",
      "Ep 1 (Step 057190): Train loss 1.812, Val loss 1.774\n",
      "Ep 1 (Step 057195): Train loss 1.719, Val loss 1.765\n",
      "Ep 1 (Step 057200): Train loss 1.737, Val loss 1.768\n",
      "Ep 1 (Step 057205): Train loss 1.954, Val loss 1.775\n",
      "Ep 1 (Step 057210): Train loss 1.748, Val loss 1.784\n",
      "Ep 1 (Step 057215): Train loss 1.812, Val loss 1.786\n",
      "Ep 1 (Step 057220): Train loss 1.902, Val loss 1.785\n",
      "Ep 1 (Step 057225): Train loss 1.852, Val loss 1.778\n",
      "Ep 1 (Step 057230): Train loss 1.853, Val loss 1.778\n",
      "Ep 1 (Step 057235): Train loss 1.758, Val loss 1.784\n",
      "Ep 1 (Step 057240): Train loss 1.528, Val loss 1.795\n",
      "Ep 1 (Step 057245): Train loss 2.271, Val loss 1.796\n",
      "Ep 1 (Step 057250): Train loss 1.949, Val loss 1.800\n",
      "Ep 1 (Step 057255): Train loss 1.529, Val loss 1.796\n",
      "Ep 1 (Step 057260): Train loss 1.642, Val loss 1.786\n",
      "Ep 1 (Step 057265): Train loss 1.915, Val loss 1.781\n",
      "Ep 1 (Step 057270): Train loss 1.874, Val loss 1.785\n",
      "Ep 1 (Step 057275): Train loss 1.923, Val loss 1.783\n",
      "Ep 1 (Step 057280): Train loss 1.812, Val loss 1.778\n",
      "Ep 1 (Step 057285): Train loss 2.474, Val loss 1.786\n",
      "Ep 1 (Step 057290): Train loss 2.090, Val loss 1.783\n",
      "Ep 1 (Step 057295): Train loss 1.760, Val loss 1.782\n",
      "Ep 1 (Step 057300): Train loss 1.828, Val loss 1.784\n",
      "Ep 1 (Step 057305): Train loss 1.834, Val loss 1.784\n",
      "Ep 1 (Step 057310): Train loss 1.734, Val loss 1.785\n",
      "Ep 1 (Step 057315): Train loss 1.690, Val loss 1.788\n",
      "Ep 1 (Step 057320): Train loss 2.190, Val loss 1.793\n",
      "Ep 1 (Step 057325): Train loss 1.656, Val loss 1.783\n",
      "Ep 1 (Step 057330): Train loss 1.788, Val loss 1.785\n",
      "Ep 1 (Step 057335): Train loss 1.806, Val loss 1.793\n",
      "Ep 1 (Step 057340): Train loss 2.174, Val loss 1.794\n",
      "Ep 1 (Step 057345): Train loss 2.220, Val loss 1.790\n",
      "Ep 1 (Step 057350): Train loss 1.784, Val loss 1.790\n",
      "Ep 1 (Step 057355): Train loss 1.862, Val loss 1.793\n",
      "Ep 1 (Step 057360): Train loss 1.877, Val loss 1.789\n",
      "Ep 1 (Step 057365): Train loss 1.869, Val loss 1.791\n",
      "Ep 1 (Step 057370): Train loss 1.898, Val loss 1.796\n",
      "Ep 1 (Step 057375): Train loss 1.802, Val loss 1.795\n",
      "Ep 1 (Step 057380): Train loss 1.850, Val loss 1.789\n",
      "Ep 1 (Step 057385): Train loss 1.770, Val loss 1.784\n",
      "Ep 1 (Step 057390): Train loss 1.663, Val loss 1.778\n",
      "Ep 1 (Step 057395): Train loss 1.682, Val loss 1.764\n",
      "Ep 1 (Step 057400): Train loss 2.007, Val loss 1.775\n",
      "Ep 1 (Step 057405): Train loss 1.679, Val loss 1.785\n",
      "Ep 1 (Step 057410): Train loss 1.859, Val loss 1.783\n",
      "Ep 1 (Step 057415): Train loss 1.947, Val loss 1.785\n",
      "Ep 1 (Step 057420): Train loss 1.688, Val loss 1.787\n",
      "Ep 1 (Step 057425): Train loss 1.740, Val loss 1.787\n",
      "Ep 1 (Step 057430): Train loss 1.957, Val loss 1.786\n",
      "Ep 1 (Step 057435): Train loss 1.740, Val loss 1.785\n",
      "Ep 1 (Step 057440): Train loss 1.931, Val loss 1.791\n",
      "Ep 1 (Step 057445): Train loss 1.821, Val loss 1.773\n",
      "Ep 1 (Step 057450): Train loss 1.635, Val loss 1.761\n",
      "Ep 1 (Step 057455): Train loss 1.791, Val loss 1.758\n",
      "Ep 1 (Step 057460): Train loss 1.630, Val loss 1.762\n",
      "Ep 1 (Step 057465): Train loss 1.696, Val loss 1.764\n",
      "Ep 1 (Step 057470): Train loss 1.871, Val loss 1.760\n",
      "Ep 1 (Step 057475): Train loss 1.782, Val loss 1.768\n",
      "Ep 1 (Step 057480): Train loss 1.815, Val loss 1.782\n",
      "Ep 1 (Step 057485): Train loss 1.814, Val loss 1.789\n",
      "Ep 1 (Step 057490): Train loss 2.052, Val loss 1.784\n",
      "Ep 1 (Step 057495): Train loss 1.807, Val loss 1.789\n",
      "Ep 1 (Step 057500): Train loss 1.751, Val loss 1.782\n",
      "Ep 1 (Step 057505): Train loss 1.759, Val loss 1.773\n",
      "Ep 1 (Step 057510): Train loss 2.085, Val loss 1.783\n",
      "Ep 1 (Step 057515): Train loss 1.729, Val loss 1.782\n",
      "Ep 1 (Step 057520): Train loss 1.748, Val loss 1.786\n",
      "Ep 1 (Step 057525): Train loss 1.848, Val loss 1.785\n",
      "Ep 1 (Step 057530): Train loss 1.786, Val loss 1.787\n",
      "Ep 1 (Step 057535): Train loss 1.583, Val loss 1.780\n",
      "Ep 1 (Step 057540): Train loss 1.872, Val loss 1.781\n",
      "Ep 1 (Step 057545): Train loss 1.682, Val loss 1.788\n",
      "Ep 1 (Step 057550): Train loss 1.809, Val loss 1.796\n",
      "Ep 1 (Step 057555): Train loss 1.605, Val loss 1.797\n",
      "Ep 1 (Step 057560): Train loss 1.821, Val loss 1.798\n",
      "Ep 1 (Step 057565): Train loss 2.041, Val loss 1.802\n",
      "Ep 1 (Step 057570): Train loss 1.627, Val loss 1.802\n",
      "Ep 1 (Step 057575): Train loss 2.005, Val loss 1.793\n",
      "Ep 1 (Step 057580): Train loss 1.792, Val loss 1.790\n",
      "Ep 1 (Step 057585): Train loss 1.672, Val loss 1.790\n",
      "Ep 1 (Step 057590): Train loss 1.875, Val loss 1.789\n",
      "Ep 1 (Step 057595): Train loss 1.597, Val loss 1.793\n",
      "Ep 1 (Step 057600): Train loss 1.508, Val loss 1.803\n",
      "Ep 1 (Step 057605): Train loss 1.721, Val loss 1.802\n",
      "Ep 1 (Step 057610): Train loss 1.550, Val loss 1.801\n",
      "Ep 1 (Step 057615): Train loss 1.593, Val loss 1.791\n",
      "Ep 1 (Step 057620): Train loss 1.644, Val loss 1.791\n",
      "Ep 1 (Step 057625): Train loss 1.899, Val loss 1.793\n",
      "Ep 1 (Step 057630): Train loss 1.898, Val loss 1.787\n",
      "Ep 1 (Step 057635): Train loss 1.554, Val loss 1.793\n",
      "Ep 1 (Step 057640): Train loss 1.918, Val loss 1.794\n",
      "Ep 1 (Step 057645): Train loss 1.788, Val loss 1.789\n",
      "Ep 1 (Step 057650): Train loss 1.536, Val loss 1.792\n",
      "Ep 1 (Step 057655): Train loss 1.787, Val loss 1.794\n",
      "Ep 1 (Step 057660): Train loss 1.785, Val loss 1.790\n",
      "Ep 1 (Step 057665): Train loss 1.872, Val loss 1.785\n",
      "Ep 1 (Step 057670): Train loss 1.732, Val loss 1.788\n",
      "Ep 1 (Step 057675): Train loss 1.674, Val loss 1.794\n",
      "Ep 1 (Step 057680): Train loss 1.890, Val loss 1.793\n",
      "Ep 1 (Step 057685): Train loss 1.805, Val loss 1.787\n",
      "Ep 1 (Step 057690): Train loss 1.906, Val loss 1.771\n",
      "Ep 1 (Step 057695): Train loss 1.867, Val loss 1.768\n",
      "Ep 1 (Step 057700): Train loss 1.709, Val loss 1.777\n",
      "Ep 1 (Step 057705): Train loss 1.619, Val loss 1.784\n",
      "Ep 1 (Step 057710): Train loss 1.801, Val loss 1.787\n",
      "Ep 1 (Step 057715): Train loss 1.967, Val loss 1.804\n",
      "Ep 1 (Step 057720): Train loss 1.864, Val loss 1.822\n",
      "Ep 1 (Step 057725): Train loss 1.952, Val loss 1.806\n",
      "Ep 1 (Step 057730): Train loss 1.826, Val loss 1.797\n",
      "Ep 1 (Step 057735): Train loss 1.747, Val loss 1.798\n",
      "Ep 1 (Step 057740): Train loss 2.001, Val loss 1.891\n",
      "Ep 1 (Step 057745): Train loss 2.077, Val loss 2.096\n",
      "Ep 1 (Step 057750): Train loss 1.927, Val loss 1.866\n",
      "Ep 1 (Step 057755): Train loss 1.775, Val loss 1.851\n",
      "Ep 1 (Step 057760): Train loss 1.998, Val loss 1.842\n",
      "Ep 1 (Step 057765): Train loss 2.028, Val loss 1.838\n",
      "Ep 1 (Step 057770): Train loss 1.923, Val loss 1.837\n",
      "Ep 1 (Step 057775): Train loss 1.751, Val loss 1.850\n",
      "Ep 1 (Step 057780): Train loss 1.976, Val loss 1.833\n",
      "Ep 1 (Step 057785): Train loss 2.187, Val loss 1.829\n",
      "Ep 1 (Step 057790): Train loss 1.927, Val loss 1.825\n",
      "Ep 1 (Step 057795): Train loss 1.859, Val loss 1.835\n",
      "Ep 1 (Step 057800): Train loss 1.851, Val loss 1.814\n",
      "Ep 1 (Step 057805): Train loss 2.029, Val loss 1.805\n",
      "Ep 1 (Step 057810): Train loss 1.828, Val loss 1.809\n",
      "Ep 1 (Step 057815): Train loss 1.981, Val loss 1.803\n",
      "Ep 1 (Step 057820): Train loss 1.911, Val loss 1.802\n",
      "Ep 1 (Step 057825): Train loss 2.049, Val loss 1.803\n",
      "Ep 1 (Step 057830): Train loss 1.854, Val loss 1.801\n",
      "Ep 1 (Step 057835): Train loss 1.810, Val loss 1.806\n",
      "Ep 1 (Step 057840): Train loss 1.851, Val loss 1.803\n",
      "Ep 1 (Step 057845): Train loss 1.758, Val loss 1.792\n",
      "Ep 1 (Step 057850): Train loss 1.971, Val loss 1.795\n",
      "Ep 1 (Step 057855): Train loss 2.030, Val loss 1.793\n",
      "Ep 1 (Step 057860): Train loss 1.666, Val loss 1.783\n",
      "Ep 1 (Step 057865): Train loss 1.782, Val loss 1.776\n",
      "Ep 1 (Step 057870): Train loss 1.620, Val loss 1.778\n",
      "Ep 1 (Step 057875): Train loss 1.836, Val loss 1.779\n",
      "Ep 1 (Step 057880): Train loss 1.804, Val loss 1.789\n",
      "Ep 1 (Step 057885): Train loss 1.936, Val loss 1.795\n",
      "Ep 1 (Step 057890): Train loss 1.748, Val loss 1.794\n",
      "Ep 1 (Step 057895): Train loss 1.695, Val loss 1.792\n",
      "Ep 1 (Step 057900): Train loss 1.603, Val loss 1.791\n",
      "Ep 1 (Step 057905): Train loss 1.696, Val loss 1.801\n",
      "Ep 1 (Step 057910): Train loss 1.838, Val loss 1.810\n",
      "Ep 1 (Step 057915): Train loss 1.693, Val loss 1.800\n",
      "Ep 1 (Step 057920): Train loss 1.661, Val loss 1.794\n",
      "Ep 1 (Step 057925): Train loss 1.549, Val loss 1.794\n",
      "Ep 1 (Step 057930): Train loss 1.781, Val loss 1.800\n",
      "Ep 1 (Step 057935): Train loss 1.779, Val loss 1.799\n",
      "Ep 1 (Step 057940): Train loss 1.794, Val loss 1.791\n",
      "Ep 1 (Step 057945): Train loss 1.915, Val loss 1.794\n",
      "Ep 1 (Step 057950): Train loss 1.925, Val loss 1.788\n",
      "Ep 1 (Step 057955): Train loss 1.549, Val loss 1.787\n",
      "Ep 1 (Step 057960): Train loss 1.878, Val loss 1.789\n",
      "Ep 1 (Step 057965): Train loss 1.772, Val loss 1.784\n",
      "Ep 1 (Step 057970): Train loss 1.786, Val loss 1.778\n",
      "Ep 1 (Step 057975): Train loss 2.066, Val loss 1.774\n",
      "Ep 1 (Step 057980): Train loss 1.683, Val loss 1.775\n",
      "Ep 1 (Step 057985): Train loss 1.870, Val loss 1.768\n",
      "Ep 1 (Step 057990): Train loss 1.463, Val loss 1.768\n",
      "Ep 1 (Step 057995): Train loss 1.607, Val loss 1.778\n",
      "Ep 1 (Step 058000): Train loss 1.821, Val loss 1.792\n",
      "Ep 1 (Step 058005): Train loss 2.158, Val loss 1.793\n",
      "Ep 1 (Step 058010): Train loss 1.509, Val loss 1.797\n",
      "Ep 1 (Step 058015): Train loss 1.860, Val loss 1.785\n",
      "Ep 1 (Step 058020): Train loss 1.682, Val loss 1.778\n",
      "Ep 1 (Step 058025): Train loss 1.599, Val loss 1.779\n",
      "Ep 1 (Step 058030): Train loss 1.677, Val loss 1.778\n",
      "Ep 1 (Step 058035): Train loss 1.683, Val loss 1.777\n",
      "Ep 1 (Step 058040): Train loss 1.690, Val loss 1.778\n",
      "Ep 1 (Step 058045): Train loss 1.589, Val loss 1.780\n",
      "Ep 1 (Step 058050): Train loss 2.085, Val loss 1.777\n",
      "Ep 1 (Step 058055): Train loss 1.713, Val loss 1.776\n",
      "Ep 1 (Step 058060): Train loss 1.899, Val loss 1.773\n",
      "Ep 1 (Step 058065): Train loss 1.640, Val loss 1.764\n",
      "Ep 1 (Step 058070): Train loss 1.908, Val loss 1.763\n",
      "Ep 1 (Step 058075): Train loss 2.098, Val loss 1.763\n",
      "Ep 1 (Step 058080): Train loss 1.964, Val loss 1.765\n",
      "Ep 1 (Step 058085): Train loss 1.622, Val loss 1.768\n",
      "Ep 1 (Step 058090): Train loss 1.675, Val loss 1.778\n",
      "Ep 1 (Step 058095): Train loss 1.551, Val loss 1.790\n",
      "Ep 1 (Step 058100): Train loss 1.632, Val loss 1.793\n",
      "Ep 1 (Step 058105): Train loss 1.703, Val loss 1.793\n",
      "Ep 1 (Step 058110): Train loss 1.592, Val loss 1.785\n",
      "Ep 1 (Step 058115): Train loss 1.666, Val loss 1.775\n",
      "Ep 1 (Step 058120): Train loss 1.704, Val loss 1.783\n",
      "Ep 1 (Step 058125): Train loss 1.893, Val loss 1.787\n",
      "Ep 1 (Step 058130): Train loss 1.775, Val loss 1.786\n",
      "Ep 1 (Step 058135): Train loss 2.015, Val loss 1.781\n",
      "Ep 1 (Step 058140): Train loss 1.706, Val loss 1.775\n",
      "Ep 1 (Step 058145): Train loss 1.824, Val loss 1.772\n",
      "Ep 1 (Step 058150): Train loss 1.847, Val loss 1.773\n",
      "Ep 1 (Step 058155): Train loss 1.896, Val loss 1.777\n",
      "Ep 1 (Step 058160): Train loss 1.608, Val loss 1.780\n",
      "Ep 1 (Step 058165): Train loss 1.986, Val loss 1.777\n",
      "Ep 1 (Step 058170): Train loss 1.691, Val loss 1.784\n",
      "Ep 1 (Step 058175): Train loss 1.421, Val loss 1.792\n",
      "Ep 1 (Step 058180): Train loss 1.572, Val loss 1.788\n",
      "Ep 1 (Step 058185): Train loss 1.823, Val loss 1.776\n",
      "Ep 1 (Step 058190): Train loss 1.761, Val loss 1.766\n",
      "Ep 1 (Step 058195): Train loss 1.901, Val loss 1.773\n",
      "Ep 1 (Step 058200): Train loss 1.599, Val loss 1.788\n",
      "Ep 1 (Step 058205): Train loss 1.958, Val loss 1.786\n",
      "Ep 1 (Step 058210): Train loss 1.772, Val loss 1.775\n",
      "Ep 1 (Step 058215): Train loss 1.867, Val loss 1.766\n",
      "Ep 1 (Step 058220): Train loss 2.009, Val loss 1.770\n",
      "Ep 1 (Step 058225): Train loss 1.825, Val loss 1.773\n",
      "Ep 1 (Step 058230): Train loss 1.834, Val loss 1.766\n",
      "Ep 1 (Step 058235): Train loss 1.832, Val loss 1.770\n",
      "Ep 1 (Step 058240): Train loss 1.813, Val loss 1.775\n",
      "Ep 1 (Step 058245): Train loss 1.772, Val loss 1.777\n",
      "Ep 1 (Step 058250): Train loss 1.815, Val loss 1.787\n",
      "Ep 1 (Step 058255): Train loss 1.719, Val loss 1.787\n",
      "Ep 1 (Step 058260): Train loss 1.853, Val loss 1.783\n",
      "Ep 1 (Step 058265): Train loss 1.794, Val loss 1.787\n",
      "Ep 1 (Step 058270): Train loss 1.792, Val loss 1.795\n",
      "Ep 1 (Step 058275): Train loss 1.986, Val loss 1.798\n",
      "Ep 1 (Step 058280): Train loss 1.787, Val loss 1.802\n",
      "Ep 1 (Step 058285): Train loss 1.841, Val loss 1.802\n",
      "Ep 1 (Step 058290): Train loss 1.752, Val loss 1.801\n",
      "Ep 1 (Step 058295): Train loss 1.789, Val loss 1.798\n",
      "Ep 1 (Step 058300): Train loss 1.994, Val loss 1.795\n",
      "Ep 1 (Step 058305): Train loss 1.576, Val loss 1.798\n",
      "Ep 1 (Step 058310): Train loss 1.993, Val loss 1.806\n",
      "Ep 1 (Step 058315): Train loss 1.605, Val loss 1.807\n",
      "Ep 1 (Step 058320): Train loss 1.578, Val loss 1.798\n",
      "Ep 1 (Step 058325): Train loss 1.552, Val loss 1.791\n",
      "Ep 1 (Step 058330): Train loss 1.908, Val loss 1.797\n",
      "Ep 1 (Step 058335): Train loss 1.854, Val loss 1.797\n",
      "Ep 1 (Step 058340): Train loss 1.802, Val loss 1.786\n",
      "Ep 1 (Step 058345): Train loss 1.667, Val loss 1.784\n",
      "Ep 1 (Step 058350): Train loss 1.827, Val loss 1.785\n",
      "Ep 1 (Step 058355): Train loss 1.650, Val loss 1.780\n",
      "Ep 1 (Step 058360): Train loss 1.725, Val loss 1.774\n",
      "Ep 1 (Step 058365): Train loss 1.777, Val loss 1.760\n",
      "Ep 1 (Step 058370): Train loss 1.815, Val loss 1.764\n",
      "Ep 1 (Step 058375): Train loss 1.862, Val loss 1.768\n",
      "Ep 1 (Step 058380): Train loss 1.979, Val loss 1.772\n",
      "Ep 1 (Step 058385): Train loss 1.826, Val loss 1.775\n",
      "Ep 1 (Step 058390): Train loss 1.686, Val loss 1.781\n",
      "Ep 1 (Step 058395): Train loss 1.794, Val loss 1.783\n",
      "Ep 1 (Step 058400): Train loss 1.951, Val loss 1.779\n",
      "Ep 1 (Step 058405): Train loss 1.898, Val loss 1.788\n",
      "Ep 1 (Step 058410): Train loss 1.789, Val loss 1.789\n",
      "Ep 1 (Step 058415): Train loss 2.004, Val loss 1.792\n",
      "Ep 1 (Step 058420): Train loss 1.580, Val loss 1.789\n",
      "Ep 1 (Step 058425): Train loss 2.134, Val loss 1.779\n",
      "Ep 1 (Step 058430): Train loss 2.139, Val loss 1.765\n",
      "Ep 1 (Step 058435): Train loss 1.872, Val loss 1.766\n",
      "Ep 1 (Step 058440): Train loss 2.233, Val loss 1.774\n",
      "Ep 1 (Step 058445): Train loss 1.809, Val loss 1.781\n",
      "Ep 1 (Step 058450): Train loss 1.704, Val loss 1.788\n",
      "Ep 1 (Step 058455): Train loss 1.580, Val loss 1.783\n",
      "Ep 1 (Step 058460): Train loss 1.473, Val loss 1.781\n",
      "Ep 1 (Step 058465): Train loss 1.871, Val loss 1.782\n",
      "Ep 1 (Step 058470): Train loss 1.700, Val loss 1.779\n",
      "Ep 1 (Step 058475): Train loss 1.820, Val loss 1.773\n",
      "Ep 1 (Step 058480): Train loss 1.930, Val loss 1.775\n",
      "Ep 1 (Step 058485): Train loss 1.783, Val loss 1.773\n",
      "Ep 1 (Step 058490): Train loss 1.667, Val loss 1.771\n",
      "Ep 1 (Step 058495): Train loss 2.129, Val loss 1.767\n",
      "Ep 1 (Step 058500): Train loss 1.741, Val loss 1.779\n",
      "Ep 1 (Step 058505): Train loss 1.805, Val loss 1.783\n",
      "Ep 1 (Step 058510): Train loss 1.756, Val loss 1.778\n",
      "Ep 1 (Step 058515): Train loss 2.068, Val loss 1.779\n",
      "Ep 1 (Step 058520): Train loss 1.691, Val loss 1.781\n",
      "Ep 1 (Step 058525): Train loss 2.091, Val loss 1.777\n",
      "Ep 1 (Step 058530): Train loss 1.714, Val loss 1.778\n",
      "Ep 1 (Step 058535): Train loss 1.774, Val loss 1.782\n",
      "Ep 1 (Step 058540): Train loss 1.787, Val loss 1.776\n",
      "Ep 1 (Step 058545): Train loss 1.984, Val loss 1.779\n",
      "Ep 1 (Step 058550): Train loss 1.773, Val loss 1.776\n",
      "Ep 1 (Step 058555): Train loss 1.885, Val loss 1.772\n",
      "Ep 1 (Step 058560): Train loss 1.924, Val loss 1.776\n",
      "Ep 1 (Step 058565): Train loss 1.838, Val loss 1.775\n",
      "Ep 1 (Step 058570): Train loss 1.931, Val loss 1.780\n",
      "Ep 1 (Step 058575): Train loss 1.613, Val loss 1.769\n",
      "Ep 1 (Step 058580): Train loss 1.928, Val loss 1.772\n",
      "Ep 1 (Step 058585): Train loss 1.685, Val loss 1.776\n",
      "Ep 1 (Step 058590): Train loss 1.646, Val loss 1.778\n",
      "Ep 1 (Step 058595): Train loss 1.847, Val loss 1.777\n",
      "Ep 1 (Step 058600): Train loss 1.932, Val loss 1.776\n",
      "Ep 1 (Step 058605): Train loss 1.540, Val loss 1.766\n",
      "Ep 1 (Step 058610): Train loss 1.936, Val loss 1.761\n",
      "Ep 1 (Step 058615): Train loss 1.873, Val loss 1.769\n",
      "Ep 1 (Step 058620): Train loss 1.627, Val loss 1.782\n",
      "Ep 1 (Step 058625): Train loss 1.939, Val loss 1.781\n",
      "Ep 1 (Step 058630): Train loss 1.860, Val loss 1.779\n",
      "Ep 1 (Step 058635): Train loss 2.165, Val loss 1.784\n",
      "Ep 1 (Step 058640): Train loss 1.530, Val loss 1.784\n",
      "Ep 1 (Step 058645): Train loss 1.726, Val loss 1.782\n",
      "Ep 1 (Step 058650): Train loss 1.843, Val loss 1.776\n",
      "Ep 1 (Step 058655): Train loss 1.653, Val loss 1.780\n",
      "Ep 1 (Step 058660): Train loss 1.948, Val loss 1.778\n",
      "Ep 1 (Step 058665): Train loss 1.905, Val loss 1.782\n",
      "Ep 1 (Step 058670): Train loss 1.776, Val loss 1.786\n",
      "Ep 1 (Step 058675): Train loss 1.845, Val loss 1.787\n",
      "Ep 1 (Step 058680): Train loss 1.718, Val loss 1.790\n",
      "Ep 1 (Step 058685): Train loss 1.562, Val loss 1.792\n",
      "Ep 1 (Step 058690): Train loss 1.792, Val loss 1.793\n",
      "Ep 1 (Step 058695): Train loss 1.931, Val loss 1.795\n",
      "Ep 1 (Step 058700): Train loss 1.879, Val loss 1.794\n",
      "Ep 1 (Step 058705): Train loss 1.695, Val loss 1.791\n",
      "Ep 1 (Step 058710): Train loss 1.952, Val loss 1.784\n",
      "Ep 1 (Step 058715): Train loss 1.940, Val loss 1.788\n",
      "Ep 1 (Step 058720): Train loss 1.948, Val loss 1.789\n",
      "Ep 1 (Step 058725): Train loss 2.159, Val loss 1.781\n",
      "Ep 1 (Step 058730): Train loss 1.818, Val loss 1.778\n",
      "Ep 1 (Step 058735): Train loss 2.009, Val loss 1.775\n",
      "Ep 1 (Step 058740): Train loss 1.793, Val loss 1.780\n",
      "Ep 1 (Step 058745): Train loss 1.815, Val loss 1.772\n",
      "Ep 1 (Step 058750): Train loss 1.705, Val loss 1.761\n",
      "Ep 1 (Step 058755): Train loss 1.768, Val loss 1.757\n",
      "Ep 1 (Step 058760): Train loss 1.903, Val loss 1.754\n",
      "Ep 1 (Step 058765): Train loss 1.868, Val loss 1.756\n",
      "Ep 1 (Step 058770): Train loss 1.971, Val loss 1.756\n",
      "Ep 1 (Step 058775): Train loss 1.675, Val loss 1.755\n",
      "Ep 1 (Step 058780): Train loss 1.746, Val loss 1.750\n",
      "Ep 1 (Step 058785): Train loss 1.813, Val loss 1.750\n",
      "Ep 1 (Step 058790): Train loss 1.861, Val loss 1.758\n",
      "Ep 1 (Step 058795): Train loss 2.003, Val loss 1.763\n",
      "Ep 1 (Step 058800): Train loss 1.865, Val loss 1.762\n",
      "Ep 1 (Step 058805): Train loss 1.699, Val loss 1.771\n",
      "Ep 1 (Step 058810): Train loss 1.805, Val loss 1.770\n",
      "Ep 1 (Step 058815): Train loss 1.815, Val loss 1.770\n",
      "Ep 1 (Step 058820): Train loss 1.939, Val loss 1.767\n",
      "Ep 1 (Step 058825): Train loss 1.675, Val loss 1.770\n",
      "Ep 1 (Step 058830): Train loss 1.813, Val loss 1.777\n",
      "Ep 1 (Step 058835): Train loss 1.690, Val loss 1.776\n",
      "Ep 1 (Step 058840): Train loss 1.880, Val loss 1.776\n",
      "Ep 1 (Step 058845): Train loss 1.639, Val loss 1.780\n",
      "Ep 1 (Step 058850): Train loss 1.667, Val loss 1.777\n",
      "Ep 1 (Step 058855): Train loss 1.926, Val loss 1.774\n",
      "Ep 1 (Step 058860): Train loss 1.685, Val loss 1.773\n",
      "Ep 1 (Step 058865): Train loss 1.795, Val loss 1.771\n",
      "Ep 1 (Step 058870): Train loss 1.900, Val loss 1.769\n",
      "Ep 1 (Step 058875): Train loss 1.784, Val loss 1.772\n",
      "Ep 1 (Step 058880): Train loss 1.767, Val loss 1.774\n",
      "Ep 1 (Step 058885): Train loss 1.942, Val loss 1.774\n",
      "Ep 1 (Step 058890): Train loss 1.700, Val loss 1.772\n",
      "Ep 1 (Step 058895): Train loss 1.777, Val loss 1.778\n",
      "Ep 1 (Step 058900): Train loss 1.695, Val loss 1.778\n",
      "Ep 1 (Step 058905): Train loss 1.763, Val loss 1.772\n",
      "Ep 1 (Step 058910): Train loss 1.621, Val loss 1.776\n",
      "Ep 1 (Step 058915): Train loss 1.733, Val loss 1.778\n",
      "Ep 1 (Step 058920): Train loss 1.615, Val loss 1.775\n",
      "Ep 1 (Step 058925): Train loss 1.779, Val loss 1.767\n",
      "Ep 1 (Step 058930): Train loss 1.811, Val loss 1.763\n",
      "Ep 1 (Step 058935): Train loss 1.649, Val loss 1.769\n",
      "Ep 1 (Step 058940): Train loss 1.843, Val loss 1.782\n",
      "Ep 1 (Step 058945): Train loss 1.624, Val loss 1.779\n",
      "Ep 1 (Step 058950): Train loss 2.061, Val loss 1.773\n",
      "Ep 1 (Step 058955): Train loss 1.603, Val loss 1.773\n",
      "Ep 1 (Step 058960): Train loss 1.802, Val loss 1.781\n",
      "Ep 1 (Step 058965): Train loss 1.861, Val loss 1.784\n",
      "Ep 1 (Step 058970): Train loss 1.540, Val loss 1.784\n",
      "Ep 1 (Step 058975): Train loss 1.945, Val loss 1.771\n",
      "Ep 1 (Step 058980): Train loss 1.845, Val loss 1.760\n",
      "Ep 1 (Step 058985): Train loss 2.012, Val loss 1.759\n",
      "Ep 1 (Step 058990): Train loss 1.730, Val loss 1.762\n",
      "Ep 1 (Step 058995): Train loss 1.640, Val loss 1.764\n",
      "Ep 1 (Step 059000): Train loss 1.827, Val loss 1.769\n",
      "Ep 1 (Step 059005): Train loss 1.747, Val loss 1.773\n",
      "Ep 1 (Step 059010): Train loss 1.798, Val loss 1.773\n",
      "Ep 1 (Step 059015): Train loss 1.741, Val loss 1.776\n",
      "Ep 1 (Step 059020): Train loss 1.897, Val loss 1.782\n",
      "Ep 1 (Step 059025): Train loss 2.277, Val loss 1.793\n",
      "Ep 1 (Step 059030): Train loss 1.759, Val loss 1.789\n",
      "Ep 1 (Step 059035): Train loss 1.745, Val loss 1.777\n",
      "Ep 1 (Step 059040): Train loss 2.005, Val loss 1.777\n",
      "Ep 1 (Step 059045): Train loss 2.073, Val loss 1.791\n",
      "Ep 1 (Step 059050): Train loss 1.990, Val loss 1.799\n",
      "Ep 1 (Step 059055): Train loss 1.802, Val loss 1.797\n",
      "Ep 1 (Step 059060): Train loss 1.878, Val loss 1.791\n",
      "Ep 1 (Step 059065): Train loss 1.942, Val loss 1.782\n",
      "Ep 1 (Step 059070): Train loss 1.874, Val loss 1.781\n",
      "Ep 1 (Step 059075): Train loss 1.684, Val loss 1.784\n",
      "Ep 1 (Step 059080): Train loss 1.655, Val loss 1.789\n",
      "Ep 1 (Step 059085): Train loss 1.966, Val loss 1.796\n",
      "Ep 1 (Step 059090): Train loss 1.603, Val loss 1.800\n",
      "Ep 1 (Step 059095): Train loss 1.786, Val loss 1.793\n",
      "Ep 1 (Step 059100): Train loss 1.925, Val loss 1.777\n",
      "Ep 1 (Step 059105): Train loss 1.596, Val loss 1.774\n",
      "Ep 1 (Step 059110): Train loss 1.796, Val loss 1.779\n",
      "Ep 1 (Step 059115): Train loss 1.760, Val loss 1.781\n",
      "Ep 1 (Step 059120): Train loss 1.822, Val loss 1.785\n",
      "Ep 1 (Step 059125): Train loss 1.691, Val loss 1.783\n",
      "Ep 1 (Step 059130): Train loss 1.853, Val loss 1.777\n",
      "Ep 1 (Step 059135): Train loss 1.571, Val loss 1.767\n",
      "Ep 1 (Step 059140): Train loss 1.664, Val loss 1.768\n",
      "Ep 1 (Step 059145): Train loss 1.820, Val loss 1.762\n",
      "Ep 1 (Step 059150): Train loss 1.816, Val loss 1.770\n",
      "Ep 1 (Step 059155): Train loss 1.620, Val loss 1.774\n",
      "Ep 1 (Step 059160): Train loss 1.914, Val loss 1.771\n",
      "Ep 1 (Step 059165): Train loss 1.669, Val loss 1.771\n",
      "Ep 1 (Step 059170): Train loss 1.659, Val loss 1.761\n",
      "Ep 1 (Step 059175): Train loss 1.831, Val loss 1.759\n",
      "Ep 1 (Step 059180): Train loss 1.679, Val loss 1.768\n",
      "Ep 1 (Step 059185): Train loss 1.952, Val loss 1.768\n",
      "Ep 1 (Step 059190): Train loss 1.808, Val loss 1.768\n",
      "Ep 1 (Step 059195): Train loss 1.714, Val loss 1.761\n",
      "Ep 1 (Step 059200): Train loss 1.718, Val loss 1.766\n",
      "Ep 1 (Step 059205): Train loss 1.881, Val loss 1.770\n",
      "Ep 1 (Step 059210): Train loss 1.906, Val loss 1.767\n",
      "Ep 1 (Step 059215): Train loss 1.827, Val loss 1.764\n",
      "Ep 1 (Step 059220): Train loss 1.793, Val loss 1.761\n",
      "Ep 1 (Step 059225): Train loss 1.863, Val loss 1.763\n",
      "Ep 1 (Step 059230): Train loss 1.918, Val loss 1.770\n",
      "Ep 1 (Step 059235): Train loss 1.591, Val loss 1.770\n",
      "Ep 1 (Step 059240): Train loss 1.791, Val loss 1.766\n",
      "Ep 1 (Step 059245): Train loss 1.897, Val loss 1.761\n",
      "Ep 1 (Step 059250): Train loss 1.550, Val loss 1.755\n",
      "Ep 1 (Step 059255): Train loss 1.661, Val loss 1.765\n",
      "Ep 1 (Step 059260): Train loss 1.775, Val loss 1.771\n",
      "Ep 1 (Step 059265): Train loss 1.843, Val loss 1.761\n",
      "Ep 1 (Step 059270): Train loss 1.607, Val loss 1.753\n",
      "Ep 1 (Step 059275): Train loss 1.692, Val loss 1.754\n",
      "Ep 1 (Step 059280): Train loss 1.617, Val loss 1.760\n",
      "Ep 1 (Step 059285): Train loss 1.785, Val loss 1.756\n",
      "Ep 1 (Step 059290): Train loss 1.813, Val loss 1.751\n",
      "Ep 1 (Step 059295): Train loss 1.652, Val loss 1.757\n",
      "Ep 1 (Step 059300): Train loss 1.956, Val loss 1.755\n",
      "Ep 1 (Step 059305): Train loss 1.668, Val loss 1.759\n",
      "Ep 1 (Step 059310): Train loss 1.973, Val loss 1.764\n",
      "Ep 1 (Step 059315): Train loss 1.852, Val loss 1.764\n",
      "Ep 1 (Step 059320): Train loss 1.842, Val loss 1.758\n",
      "Ep 1 (Step 059325): Train loss 1.811, Val loss 1.757\n",
      "Ep 1 (Step 059330): Train loss 1.839, Val loss 1.770\n",
      "Ep 1 (Step 059335): Train loss 1.709, Val loss 1.762\n",
      "Ep 1 (Step 059340): Train loss 1.959, Val loss 1.760\n",
      "Ep 1 (Step 059345): Train loss 1.797, Val loss 1.760\n",
      "Ep 1 (Step 059350): Train loss 1.832, Val loss 1.758\n",
      "Ep 1 (Step 059355): Train loss 2.046, Val loss 1.755\n",
      "Ep 1 (Step 059360): Train loss 2.071, Val loss 1.748\n",
      "Ep 1 (Step 059365): Train loss 1.604, Val loss 1.751\n",
      "Ep 1 (Step 059370): Train loss 1.741, Val loss 1.754\n",
      "Ep 1 (Step 059375): Train loss 1.802, Val loss 1.752\n",
      "Ep 1 (Step 059380): Train loss 1.707, Val loss 1.755\n",
      "Ep 1 (Step 059385): Train loss 1.845, Val loss 1.758\n",
      "Ep 1 (Step 059390): Train loss 1.634, Val loss 1.769\n",
      "Ep 1 (Step 059395): Train loss 1.546, Val loss 1.763\n",
      "Ep 1 (Step 059400): Train loss 1.926, Val loss 1.770\n",
      "Ep 1 (Step 059405): Train loss 1.697, Val loss 1.771\n",
      "Ep 1 (Step 059410): Train loss 1.873, Val loss 1.771\n",
      "Ep 1 (Step 059415): Train loss 1.590, Val loss 1.779\n",
      "Ep 1 (Step 059420): Train loss 2.053, Val loss 1.782\n",
      "Ep 1 (Step 059425): Train loss 1.558, Val loss 1.781\n",
      "Ep 1 (Step 059430): Train loss 1.780, Val loss 1.780\n",
      "Ep 1 (Step 059435): Train loss 1.768, Val loss 1.785\n",
      "Ep 1 (Step 059440): Train loss 1.893, Val loss 1.788\n",
      "Ep 1 (Step 059445): Train loss 1.648, Val loss 1.777\n",
      "Ep 1 (Step 059450): Train loss 1.588, Val loss 1.768\n",
      "Ep 1 (Step 059455): Train loss 1.721, Val loss 1.768\n",
      "Ep 1 (Step 059460): Train loss 1.905, Val loss 1.778\n",
      "Ep 1 (Step 059465): Train loss 1.693, Val loss 1.775\n",
      "Ep 1 (Step 059470): Train loss 1.777, Val loss 1.772\n",
      "Ep 1 (Step 059475): Train loss 1.687, Val loss 1.772\n",
      "Ep 1 (Step 059480): Train loss 1.693, Val loss 1.773\n",
      "Ep 1 (Step 059485): Train loss 1.675, Val loss 1.774\n",
      "Ep 1 (Step 059490): Train loss 1.605, Val loss 1.787\n",
      "Ep 1 (Step 059495): Train loss 1.766, Val loss 1.795\n",
      "Ep 1 (Step 059500): Train loss 1.910, Val loss 1.792\n",
      "Ep 1 (Step 059505): Train loss 1.761, Val loss 1.788\n",
      "Ep 1 (Step 059510): Train loss 1.710, Val loss 1.777\n",
      "Ep 1 (Step 059515): Train loss 1.647, Val loss 1.769\n",
      "Ep 1 (Step 059520): Train loss 1.433, Val loss 1.778\n",
      "Ep 1 (Step 059525): Train loss 1.786, Val loss 1.781\n",
      "Ep 1 (Step 059530): Train loss 1.597, Val loss 1.776\n",
      "Ep 1 (Step 059535): Train loss 1.802, Val loss 1.775\n",
      "Ep 1 (Step 059540): Train loss 1.754, Val loss 1.773\n",
      "Ep 1 (Step 059545): Train loss 1.879, Val loss 1.784\n",
      "Ep 1 (Step 059550): Train loss 1.579, Val loss 1.782\n",
      "Ep 1 (Step 059555): Train loss 1.824, Val loss 1.768\n",
      "Ep 1 (Step 059560): Train loss 1.950, Val loss 1.771\n",
      "Ep 1 (Step 059565): Train loss 1.701, Val loss 1.771\n",
      "Ep 1 (Step 059570): Train loss 1.781, Val loss 1.773\n",
      "Ep 1 (Step 059575): Train loss 1.758, Val loss 1.764\n",
      "Ep 1 (Step 059580): Train loss 1.957, Val loss 1.769\n",
      "Ep 1 (Step 059585): Train loss 1.830, Val loss 1.779\n",
      "Ep 1 (Step 059590): Train loss 1.889, Val loss 1.785\n",
      "Ep 1 (Step 059595): Train loss 1.737, Val loss 1.778\n",
      "Ep 1 (Step 059600): Train loss 1.673, Val loss 1.782\n",
      "Ep 1 (Step 059605): Train loss 1.939, Val loss 1.778\n",
      "Ep 1 (Step 059610): Train loss 1.753, Val loss 1.774\n",
      "Ep 1 (Step 059615): Train loss 1.639, Val loss 1.781\n",
      "Ep 1 (Step 059620): Train loss 1.943, Val loss 1.783\n",
      "Ep 1 (Step 059625): Train loss 1.526, Val loss 1.775\n",
      "Ep 1 (Step 059630): Train loss 1.634, Val loss 1.767\n",
      "Ep 1 (Step 059635): Train loss 1.931, Val loss 1.768\n",
      "Ep 1 (Step 059640): Train loss 2.164, Val loss 1.769\n",
      "Ep 1 (Step 059645): Train loss 1.677, Val loss 1.772\n",
      "Ep 1 (Step 059650): Train loss 1.920, Val loss 1.768\n",
      "Ep 1 (Step 059655): Train loss 2.066, Val loss 1.761\n",
      "Ep 1 (Step 059660): Train loss 1.746, Val loss 1.761\n",
      "Ep 1 (Step 059665): Train loss 1.731, Val loss 1.758\n",
      "Ep 1 (Step 059670): Train loss 1.587, Val loss 1.760\n",
      "Ep 1 (Step 059675): Train loss 1.647, Val loss 1.767\n",
      "Ep 1 (Step 059680): Train loss 1.581, Val loss 1.765\n",
      "Ep 1 (Step 059685): Train loss 1.668, Val loss 1.755\n",
      "Ep 1 (Step 059690): Train loss 1.502, Val loss 1.749\n",
      "Ep 1 (Step 059695): Train loss 1.819, Val loss 1.745\n",
      "Ep 1 (Step 059700): Train loss 1.991, Val loss 1.751\n",
      "Ep 1 (Step 059705): Train loss 2.016, Val loss 1.754\n",
      "Ep 1 (Step 059710): Train loss 1.937, Val loss 1.753\n",
      "Ep 1 (Step 059715): Train loss 1.877, Val loss 1.745\n",
      "Ep 1 (Step 059720): Train loss 1.715, Val loss 1.749\n",
      "Ep 1 (Step 059725): Train loss 1.474, Val loss 1.752\n",
      "Ep 1 (Step 059730): Train loss 1.643, Val loss 1.755\n",
      "Ep 1 (Step 059735): Train loss 1.647, Val loss 1.762\n",
      "Ep 1 (Step 059740): Train loss 1.810, Val loss 1.756\n",
      "Ep 1 (Step 059745): Train loss 1.670, Val loss 1.748\n",
      "Ep 1 (Step 059750): Train loss 1.910, Val loss 1.744\n",
      "Ep 1 (Step 059755): Train loss 1.722, Val loss 1.743\n",
      "Ep 1 (Step 059760): Train loss 1.952, Val loss 1.744\n",
      "Ep 1 (Step 059765): Train loss 1.814, Val loss 1.746\n",
      "Ep 1 (Step 059770): Train loss 1.735, Val loss 1.747\n",
      "Ep 1 (Step 059775): Train loss 1.679, Val loss 1.753\n",
      "Ep 1 (Step 059780): Train loss 1.833, Val loss 1.765\n",
      "Ep 1 (Step 059785): Train loss 1.746, Val loss 1.763\n",
      "Ep 1 (Step 059790): Train loss 1.778, Val loss 1.759\n",
      "Ep 1 (Step 059795): Train loss 1.835, Val loss 1.762\n",
      "Ep 1 (Step 059800): Train loss 1.855, Val loss 1.767\n",
      "Ep 1 (Step 059805): Train loss 1.662, Val loss 1.765\n",
      "Ep 1 (Step 059810): Train loss 1.965, Val loss 1.761\n",
      "Ep 1 (Step 059815): Train loss 1.990, Val loss 1.762\n",
      "Ep 1 (Step 059820): Train loss 1.777, Val loss 1.770\n",
      "Ep 1 (Step 059825): Train loss 1.827, Val loss 1.774\n",
      "Ep 1 (Step 059830): Train loss 1.803, Val loss 1.777\n",
      "Ep 1 (Step 059835): Train loss 1.844, Val loss 1.788\n",
      "Ep 1 (Step 059840): Train loss 1.605, Val loss 1.787\n",
      "Ep 1 (Step 059845): Train loss 1.607, Val loss 1.786\n",
      "Ep 1 (Step 059850): Train loss 1.720, Val loss 1.785\n",
      "Ep 1 (Step 059855): Train loss 1.771, Val loss 1.784\n",
      "Ep 1 (Step 059860): Train loss 1.837, Val loss 1.784\n",
      "Ep 1 (Step 059865): Train loss 2.020, Val loss 1.792\n",
      "Ep 1 (Step 059870): Train loss 1.955, Val loss 1.785\n",
      "Ep 1 (Step 059875): Train loss 1.745, Val loss 1.781\n",
      "Ep 1 (Step 059880): Train loss 1.893, Val loss 1.785\n",
      "Ep 1 (Step 059885): Train loss 1.808, Val loss 1.788\n",
      "Ep 1 (Step 059890): Train loss 1.741, Val loss 1.790\n",
      "Ep 1 (Step 059895): Train loss 2.046, Val loss 1.781\n",
      "Ep 1 (Step 059900): Train loss 1.880, Val loss 1.780\n",
      "Ep 1 (Step 059905): Train loss 2.115, Val loss 1.780\n",
      "Ep 1 (Step 059910): Train loss 1.700, Val loss 1.786\n",
      "Ep 1 (Step 059915): Train loss 1.731, Val loss 1.782\n",
      "Ep 1 (Step 059920): Train loss 1.623, Val loss 1.777\n",
      "Ep 1 (Step 059925): Train loss 1.935, Val loss 1.777\n",
      "Ep 1 (Step 059930): Train loss 1.807, Val loss 1.764\n",
      "Ep 1 (Step 059935): Train loss 1.886, Val loss 1.762\n",
      "Ep 1 (Step 059940): Train loss 1.986, Val loss 1.765\n",
      "Ep 1 (Step 059945): Train loss 1.717, Val loss 1.769\n",
      "Ep 1 (Step 059950): Train loss 1.967, Val loss 1.777\n",
      "Ep 1 (Step 059955): Train loss 1.768, Val loss 1.780\n",
      "Ep 1 (Step 059960): Train loss 1.853, Val loss 1.790\n",
      "Ep 1 (Step 059965): Train loss 1.665, Val loss 1.793\n",
      "Ep 1 (Step 059970): Train loss 2.037, Val loss 1.787\n",
      "Ep 1 (Step 059975): Train loss 1.864, Val loss 1.780\n",
      "Ep 1 (Step 059980): Train loss 1.602, Val loss 1.776\n",
      "Ep 1 (Step 059985): Train loss 1.821, Val loss 1.767\n",
      "Ep 1 (Step 059990): Train loss 1.769, Val loss 1.749\n",
      "Ep 1 (Step 059995): Train loss 1.546, Val loss 1.749\n",
      "Ep 1 (Step 060000): Train loss 1.853, Val loss 1.755\n",
      "Ep 1 (Step 060005): Train loss 1.801, Val loss 1.759\n",
      "Ep 1 (Step 060010): Train loss 1.751, Val loss 1.763\n",
      "Ep 1 (Step 060015): Train loss 1.680, Val loss 1.765\n",
      "Ep 1 (Step 060020): Train loss 1.742, Val loss 1.763\n",
      "Ep 1 (Step 060025): Train loss 1.895, Val loss 1.755\n",
      "Ep 1 (Step 060030): Train loss 1.914, Val loss 1.753\n",
      "Ep 1 (Step 060035): Train loss 2.026, Val loss 1.757\n",
      "Ep 1 (Step 060040): Train loss 1.798, Val loss 1.754\n",
      "Ep 1 (Step 060045): Train loss 1.716, Val loss 1.757\n",
      "Ep 1 (Step 060050): Train loss 1.923, Val loss 1.749\n",
      "Ep 1 (Step 060055): Train loss 1.534, Val loss 1.750\n",
      "Ep 1 (Step 060060): Train loss 1.881, Val loss 1.765\n",
      "Ep 1 (Step 060065): Train loss 1.918, Val loss 1.768\n",
      "Ep 1 (Step 060070): Train loss 1.658, Val loss 1.763\n",
      "Ep 1 (Step 060075): Train loss 1.857, Val loss 1.763\n",
      "Ep 1 (Step 060080): Train loss 1.736, Val loss 1.765\n",
      "Ep 1 (Step 060085): Train loss 1.910, Val loss 1.762\n",
      "Ep 1 (Step 060090): Train loss 1.457, Val loss 1.754\n",
      "Ep 1 (Step 060095): Train loss 1.749, Val loss 1.758\n",
      "Ep 1 (Step 060100): Train loss 1.801, Val loss 1.763\n",
      "Ep 1 (Step 060105): Train loss 1.814, Val loss 1.772\n",
      "Ep 1 (Step 060110): Train loss 2.024, Val loss 1.769\n",
      "Ep 1 (Step 060115): Train loss 1.510, Val loss 1.759\n",
      "Ep 1 (Step 060120): Train loss 1.683, Val loss 1.756\n",
      "Ep 1 (Step 060125): Train loss 1.550, Val loss 1.762\n",
      "Ep 1 (Step 060130): Train loss 1.919, Val loss 1.763\n",
      "Ep 1 (Step 060135): Train loss 2.024, Val loss 1.753\n",
      "Ep 1 (Step 060140): Train loss 1.768, Val loss 1.755\n",
      "Ep 1 (Step 060145): Train loss 1.761, Val loss 1.764\n",
      "Ep 1 (Step 060150): Train loss 1.903, Val loss 1.755\n",
      "Ep 1 (Step 060155): Train loss 1.845, Val loss 1.752\n",
      "Ep 1 (Step 060160): Train loss 1.733, Val loss 1.753\n",
      "Ep 1 (Step 060165): Train loss 1.839, Val loss 1.750\n",
      "Ep 1 (Step 060170): Train loss 1.676, Val loss 1.746\n",
      "Ep 1 (Step 060175): Train loss 1.650, Val loss 1.745\n",
      "Ep 1 (Step 060180): Train loss 1.703, Val loss 1.753\n",
      "Ep 1 (Step 060185): Train loss 1.714, Val loss 1.761\n",
      "Ep 1 (Step 060190): Train loss 1.876, Val loss 1.764\n",
      "Ep 1 (Step 060195): Train loss 1.776, Val loss 1.765\n",
      "Ep 1 (Step 060200): Train loss 1.916, Val loss 1.764\n",
      "Ep 1 (Step 060205): Train loss 2.089, Val loss 1.763\n",
      "Ep 1 (Step 060210): Train loss 1.931, Val loss 1.765\n",
      "Ep 1 (Step 060215): Train loss 1.784, Val loss 1.773\n",
      "Ep 1 (Step 060220): Train loss 1.914, Val loss 1.767\n",
      "Ep 1 (Step 060225): Train loss 1.764, Val loss 1.758\n",
      "Ep 1 (Step 060230): Train loss 1.840, Val loss 1.756\n",
      "Ep 1 (Step 060235): Train loss 1.940, Val loss 1.761\n",
      "Ep 1 (Step 060240): Train loss 1.828, Val loss 1.762\n",
      "Ep 1 (Step 060245): Train loss 1.956, Val loss 1.766\n",
      "Ep 1 (Step 060250): Train loss 1.992, Val loss 1.758\n",
      "Ep 1 (Step 060255): Train loss 1.837, Val loss 1.754\n",
      "Ep 1 (Step 060260): Train loss 1.594, Val loss 1.748\n",
      "Ep 1 (Step 060265): Train loss 2.136, Val loss 1.744\n",
      "Ep 1 (Step 060270): Train loss 2.026, Val loss 1.745\n",
      "Ep 1 (Step 060275): Train loss 1.730, Val loss 1.745\n",
      "Ep 1 (Step 060280): Train loss 1.869, Val loss 1.746\n",
      "Ep 1 (Step 060285): Train loss 1.662, Val loss 1.758\n",
      "Ep 1 (Step 060290): Train loss 1.814, Val loss 1.760\n",
      "Ep 1 (Step 060295): Train loss 1.871, Val loss 1.763\n",
      "Ep 1 (Step 060300): Train loss 1.793, Val loss 1.759\n",
      "Ep 1 (Step 060305): Train loss 1.866, Val loss 1.762\n",
      "Ep 1 (Step 060310): Train loss 1.627, Val loss 1.761\n",
      "Ep 1 (Step 060315): Train loss 1.721, Val loss 1.759\n",
      "Ep 1 (Step 060320): Train loss 1.994, Val loss 1.758\n",
      "Ep 1 (Step 060325): Train loss 1.787, Val loss 1.758\n",
      "Ep 1 (Step 060330): Train loss 1.632, Val loss 1.758\n",
      "Ep 1 (Step 060335): Train loss 1.725, Val loss 1.764\n",
      "Ep 1 (Step 060340): Train loss 1.795, Val loss 1.757\n",
      "Ep 1 (Step 060345): Train loss 1.715, Val loss 1.764\n",
      "Ep 1 (Step 060350): Train loss 1.991, Val loss 1.768\n",
      "Ep 1 (Step 060355): Train loss 2.039, Val loss 1.771\n",
      "Ep 1 (Step 060360): Train loss 1.709, Val loss 1.763\n",
      "Ep 1 (Step 060365): Train loss 1.592, Val loss 1.761\n",
      "Ep 1 (Step 060370): Train loss 1.954, Val loss 1.760\n",
      "Ep 1 (Step 060375): Train loss 1.669, Val loss 1.753\n",
      "Ep 1 (Step 060380): Train loss 1.909, Val loss 1.760\n",
      "Ep 1 (Step 060385): Train loss 1.955, Val loss 1.791\n",
      "Ep 1 (Step 060390): Train loss 1.670, Val loss 1.788\n",
      "Ep 1 (Step 060395): Train loss 1.883, Val loss 1.774\n",
      "Ep 1 (Step 060400): Train loss 1.787, Val loss 1.771\n",
      "Ep 1 (Step 060405): Train loss 1.954, Val loss 1.767\n",
      "Ep 1 (Step 060410): Train loss 1.722, Val loss 1.770\n",
      "Ep 1 (Step 060415): Train loss 1.972, Val loss 1.771\n",
      "Ep 1 (Step 060420): Train loss 1.444, Val loss 1.768\n",
      "Ep 1 (Step 060425): Train loss 1.941, Val loss 1.769\n",
      "Ep 1 (Step 060430): Train loss 1.664, Val loss 1.775\n",
      "Ep 1 (Step 060435): Train loss 1.781, Val loss 1.776\n",
      "Ep 1 (Step 060440): Train loss 1.882, Val loss 1.770\n",
      "Ep 1 (Step 060445): Train loss 1.816, Val loss 1.770\n",
      "Ep 1 (Step 060450): Train loss 1.739, Val loss 1.786\n",
      "Ep 1 (Step 060455): Train loss 1.847, Val loss 1.786\n",
      "Ep 1 (Step 060460): Train loss 1.847, Val loss 1.775\n",
      "Ep 1 (Step 060465): Train loss 1.867, Val loss 1.772\n",
      "Ep 1 (Step 060470): Train loss 1.534, Val loss 1.781\n",
      "Ep 1 (Step 060475): Train loss 1.504, Val loss 1.783\n",
      "Ep 1 (Step 060480): Train loss 1.929, Val loss 1.776\n",
      "Ep 1 (Step 060485): Train loss 1.577, Val loss 1.773\n",
      "Ep 1 (Step 060490): Train loss 1.924, Val loss 1.776\n",
      "Ep 1 (Step 060495): Train loss 1.780, Val loss 1.780\n",
      "Ep 1 (Step 060500): Train loss 1.852, Val loss 1.776\n",
      "Ep 1 (Step 060505): Train loss 2.008, Val loss 1.776\n",
      "Ep 1 (Step 060510): Train loss 1.884, Val loss 1.780\n",
      "Ep 1 (Step 060515): Train loss 1.712, Val loss 1.781\n",
      "Ep 1 (Step 060520): Train loss 1.938, Val loss 1.782\n",
      "Ep 1 (Step 060525): Train loss 1.780, Val loss 1.780\n",
      "Ep 1 (Step 060530): Train loss 1.660, Val loss 1.777\n",
      "Ep 1 (Step 060535): Train loss 1.838, Val loss 1.778\n",
      "Ep 1 (Step 060540): Train loss 1.653, Val loss 1.777\n",
      "Ep 1 (Step 060545): Train loss 1.855, Val loss 1.770\n",
      "Ep 1 (Step 060550): Train loss 1.719, Val loss 1.763\n",
      "Ep 1 (Step 060555): Train loss 1.676, Val loss 1.757\n",
      "Ep 1 (Step 060560): Train loss 1.874, Val loss 1.764\n",
      "Ep 1 (Step 060565): Train loss 2.017, Val loss 1.768\n",
      "Ep 1 (Step 060570): Train loss 1.977, Val loss 1.769\n",
      "Ep 1 (Step 060575): Train loss 1.857, Val loss 1.769\n",
      "Ep 1 (Step 060580): Train loss 1.658, Val loss 1.768\n",
      "Ep 1 (Step 060585): Train loss 1.927, Val loss 1.778\n",
      "Ep 1 (Step 060590): Train loss 1.787, Val loss 1.772\n",
      "Ep 1 (Step 060595): Train loss 1.871, Val loss 1.773\n",
      "Ep 1 (Step 060600): Train loss 1.847, Val loss 1.783\n",
      "Ep 1 (Step 060605): Train loss 1.923, Val loss 1.790\n",
      "Ep 1 (Step 060610): Train loss 1.602, Val loss 1.792\n",
      "Ep 1 (Step 060615): Train loss 1.565, Val loss 1.793\n",
      "Ep 1 (Step 060620): Train loss 1.755, Val loss 1.790\n",
      "Ep 1 (Step 060625): Train loss 1.640, Val loss 1.787\n",
      "Ep 1 (Step 060630): Train loss 1.712, Val loss 1.783\n",
      "Ep 1 (Step 060635): Train loss 1.587, Val loss 1.789\n",
      "Ep 1 (Step 060640): Train loss 1.791, Val loss 1.787\n",
      "Ep 1 (Step 060645): Train loss 1.805, Val loss 1.786\n",
      "Ep 1 (Step 060650): Train loss 2.048, Val loss 1.774\n",
      "Ep 1 (Step 060655): Train loss 1.733, Val loss 1.774\n",
      "Ep 1 (Step 060660): Train loss 1.862, Val loss 1.784\n",
      "Ep 1 (Step 060665): Train loss 1.723, Val loss 1.800\n",
      "Ep 1 (Step 060670): Train loss 1.666, Val loss 1.799\n",
      "Ep 1 (Step 060675): Train loss 1.711, Val loss 1.798\n",
      "Ep 1 (Step 060680): Train loss 1.916, Val loss 1.800\n",
      "Ep 1 (Step 060685): Train loss 1.817, Val loss 1.802\n",
      "Ep 1 (Step 060690): Train loss 1.740, Val loss 1.805\n",
      "Ep 1 (Step 060695): Train loss 1.982, Val loss 1.800\n",
      "Ep 1 (Step 060700): Train loss 1.761, Val loss 1.796\n",
      "Ep 1 (Step 060705): Train loss 1.963, Val loss 1.792\n",
      "Ep 1 (Step 060710): Train loss 1.677, Val loss 1.789\n",
      "Ep 1 (Step 060715): Train loss 1.974, Val loss 1.790\n",
      "Ep 1 (Step 060720): Train loss 1.726, Val loss 1.788\n",
      "Ep 1 (Step 060725): Train loss 1.909, Val loss 1.782\n",
      "Ep 1 (Step 060730): Train loss 1.752, Val loss 1.791\n",
      "Ep 1 (Step 060735): Train loss 1.866, Val loss 1.790\n",
      "Ep 1 (Step 060740): Train loss 1.743, Val loss 1.790\n",
      "Ep 1 (Step 060745): Train loss 1.656, Val loss 1.790\n",
      "Ep 1 (Step 060750): Train loss 1.796, Val loss 1.793\n",
      "Ep 1 (Step 060755): Train loss 1.698, Val loss 1.794\n",
      "Ep 1 (Step 060760): Train loss 1.829, Val loss 1.793\n",
      "Ep 1 (Step 060765): Train loss 1.702, Val loss 1.792\n",
      "Ep 1 (Step 060770): Train loss 1.951, Val loss 1.787\n",
      "Ep 1 (Step 060775): Train loss 1.603, Val loss 1.794\n",
      "Ep 1 (Step 060780): Train loss 1.982, Val loss 1.791\n",
      "Ep 1 (Step 060785): Train loss 1.717, Val loss 1.775\n",
      "Ep 1 (Step 060790): Train loss 1.769, Val loss 1.776\n",
      "Ep 1 (Step 060795): Train loss 1.696, Val loss 1.788\n",
      "Ep 1 (Step 060800): Train loss 1.644, Val loss 1.780\n",
      "Ep 1 (Step 060805): Train loss 1.957, Val loss 1.773\n",
      "Ep 1 (Step 060810): Train loss 2.197, Val loss 1.777\n",
      "Ep 1 (Step 060815): Train loss 1.814, Val loss 1.788\n",
      "Ep 1 (Step 060820): Train loss 1.771, Val loss 1.788\n",
      "Ep 1 (Step 060825): Train loss 1.690, Val loss 1.786\n",
      "Ep 1 (Step 060830): Train loss 1.826, Val loss 1.793\n",
      "Ep 1 (Step 060835): Train loss 1.853, Val loss 1.798\n",
      "Ep 1 (Step 060840): Train loss 2.026, Val loss 1.795\n",
      "Ep 1 (Step 060845): Train loss 1.741, Val loss 1.788\n",
      "Ep 1 (Step 060850): Train loss 1.766, Val loss 1.789\n",
      "Ep 1 (Step 060855): Train loss 1.923, Val loss 1.795\n",
      "Ep 1 (Step 060860): Train loss 1.854, Val loss 1.789\n",
      "Ep 1 (Step 060865): Train loss 1.805, Val loss 1.790\n",
      "Ep 1 (Step 060870): Train loss 1.556, Val loss 1.784\n",
      "Ep 1 (Step 060875): Train loss 1.915, Val loss 1.790\n",
      "Ep 1 (Step 060880): Train loss 1.789, Val loss 1.793\n",
      "Ep 1 (Step 060885): Train loss 2.005, Val loss 1.794\n",
      "Ep 1 (Step 060890): Train loss 1.760, Val loss 1.793\n",
      "Ep 1 (Step 060895): Train loss 1.760, Val loss 1.792\n",
      "Ep 1 (Step 060900): Train loss 1.826, Val loss 1.790\n",
      "Ep 1 (Step 060905): Train loss 2.008, Val loss 1.795\n",
      "Ep 1 (Step 060910): Train loss 1.913, Val loss 1.793\n",
      "Ep 1 (Step 060915): Train loss 1.687, Val loss 1.783\n",
      "Ep 1 (Step 060920): Train loss 1.603, Val loss 1.771\n",
      "Ep 1 (Step 060925): Train loss 2.247, Val loss 1.758\n",
      "Ep 1 (Step 060930): Train loss 1.534, Val loss 1.760\n",
      "Ep 1 (Step 060935): Train loss 1.701, Val loss 1.766\n",
      "Ep 1 (Step 060940): Train loss 1.787, Val loss 1.763\n",
      "Ep 1 (Step 060945): Train loss 1.910, Val loss 1.767\n",
      "Ep 1 (Step 060950): Train loss 1.904, Val loss 1.759\n",
      "Ep 1 (Step 060955): Train loss 1.633, Val loss 1.757\n",
      "Ep 1 (Step 060960): Train loss 1.963, Val loss 1.751\n",
      "Ep 1 (Step 060965): Train loss 1.640, Val loss 1.743\n",
      "Ep 1 (Step 060970): Train loss 1.664, Val loss 1.742\n",
      "Ep 1 (Step 060975): Train loss 1.824, Val loss 1.744\n",
      "Ep 1 (Step 060980): Train loss 1.848, Val loss 1.747\n",
      "Ep 1 (Step 060985): Train loss 1.873, Val loss 1.750\n",
      "Ep 1 (Step 060990): Train loss 1.761, Val loss 1.763\n",
      "Ep 1 (Step 060995): Train loss 1.807, Val loss 1.752\n",
      "Ep 1 (Step 061000): Train loss 1.556, Val loss 1.750\n",
      "Ep 1 (Step 061005): Train loss 1.959, Val loss 1.755\n",
      "Ep 1 (Step 061010): Train loss 1.628, Val loss 1.754\n",
      "Ep 1 (Step 061015): Train loss 1.699, Val loss 1.748\n",
      "Ep 1 (Step 061020): Train loss 1.763, Val loss 1.756\n",
      "Ep 1 (Step 061025): Train loss 1.903, Val loss 1.750\n",
      "Ep 1 (Step 061030): Train loss 1.798, Val loss 1.759\n",
      "Ep 1 (Step 061035): Train loss 1.860, Val loss 1.757\n",
      "Ep 1 (Step 061040): Train loss 2.074, Val loss 1.764\n",
      "Ep 1 (Step 061045): Train loss 2.170, Val loss 1.772\n",
      "Ep 1 (Step 061050): Train loss 1.933, Val loss 1.762\n",
      "Ep 1 (Step 061055): Train loss 1.742, Val loss 1.752\n",
      "Ep 1 (Step 061060): Train loss 1.859, Val loss 1.754\n",
      "Ep 1 (Step 061065): Train loss 1.681, Val loss 1.755\n",
      "Ep 1 (Step 061070): Train loss 1.646, Val loss 1.754\n",
      "Ep 1 (Step 061075): Train loss 1.783, Val loss 1.753\n",
      "Ep 1 (Step 061080): Train loss 1.974, Val loss 1.757\n",
      "Ep 1 (Step 061085): Train loss 1.834, Val loss 1.752\n",
      "Ep 1 (Step 061090): Train loss 1.871, Val loss 1.754\n",
      "Ep 1 (Step 061095): Train loss 1.652, Val loss 1.752\n",
      "Ep 1 (Step 061100): Train loss 1.829, Val loss 1.750\n",
      "Ep 1 (Step 061105): Train loss 2.016, Val loss 1.754\n",
      "Ep 1 (Step 061110): Train loss 1.799, Val loss 1.745\n",
      "Ep 1 (Step 061115): Train loss 1.762, Val loss 1.741\n",
      "Ep 1 (Step 061120): Train loss 1.837, Val loss 1.747\n",
      "Ep 1 (Step 061125): Train loss 1.744, Val loss 1.758\n",
      "Ep 1 (Step 061130): Train loss 1.547, Val loss 1.760\n",
      "Ep 1 (Step 061135): Train loss 2.206, Val loss 1.754\n",
      "Ep 1 (Step 061140): Train loss 1.942, Val loss 1.748\n",
      "Ep 1 (Step 061145): Train loss 1.958, Val loss 1.751\n",
      "Ep 1 (Step 061150): Train loss 2.046, Val loss 1.760\n",
      "Ep 1 (Step 061155): Train loss 1.501, Val loss 1.756\n",
      "Ep 1 (Step 061160): Train loss 2.023, Val loss 1.756\n",
      "Ep 1 (Step 061165): Train loss 1.796, Val loss 1.748\n",
      "Ep 1 (Step 061170): Train loss 1.783, Val loss 1.751\n",
      "Ep 1 (Step 061175): Train loss 1.776, Val loss 1.749\n",
      "Ep 1 (Step 061180): Train loss 1.662, Val loss 1.751\n",
      "Ep 1 (Step 061185): Train loss 1.782, Val loss 1.752\n",
      "Ep 1 (Step 061190): Train loss 2.108, Val loss 1.743\n",
      "Ep 1 (Step 061195): Train loss 1.996, Val loss 1.755\n",
      "Ep 1 (Step 061200): Train loss 1.916, Val loss 1.774\n",
      "Ep 1 (Step 061205): Train loss 1.624, Val loss 1.780\n",
      "Ep 1 (Step 061210): Train loss 1.609, Val loss 1.763\n",
      "Ep 1 (Step 061215): Train loss 1.542, Val loss 1.760\n",
      "Ep 1 (Step 061220): Train loss 1.613, Val loss 1.759\n",
      "Ep 1 (Step 061225): Train loss 2.042, Val loss 1.759\n",
      "Ep 1 (Step 061230): Train loss 1.611, Val loss 1.760\n",
      "Ep 1 (Step 061235): Train loss 1.649, Val loss 1.758\n",
      "Ep 1 (Step 061240): Train loss 1.599, Val loss 1.765\n",
      "Ep 1 (Step 061245): Train loss 2.008, Val loss 1.764\n",
      "Ep 1 (Step 061250): Train loss 1.710, Val loss 1.753\n",
      "Ep 1 (Step 061255): Train loss 1.930, Val loss 1.755\n",
      "Ep 1 (Step 061260): Train loss 2.073, Val loss 1.760\n",
      "Ep 1 (Step 061265): Train loss 1.696, Val loss 1.760\n",
      "Ep 1 (Step 061270): Train loss 1.561, Val loss 1.758\n",
      "Ep 1 (Step 061275): Train loss 1.671, Val loss 1.756\n",
      "Ep 1 (Step 061280): Train loss 1.934, Val loss 1.754\n",
      "Ep 1 (Step 061285): Train loss 1.860, Val loss 1.754\n",
      "Ep 1 (Step 061290): Train loss 1.606, Val loss 1.744\n",
      "Ep 1 (Step 061295): Train loss 1.797, Val loss 1.749\n",
      "Ep 1 (Step 061300): Train loss 1.842, Val loss 1.752\n",
      "Ep 1 (Step 061305): Train loss 2.097, Val loss 1.753\n",
      "Ep 1 (Step 061310): Train loss 1.735, Val loss 1.752\n",
      "Ep 1 (Step 061315): Train loss 1.566, Val loss 1.748\n",
      "Ep 1 (Step 061320): Train loss 1.610, Val loss 1.751\n",
      "Ep 1 (Step 061325): Train loss 1.646, Val loss 1.762\n",
      "Ep 1 (Step 061330): Train loss 1.694, Val loss 1.766\n",
      "Ep 1 (Step 061335): Train loss 1.817, Val loss 1.768\n",
      "Ep 1 (Step 061340): Train loss 2.097, Val loss 1.763\n",
      "Ep 1 (Step 061345): Train loss 1.887, Val loss 1.762\n",
      "Ep 1 (Step 061350): Train loss 1.730, Val loss 1.755\n",
      "Ep 1 (Step 061355): Train loss 1.720, Val loss 1.752\n",
      "Ep 1 (Step 061360): Train loss 1.686, Val loss 1.751\n",
      "Ep 1 (Step 061365): Train loss 1.918, Val loss 1.753\n",
      "Ep 1 (Step 061370): Train loss 1.768, Val loss 1.753\n",
      "Ep 1 (Step 061375): Train loss 1.694, Val loss 1.755\n",
      "Ep 1 (Step 061380): Train loss 1.725, Val loss 1.757\n",
      "Ep 1 (Step 061385): Train loss 1.712, Val loss 1.764\n",
      "Ep 1 (Step 061390): Train loss 1.984, Val loss 1.763\n",
      "Ep 1 (Step 061395): Train loss 2.087, Val loss 1.754\n",
      "Ep 1 (Step 061400): Train loss 1.867, Val loss 1.761\n",
      "Ep 1 (Step 061405): Train loss 1.951, Val loss 1.779\n",
      "Ep 1 (Step 061410): Train loss 1.993, Val loss 1.776\n",
      "Ep 1 (Step 061415): Train loss 1.438, Val loss 1.770\n",
      "Ep 1 (Step 061420): Train loss 1.630, Val loss 1.759\n",
      "Ep 1 (Step 061425): Train loss 1.640, Val loss 1.754\n",
      "Ep 1 (Step 061430): Train loss 1.752, Val loss 1.746\n",
      "Ep 1 (Step 061435): Train loss 1.573, Val loss 1.744\n",
      "Ep 1 (Step 061440): Train loss 1.959, Val loss 1.751\n",
      "Ep 1 (Step 061445): Train loss 1.815, Val loss 1.757\n",
      "Ep 1 (Step 061450): Train loss 1.862, Val loss 1.761\n",
      "Ep 1 (Step 061455): Train loss 1.848, Val loss 1.765\n",
      "Ep 1 (Step 061460): Train loss 1.830, Val loss 1.764\n",
      "Ep 1 (Step 061465): Train loss 1.780, Val loss 1.762\n",
      "Ep 1 (Step 061470): Train loss 1.750, Val loss 1.769\n",
      "Ep 1 (Step 061475): Train loss 1.930, Val loss 1.771\n",
      "Ep 1 (Step 061480): Train loss 1.847, Val loss 1.767\n",
      "Ep 1 (Step 061485): Train loss 1.686, Val loss 1.772\n",
      "Ep 1 (Step 061490): Train loss 1.766, Val loss 1.773\n",
      "Ep 1 (Step 061495): Train loss 1.873, Val loss 1.768\n",
      "Ep 1 (Step 061500): Train loss 2.157, Val loss 1.760\n",
      "Ep 1 (Step 061505): Train loss 1.572, Val loss 1.762\n",
      "Ep 1 (Step 061510): Train loss 1.790, Val loss 1.760\n",
      "Ep 1 (Step 061515): Train loss 2.107, Val loss 1.756\n",
      "Ep 1 (Step 061520): Train loss 2.137, Val loss 1.766\n",
      "Ep 1 (Step 061525): Train loss 1.795, Val loss 1.762\n",
      "Ep 1 (Step 061530): Train loss 1.647, Val loss 1.756\n",
      "Ep 1 (Step 061535): Train loss 1.870, Val loss 1.752\n",
      "Ep 1 (Step 061540): Train loss 1.849, Val loss 1.752\n",
      "Ep 1 (Step 061545): Train loss 1.724, Val loss 1.750\n",
      "Ep 1 (Step 061550): Train loss 1.745, Val loss 1.753\n",
      "Ep 1 (Step 061555): Train loss 2.134, Val loss 1.760\n",
      "Ep 1 (Step 061560): Train loss 1.540, Val loss 1.762\n",
      "Ep 1 (Step 061565): Train loss 1.958, Val loss 1.764\n",
      "Ep 1 (Step 061570): Train loss 1.534, Val loss 1.759\n",
      "Ep 1 (Step 061575): Train loss 1.662, Val loss 1.757\n",
      "Ep 1 (Step 061580): Train loss 1.736, Val loss 1.754\n",
      "Ep 1 (Step 061585): Train loss 1.877, Val loss 1.745\n",
      "Ep 1 (Step 061590): Train loss 1.910, Val loss 1.751\n",
      "Ep 1 (Step 061595): Train loss 1.686, Val loss 1.758\n",
      "Ep 1 (Step 061600): Train loss 1.755, Val loss 1.756\n",
      "Ep 1 (Step 061605): Train loss 1.818, Val loss 1.750\n",
      "Ep 1 (Step 061610): Train loss 1.726, Val loss 1.754\n",
      "Ep 1 (Step 061615): Train loss 1.827, Val loss 1.751\n",
      "Ep 1 (Step 061620): Train loss 1.648, Val loss 1.762\n",
      "Ep 1 (Step 061625): Train loss 1.740, Val loss 1.762\n",
      "Ep 1 (Step 061630): Train loss 1.800, Val loss 1.761\n",
      "Ep 1 (Step 061635): Train loss 1.758, Val loss 1.752\n",
      "Ep 1 (Step 061640): Train loss 2.090, Val loss 1.744\n",
      "Ep 1 (Step 061645): Train loss 1.793, Val loss 1.745\n",
      "Ep 1 (Step 061650): Train loss 1.632, Val loss 1.742\n",
      "Ep 1 (Step 061655): Train loss 1.695, Val loss 1.737\n",
      "Ep 1 (Step 061660): Train loss 1.867, Val loss 1.739\n",
      "Ep 1 (Step 061665): Train loss 1.841, Val loss 1.753\n",
      "Ep 1 (Step 061670): Train loss 1.814, Val loss 1.761\n",
      "Ep 1 (Step 061675): Train loss 1.753, Val loss 1.760\n",
      "Ep 1 (Step 061680): Train loss 1.978, Val loss 1.756\n",
      "Ep 1 (Step 061685): Train loss 1.738, Val loss 1.760\n",
      "Ep 1 (Step 061690): Train loss 1.705, Val loss 1.759\n",
      "Ep 1 (Step 061695): Train loss 1.594, Val loss 1.757\n",
      "Ep 1 (Step 061700): Train loss 1.620, Val loss 1.754\n",
      "Ep 1 (Step 061705): Train loss 1.742, Val loss 1.754\n",
      "Ep 1 (Step 061710): Train loss 1.678, Val loss 1.741\n",
      "Ep 1 (Step 061715): Train loss 1.663, Val loss 1.736\n",
      "Ep 1 (Step 061720): Train loss 1.916, Val loss 1.741\n",
      "Ep 1 (Step 061725): Train loss 1.697, Val loss 1.740\n",
      "Ep 1 (Step 061730): Train loss 1.681, Val loss 1.752\n",
      "Ep 1 (Step 061735): Train loss 1.591, Val loss 1.756\n",
      "Ep 1 (Step 061740): Train loss 1.766, Val loss 1.754\n",
      "Ep 1 (Step 061745): Train loss 1.736, Val loss 1.760\n",
      "Ep 1 (Step 061750): Train loss 1.781, Val loss 1.759\n",
      "Ep 1 (Step 061755): Train loss 1.711, Val loss 1.762\n",
      "Ep 1 (Step 061760): Train loss 1.806, Val loss 1.761\n",
      "Ep 1 (Step 061765): Train loss 1.842, Val loss 1.762\n",
      "Ep 1 (Step 061770): Train loss 1.902, Val loss 1.765\n",
      "Ep 1 (Step 061775): Train loss 1.721, Val loss 1.763\n",
      "Ep 1 (Step 061780): Train loss 1.703, Val loss 1.765\n",
      "Ep 1 (Step 061785): Train loss 1.804, Val loss 1.762\n",
      "Ep 1 (Step 061790): Train loss 1.687, Val loss 1.769\n",
      "Ep 1 (Step 061795): Train loss 1.933, Val loss 1.772\n",
      "Ep 1 (Step 061800): Train loss 1.607, Val loss 1.776\n",
      "Ep 1 (Step 061805): Train loss 1.666, Val loss 1.766\n",
      "Ep 1 (Step 061810): Train loss 1.988, Val loss 1.753\n",
      "Ep 1 (Step 061815): Train loss 1.752, Val loss 1.750\n",
      "Ep 1 (Step 061820): Train loss 2.033, Val loss 1.761\n",
      "Ep 1 (Step 061825): Train loss 1.702, Val loss 1.769\n",
      "Ep 1 (Step 061830): Train loss 1.855, Val loss 1.764\n",
      "Ep 1 (Step 061835): Train loss 1.736, Val loss 1.769\n",
      "Ep 1 (Step 061840): Train loss 2.152, Val loss 1.764\n",
      "Ep 1 (Step 061845): Train loss 1.708, Val loss 1.755\n",
      "Ep 1 (Step 061850): Train loss 1.503, Val loss 1.746\n",
      "Ep 1 (Step 061855): Train loss 1.600, Val loss 1.744\n",
      "Ep 1 (Step 061860): Train loss 1.799, Val loss 1.749\n",
      "Ep 1 (Step 061865): Train loss 1.540, Val loss 1.754\n",
      "Ep 1 (Step 061870): Train loss 1.692, Val loss 1.763\n",
      "Ep 1 (Step 061875): Train loss 1.817, Val loss 1.765\n",
      "Ep 1 (Step 061880): Train loss 1.731, Val loss 1.770\n",
      "Ep 1 (Step 061885): Train loss 1.927, Val loss 1.778\n",
      "Ep 1 (Step 061890): Train loss 1.907, Val loss 1.778\n",
      "Ep 1 (Step 061895): Train loss 1.657, Val loss 1.766\n",
      "Ep 1 (Step 061900): Train loss 2.183, Val loss 1.755\n",
      "Ep 1 (Step 061905): Train loss 1.838, Val loss 1.756\n",
      "Ep 1 (Step 061910): Train loss 1.601, Val loss 1.764\n",
      "Ep 1 (Step 061915): Train loss 1.943, Val loss 1.764\n",
      "Ep 1 (Step 061920): Train loss 1.956, Val loss 1.754\n",
      "Ep 1 (Step 061925): Train loss 1.699, Val loss 1.750\n",
      "Ep 1 (Step 061930): Train loss 2.028, Val loss 1.747\n",
      "Ep 1 (Step 061935): Train loss 1.791, Val loss 1.747\n",
      "Ep 1 (Step 061940): Train loss 1.967, Val loss 1.737\n",
      "Ep 1 (Step 061945): Train loss 1.606, Val loss 1.745\n",
      "Ep 1 (Step 061950): Train loss 1.832, Val loss 1.757\n",
      "Ep 1 (Step 061955): Train loss 2.098, Val loss 1.752\n",
      "Ep 1 (Step 061960): Train loss 1.646, Val loss 1.752\n",
      "Ep 1 (Step 061965): Train loss 2.100, Val loss 1.751\n",
      "Ep 1 (Step 061970): Train loss 1.675, Val loss 1.769\n",
      "Ep 1 (Step 061975): Train loss 1.943, Val loss 1.791\n",
      "Ep 1 (Step 061980): Train loss 1.940, Val loss 1.794\n",
      "Ep 1 (Step 061985): Train loss 1.735, Val loss 1.782\n",
      "Ep 1 (Step 061990): Train loss 1.836, Val loss 1.783\n",
      "Ep 1 (Step 061995): Train loss 1.771, Val loss 1.782\n",
      "Ep 1 (Step 062000): Train loss 1.912, Val loss 1.786\n",
      "Ep 1 (Step 062005): Train loss 2.002, Val loss 1.783\n",
      "Ep 1 (Step 062010): Train loss 1.649, Val loss 1.778\n",
      "Ep 1 (Step 062015): Train loss 1.672, Val loss 1.781\n",
      "Ep 1 (Step 062020): Train loss 1.667, Val loss 1.796\n",
      "Ep 1 (Step 062025): Train loss 2.034, Val loss 1.780\n",
      "Ep 1 (Step 062030): Train loss 1.924, Val loss 1.759\n",
      "Ep 1 (Step 062035): Train loss 1.722, Val loss 1.752\n",
      "Ep 1 (Step 062040): Train loss 1.813, Val loss 1.756\n",
      "Ep 1 (Step 062045): Train loss 1.749, Val loss 1.773\n",
      "Ep 1 (Step 062050): Train loss 1.848, Val loss 1.771\n",
      "Ep 1 (Step 062055): Train loss 1.741, Val loss 1.751\n",
      "Ep 1 (Step 062060): Train loss 1.724, Val loss 1.750\n",
      "Ep 1 (Step 062065): Train loss 1.825, Val loss 1.755\n",
      "Ep 1 (Step 062070): Train loss 1.704, Val loss 1.761\n",
      "Ep 1 (Step 062075): Train loss 1.817, Val loss 1.767\n",
      "Ep 1 (Step 062080): Train loss 2.100, Val loss 1.758\n",
      "Ep 1 (Step 062085): Train loss 1.690, Val loss 1.760\n",
      "Ep 1 (Step 062090): Train loss 1.954, Val loss 1.771\n",
      "Ep 1 (Step 062095): Train loss 1.882, Val loss 1.793\n",
      "Ep 1 (Step 062100): Train loss 1.904, Val loss 1.784\n",
      "Ep 1 (Step 062105): Train loss 1.956, Val loss 1.777\n",
      "Ep 1 (Step 062110): Train loss 1.686, Val loss 1.770\n",
      "Ep 1 (Step 062115): Train loss 1.908, Val loss 1.765\n",
      "Ep 1 (Step 062120): Train loss 1.530, Val loss 1.756\n",
      "Ep 1 (Step 062125): Train loss 1.531, Val loss 1.755\n",
      "Ep 1 (Step 062130): Train loss 1.906, Val loss 1.757\n",
      "Ep 1 (Step 062135): Train loss 1.488, Val loss 1.755\n",
      "Ep 1 (Step 062140): Train loss 1.470, Val loss 1.751\n",
      "Ep 1 (Step 062145): Train loss 1.566, Val loss 1.749\n",
      "Ep 1 (Step 062150): Train loss 1.760, Val loss 1.748\n",
      "Ep 1 (Step 062155): Train loss 1.506, Val loss 1.748\n",
      "Ep 1 (Step 062160): Train loss 1.982, Val loss 1.752\n",
      "Ep 1 (Step 062165): Train loss 1.652, Val loss 1.761\n",
      "Ep 1 (Step 062170): Train loss 1.911, Val loss 1.760\n",
      "Ep 1 (Step 062175): Train loss 1.739, Val loss 1.751\n",
      "Ep 1 (Step 062180): Train loss 1.997, Val loss 1.739\n",
      "Ep 1 (Step 062185): Train loss 1.907, Val loss 1.739\n",
      "Ep 1 (Step 062190): Train loss 1.860, Val loss 1.745\n",
      "Ep 1 (Step 062195): Train loss 1.694, Val loss 1.751\n",
      "Ep 1 (Step 062200): Train loss 1.661, Val loss 1.756\n",
      "Ep 1 (Step 062205): Train loss 1.606, Val loss 1.763\n",
      "Ep 1 (Step 062210): Train loss 1.667, Val loss 1.758\n",
      "Ep 1 (Step 062215): Train loss 1.740, Val loss 1.753\n",
      "Ep 1 (Step 062220): Train loss 2.090, Val loss 1.751\n",
      "Ep 1 (Step 062225): Train loss 1.760, Val loss 1.758\n",
      "Ep 1 (Step 062230): Train loss 1.980, Val loss 1.759\n",
      "Ep 1 (Step 062235): Train loss 1.617, Val loss 1.753\n",
      "Ep 1 (Step 062240): Train loss 1.708, Val loss 1.767\n",
      "Ep 1 (Step 062245): Train loss 1.587, Val loss 1.771\n",
      "Ep 1 (Step 062250): Train loss 1.686, Val loss 1.774\n",
      "Ep 1 (Step 062255): Train loss 1.857, Val loss 1.774\n",
      "Ep 1 (Step 062260): Train loss 1.907, Val loss 1.773\n",
      "Ep 1 (Step 062265): Train loss 2.010, Val loss 1.777\n",
      "Ep 1 (Step 062270): Train loss 1.728, Val loss 1.764\n",
      "Ep 1 (Step 062275): Train loss 1.443, Val loss 1.754\n",
      "Ep 1 (Step 062280): Train loss 1.877, Val loss 1.759\n",
      "Ep 1 (Step 062285): Train loss 1.692, Val loss 1.752\n",
      "Ep 1 (Step 062290): Train loss 1.686, Val loss 1.740\n",
      "Ep 1 (Step 062295): Train loss 1.723, Val loss 1.743\n",
      "Ep 1 (Step 062300): Train loss 1.555, Val loss 1.747\n",
      "Ep 1 (Step 062305): Train loss 1.955, Val loss 1.753\n",
      "Ep 1 (Step 062310): Train loss 1.706, Val loss 1.751\n",
      "Ep 1 (Step 062315): Train loss 1.698, Val loss 1.749\n",
      "Ep 1 (Step 062320): Train loss 1.713, Val loss 1.756\n",
      "Ep 1 (Step 062325): Train loss 1.486, Val loss 1.765\n",
      "Ep 1 (Step 062330): Train loss 1.916, Val loss 1.768\n",
      "Ep 1 (Step 062335): Train loss 1.851, Val loss 1.747\n",
      "Ep 1 (Step 062340): Train loss 1.627, Val loss 1.740\n",
      "Ep 1 (Step 062345): Train loss 1.733, Val loss 1.740\n",
      "Ep 1 (Step 062350): Train loss 1.855, Val loss 1.755\n",
      "Ep 1 (Step 062355): Train loss 1.762, Val loss 1.756\n",
      "Ep 1 (Step 062360): Train loss 1.744, Val loss 1.755\n",
      "Ep 1 (Step 062365): Train loss 1.825, Val loss 1.745\n",
      "Ep 1 (Step 062370): Train loss 1.876, Val loss 1.740\n",
      "Ep 1 (Step 062375): Train loss 1.853, Val loss 1.736\n",
      "Ep 1 (Step 062380): Train loss 2.029, Val loss 1.736\n",
      "Ep 1 (Step 062385): Train loss 2.313, Val loss 1.734\n",
      "Ep 1 (Step 062390): Train loss 1.871, Val loss 1.731\n",
      "Ep 1 (Step 062395): Train loss 1.629, Val loss 1.749\n",
      "Ep 1 (Step 062400): Train loss 1.863, Val loss 1.755\n",
      "Ep 1 (Step 062405): Train loss 1.760, Val loss 1.756\n",
      "Ep 1 (Step 062410): Train loss 1.823, Val loss 1.748\n",
      "Ep 1 (Step 062415): Train loss 1.683, Val loss 1.751\n",
      "Ep 1 (Step 062420): Train loss 1.796, Val loss 1.747\n",
      "Ep 1 (Step 062425): Train loss 1.812, Val loss 1.752\n",
      "Ep 1 (Step 062430): Train loss 1.684, Val loss 1.754\n",
      "Ep 1 (Step 062435): Train loss 1.670, Val loss 1.756\n",
      "Ep 1 (Step 062440): Train loss 1.662, Val loss 1.759\n",
      "Ep 1 (Step 062445): Train loss 2.186, Val loss 1.755\n",
      "Ep 1 (Step 062450): Train loss 1.803, Val loss 1.761\n",
      "Ep 1 (Step 062455): Train loss 1.937, Val loss 1.771\n",
      "Ep 1 (Step 062460): Train loss 1.757, Val loss 1.780\n",
      "Ep 1 (Step 062465): Train loss 1.773, Val loss 1.770\n",
      "Ep 1 (Step 062470): Train loss 1.660, Val loss 1.765\n",
      "Ep 1 (Step 062475): Train loss 1.829, Val loss 1.758\n",
      "Ep 1 (Step 062480): Train loss 2.059, Val loss 1.766\n",
      "Ep 1 (Step 062485): Train loss 1.983, Val loss 1.760\n",
      "Ep 1 (Step 062490): Train loss 1.844, Val loss 1.751\n",
      "Ep 1 (Step 062495): Train loss 1.559, Val loss 1.756\n",
      "Ep 1 (Step 062500): Train loss 1.767, Val loss 1.762\n",
      "Ep 1 (Step 062505): Train loss 1.711, Val loss 1.762\n",
      "Ep 1 (Step 062510): Train loss 1.710, Val loss 1.767\n",
      "Ep 1 (Step 062515): Train loss 1.908, Val loss 1.764\n",
      "Ep 1 (Step 062520): Train loss 1.838, Val loss 1.758\n",
      "Ep 1 (Step 062525): Train loss 1.898, Val loss 1.752\n",
      "Ep 1 (Step 062530): Train loss 1.767, Val loss 1.749\n",
      "Ep 1 (Step 062535): Train loss 1.839, Val loss 1.747\n",
      "Ep 1 (Step 062540): Train loss 1.678, Val loss 1.752\n",
      "Ep 1 (Step 062545): Train loss 1.907, Val loss 1.750\n",
      "Ep 1 (Step 062550): Train loss 1.868, Val loss 1.751\n",
      "Ep 1 (Step 062555): Train loss 1.592, Val loss 1.748\n",
      "Ep 1 (Step 062560): Train loss 1.892, Val loss 1.737\n",
      "Ep 1 (Step 062565): Train loss 2.107, Val loss 1.738\n",
      "Ep 1 (Step 062570): Train loss 1.838, Val loss 1.734\n",
      "Ep 1 (Step 062575): Train loss 1.936, Val loss 1.737\n",
      "Ep 1 (Step 062580): Train loss 1.883, Val loss 1.745\n",
      "Ep 1 (Step 062585): Train loss 1.806, Val loss 1.746\n",
      "Ep 1 (Step 062590): Train loss 2.036, Val loss 1.747\n",
      "Ep 1 (Step 062595): Train loss 1.847, Val loss 1.749\n",
      "Ep 1 (Step 062600): Train loss 1.868, Val loss 1.745\n",
      "Ep 1 (Step 062605): Train loss 1.837, Val loss 1.743\n",
      "Ep 1 (Step 062610): Train loss 1.513, Val loss 1.738\n",
      "Ep 1 (Step 062615): Train loss 1.965, Val loss 1.735\n",
      "Ep 1 (Step 062620): Train loss 1.609, Val loss 1.734\n",
      "Ep 1 (Step 062625): Train loss 1.881, Val loss 1.736\n",
      "Ep 1 (Step 062630): Train loss 1.577, Val loss 1.746\n",
      "Ep 1 (Step 062635): Train loss 1.928, Val loss 1.753\n",
      "Ep 1 (Step 062640): Train loss 1.858, Val loss 1.760\n",
      "Ep 1 (Step 062645): Train loss 1.605, Val loss 1.749\n",
      "Ep 1 (Step 062650): Train loss 1.687, Val loss 1.748\n",
      "Ep 1 (Step 062655): Train loss 1.907, Val loss 1.746\n",
      "Ep 1 (Step 062660): Train loss 1.614, Val loss 1.746\n",
      "Ep 1 (Step 062665): Train loss 1.832, Val loss 1.733\n",
      "Ep 1 (Step 062670): Train loss 2.070, Val loss 1.728\n",
      "Ep 1 (Step 062675): Train loss 1.629, Val loss 1.736\n",
      "Ep 1 (Step 062680): Train loss 1.773, Val loss 1.744\n",
      "Ep 1 (Step 062685): Train loss 1.784, Val loss 1.742\n",
      "Ep 1 (Step 062690): Train loss 1.810, Val loss 1.741\n",
      "Ep 1 (Step 062695): Train loss 1.726, Val loss 1.743\n",
      "Ep 1 (Step 062700): Train loss 2.036, Val loss 1.749\n",
      "Ep 1 (Step 062705): Train loss 1.954, Val loss 1.750\n",
      "Ep 1 (Step 062710): Train loss 1.663, Val loss 1.755\n",
      "Ep 1 (Step 062715): Train loss 1.761, Val loss 1.762\n",
      "Ep 1 (Step 062720): Train loss 1.651, Val loss 1.766\n",
      "Ep 1 (Step 062725): Train loss 1.812, Val loss 1.767\n",
      "Ep 1 (Step 062730): Train loss 1.889, Val loss 1.768\n",
      "Ep 1 (Step 062735): Train loss 1.639, Val loss 1.762\n",
      "Ep 1 (Step 062740): Train loss 1.671, Val loss 1.768\n",
      "Ep 1 (Step 062745): Train loss 1.746, Val loss 1.760\n",
      "Ep 1 (Step 062750): Train loss 1.646, Val loss 1.757\n",
      "Ep 1 (Step 062755): Train loss 1.957, Val loss 1.765\n",
      "Ep 1 (Step 062760): Train loss 2.158, Val loss 1.760\n",
      "Ep 1 (Step 062765): Train loss 1.736, Val loss 1.759\n",
      "Ep 1 (Step 062770): Train loss 1.726, Val loss 1.759\n",
      "Ep 1 (Step 062775): Train loss 1.797, Val loss 1.754\n",
      "Ep 1 (Step 062780): Train loss 1.855, Val loss 1.747\n",
      "Ep 1 (Step 062785): Train loss 1.683, Val loss 1.751\n",
      "Ep 1 (Step 062790): Train loss 1.734, Val loss 1.760\n",
      "Ep 1 (Step 062795): Train loss 1.828, Val loss 1.758\n",
      "Ep 1 (Step 062800): Train loss 1.690, Val loss 1.757\n",
      "Ep 1 (Step 062805): Train loss 1.750, Val loss 1.756\n",
      "Ep 1 (Step 062810): Train loss 2.031, Val loss 1.754\n",
      "Ep 1 (Step 062815): Train loss 1.854, Val loss 1.752\n",
      "Ep 1 (Step 062820): Train loss 1.847, Val loss 1.760\n",
      "Ep 1 (Step 062825): Train loss 1.860, Val loss 1.758\n",
      "Ep 1 (Step 062830): Train loss 1.924, Val loss 1.755\n",
      "Ep 1 (Step 062835): Train loss 1.903, Val loss 1.755\n",
      "Ep 1 (Step 062840): Train loss 1.634, Val loss 1.747\n",
      "Ep 1 (Step 062845): Train loss 1.959, Val loss 1.751\n",
      "Ep 1 (Step 062850): Train loss 1.689, Val loss 1.747\n",
      "Ep 1 (Step 062855): Train loss 1.931, Val loss 1.749\n",
      "Ep 1 (Step 062860): Train loss 1.715, Val loss 1.758\n",
      "Ep 1 (Step 062865): Train loss 1.608, Val loss 1.761\n",
      "Ep 1 (Step 062870): Train loss 1.597, Val loss 1.749\n",
      "Ep 1 (Step 062875): Train loss 1.787, Val loss 1.741\n",
      "Ep 1 (Step 062880): Train loss 2.098, Val loss 1.737\n",
      "Ep 1 (Step 062885): Train loss 1.647, Val loss 1.746\n",
      "Ep 1 (Step 062890): Train loss 2.033, Val loss 1.750\n",
      "Ep 1 (Step 062895): Train loss 1.830, Val loss 1.744\n",
      "Ep 1 (Step 062900): Train loss 1.850, Val loss 1.749\n",
      "Ep 1 (Step 062905): Train loss 1.948, Val loss 1.743\n",
      "Ep 1 (Step 062910): Train loss 1.643, Val loss 1.734\n",
      "Ep 1 (Step 062915): Train loss 1.770, Val loss 1.733\n",
      "Ep 1 (Step 062920): Train loss 1.698, Val loss 1.739\n",
      "Ep 1 (Step 062925): Train loss 1.966, Val loss 1.744\n",
      "Ep 1 (Step 062930): Train loss 1.602, Val loss 1.752\n",
      "Ep 1 (Step 062935): Train loss 1.994, Val loss 1.753\n",
      "Ep 1 (Step 062940): Train loss 1.773, Val loss 1.752\n",
      "Ep 1 (Step 062945): Train loss 1.708, Val loss 1.753\n",
      "Ep 1 (Step 062950): Train loss 1.961, Val loss 1.758\n",
      "Ep 1 (Step 062955): Train loss 1.886, Val loss 1.766\n",
      "Ep 1 (Step 062960): Train loss 1.949, Val loss 1.758\n",
      "Ep 1 (Step 062965): Train loss 1.767, Val loss 1.754\n",
      "Ep 1 (Step 062970): Train loss 1.883, Val loss 1.748\n",
      "Ep 1 (Step 062975): Train loss 1.911, Val loss 1.753\n",
      "Ep 1 (Step 062980): Train loss 1.674, Val loss 1.759\n",
      "Ep 1 (Step 062985): Train loss 1.813, Val loss 1.756\n",
      "Ep 1 (Step 062990): Train loss 1.727, Val loss 1.761\n",
      "Ep 1 (Step 062995): Train loss 1.758, Val loss 1.765\n",
      "Ep 1 (Step 063000): Train loss 1.645, Val loss 1.766\n",
      "Ep 1 (Step 063005): Train loss 2.091, Val loss 1.769\n",
      "Ep 1 (Step 063010): Train loss 1.773, Val loss 1.768\n",
      "Ep 1 (Step 063015): Train loss 1.722, Val loss 1.762\n",
      "Ep 1 (Step 063020): Train loss 1.854, Val loss 1.759\n",
      "Ep 1 (Step 063025): Train loss 1.935, Val loss 1.769\n",
      "Ep 1 (Step 063030): Train loss 1.906, Val loss 1.782\n",
      "Ep 1 (Step 063035): Train loss 1.788, Val loss 1.779\n",
      "Ep 1 (Step 063040): Train loss 1.479, Val loss 1.766\n",
      "Ep 1 (Step 063045): Train loss 1.842, Val loss 1.758\n",
      "Ep 1 (Step 063050): Train loss 1.867, Val loss 1.754\n",
      "Ep 1 (Step 063055): Train loss 1.641, Val loss 1.755\n",
      "Ep 1 (Step 063060): Train loss 1.846, Val loss 1.747\n",
      "Ep 1 (Step 063065): Train loss 1.821, Val loss 1.746\n",
      "Ep 1 (Step 063070): Train loss 1.936, Val loss 1.740\n",
      "Ep 1 (Step 063075): Train loss 1.883, Val loss 1.734\n",
      "Ep 1 (Step 063080): Train loss 1.787, Val loss 1.740\n",
      "Ep 1 (Step 063085): Train loss 2.245, Val loss 1.750\n",
      "Ep 1 (Step 063090): Train loss 1.751, Val loss 1.749\n",
      "Ep 1 (Step 063095): Train loss 1.739, Val loss 1.737\n",
      "Ep 1 (Step 063100): Train loss 2.077, Val loss 1.721\n",
      "Ep 1 (Step 063105): Train loss 1.602, Val loss 1.726\n",
      "Ep 1 (Step 063110): Train loss 1.576, Val loss 1.734\n",
      "Ep 1 (Step 063115): Train loss 2.026, Val loss 1.744\n",
      "Ep 1 (Step 063120): Train loss 1.735, Val loss 1.749\n",
      "Ep 1 (Step 063125): Train loss 2.002, Val loss 1.741\n",
      "Ep 1 (Step 063130): Train loss 1.601, Val loss 1.735\n",
      "Ep 1 (Step 063135): Train loss 1.841, Val loss 1.747\n",
      "Ep 1 (Step 063140): Train loss 1.921, Val loss 1.743\n",
      "Ep 1 (Step 063145): Train loss 1.629, Val loss 1.749\n",
      "Ep 1 (Step 063150): Train loss 1.818, Val loss 1.753\n",
      "Ep 1 (Step 063155): Train loss 1.728, Val loss 1.747\n",
      "Ep 1 (Step 063160): Train loss 1.929, Val loss 1.748\n",
      "Ep 1 (Step 063165): Train loss 1.643, Val loss 1.760\n",
      "Ep 1 (Step 063170): Train loss 1.732, Val loss 1.757\n",
      "Ep 1 (Step 063175): Train loss 1.789, Val loss 1.755\n",
      "Ep 1 (Step 063180): Train loss 1.613, Val loss 1.754\n",
      "Ep 1 (Step 063185): Train loss 1.675, Val loss 1.755\n",
      "Ep 1 (Step 063190): Train loss 1.850, Val loss 1.752\n",
      "Ep 1 (Step 063195): Train loss 1.544, Val loss 1.752\n",
      "Ep 1 (Step 063200): Train loss 2.011, Val loss 1.750\n",
      "Ep 1 (Step 063205): Train loss 1.875, Val loss 1.758\n",
      "Ep 1 (Step 063210): Train loss 1.705, Val loss 1.762\n",
      "Ep 1 (Step 063215): Train loss 1.847, Val loss 1.762\n",
      "Ep 1 (Step 063220): Train loss 1.886, Val loss 1.761\n",
      "Ep 1 (Step 063225): Train loss 1.733, Val loss 1.773\n",
      "Ep 1 (Step 063230): Train loss 1.865, Val loss 1.771\n",
      "Ep 1 (Step 063235): Train loss 1.720, Val loss 1.760\n",
      "Ep 1 (Step 063240): Train loss 1.831, Val loss 1.761\n",
      "Ep 1 (Step 063245): Train loss 1.988, Val loss 1.760\n",
      "Ep 1 (Step 063250): Train loss 1.611, Val loss 1.740\n",
      "Ep 1 (Step 063255): Train loss 1.802, Val loss 1.731\n",
      "Ep 1 (Step 063260): Train loss 1.813, Val loss 1.736\n",
      "Ep 1 (Step 063265): Train loss 1.631, Val loss 1.739\n",
      "Ep 1 (Step 063270): Train loss 1.668, Val loss 1.741\n",
      "Ep 1 (Step 063275): Train loss 1.648, Val loss 1.736\n",
      "Ep 1 (Step 063280): Train loss 1.994, Val loss 1.740\n",
      "Ep 1 (Step 063285): Train loss 1.777, Val loss 1.750\n",
      "Ep 1 (Step 063290): Train loss 1.832, Val loss 1.749\n",
      "Ep 1 (Step 063295): Train loss 1.680, Val loss 1.762\n",
      "Ep 1 (Step 063300): Train loss 2.037, Val loss 1.765\n",
      "Ep 1 (Step 063305): Train loss 1.713, Val loss 1.770\n",
      "Ep 1 (Step 063310): Train loss 1.697, Val loss 1.771\n",
      "Ep 1 (Step 063315): Train loss 1.532, Val loss 1.765\n",
      "Ep 1 (Step 063320): Train loss 1.750, Val loss 1.765\n",
      "Ep 1 (Step 063325): Train loss 1.747, Val loss 1.767\n",
      "Ep 1 (Step 063330): Train loss 1.707, Val loss 1.772\n",
      "Ep 1 (Step 063335): Train loss 2.068, Val loss 1.768\n",
      "Ep 1 (Step 063340): Train loss 1.622, Val loss 1.779\n",
      "Ep 1 (Step 063345): Train loss 1.711, Val loss 1.777\n",
      "Ep 1 (Step 063350): Train loss 1.730, Val loss 1.769\n",
      "Ep 1 (Step 063355): Train loss 1.931, Val loss 1.772\n",
      "Ep 1 (Step 063360): Train loss 1.692, Val loss 1.776\n",
      "Ep 1 (Step 063365): Train loss 1.712, Val loss 1.773\n",
      "Ep 1 (Step 063370): Train loss 1.480, Val loss 1.762\n",
      "Ep 1 (Step 063375): Train loss 1.741, Val loss 1.759\n",
      "Ep 1 (Step 063380): Train loss 1.829, Val loss 1.761\n",
      "Ep 1 (Step 063385): Train loss 1.946, Val loss 1.757\n",
      "Ep 1 (Step 063390): Train loss 1.696, Val loss 1.763\n",
      "Ep 1 (Step 063395): Train loss 1.974, Val loss 1.767\n",
      "Ep 1 (Step 063400): Train loss 1.954, Val loss 1.779\n",
      "Ep 1 (Step 063405): Train loss 1.593, Val loss 1.776\n",
      "Ep 1 (Step 063410): Train loss 1.743, Val loss 1.777\n",
      "Ep 1 (Step 063415): Train loss 1.888, Val loss 1.777\n",
      "Ep 1 (Step 063420): Train loss 1.589, Val loss 1.774\n",
      "Ep 1 (Step 063425): Train loss 1.636, Val loss 1.769\n",
      "Ep 1 (Step 063430): Train loss 1.601, Val loss 1.772\n",
      "Ep 1 (Step 063435): Train loss 1.850, Val loss 1.785\n",
      "Ep 1 (Step 063440): Train loss 1.498, Val loss 1.774\n",
      "Ep 1 (Step 063445): Train loss 1.898, Val loss 1.761\n",
      "Ep 1 (Step 063450): Train loss 1.818, Val loss 1.761\n",
      "Ep 1 (Step 063455): Train loss 1.631, Val loss 1.762\n",
      "Ep 1 (Step 063460): Train loss 1.723, Val loss 1.767\n",
      "Ep 1 (Step 063465): Train loss 2.058, Val loss 1.765\n",
      "Ep 1 (Step 063470): Train loss 2.003, Val loss 1.768\n",
      "Ep 1 (Step 063475): Train loss 1.696, Val loss 1.792\n",
      "Ep 1 (Step 063480): Train loss 1.990, Val loss 1.794\n",
      "Ep 1 (Step 063485): Train loss 1.669, Val loss 1.785\n",
      "Ep 1 (Step 063490): Train loss 1.566, Val loss 1.786\n",
      "Ep 1 (Step 063495): Train loss 1.760, Val loss 1.780\n",
      "Ep 1 (Step 063500): Train loss 1.731, Val loss 1.781\n",
      "Ep 1 (Step 063505): Train loss 1.690, Val loss 1.786\n",
      "Ep 1 (Step 063510): Train loss 1.592, Val loss 1.784\n",
      "Ep 1 (Step 063515): Train loss 1.662, Val loss 1.773\n",
      "Ep 1 (Step 063520): Train loss 1.821, Val loss 1.767\n",
      "Ep 1 (Step 063525): Train loss 1.639, Val loss 1.764\n",
      "Ep 1 (Step 063530): Train loss 1.744, Val loss 1.770\n",
      "Ep 1 (Step 063535): Train loss 1.676, Val loss 1.778\n",
      "Ep 1 (Step 063540): Train loss 1.805, Val loss 1.775\n",
      "Ep 1 (Step 063545): Train loss 1.649, Val loss 1.766\n",
      "Ep 1 (Step 063550): Train loss 1.750, Val loss 1.766\n",
      "Ep 1 (Step 063555): Train loss 1.897, Val loss 1.772\n",
      "Ep 1 (Step 063560): Train loss 1.974, Val loss 1.779\n",
      "Ep 1 (Step 063565): Train loss 2.065, Val loss 1.777\n",
      "Ep 1 (Step 063570): Train loss 1.690, Val loss 1.772\n",
      "Ep 1 (Step 063575): Train loss 1.465, Val loss 1.770\n",
      "Ep 1 (Step 063580): Train loss 1.721, Val loss 1.758\n",
      "Ep 1 (Step 063585): Train loss 1.800, Val loss 1.753\n",
      "Ep 1 (Step 063590): Train loss 1.848, Val loss 1.756\n",
      "Ep 1 (Step 063595): Train loss 1.993, Val loss 1.769\n",
      "Ep 1 (Step 063600): Train loss 1.820, Val loss 1.773\n",
      "Ep 1 (Step 063605): Train loss 1.838, Val loss 1.779\n",
      "Ep 1 (Step 063610): Train loss 1.490, Val loss 1.781\n",
      "Ep 1 (Step 063615): Train loss 1.663, Val loss 1.775\n",
      "Ep 1 (Step 063620): Train loss 1.729, Val loss 1.763\n",
      "Ep 1 (Step 063625): Train loss 1.932, Val loss 1.749\n",
      "Ep 1 (Step 063630): Train loss 1.701, Val loss 1.751\n",
      "Ep 1 (Step 063635): Train loss 2.180, Val loss 1.758\n",
      "Ep 1 (Step 063640): Train loss 1.505, Val loss 1.769\n",
      "Ep 1 (Step 063645): Train loss 2.089, Val loss 1.767\n",
      "Ep 1 (Step 063650): Train loss 1.871, Val loss 1.768\n",
      "Ep 1 (Step 063655): Train loss 2.041, Val loss 1.760\n",
      "Ep 1 (Step 063660): Train loss 1.629, Val loss 1.758\n",
      "Ep 1 (Step 063665): Train loss 1.633, Val loss 1.761\n",
      "Ep 1 (Step 063670): Train loss 1.663, Val loss 1.770\n",
      "Ep 1 (Step 063675): Train loss 1.831, Val loss 1.774\n",
      "Ep 1 (Step 063680): Train loss 1.683, Val loss 1.773\n",
      "Ep 1 (Step 063685): Train loss 1.422, Val loss 1.773\n",
      "Ep 1 (Step 063690): Train loss 1.881, Val loss 1.778\n",
      "Ep 1 (Step 063695): Train loss 1.797, Val loss 1.774\n",
      "Ep 1 (Step 063700): Train loss 1.978, Val loss 1.773\n",
      "Ep 1 (Step 063705): Train loss 1.944, Val loss 1.777\n",
      "Ep 1 (Step 063710): Train loss 1.548, Val loss 1.777\n",
      "Ep 1 (Step 063715): Train loss 1.896, Val loss 1.771\n",
      "Ep 1 (Step 063720): Train loss 1.616, Val loss 1.773\n",
      "Ep 1 (Step 063725): Train loss 1.989, Val loss 1.775\n",
      "Ep 1 (Step 063730): Train loss 1.618, Val loss 1.767\n",
      "Ep 1 (Step 063735): Train loss 1.740, Val loss 1.751\n",
      "Ep 1 (Step 063740): Train loss 1.895, Val loss 1.749\n",
      "Ep 1 (Step 063745): Train loss 2.064, Val loss 1.743\n",
      "Ep 1 (Step 063750): Train loss 1.827, Val loss 1.744\n",
      "Ep 1 (Step 063755): Train loss 1.643, Val loss 1.752\n",
      "Ep 1 (Step 063760): Train loss 1.680, Val loss 1.760\n",
      "Ep 1 (Step 063765): Train loss 1.627, Val loss 1.768\n",
      "Ep 1 (Step 063770): Train loss 1.920, Val loss 1.766\n",
      "Ep 1 (Step 063775): Train loss 1.779, Val loss 1.763\n",
      "Ep 1 (Step 063780): Train loss 2.098, Val loss 1.762\n",
      "Ep 1 (Step 063785): Train loss 1.659, Val loss 1.774\n",
      "Ep 1 (Step 063790): Train loss 1.681, Val loss 1.779\n",
      "Ep 1 (Step 063795): Train loss 1.779, Val loss 1.769\n",
      "Ep 1 (Step 063800): Train loss 1.661, Val loss 1.760\n",
      "Ep 1 (Step 063805): Train loss 1.711, Val loss 1.761\n",
      "Ep 1 (Step 063810): Train loss 1.927, Val loss 1.767\n",
      "Ep 1 (Step 063815): Train loss 1.841, Val loss 1.777\n",
      "Ep 1 (Step 063820): Train loss 1.704, Val loss 1.778\n",
      "Ep 1 (Step 063825): Train loss 1.724, Val loss 1.773\n",
      "Ep 1 (Step 063830): Train loss 1.840, Val loss 1.760\n",
      "Ep 1 (Step 063835): Train loss 1.719, Val loss 1.749\n",
      "Ep 1 (Step 063840): Train loss 1.406, Val loss 1.749\n",
      "Ep 1 (Step 063845): Train loss 1.914, Val loss 1.740\n",
      "Ep 1 (Step 063850): Train loss 1.851, Val loss 1.743\n",
      "Ep 1 (Step 063855): Train loss 1.953, Val loss 1.752\n",
      "Ep 1 (Step 063860): Train loss 2.029, Val loss 1.751\n",
      "Ep 1 (Step 063865): Train loss 2.085, Val loss 1.750\n",
      "Ep 1 (Step 063870): Train loss 1.691, Val loss 1.763\n",
      "Ep 1 (Step 063875): Train loss 1.626, Val loss 1.766\n",
      "Ep 1 (Step 063880): Train loss 2.078, Val loss 1.764\n",
      "Ep 1 (Step 063885): Train loss 2.496, Val loss 1.767\n",
      "Ep 1 (Step 063890): Train loss 1.714, Val loss 1.761\n",
      "Ep 1 (Step 063895): Train loss 1.720, Val loss 1.764\n",
      "Ep 1 (Step 063900): Train loss 1.740, Val loss 1.765\n",
      "Ep 1 (Step 063905): Train loss 1.827, Val loss 1.764\n",
      "Ep 1 (Step 063910): Train loss 1.736, Val loss 1.769\n",
      "Ep 1 (Step 063915): Train loss 1.768, Val loss 1.764\n",
      "Ep 1 (Step 063920): Train loss 1.644, Val loss 1.755\n",
      "Ep 1 (Step 063925): Train loss 1.661, Val loss 1.749\n",
      "Ep 1 (Step 063930): Train loss 1.597, Val loss 1.749\n",
      "Ep 1 (Step 063935): Train loss 2.161, Val loss 1.750\n",
      "Ep 1 (Step 063940): Train loss 1.991, Val loss 1.750\n",
      "Ep 1 (Step 063945): Train loss 2.134, Val loss 1.757\n",
      "Ep 1 (Step 063950): Train loss 1.849, Val loss 1.761\n",
      "Ep 1 (Step 063955): Train loss 1.872, Val loss 1.761\n",
      "Ep 1 (Step 063960): Train loss 1.718, Val loss 1.763\n",
      "Ep 1 (Step 063965): Train loss 1.884, Val loss 1.769\n",
      "Ep 1 (Step 063970): Train loss 2.000, Val loss 1.776\n",
      "Ep 1 (Step 063975): Train loss 1.724, Val loss 1.778\n",
      "Ep 1 (Step 063980): Train loss 2.110, Val loss 1.772\n",
      "Ep 1 (Step 063985): Train loss 1.810, Val loss 1.765\n",
      "Ep 1 (Step 063990): Train loss 1.851, Val loss 1.761\n",
      "Ep 1 (Step 063995): Train loss 1.763, Val loss 1.764\n",
      "Ep 1 (Step 064000): Train loss 1.961, Val loss 1.767\n",
      "Ep 1 (Step 064005): Train loss 1.843, Val loss 1.772\n",
      "Ep 1 (Step 064010): Train loss 1.562, Val loss 1.773\n",
      "Ep 1 (Step 064015): Train loss 1.935, Val loss 1.773\n",
      "Ep 1 (Step 064020): Train loss 1.524, Val loss 1.774\n",
      "Ep 1 (Step 064025): Train loss 1.663, Val loss 1.770\n",
      "Ep 1 (Step 064030): Train loss 1.921, Val loss 1.768\n",
      "Ep 1 (Step 064035): Train loss 1.664, Val loss 1.773\n",
      "Ep 1 (Step 064040): Train loss 1.554, Val loss 1.773\n",
      "Ep 1 (Step 064045): Train loss 1.749, Val loss 1.768\n",
      "Ep 1 (Step 064050): Train loss 2.205, Val loss 1.764\n",
      "Ep 1 (Step 064055): Train loss 1.956, Val loss 1.770\n",
      "Ep 1 (Step 064060): Train loss 2.004, Val loss 1.776\n",
      "Ep 1 (Step 064065): Train loss 1.828, Val loss 1.777\n",
      "Ep 1 (Step 064070): Train loss 1.764, Val loss 1.770\n",
      "Ep 1 (Step 064075): Train loss 2.099, Val loss 1.767\n",
      "Ep 1 (Step 064080): Train loss 1.700, Val loss 1.771\n",
      "Ep 1 (Step 064085): Train loss 1.844, Val loss 1.783\n",
      "Ep 1 (Step 064090): Train loss 1.750, Val loss 1.777\n",
      "Ep 1 (Step 064095): Train loss 1.770, Val loss 1.769\n",
      "Ep 1 (Step 064100): Train loss 1.987, Val loss 1.773\n",
      "Ep 1 (Step 064105): Train loss 1.603, Val loss 1.775\n",
      "Ep 1 (Step 064110): Train loss 1.726, Val loss 1.783\n",
      "Ep 1 (Step 064115): Train loss 1.947, Val loss 1.780\n",
      "Ep 1 (Step 064120): Train loss 1.882, Val loss 1.775\n",
      "Ep 1 (Step 064125): Train loss 1.638, Val loss 1.766\n",
      "Ep 1 (Step 064130): Train loss 1.659, Val loss 1.769\n",
      "Ep 1 (Step 064135): Train loss 1.473, Val loss 1.765\n",
      "Ep 1 (Step 064140): Train loss 1.777, Val loss 1.762\n",
      "Ep 1 (Step 064145): Train loss 1.614, Val loss 1.756\n",
      "Ep 1 (Step 064150): Train loss 1.659, Val loss 1.757\n",
      "Ep 1 (Step 064155): Train loss 1.791, Val loss 1.758\n",
      "Ep 1 (Step 064160): Train loss 1.577, Val loss 1.752\n",
      "Ep 1 (Step 064165): Train loss 1.871, Val loss 1.749\n",
      "Ep 1 (Step 064170): Train loss 1.754, Val loss 1.759\n",
      "Ep 1 (Step 064175): Train loss 1.496, Val loss 1.752\n",
      "Ep 1 (Step 064180): Train loss 1.641, Val loss 1.751\n",
      "Ep 1 (Step 064185): Train loss 2.028, Val loss 1.756\n",
      "Ep 1 (Step 064190): Train loss 1.677, Val loss 1.754\n",
      "Ep 1 (Step 064195): Train loss 1.883, Val loss 1.762\n",
      "Ep 1 (Step 064200): Train loss 1.707, Val loss 1.760\n",
      "Ep 1 (Step 064205): Train loss 1.743, Val loss 1.755\n",
      "Ep 1 (Step 064210): Train loss 1.947, Val loss 1.754\n",
      "Ep 1 (Step 064215): Train loss 1.667, Val loss 1.754\n",
      "Ep 1 (Step 064220): Train loss 1.660, Val loss 1.755\n",
      "Ep 1 (Step 064225): Train loss 1.707, Val loss 1.743\n",
      "Ep 1 (Step 064230): Train loss 1.391, Val loss 1.744\n",
      "Ep 1 (Step 064235): Train loss 1.726, Val loss 1.754\n",
      "Ep 1 (Step 064240): Train loss 1.813, Val loss 1.757\n",
      "Ep 1 (Step 064245): Train loss 1.956, Val loss 1.766\n",
      "Ep 1 (Step 064250): Train loss 1.947, Val loss 1.766\n",
      "Ep 1 (Step 064255): Train loss 1.558, Val loss 1.763\n",
      "Ep 1 (Step 064260): Train loss 1.950, Val loss 1.749\n",
      "Ep 1 (Step 064265): Train loss 1.672, Val loss 1.745\n",
      "Ep 1 (Step 064270): Train loss 2.057, Val loss 1.752\n",
      "Ep 1 (Step 064275): Train loss 1.845, Val loss 1.758\n",
      "Ep 1 (Step 064280): Train loss 2.069, Val loss 1.770\n",
      "Ep 1 (Step 064285): Train loss 1.560, Val loss 1.776\n",
      "Ep 1 (Step 064290): Train loss 1.773, Val loss 1.767\n",
      "Ep 1 (Step 064295): Train loss 1.789, Val loss 1.756\n",
      "Ep 1 (Step 064300): Train loss 2.031, Val loss 1.742\n",
      "Ep 1 (Step 064305): Train loss 1.756, Val loss 1.743\n",
      "Ep 1 (Step 064310): Train loss 1.881, Val loss 1.740\n",
      "Ep 1 (Step 064315): Train loss 1.740, Val loss 1.742\n",
      "Ep 1 (Step 064320): Train loss 1.985, Val loss 1.743\n",
      "Ep 1 (Step 064325): Train loss 1.556, Val loss 1.741\n",
      "Ep 1 (Step 064330): Train loss 1.838, Val loss 1.745\n",
      "Ep 1 (Step 064335): Train loss 1.853, Val loss 1.748\n",
      "Ep 1 (Step 064340): Train loss 2.053, Val loss 1.756\n",
      "Ep 1 (Step 064345): Train loss 1.477, Val loss 1.754\n",
      "Ep 1 (Step 064350): Train loss 1.670, Val loss 1.758\n",
      "Ep 1 (Step 064355): Train loss 1.755, Val loss 1.771\n",
      "Ep 1 (Step 064360): Train loss 1.889, Val loss 1.768\n",
      "Ep 1 (Step 064365): Train loss 1.924, Val loss 1.752\n",
      "Ep 1 (Step 064370): Train loss 1.663, Val loss 1.754\n",
      "Ep 1 (Step 064375): Train loss 1.839, Val loss 1.767\n",
      "Ep 1 (Step 064380): Train loss 1.724, Val loss 1.774\n",
      "Ep 1 (Step 064385): Train loss 1.655, Val loss 1.775\n",
      "Ep 1 (Step 064390): Train loss 1.707, Val loss 1.767\n",
      "Ep 1 (Step 064395): Train loss 1.735, Val loss 1.763\n",
      "Ep 1 (Step 064400): Train loss 2.086, Val loss 1.757\n",
      "Ep 1 (Step 064405): Train loss 1.761, Val loss 1.752\n",
      "Ep 1 (Step 064410): Train loss 1.716, Val loss 1.738\n",
      "Ep 1 (Step 064415): Train loss 1.982, Val loss 1.737\n",
      "Ep 1 (Step 064420): Train loss 1.817, Val loss 1.727\n",
      "Ep 1 (Step 064425): Train loss 1.795, Val loss 1.728\n",
      "Ep 1 (Step 064430): Train loss 1.667, Val loss 1.732\n",
      "Ep 1 (Step 064435): Train loss 1.560, Val loss 1.750\n",
      "Ep 1 (Step 064440): Train loss 1.994, Val loss 1.762\n",
      "Ep 1 (Step 064445): Train loss 1.561, Val loss 1.748\n",
      "Ep 1 (Step 064450): Train loss 1.728, Val loss 1.743\n",
      "Ep 1 (Step 064455): Train loss 1.818, Val loss 1.740\n",
      "Ep 1 (Step 064460): Train loss 1.481, Val loss 1.738\n",
      "Ep 1 (Step 064465): Train loss 1.434, Val loss 1.734\n",
      "Ep 1 (Step 064470): Train loss 1.531, Val loss 1.737\n",
      "Ep 1 (Step 064475): Train loss 1.728, Val loss 1.742\n",
      "Ep 1 (Step 064480): Train loss 1.759, Val loss 1.761\n",
      "Ep 1 (Step 064485): Train loss 1.938, Val loss 1.758\n",
      "Ep 1 (Step 064490): Train loss 1.670, Val loss 1.755\n",
      "Ep 1 (Step 064495): Train loss 1.909, Val loss 1.745\n",
      "Ep 1 (Step 064500): Train loss 1.665, Val loss 1.742\n",
      "Ep 1 (Step 064505): Train loss 1.638, Val loss 1.737\n",
      "Ep 1 (Step 064510): Train loss 1.471, Val loss 1.734\n",
      "Ep 1 (Step 064515): Train loss 1.771, Val loss 1.734\n",
      "Ep 1 (Step 064520): Train loss 1.502, Val loss 1.730\n",
      "Ep 1 (Step 064525): Train loss 1.867, Val loss 1.728\n",
      "Ep 1 (Step 064530): Train loss 1.848, Val loss 1.735\n",
      "Ep 1 (Step 064535): Train loss 1.606, Val loss 1.736\n",
      "Ep 1 (Step 064540): Train loss 1.815, Val loss 1.724\n",
      "Ep 1 (Step 064545): Train loss 1.943, Val loss 1.715\n",
      "Ep 1 (Step 064550): Train loss 1.786, Val loss 1.721\n",
      "Ep 1 (Step 064555): Train loss 1.847, Val loss 1.717\n",
      "Ep 1 (Step 064560): Train loss 1.913, Val loss 1.711\n",
      "Ep 1 (Step 064565): Train loss 2.080, Val loss 1.712\n",
      "Ep 1 (Step 064570): Train loss 2.026, Val loss 1.756\n",
      "Ep 1 (Step 064575): Train loss 2.067, Val loss 1.734\n",
      "Ep 1 (Step 064580): Train loss 1.738, Val loss 1.734\n",
      "Ep 1 (Step 064585): Train loss 2.154, Val loss 1.736\n",
      "Ep 1 (Step 064590): Train loss 1.933, Val loss 1.739\n",
      "Ep 1 (Step 064595): Train loss 1.526, Val loss 1.733\n",
      "Ep 1 (Step 064600): Train loss 1.435, Val loss 1.739\n",
      "Ep 1 (Step 064605): Train loss 1.645, Val loss 1.739\n",
      "Ep 1 (Step 064610): Train loss 1.677, Val loss 1.734\n",
      "Ep 1 (Step 064615): Train loss 1.505, Val loss 1.735\n",
      "Ep 1 (Step 064620): Train loss 1.759, Val loss 1.732\n",
      "Ep 1 (Step 064625): Train loss 1.927, Val loss 1.737\n",
      "Ep 1 (Step 064630): Train loss 1.724, Val loss 1.752\n",
      "Ep 1 (Step 064635): Train loss 1.812, Val loss 1.747\n",
      "Ep 1 (Step 064640): Train loss 1.961, Val loss 1.746\n",
      "Ep 1 (Step 064645): Train loss 2.161, Val loss 1.749\n",
      "Ep 1 (Step 064650): Train loss 1.741, Val loss 1.750\n",
      "Ep 1 (Step 064655): Train loss 1.740, Val loss 1.750\n",
      "Ep 1 (Step 064660): Train loss 1.833, Val loss 1.750\n",
      "Ep 1 (Step 064665): Train loss 1.536, Val loss 1.750\n",
      "Ep 1 (Step 064670): Train loss 1.938, Val loss 1.752\n",
      "Ep 1 (Step 064675): Train loss 1.656, Val loss 1.747\n",
      "Ep 1 (Step 064680): Train loss 1.833, Val loss 1.740\n",
      "Ep 1 (Step 064685): Train loss 1.917, Val loss 1.742\n",
      "Ep 1 (Step 064690): Train loss 1.600, Val loss 1.740\n",
      "Ep 1 (Step 064695): Train loss 1.796, Val loss 1.736\n",
      "Ep 1 (Step 064700): Train loss 1.842, Val loss 1.721\n",
      "Ep 1 (Step 064705): Train loss 1.620, Val loss 1.722\n",
      "Ep 1 (Step 064710): Train loss 1.858, Val loss 1.729\n",
      "Ep 1 (Step 064715): Train loss 1.845, Val loss 1.740\n",
      "Ep 1 (Step 064720): Train loss 1.910, Val loss 1.748\n",
      "Ep 1 (Step 064725): Train loss 1.811, Val loss 1.754\n",
      "Ep 1 (Step 064730): Train loss 1.663, Val loss 1.756\n",
      "Ep 1 (Step 064735): Train loss 1.727, Val loss 1.760\n",
      "Ep 1 (Step 064740): Train loss 1.618, Val loss 1.759\n",
      "Ep 1 (Step 064745): Train loss 1.584, Val loss 1.752\n",
      "Ep 1 (Step 064750): Train loss 1.724, Val loss 1.745\n",
      "Ep 1 (Step 064755): Train loss 1.849, Val loss 1.747\n",
      "Ep 1 (Step 064760): Train loss 1.869, Val loss 1.755\n",
      "Ep 1 (Step 064765): Train loss 1.876, Val loss 1.761\n",
      "Ep 1 (Step 064770): Train loss 1.659, Val loss 1.764\n",
      "Ep 1 (Step 064775): Train loss 1.594, Val loss 1.766\n",
      "Ep 1 (Step 064780): Train loss 1.516, Val loss 1.756\n",
      "Ep 1 (Step 064785): Train loss 1.637, Val loss 1.752\n",
      "Ep 1 (Step 064790): Train loss 1.647, Val loss 1.755\n",
      "Ep 1 (Step 064795): Train loss 1.937, Val loss 1.758\n",
      "Ep 1 (Step 064800): Train loss 1.690, Val loss 1.768\n",
      "Ep 1 (Step 064805): Train loss 1.871, Val loss 1.767\n",
      "Ep 1 (Step 064810): Train loss 2.057, Val loss 1.771\n",
      "Ep 1 (Step 064815): Train loss 1.790, Val loss 1.768\n",
      "Ep 1 (Step 064820): Train loss 1.697, Val loss 1.767\n",
      "Ep 1 (Step 064825): Train loss 1.789, Val loss 1.767\n",
      "Ep 1 (Step 064830): Train loss 1.701, Val loss 1.758\n",
      "Ep 1 (Step 064835): Train loss 1.898, Val loss 1.757\n",
      "Ep 1 (Step 064840): Train loss 1.787, Val loss 1.758\n",
      "Ep 1 (Step 064845): Train loss 1.731, Val loss 1.754\n",
      "Ep 1 (Step 064850): Train loss 1.830, Val loss 1.756\n",
      "Ep 1 (Step 064855): Train loss 1.980, Val loss 1.754\n",
      "Ep 1 (Step 064860): Train loss 1.874, Val loss 1.754\n",
      "Ep 1 (Step 064865): Train loss 1.732, Val loss 1.759\n",
      "Ep 1 (Step 064870): Train loss 1.996, Val loss 1.758\n",
      "Ep 1 (Step 064875): Train loss 1.808, Val loss 1.756\n",
      "Ep 1 (Step 064880): Train loss 1.758, Val loss 1.759\n",
      "Ep 1 (Step 064885): Train loss 1.574, Val loss 1.755\n",
      "Ep 1 (Step 064890): Train loss 2.058, Val loss 1.746\n",
      "Ep 1 (Step 064895): Train loss 1.857, Val loss 1.740\n",
      "Ep 1 (Step 064900): Train loss 2.164, Val loss 1.742\n",
      "Ep 1 (Step 064905): Train loss 1.813, Val loss 1.749\n",
      "Ep 1 (Step 064910): Train loss 1.768, Val loss 1.756\n",
      "Ep 1 (Step 064915): Train loss 2.080, Val loss 1.755\n",
      "Ep 1 (Step 064920): Train loss 1.903, Val loss 1.752\n",
      "Ep 1 (Step 064925): Train loss 1.722, Val loss 1.762\n",
      "Ep 1 (Step 064930): Train loss 1.638, Val loss 1.762\n",
      "Ep 1 (Step 064935): Train loss 1.631, Val loss 1.767\n",
      "Ep 1 (Step 064940): Train loss 1.823, Val loss 1.758\n",
      "Ep 1 (Step 064945): Train loss 2.007, Val loss 1.747\n",
      "Ep 1 (Step 064950): Train loss 1.592, Val loss 1.746\n",
      "Ep 1 (Step 064955): Train loss 1.788, Val loss 1.740\n",
      "Ep 1 (Step 064960): Train loss 1.591, Val loss 1.734\n",
      "Ep 1 (Step 064965): Train loss 1.695, Val loss 1.734\n",
      "Ep 1 (Step 064970): Train loss 1.810, Val loss 1.739\n",
      "Ep 1 (Step 064975): Train loss 1.616, Val loss 1.745\n",
      "Ep 1 (Step 064980): Train loss 1.597, Val loss 1.749\n",
      "Ep 1 (Step 064985): Train loss 1.621, Val loss 1.759\n",
      "Ep 1 (Step 064990): Train loss 1.742, Val loss 1.763\n",
      "Ep 1 (Step 064995): Train loss 2.033, Val loss 1.776\n",
      "Ep 1 (Step 065000): Train loss 1.954, Val loss 1.787\n",
      "Ep 1 (Step 065005): Train loss 1.882, Val loss 1.781\n",
      "Ep 1 (Step 065010): Train loss 1.816, Val loss 1.790\n",
      "Ep 1 (Step 065015): Train loss 1.760, Val loss 1.770\n",
      "Ep 1 (Step 065020): Train loss 1.751, Val loss 1.759\n",
      "Ep 1 (Step 065025): Train loss 1.873, Val loss 1.755\n",
      "Ep 1 (Step 065030): Train loss 1.788, Val loss 1.748\n",
      "Ep 1 (Step 065035): Train loss 1.678, Val loss 1.749\n",
      "Ep 1 (Step 065040): Train loss 1.703, Val loss 1.750\n",
      "Ep 1 (Step 065045): Train loss 1.662, Val loss 1.744\n",
      "Ep 1 (Step 065050): Train loss 1.804, Val loss 1.745\n",
      "Ep 1 (Step 065055): Train loss 1.916, Val loss 1.747\n",
      "Ep 1 (Step 065060): Train loss 1.942, Val loss 1.757\n",
      "Ep 1 (Step 065065): Train loss 1.869, Val loss 1.760\n",
      "Ep 1 (Step 065070): Train loss 1.979, Val loss 1.756\n",
      "Ep 1 (Step 065075): Train loss 1.612, Val loss 1.757\n",
      "Ep 1 (Step 065080): Train loss 1.982, Val loss 1.747\n",
      "Ep 1 (Step 065085): Train loss 1.675, Val loss 1.749\n",
      "Ep 1 (Step 065090): Train loss 1.958, Val loss 1.757\n",
      "Ep 1 (Step 065095): Train loss 1.987, Val loss 1.764\n",
      "Ep 1 (Step 065100): Train loss 1.596, Val loss 1.763\n",
      "Ep 1 (Step 065105): Train loss 1.515, Val loss 1.767\n",
      "Ep 1 (Step 065110): Train loss 1.874, Val loss 1.777\n",
      "Ep 1 (Step 065115): Train loss 1.919, Val loss 1.783\n",
      "Ep 1 (Step 065120): Train loss 1.653, Val loss 1.785\n",
      "Ep 1 (Step 065125): Train loss 1.765, Val loss 1.784\n",
      "Ep 1 (Step 065130): Train loss 1.881, Val loss 1.780\n",
      "Ep 1 (Step 065135): Train loss 1.437, Val loss 1.776\n",
      "Ep 1 (Step 065140): Train loss 1.619, Val loss 1.772\n",
      "Ep 1 (Step 065145): Train loss 2.055, Val loss 1.778\n",
      "Ep 1 (Step 065150): Train loss 2.022, Val loss 1.797\n",
      "Ep 1 (Step 065155): Train loss 1.810, Val loss 1.782\n",
      "Ep 1 (Step 065160): Train loss 1.764, Val loss 1.776\n",
      "Ep 1 (Step 065165): Train loss 1.658, Val loss 1.777\n",
      "Ep 1 (Step 065170): Train loss 1.702, Val loss 1.779\n",
      "Ep 1 (Step 065175): Train loss 1.641, Val loss 1.772\n",
      "Ep 1 (Step 065180): Train loss 1.762, Val loss 1.762\n",
      "Ep 1 (Step 065185): Train loss 1.641, Val loss 1.756\n",
      "Ep 1 (Step 065190): Train loss 1.849, Val loss 1.759\n",
      "Ep 1 (Step 065195): Train loss 1.807, Val loss 1.767\n",
      "Ep 1 (Step 065200): Train loss 1.672, Val loss 1.771\n",
      "Ep 1 (Step 065205): Train loss 1.985, Val loss 1.769\n",
      "Ep 1 (Step 065210): Train loss 1.764, Val loss 1.772\n",
      "Ep 1 (Step 065215): Train loss 1.933, Val loss 1.771\n",
      "Ep 1 (Step 065220): Train loss 1.740, Val loss 1.764\n",
      "Ep 1 (Step 065225): Train loss 1.769, Val loss 1.766\n",
      "Ep 1 (Step 065230): Train loss 1.868, Val loss 1.766\n",
      "Ep 1 (Step 065235): Train loss 1.907, Val loss 1.762\n",
      "Ep 1 (Step 065240): Train loss 1.748, Val loss 1.756\n",
      "Ep 1 (Step 065245): Train loss 1.613, Val loss 1.748\n",
      "Ep 1 (Step 065250): Train loss 2.082, Val loss 1.753\n",
      "Ep 1 (Step 065255): Train loss 2.152, Val loss 1.751\n",
      "Ep 1 (Step 065260): Train loss 1.959, Val loss 1.751\n",
      "Ep 1 (Step 065265): Train loss 2.050, Val loss 1.753\n",
      "Ep 1 (Step 065270): Train loss 1.850, Val loss 1.756\n",
      "Ep 1 (Step 065275): Train loss 1.639, Val loss 1.756\n",
      "Ep 1 (Step 065280): Train loss 1.807, Val loss 1.747\n",
      "Ep 1 (Step 065285): Train loss 1.761, Val loss 1.744\n",
      "Ep 1 (Step 065290): Train loss 1.774, Val loss 1.746\n",
      "Ep 1 (Step 065295): Train loss 1.843, Val loss 1.748\n",
      "Ep 1 (Step 065300): Train loss 1.731, Val loss 1.748\n",
      "Ep 1 (Step 065305): Train loss 1.662, Val loss 1.753\n",
      "Ep 1 (Step 065310): Train loss 1.756, Val loss 1.761\n",
      "Ep 1 (Step 065315): Train loss 1.804, Val loss 1.759\n",
      "Ep 1 (Step 065320): Train loss 1.818, Val loss 1.756\n",
      "Ep 1 (Step 065325): Train loss 1.735, Val loss 1.755\n",
      "Ep 1 (Step 065330): Train loss 1.833, Val loss 1.751\n",
      "Ep 1 (Step 065335): Train loss 1.689, Val loss 1.752\n",
      "Ep 1 (Step 065340): Train loss 1.643, Val loss 1.749\n",
      "Ep 1 (Step 065345): Train loss 1.679, Val loss 1.746\n",
      "Ep 1 (Step 065350): Train loss 1.802, Val loss 1.752\n",
      "Ep 1 (Step 065355): Train loss 1.705, Val loss 1.754\n",
      "Ep 1 (Step 065360): Train loss 1.626, Val loss 1.750\n",
      "Ep 1 (Step 065365): Train loss 1.981, Val loss 1.744\n",
      "Ep 1 (Step 065370): Train loss 1.594, Val loss 1.746\n",
      "Ep 1 (Step 065375): Train loss 1.638, Val loss 1.754\n",
      "Ep 1 (Step 065380): Train loss 1.563, Val loss 1.760\n",
      "Ep 1 (Step 065385): Train loss 1.537, Val loss 1.760\n",
      "Ep 1 (Step 065390): Train loss 1.898, Val loss 1.760\n",
      "Ep 1 (Step 065395): Train loss 1.763, Val loss 1.762\n",
      "Ep 1 (Step 065400): Train loss 1.979, Val loss 1.764\n",
      "Ep 1 (Step 065405): Train loss 1.736, Val loss 1.774\n",
      "Ep 1 (Step 065410): Train loss 1.703, Val loss 1.763\n",
      "Ep 1 (Step 065415): Train loss 1.709, Val loss 1.753\n",
      "Ep 1 (Step 065420): Train loss 1.570, Val loss 1.748\n",
      "Ep 1 (Step 065425): Train loss 1.950, Val loss 1.744\n",
      "Ep 1 (Step 065430): Train loss 1.700, Val loss 1.749\n",
      "Ep 1 (Step 065435): Train loss 1.702, Val loss 1.744\n",
      "Ep 1 (Step 065440): Train loss 1.507, Val loss 1.746\n",
      "Ep 1 (Step 065445): Train loss 1.956, Val loss 1.746\n",
      "Ep 1 (Step 065450): Train loss 1.824, Val loss 1.753\n",
      "Ep 1 (Step 065455): Train loss 1.678, Val loss 1.757\n",
      "Ep 1 (Step 065460): Train loss 1.421, Val loss 1.750\n",
      "Ep 1 (Step 065465): Train loss 1.566, Val loss 1.746\n",
      "Ep 1 (Step 065470): Train loss 1.970, Val loss 1.749\n",
      "Ep 1 (Step 065475): Train loss 1.759, Val loss 1.751\n",
      "Ep 1 (Step 065480): Train loss 1.642, Val loss 1.748\n",
      "Ep 1 (Step 065485): Train loss 1.782, Val loss 1.748\n",
      "Ep 1 (Step 065490): Train loss 2.005, Val loss 1.754\n",
      "Ep 1 (Step 065495): Train loss 1.658, Val loss 1.756\n",
      "Ep 1 (Step 065500): Train loss 1.727, Val loss 1.746\n",
      "Ep 1 (Step 065505): Train loss 1.744, Val loss 1.744\n",
      "Ep 1 (Step 065510): Train loss 1.865, Val loss 1.745\n",
      "Ep 1 (Step 065515): Train loss 1.803, Val loss 1.753\n",
      "Ep 1 (Step 065520): Train loss 1.847, Val loss 1.741\n",
      "Ep 1 (Step 065525): Train loss 1.742, Val loss 1.737\n",
      "Ep 1 (Step 065530): Train loss 1.722, Val loss 1.738\n",
      "Ep 1 (Step 065535): Train loss 2.009, Val loss 1.747\n",
      "Ep 1 (Step 065540): Train loss 1.685, Val loss 1.749\n",
      "Ep 1 (Step 065545): Train loss 1.906, Val loss 1.752\n",
      "Ep 1 (Step 065550): Train loss 1.920, Val loss 1.757\n",
      "Ep 1 (Step 065555): Train loss 1.770, Val loss 1.757\n",
      "Ep 1 (Step 065560): Train loss 1.727, Val loss 1.756\n",
      "Ep 1 (Step 065565): Train loss 1.588, Val loss 1.762\n",
      "Ep 1 (Step 065570): Train loss 1.703, Val loss 1.761\n",
      "Ep 1 (Step 065575): Train loss 1.627, Val loss 1.745\n",
      "Ep 1 (Step 065580): Train loss 2.102, Val loss 1.746\n",
      "Ep 1 (Step 065585): Train loss 1.654, Val loss 1.747\n",
      "Ep 1 (Step 065590): Train loss 1.887, Val loss 1.739\n",
      "Ep 1 (Step 065595): Train loss 1.975, Val loss 1.740\n",
      "Ep 1 (Step 065600): Train loss 1.806, Val loss 1.741\n",
      "Ep 1 (Step 065605): Train loss 1.855, Val loss 1.741\n",
      "Ep 1 (Step 065610): Train loss 1.983, Val loss 1.744\n",
      "Ep 1 (Step 065615): Train loss 2.001, Val loss 1.749\n",
      "Ep 1 (Step 065620): Train loss 1.694, Val loss 1.757\n",
      "Ep 1 (Step 065625): Train loss 1.935, Val loss 1.762\n",
      "Ep 1 (Step 065630): Train loss 1.822, Val loss 1.752\n",
      "Ep 1 (Step 065635): Train loss 1.474, Val loss 1.747\n",
      "Ep 1 (Step 065640): Train loss 1.709, Val loss 1.747\n",
      "Ep 1 (Step 065645): Train loss 1.818, Val loss 1.746\n",
      "Ep 1 (Step 065650): Train loss 1.978, Val loss 1.754\n",
      "Ep 1 (Step 065655): Train loss 1.926, Val loss 1.750\n",
      "Ep 1 (Step 065660): Train loss 1.727, Val loss 1.748\n",
      "Ep 1 (Step 065665): Train loss 1.726, Val loss 1.753\n",
      "Ep 1 (Step 065670): Train loss 1.728, Val loss 1.745\n",
      "Ep 1 (Step 065675): Train loss 1.793, Val loss 1.746\n",
      "Ep 1 (Step 065680): Train loss 1.752, Val loss 1.748\n",
      "Ep 1 (Step 065685): Train loss 1.645, Val loss 1.750\n",
      "Ep 1 (Step 065690): Train loss 1.835, Val loss 1.758\n",
      "Ep 1 (Step 065695): Train loss 1.856, Val loss 1.751\n",
      "Ep 1 (Step 065700): Train loss 1.890, Val loss 1.751\n",
      "Ep 1 (Step 065705): Train loss 1.765, Val loss 1.753\n",
      "Ep 1 (Step 065710): Train loss 1.767, Val loss 1.740\n",
      "Ep 1 (Step 065715): Train loss 2.046, Val loss 1.730\n",
      "Ep 1 (Step 065720): Train loss 1.622, Val loss 1.721\n",
      "Ep 1 (Step 065725): Train loss 1.707, Val loss 1.725\n",
      "Ep 1 (Step 065730): Train loss 1.971, Val loss 1.732\n",
      "Ep 1 (Step 065735): Train loss 1.595, Val loss 1.734\n",
      "Ep 1 (Step 065740): Train loss 1.838, Val loss 1.737\n",
      "Ep 1 (Step 065745): Train loss 1.763, Val loss 1.736\n",
      "Ep 1 (Step 065750): Train loss 1.769, Val loss 1.741\n",
      "Ep 1 (Step 065755): Train loss 1.861, Val loss 1.740\n",
      "Ep 1 (Step 065760): Train loss 2.034, Val loss 1.738\n",
      "Ep 1 (Step 065765): Train loss 1.891, Val loss 1.734\n",
      "Ep 1 (Step 065770): Train loss 1.873, Val loss 1.734\n",
      "Ep 1 (Step 065775): Train loss 1.628, Val loss 1.743\n",
      "Ep 1 (Step 065780): Train loss 1.584, Val loss 1.744\n",
      "Ep 1 (Step 065785): Train loss 1.837, Val loss 1.746\n",
      "Ep 1 (Step 065790): Train loss 1.606, Val loss 1.751\n",
      "Ep 1 (Step 065795): Train loss 1.657, Val loss 1.749\n",
      "Ep 1 (Step 065800): Train loss 1.729, Val loss 1.747\n",
      "Ep 1 (Step 065805): Train loss 1.864, Val loss 1.740\n",
      "Ep 1 (Step 065810): Train loss 2.017, Val loss 1.749\n",
      "Ep 1 (Step 065815): Train loss 1.995, Val loss 1.753\n",
      "Ep 1 (Step 065820): Train loss 1.789, Val loss 1.742\n",
      "Ep 1 (Step 065825): Train loss 2.112, Val loss 1.735\n",
      "Ep 1 (Step 065830): Train loss 2.045, Val loss 1.734\n",
      "Ep 1 (Step 065835): Train loss 1.617, Val loss 1.751\n",
      "Ep 1 (Step 065840): Train loss 1.715, Val loss 1.748\n",
      "Ep 1 (Step 065845): Train loss 1.655, Val loss 1.746\n",
      "Ep 1 (Step 065850): Train loss 1.467, Val loss 1.747\n",
      "Ep 1 (Step 065855): Train loss 2.038, Val loss 1.739\n",
      "Ep 1 (Step 065860): Train loss 1.966, Val loss 1.740\n",
      "Ep 1 (Step 065865): Train loss 1.855, Val loss 1.737\n",
      "Ep 1 (Step 065870): Train loss 1.571, Val loss 1.732\n",
      "Ep 1 (Step 065875): Train loss 1.680, Val loss 1.740\n",
      "Ep 1 (Step 065880): Train loss 1.688, Val loss 1.747\n",
      "Ep 1 (Step 065885): Train loss 1.773, Val loss 1.744\n",
      "Ep 1 (Step 065890): Train loss 1.788, Val loss 1.737\n",
      "Ep 1 (Step 065895): Train loss 1.527, Val loss 1.742\n",
      "Ep 1 (Step 065900): Train loss 1.785, Val loss 1.743\n",
      "Ep 1 (Step 065905): Train loss 1.528, Val loss 1.737\n",
      "Ep 1 (Step 065910): Train loss 1.592, Val loss 1.731\n",
      "Ep 1 (Step 065915): Train loss 1.714, Val loss 1.734\n",
      "Ep 1 (Step 065920): Train loss 1.732, Val loss 1.743\n",
      "Ep 1 (Step 065925): Train loss 1.648, Val loss 1.736\n",
      "Ep 1 (Step 065930): Train loss 1.810, Val loss 1.732\n",
      "Ep 1 (Step 065935): Train loss 1.911, Val loss 1.736\n",
      "Ep 1 (Step 065940): Train loss 1.682, Val loss 1.738\n",
      "Ep 1 (Step 065945): Train loss 1.595, Val loss 1.740\n",
      "Ep 1 (Step 065950): Train loss 1.636, Val loss 1.735\n",
      "Ep 1 (Step 065955): Train loss 1.928, Val loss 1.735\n",
      "Ep 1 (Step 065960): Train loss 1.817, Val loss 1.736\n",
      "Ep 1 (Step 065965): Train loss 1.727, Val loss 1.753\n",
      "Ep 1 (Step 065970): Train loss 1.860, Val loss 1.759\n",
      "Ep 1 (Step 065975): Train loss 1.771, Val loss 1.749\n",
      "Ep 1 (Step 065980): Train loss 2.051, Val loss 1.738\n",
      "Ep 1 (Step 065985): Train loss 1.909, Val loss 1.733\n",
      "Ep 1 (Step 065990): Train loss 1.811, Val loss 1.746\n",
      "Ep 1 (Step 065995): Train loss 1.629, Val loss 1.754\n",
      "Ep 1 (Step 066000): Train loss 1.705, Val loss 1.753\n",
      "Ep 1 (Step 066005): Train loss 1.592, Val loss 1.744\n",
      "Ep 1 (Step 066010): Train loss 1.644, Val loss 1.741\n",
      "Ep 1 (Step 066015): Train loss 1.567, Val loss 1.736\n",
      "Ep 1 (Step 066020): Train loss 1.910, Val loss 1.729\n",
      "Ep 1 (Step 066025): Train loss 1.580, Val loss 1.725\n",
      "Ep 1 (Step 066030): Train loss 1.849, Val loss 1.723\n",
      "Ep 1 (Step 066035): Train loss 1.725, Val loss 1.719\n",
      "Ep 1 (Step 066040): Train loss 1.714, Val loss 1.718\n",
      "Ep 1 (Step 066045): Train loss 2.055, Val loss 1.727\n",
      "Ep 1 (Step 066050): Train loss 1.717, Val loss 1.734\n",
      "Ep 1 (Step 066055): Train loss 1.877, Val loss 1.746\n",
      "Ep 1 (Step 066060): Train loss 1.958, Val loss 1.740\n",
      "Ep 1 (Step 066065): Train loss 1.951, Val loss 1.746\n",
      "Ep 1 (Step 066070): Train loss 1.726, Val loss 1.752\n",
      "Ep 1 (Step 066075): Train loss 1.721, Val loss 1.750\n",
      "Ep 1 (Step 066080): Train loss 1.688, Val loss 1.757\n",
      "Ep 1 (Step 066085): Train loss 1.994, Val loss 1.757\n",
      "Ep 1 (Step 066090): Train loss 1.678, Val loss 1.770\n",
      "Ep 1 (Step 066095): Train loss 1.716, Val loss 1.778\n",
      "Ep 1 (Step 066100): Train loss 1.508, Val loss 1.762\n",
      "Ep 1 (Step 066105): Train loss 1.865, Val loss 1.757\n",
      "Ep 1 (Step 066110): Train loss 1.722, Val loss 1.748\n",
      "Ep 1 (Step 066115): Train loss 1.708, Val loss 1.742\n",
      "Ep 1 (Step 066120): Train loss 1.940, Val loss 1.741\n",
      "Ep 1 (Step 066125): Train loss 1.790, Val loss 1.751\n",
      "Ep 1 (Step 066130): Train loss 1.718, Val loss 1.753\n",
      "Ep 1 (Step 066135): Train loss 1.681, Val loss 1.749\n",
      "Ep 1 (Step 066140): Train loss 1.910, Val loss 1.750\n",
      "Ep 1 (Step 066145): Train loss 1.857, Val loss 1.752\n",
      "Ep 1 (Step 066150): Train loss 1.752, Val loss 1.753\n",
      "Ep 1 (Step 066155): Train loss 1.805, Val loss 1.748\n",
      "Ep 1 (Step 066160): Train loss 1.818, Val loss 1.758\n",
      "Ep 1 (Step 066165): Train loss 1.785, Val loss 1.770\n",
      "Ep 1 (Step 066170): Train loss 1.924, Val loss 1.772\n",
      "Ep 1 (Step 066175): Train loss 2.071, Val loss 1.763\n",
      "Ep 1 (Step 066180): Train loss 1.739, Val loss 1.761\n",
      "Ep 1 (Step 066185): Train loss 1.919, Val loss 1.765\n",
      "Ep 1 (Step 066190): Train loss 1.871, Val loss 1.756\n",
      "Ep 1 (Step 066195): Train loss 1.710, Val loss 1.759\n",
      "Ep 1 (Step 066200): Train loss 2.024, Val loss 1.757\n",
      "Ep 1 (Step 066205): Train loss 1.775, Val loss 1.750\n",
      "Ep 1 (Step 066210): Train loss 1.797, Val loss 1.752\n",
      "Ep 1 (Step 066215): Train loss 1.600, Val loss 1.752\n",
      "Ep 1 (Step 066220): Train loss 1.537, Val loss 1.750\n",
      "Ep 1 (Step 066225): Train loss 1.836, Val loss 1.750\n",
      "Ep 1 (Step 066230): Train loss 1.599, Val loss 1.750\n",
      "Ep 1 (Step 066235): Train loss 1.600, Val loss 1.750\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0004\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     12\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 13\u001b[0m train_losses, val_losses, tokens_seen \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvery effort moves you\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Uncomment the following code to show the execution time\u001b[39;00m\n\u001b[0;32m     28\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[13], line 31\u001b[0m, in \u001b[0;36mtrain_model_simple\u001b[1;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Optional evaluation step\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 31\u001b[0m     train_loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     35\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[1;32mIn[13], line 51\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, train_loader, val_loader, device, eval_iter)\u001b[0m\n\u001b[0;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 51\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_loss_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_iter\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m calc_loss_loader(val_loader, model, device, num_batches\u001b[38;5;241m=\u001b[39meval_iter)\n\u001b[0;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m, in \u001b[0;36mcalc_loss_loader\u001b[1;34m(data_loader, model, device, num_batches)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Reduce the number of batches to match the total number of batches in the data loader\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# if num_batches exceeds the number of batches in the data loader\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(num_batches, \u001b[38;5;28mlen\u001b[39m(data_loader))\n\u001b[1;32m---> 20\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalc_loss_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:756\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:691\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\sampler.py:340\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msampler_iter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\sampler.py:340\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m         batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(sampler_iter) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)]\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\sampler.py:197\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n):\n\u001b[1;32m--> 197\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(n, generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()[\n\u001b[0;32m    199\u001b[0m         : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m%\u001b[39m n\n\u001b[0;32m    200\u001b[0m     ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aec432e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced1f1b",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7273582",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
